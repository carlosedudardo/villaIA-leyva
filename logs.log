2025-10-19 01:18:27,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 01:18:27,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 01:18:27,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 01:18:27,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 01:18:31,258:INFO:PyCaret ClassificationExperiment
2025-10-19 01:18:31,259:INFO:Logging name: clf-default-name
2025-10-19 01:18:31,259:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 01:18:31,259:INFO:version 3.3.2
2025-10-19 01:18:31,259:INFO:Initializing setup()
2025-10-19 01:18:31,259:INFO:self.USI: f35f
2025-10-19 01:18:31,259:INFO:self._variable_keys: {'USI', 'seed', 'memory', 'html_param', 'X_test', 'target_param', 'logging_param', 'fold_groups_param', 'exp_id', 'exp_name_log', 'fix_imbalance', 'is_multiclass', 'log_plots_param', 'y_train', 'y', 'X', 'fold_generator', 'fold_shuffle_param', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', '_available_plots', 'idx', 'data', 'pipeline', 'X_train', '_ml_usecase', 'y_test'}
2025-10-19 01:18:31,259:INFO:Checking environment
2025-10-19 01:18:31,259:INFO:python_version: 3.11.13
2025-10-19 01:18:31,259:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 01:18:31,259:INFO:machine: AMD64
2025-10-19 01:18:31,259:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 01:18:31,268:INFO:Memory: svmem(total=16856211456, available=1754570752, percent=89.6, used=15101640704, free=1754570752)
2025-10-19 01:18:31,268:INFO:Physical Core: 4
2025-10-19 01:18:31,268:INFO:Logical Core: 8
2025-10-19 01:18:31,268:INFO:Checking libraries
2025-10-19 01:18:31,268:INFO:System:
2025-10-19 01:18:31,268:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 01:18:31,268:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 01:18:31,268:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 01:18:31,268:INFO:PyCaret required dependencies:
2025-10-19 01:18:33,648:INFO:                 pip: 25.2
2025-10-19 01:18:33,648:INFO:          setuptools: 80.9.0
2025-10-19 01:18:33,648:INFO:             pycaret: 3.3.2
2025-10-19 01:18:33,648:INFO:             IPython: 9.6.0
2025-10-19 01:18:33,648:INFO:          ipywidgets: 8.1.7
2025-10-19 01:18:33,648:INFO:                tqdm: 4.67.1
2025-10-19 01:18:33,648:INFO:               numpy: 1.26.4
2025-10-19 01:18:33,648:INFO:              pandas: 2.1.4
2025-10-19 01:18:33,648:INFO:              jinja2: 3.1.6
2025-10-19 01:18:33,648:INFO:               scipy: 1.11.4
2025-10-19 01:18:33,648:INFO:              joblib: 1.3.2
2025-10-19 01:18:33,648:INFO:             sklearn: 1.4.2
2025-10-19 01:18:33,649:INFO:                pyod: 2.0.5
2025-10-19 01:18:33,649:INFO:            imblearn: 0.14.0
2025-10-19 01:18:33,649:INFO:   category_encoders: 2.7.0
2025-10-19 01:18:33,649:INFO:            lightgbm: 4.6.0
2025-10-19 01:18:33,649:INFO:               numba: 0.61.0
2025-10-19 01:18:33,649:INFO:            requests: 2.32.5
2025-10-19 01:18:33,649:INFO:          matplotlib: 3.7.5
2025-10-19 01:18:33,649:INFO:          scikitplot: 0.3.7
2025-10-19 01:18:33,649:INFO:         yellowbrick: 1.5
2025-10-19 01:18:33,649:INFO:              plotly: 5.24.1
2025-10-19 01:18:33,649:INFO:    plotly-resampler: Not installed
2025-10-19 01:18:33,649:INFO:             kaleido: 1.1.0
2025-10-19 01:18:33,649:INFO:           schemdraw: 0.15
2025-10-19 01:18:33,649:INFO:         statsmodels: 0.14.5
2025-10-19 01:18:33,649:INFO:              sktime: 0.26.0
2025-10-19 01:18:33,649:INFO:               tbats: 1.1.3
2025-10-19 01:18:33,649:INFO:            pmdarima: 2.0.4
2025-10-19 01:18:33,649:INFO:              psutil: 7.1.0
2025-10-19 01:18:33,649:INFO:          markupsafe: 3.0.3
2025-10-19 01:18:33,649:INFO:             pickle5: Not installed
2025-10-19 01:18:33,649:INFO:         cloudpickle: 3.1.1
2025-10-19 01:18:33,649:INFO:         deprecation: 2.1.0
2025-10-19 01:18:33,649:INFO:              xxhash: 3.6.0
2025-10-19 01:18:33,649:INFO:           wurlitzer: Not installed
2025-10-19 01:18:33,649:INFO:PyCaret optional dependencies:
2025-10-19 01:18:41,117:INFO:                shap: 0.44.1
2025-10-19 01:18:41,117:INFO:           interpret: 0.7.3
2025-10-19 01:18:41,118:INFO:                umap: 0.5.7
2025-10-19 01:18:41,118:INFO:     ydata_profiling: 4.17.0
2025-10-19 01:18:41,118:INFO:  explainerdashboard: 0.5.1
2025-10-19 01:18:41,118:INFO:             autoviz: Not installed
2025-10-19 01:18:41,118:INFO:           fairlearn: 0.7.0
2025-10-19 01:18:41,118:INFO:          deepchecks: Not installed
2025-10-19 01:18:41,118:INFO:             xgboost: Not installed
2025-10-19 01:18:41,118:INFO:            catboost: 1.2.8
2025-10-19 01:18:41,118:INFO:              kmodes: 0.12.2
2025-10-19 01:18:41,118:INFO:             mlxtend: 0.23.4
2025-10-19 01:18:41,118:INFO:       statsforecast: 1.5.0
2025-10-19 01:18:41,118:INFO:        tune_sklearn: Not installed
2025-10-19 01:18:41,118:INFO:                 ray: Not installed
2025-10-19 01:18:41,118:INFO:            hyperopt: 0.2.7
2025-10-19 01:18:41,118:INFO:              optuna: 4.5.0
2025-10-19 01:18:41,118:INFO:               skopt: 0.10.2
2025-10-19 01:18:41,118:INFO:              mlflow: 3.5.0
2025-10-19 01:18:41,118:INFO:              gradio: 5.49.1
2025-10-19 01:18:41,118:INFO:             fastapi: 0.119.0
2025-10-19 01:18:41,118:INFO:             uvicorn: 0.38.0
2025-10-19 01:18:41,118:INFO:              m2cgen: 0.10.0
2025-10-19 01:18:41,118:INFO:           evidently: 0.4.40
2025-10-19 01:18:41,119:INFO:               fugue: 0.8.7
2025-10-19 01:18:41,119:INFO:           streamlit: Not installed
2025-10-19 01:18:41,119:INFO:             prophet: Not installed
2025-10-19 01:18:41,119:INFO:None
2025-10-19 01:18:41,119:INFO:Set up data.
2025-10-19 01:18:41,291:INFO:Set up folding strategy.
2025-10-19 01:18:41,318:INFO:Set up train/test split.
2025-10-19 01:18:41,380:INFO:Set up index.
2025-10-19 01:18:41,387:INFO:Assigning column types.
2025-10-19 01:18:41,403:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 01:18:41,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 01:18:41,450:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:18:41,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:18:41,490:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:18:41,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 01:18:41,748:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:18:41,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:18:41,770:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:18:41,771:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 01:18:41,816:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:18:41,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:18:41,843:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:18:41,886:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:18:41,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:18:41,917:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:18:41,917:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 01:18:41,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:18:41,988:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:18:42,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:18:42,053:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:18:42,057:INFO:Preparing preprocessing pipeline...
2025-10-19 01:18:42,066:INFO:Set up simple imputation.
2025-10-19 01:18:42,084:INFO:Set up encoding of ordinal features.
2025-10-19 01:18:42,090:INFO:Set up encoding of categorical features.
2025-10-19 01:18:42,090:INFO:Set up removing multicollinearity.
2025-10-19 01:18:42,090:INFO:Set up imbalanced handling.
2025-10-19 01:18:42,092:INFO:Set up column name cleaning.
2025-10-19 01:26:22,044:INFO:PyCaret ClassificationExperiment
2025-10-19 01:26:22,044:INFO:Logging name: clf-default-name
2025-10-19 01:26:22,044:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 01:26:22,044:INFO:version 3.3.2
2025-10-19 01:26:22,045:INFO:Initializing setup()
2025-10-19 01:26:22,045:INFO:self.USI: 0b5f
2025-10-19 01:26:22,045:INFO:self._variable_keys: {'USI', 'seed', 'memory', 'html_param', 'X_test', 'target_param', 'logging_param', 'fold_groups_param', 'exp_id', 'exp_name_log', 'fix_imbalance', 'is_multiclass', 'log_plots_param', 'y_train', 'y', 'X', 'fold_generator', 'fold_shuffle_param', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', '_available_plots', 'idx', 'data', 'pipeline', 'X_train', '_ml_usecase', 'y_test'}
2025-10-19 01:26:22,045:INFO:Checking environment
2025-10-19 01:26:22,045:INFO:python_version: 3.11.13
2025-10-19 01:26:22,045:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 01:26:22,045:INFO:machine: AMD64
2025-10-19 01:26:22,045:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 01:26:22,054:INFO:Memory: svmem(total=16856211456, available=1873580032, percent=88.9, used=14982631424, free=1873580032)
2025-10-19 01:26:22,054:INFO:Physical Core: 4
2025-10-19 01:26:22,054:INFO:Logical Core: 8
2025-10-19 01:26:22,054:INFO:Checking libraries
2025-10-19 01:26:22,054:INFO:System:
2025-10-19 01:26:22,054:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 01:26:22,054:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 01:26:22,054:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 01:26:22,054:INFO:PyCaret required dependencies:
2025-10-19 01:26:22,054:INFO:                 pip: 25.2
2025-10-19 01:26:22,054:INFO:          setuptools: 80.9.0
2025-10-19 01:26:22,054:INFO:             pycaret: 3.3.2
2025-10-19 01:26:22,054:INFO:             IPython: 9.6.0
2025-10-19 01:26:22,055:INFO:          ipywidgets: 8.1.7
2025-10-19 01:26:22,055:INFO:                tqdm: 4.67.1
2025-10-19 01:26:22,055:INFO:               numpy: 1.26.4
2025-10-19 01:26:22,055:INFO:              pandas: 2.1.4
2025-10-19 01:26:22,055:INFO:              jinja2: 3.1.6
2025-10-19 01:26:22,055:INFO:               scipy: 1.11.4
2025-10-19 01:26:22,055:INFO:              joblib: 1.3.2
2025-10-19 01:26:22,055:INFO:             sklearn: 1.4.2
2025-10-19 01:26:22,055:INFO:                pyod: 2.0.5
2025-10-19 01:26:22,055:INFO:            imblearn: 0.14.0
2025-10-19 01:26:22,055:INFO:   category_encoders: 2.7.0
2025-10-19 01:26:22,055:INFO:            lightgbm: 4.6.0
2025-10-19 01:26:22,055:INFO:               numba: 0.61.0
2025-10-19 01:26:22,055:INFO:            requests: 2.32.5
2025-10-19 01:26:22,055:INFO:          matplotlib: 3.7.5
2025-10-19 01:26:22,055:INFO:          scikitplot: 0.3.7
2025-10-19 01:26:22,055:INFO:         yellowbrick: 1.5
2025-10-19 01:26:22,056:INFO:              plotly: 5.24.1
2025-10-19 01:26:22,056:INFO:    plotly-resampler: Not installed
2025-10-19 01:26:22,056:INFO:             kaleido: 1.1.0
2025-10-19 01:26:22,056:INFO:           schemdraw: 0.15
2025-10-19 01:26:22,056:INFO:         statsmodels: 0.14.5
2025-10-19 01:26:22,056:INFO:              sktime: 0.26.0
2025-10-19 01:26:22,056:INFO:               tbats: 1.1.3
2025-10-19 01:26:22,056:INFO:            pmdarima: 2.0.4
2025-10-19 01:26:22,056:INFO:              psutil: 7.1.0
2025-10-19 01:26:22,056:INFO:          markupsafe: 3.0.3
2025-10-19 01:26:22,056:INFO:             pickle5: Not installed
2025-10-19 01:26:22,056:INFO:         cloudpickle: 3.1.1
2025-10-19 01:26:22,056:INFO:         deprecation: 2.1.0
2025-10-19 01:26:22,056:INFO:              xxhash: 3.6.0
2025-10-19 01:26:22,056:INFO:           wurlitzer: Not installed
2025-10-19 01:26:22,056:INFO:PyCaret optional dependencies:
2025-10-19 01:26:22,056:INFO:                shap: 0.44.1
2025-10-19 01:26:22,056:INFO:           interpret: 0.7.3
2025-10-19 01:26:22,056:INFO:                umap: 0.5.7
2025-10-19 01:26:22,056:INFO:     ydata_profiling: 4.17.0
2025-10-19 01:26:22,056:INFO:  explainerdashboard: 0.5.1
2025-10-19 01:26:22,056:INFO:             autoviz: Not installed
2025-10-19 01:26:22,056:INFO:           fairlearn: 0.7.0
2025-10-19 01:26:22,056:INFO:          deepchecks: Not installed
2025-10-19 01:26:22,057:INFO:             xgboost: Not installed
2025-10-19 01:26:22,057:INFO:            catboost: 1.2.8
2025-10-19 01:26:22,057:INFO:              kmodes: 0.12.2
2025-10-19 01:26:22,057:INFO:             mlxtend: 0.23.4
2025-10-19 01:26:22,057:INFO:       statsforecast: 1.5.0
2025-10-19 01:26:22,057:INFO:        tune_sklearn: Not installed
2025-10-19 01:26:22,057:INFO:                 ray: Not installed
2025-10-19 01:26:22,057:INFO:            hyperopt: 0.2.7
2025-10-19 01:26:22,057:INFO:              optuna: 4.5.0
2025-10-19 01:26:22,057:INFO:               skopt: 0.10.2
2025-10-19 01:26:22,057:INFO:              mlflow: 3.5.0
2025-10-19 01:26:22,057:INFO:              gradio: 5.49.1
2025-10-19 01:26:22,057:INFO:             fastapi: 0.119.0
2025-10-19 01:26:22,057:INFO:             uvicorn: 0.38.0
2025-10-19 01:26:22,057:INFO:              m2cgen: 0.10.0
2025-10-19 01:26:22,057:INFO:           evidently: 0.4.40
2025-10-19 01:26:22,057:INFO:               fugue: 0.8.7
2025-10-19 01:26:22,057:INFO:           streamlit: Not installed
2025-10-19 01:26:22,057:INFO:             prophet: Not installed
2025-10-19 01:26:22,057:INFO:None
2025-10-19 01:26:22,057:INFO:Set up data.
2025-10-19 01:26:22,228:INFO:Set up folding strategy.
2025-10-19 01:26:22,250:INFO:Set up train/test split.
2025-10-19 01:26:22,292:INFO:Set up index.
2025-10-19 01:26:22,294:INFO:Assigning column types.
2025-10-19 01:26:22,316:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 01:26:22,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 01:26:22,356:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:26:22,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:26:22,424:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:26:22,461:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 01:26:22,462:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:26:22,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:26:22,486:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:26:22,487:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 01:26:22,530:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:26:22,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:26:22,560:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:26:22,604:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:26:22,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:26:22,634:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:26:22,634:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 01:26:22,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:26:22,703:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:26:22,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:26:22,775:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:26:22,777:INFO:Preparing preprocessing pipeline...
2025-10-19 01:26:22,782:INFO:Set up simple imputation.
2025-10-19 01:26:22,801:INFO:Set up encoding of ordinal features.
2025-10-19 01:26:22,811:INFO:Set up encoding of categorical features.
2025-10-19 01:26:22,811:INFO:Set up removing multicollinearity.
2025-10-19 01:26:22,811:INFO:Set up imbalanced handling.
2025-10-19 01:26:22,813:INFO:Set up column name cleaning.
2025-10-19 01:26:27,307:INFO:Finished creating preprocessing pipeline.
2025-10-19 01:26:27,331:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 01:26:27,331:INFO:Creating final display dataframe.
2025-10-19 01:26:29,630:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (63955, 28)
4        Transformed data shape       (90335, 96)
5   Transformed train set shape       (71148, 96)
6    Transformed test set shape       (19187, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20               Fold Generator        GroupKFold
21                  Fold Number                 5
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              0b5f
2025-10-19 01:26:29,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:26:29,694:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:26:29,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:26:29,752:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:26:29,755:INFO:setup() successfully completed in 7.72s...............
2025-10-19 01:26:29,756:INFO:Initializing compare_models()
2025-10-19 01:26:29,756:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 01:26:29,756:INFO:Checking exceptions
2025-10-19 01:26:29,778:INFO:Preparing display monitor
2025-10-19 01:26:29,813:INFO:Initializing Logistic Regression
2025-10-19 01:26:29,813:INFO:Total runtime is 0.0 minutes
2025-10-19 01:26:29,819:INFO:SubProcess create_model() called ==================================
2025-10-19 01:26:29,821:INFO:Initializing create_model()
2025-10-19 01:26:29,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:26:29,823:INFO:Checking exceptions
2025-10-19 01:26:29,823:INFO:Importing libraries
2025-10-19 01:26:29,823:INFO:Copying training dataset
2025-10-19 01:26:29,869:INFO:Defining folds
2025-10-19 01:26:29,869:INFO:Declaring metric variables
2025-10-19 01:26:29,874:INFO:Importing untrained model
2025-10-19 01:26:29,882:INFO:Logistic Regression Imported successfully
2025-10-19 01:26:29,888:INFO:Starting cross validation
2025-10-19 01:26:29,897:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:27:16,649:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 01:27:16,778:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 01:27:16,812:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 01:27:16,872:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 01:27:16,898:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 01:27:17,263:INFO:Calculating mean and std
2025-10-19 01:27:17,264:INFO:Creating metrics dataframe
2025-10-19 01:27:17,269:INFO:Uploading results into container
2025-10-19 01:27:17,270:INFO:Uploading model into container now
2025-10-19 01:27:17,271:INFO:_master_model_container: 1
2025-10-19 01:27:17,271:INFO:_display_container: 2
2025-10-19 01:27:17,272:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 01:27:17,272:INFO:create_model() successfully completed......................................
2025-10-19 01:27:17,510:INFO:SubProcess create_model() end ==================================
2025-10-19 01:27:17,510:INFO:Creating metrics dataframe
2025-10-19 01:27:17,517:INFO:Initializing K Neighbors Classifier
2025-10-19 01:27:17,518:INFO:Total runtime is 0.7950830658276876 minutes
2025-10-19 01:27:17,522:INFO:SubProcess create_model() called ==================================
2025-10-19 01:27:17,524:INFO:Initializing create_model()
2025-10-19 01:27:17,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:27:17,525:INFO:Checking exceptions
2025-10-19 01:27:17,525:INFO:Importing libraries
2025-10-19 01:27:17,525:INFO:Copying training dataset
2025-10-19 01:27:17,559:INFO:Defining folds
2025-10-19 01:27:17,559:INFO:Declaring metric variables
2025-10-19 01:27:17,565:INFO:Importing untrained model
2025-10-19 01:27:17,570:INFO:K Neighbors Classifier Imported successfully
2025-10-19 01:27:17,578:INFO:Starting cross validation
2025-10-19 01:27:17,584:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:27:37,276:INFO:Calculating mean and std
2025-10-19 01:27:37,280:INFO:Creating metrics dataframe
2025-10-19 01:27:37,284:INFO:Uploading results into container
2025-10-19 01:27:37,285:INFO:Uploading model into container now
2025-10-19 01:27:37,285:INFO:_master_model_container: 2
2025-10-19 01:27:37,286:INFO:_display_container: 2
2025-10-19 01:27:37,287:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 01:27:37,287:INFO:create_model() successfully completed......................................
2025-10-19 01:27:37,532:INFO:SubProcess create_model() end ==================================
2025-10-19 01:27:37,532:INFO:Creating metrics dataframe
2025-10-19 01:27:37,540:INFO:Initializing Naive Bayes
2025-10-19 01:27:37,540:INFO:Total runtime is 1.1287833650906882 minutes
2025-10-19 01:27:37,545:INFO:SubProcess create_model() called ==================================
2025-10-19 01:27:37,546:INFO:Initializing create_model()
2025-10-19 01:27:37,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:27:37,547:INFO:Checking exceptions
2025-10-19 01:27:37,547:INFO:Importing libraries
2025-10-19 01:27:37,547:INFO:Copying training dataset
2025-10-19 01:27:37,586:INFO:Defining folds
2025-10-19 01:27:37,586:INFO:Declaring metric variables
2025-10-19 01:27:37,589:INFO:Importing untrained model
2025-10-19 01:27:37,596:INFO:Naive Bayes Imported successfully
2025-10-19 01:27:37,604:INFO:Starting cross validation
2025-10-19 01:27:37,613:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:27:42,871:INFO:Calculating mean and std
2025-10-19 01:27:42,873:INFO:Creating metrics dataframe
2025-10-19 01:27:42,879:INFO:Uploading results into container
2025-10-19 01:27:42,880:INFO:Uploading model into container now
2025-10-19 01:27:42,881:INFO:_master_model_container: 3
2025-10-19 01:27:42,881:INFO:_display_container: 2
2025-10-19 01:27:42,882:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 01:27:42,882:INFO:create_model() successfully completed......................................
2025-10-19 01:27:43,137:INFO:SubProcess create_model() end ==================================
2025-10-19 01:27:43,137:INFO:Creating metrics dataframe
2025-10-19 01:27:43,145:INFO:Initializing Decision Tree Classifier
2025-10-19 01:27:43,145:INFO:Total runtime is 1.22219961086909 minutes
2025-10-19 01:27:43,150:INFO:SubProcess create_model() called ==================================
2025-10-19 01:27:43,153:INFO:Initializing create_model()
2025-10-19 01:27:43,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:27:43,153:INFO:Checking exceptions
2025-10-19 01:27:43,153:INFO:Importing libraries
2025-10-19 01:27:43,153:INFO:Copying training dataset
2025-10-19 01:27:43,188:INFO:Defining folds
2025-10-19 01:27:43,188:INFO:Declaring metric variables
2025-10-19 01:27:43,191:INFO:Importing untrained model
2025-10-19 01:27:43,197:INFO:Decision Tree Classifier Imported successfully
2025-10-19 01:27:43,205:INFO:Starting cross validation
2025-10-19 01:27:43,211:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:27:50,135:INFO:Calculating mean and std
2025-10-19 01:27:50,137:INFO:Creating metrics dataframe
2025-10-19 01:27:50,141:INFO:Uploading results into container
2025-10-19 01:27:50,142:INFO:Uploading model into container now
2025-10-19 01:27:50,143:INFO:_master_model_container: 4
2025-10-19 01:27:50,143:INFO:_display_container: 2
2025-10-19 01:27:50,144:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-19 01:27:50,144:INFO:create_model() successfully completed......................................
2025-10-19 01:27:50,350:INFO:SubProcess create_model() end ==================================
2025-10-19 01:27:50,350:INFO:Creating metrics dataframe
2025-10-19 01:27:50,357:INFO:Initializing SVM - Linear Kernel
2025-10-19 01:27:50,357:INFO:Total runtime is 1.3424013535181685 minutes
2025-10-19 01:27:50,360:INFO:SubProcess create_model() called ==================================
2025-10-19 01:27:50,364:INFO:Initializing create_model()
2025-10-19 01:27:50,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:27:50,364:INFO:Checking exceptions
2025-10-19 01:27:50,364:INFO:Importing libraries
2025-10-19 01:27:50,364:INFO:Copying training dataset
2025-10-19 01:27:50,406:INFO:Defining folds
2025-10-19 01:27:50,407:INFO:Declaring metric variables
2025-10-19 01:27:50,415:INFO:Importing untrained model
2025-10-19 01:27:50,420:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 01:27:50,431:INFO:Starting cross validation
2025-10-19 01:27:50,437:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:28:07,206:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 01:28:09,197:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 01:28:10,900:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 01:28:11,088:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 01:28:11,113:INFO:Calculating mean and std
2025-10-19 01:28:11,115:INFO:Creating metrics dataframe
2025-10-19 01:28:11,117:INFO:Uploading results into container
2025-10-19 01:28:11,117:INFO:Uploading model into container now
2025-10-19 01:28:11,118:INFO:_master_model_container: 5
2025-10-19 01:28:11,118:INFO:_display_container: 2
2025-10-19 01:28:11,118:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 01:28:11,118:INFO:create_model() successfully completed......................................
2025-10-19 01:28:11,313:INFO:SubProcess create_model() end ==================================
2025-10-19 01:28:11,313:INFO:Creating metrics dataframe
2025-10-19 01:28:11,323:INFO:Initializing Ridge Classifier
2025-10-19 01:28:11,323:INFO:Total runtime is 1.6918363610903424 minutes
2025-10-19 01:28:11,326:INFO:SubProcess create_model() called ==================================
2025-10-19 01:28:11,330:INFO:Initializing create_model()
2025-10-19 01:28:11,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:28:11,330:INFO:Checking exceptions
2025-10-19 01:28:11,330:INFO:Importing libraries
2025-10-19 01:28:11,330:INFO:Copying training dataset
2025-10-19 01:28:11,364:INFO:Defining folds
2025-10-19 01:28:11,365:INFO:Declaring metric variables
2025-10-19 01:28:11,371:INFO:Importing untrained model
2025-10-19 01:28:11,376:INFO:Ridge Classifier Imported successfully
2025-10-19 01:28:11,385:INFO:Starting cross validation
2025-10-19 01:28:11,391:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:28:16,361:INFO:Calculating mean and std
2025-10-19 01:28:16,365:INFO:Creating metrics dataframe
2025-10-19 01:28:16,368:INFO:Uploading results into container
2025-10-19 01:28:16,369:INFO:Uploading model into container now
2025-10-19 01:28:16,370:INFO:_master_model_container: 6
2025-10-19 01:28:16,370:INFO:_display_container: 2
2025-10-19 01:28:16,370:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 01:28:16,371:INFO:create_model() successfully completed......................................
2025-10-19 01:28:16,575:INFO:SubProcess create_model() end ==================================
2025-10-19 01:28:16,575:INFO:Creating metrics dataframe
2025-10-19 01:28:16,582:INFO:Initializing Random Forest Classifier
2025-10-19 01:28:16,582:INFO:Total runtime is 1.7794976154963178 minutes
2025-10-19 01:28:16,585:INFO:SubProcess create_model() called ==================================
2025-10-19 01:28:16,586:INFO:Initializing create_model()
2025-10-19 01:28:16,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:28:16,587:INFO:Checking exceptions
2025-10-19 01:28:16,587:INFO:Importing libraries
2025-10-19 01:28:16,587:INFO:Copying training dataset
2025-10-19 01:28:16,608:INFO:Defining folds
2025-10-19 01:28:16,608:INFO:Declaring metric variables
2025-10-19 01:28:16,612:INFO:Importing untrained model
2025-10-19 01:28:16,619:INFO:Random Forest Classifier Imported successfully
2025-10-19 01:28:16,626:INFO:Starting cross validation
2025-10-19 01:28:16,633:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:28:34,360:INFO:Calculating mean and std
2025-10-19 01:28:34,362:INFO:Creating metrics dataframe
2025-10-19 01:28:34,366:INFO:Uploading results into container
2025-10-19 01:28:34,367:INFO:Uploading model into container now
2025-10-19 01:28:34,368:INFO:_master_model_container: 7
2025-10-19 01:28:34,368:INFO:_display_container: 2
2025-10-19 01:28:34,368:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-19 01:28:34,369:INFO:create_model() successfully completed......................................
2025-10-19 01:28:34,687:INFO:SubProcess create_model() end ==================================
2025-10-19 01:28:34,687:INFO:Creating metrics dataframe
2025-10-19 01:28:34,699:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 01:28:34,701:INFO:Total runtime is 2.0814425031344097 minutes
2025-10-19 01:28:34,704:INFO:SubProcess create_model() called ==================================
2025-10-19 01:28:34,708:INFO:Initializing create_model()
2025-10-19 01:28:34,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:28:34,708:INFO:Checking exceptions
2025-10-19 01:28:34,708:INFO:Importing libraries
2025-10-19 01:28:34,708:INFO:Copying training dataset
2025-10-19 01:28:34,756:INFO:Defining folds
2025-10-19 01:28:34,757:INFO:Declaring metric variables
2025-10-19 01:28:34,764:INFO:Importing untrained model
2025-10-19 01:28:34,770:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 01:28:34,778:INFO:Starting cross validation
2025-10-19 01:28:34,787:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:28:40,860:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 01:28:40,865:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 01:28:40,878:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 01:28:40,907:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 01:28:40,927:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 01:28:43,057:INFO:Calculating mean and std
2025-10-19 01:28:43,057:INFO:Creating metrics dataframe
2025-10-19 01:28:43,059:INFO:Uploading results into container
2025-10-19 01:28:43,060:INFO:Uploading model into container now
2025-10-19 01:28:43,060:INFO:_master_model_container: 8
2025-10-19 01:28:43,061:INFO:_display_container: 2
2025-10-19 01:28:43,061:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 01:28:43,061:INFO:create_model() successfully completed......................................
2025-10-19 01:28:43,293:INFO:SubProcess create_model() end ==================================
2025-10-19 01:28:43,293:INFO:Creating metrics dataframe
2025-10-19 01:28:43,302:INFO:Initializing Ada Boost Classifier
2025-10-19 01:28:43,302:INFO:Total runtime is 2.2248292922973634 minutes
2025-10-19 01:28:43,306:INFO:SubProcess create_model() called ==================================
2025-10-19 01:28:43,308:INFO:Initializing create_model()
2025-10-19 01:28:43,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:28:43,309:INFO:Checking exceptions
2025-10-19 01:28:43,309:INFO:Importing libraries
2025-10-19 01:28:43,309:INFO:Copying training dataset
2025-10-19 01:28:43,350:INFO:Defining folds
2025-10-19 01:28:43,351:INFO:Declaring metric variables
2025-10-19 01:28:43,356:INFO:Importing untrained model
2025-10-19 01:28:43,362:INFO:Ada Boost Classifier Imported successfully
2025-10-19 01:28:43,374:INFO:Starting cross validation
2025-10-19 01:28:43,380:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:28:47,447:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 01:28:47,520:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 01:28:47,552:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 01:28:47,570:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 01:28:47,588:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 01:28:57,908:INFO:Calculating mean and std
2025-10-19 01:28:57,910:INFO:Creating metrics dataframe
2025-10-19 01:28:57,912:INFO:Uploading results into container
2025-10-19 01:28:57,912:INFO:Uploading model into container now
2025-10-19 01:28:57,913:INFO:_master_model_container: 9
2025-10-19 01:28:57,913:INFO:_display_container: 2
2025-10-19 01:28:57,913:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 01:28:57,913:INFO:create_model() successfully completed......................................
2025-10-19 01:28:58,118:INFO:SubProcess create_model() end ==================================
2025-10-19 01:28:58,118:INFO:Creating metrics dataframe
2025-10-19 01:28:58,127:INFO:Initializing Gradient Boosting Classifier
2025-10-19 01:28:58,127:INFO:Total runtime is 2.471914863586426 minutes
2025-10-19 01:28:58,133:INFO:SubProcess create_model() called ==================================
2025-10-19 01:28:58,134:INFO:Initializing create_model()
2025-10-19 01:28:58,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:28:58,134:INFO:Checking exceptions
2025-10-19 01:28:58,134:INFO:Importing libraries
2025-10-19 01:28:58,134:INFO:Copying training dataset
2025-10-19 01:28:58,160:INFO:Defining folds
2025-10-19 01:28:58,160:INFO:Declaring metric variables
2025-10-19 01:28:58,163:INFO:Importing untrained model
2025-10-19 01:28:58,166:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 01:28:58,175:INFO:Starting cross validation
2025-10-19 01:28:58,185:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:29:38,938:INFO:Calculating mean and std
2025-10-19 01:29:38,939:INFO:Creating metrics dataframe
2025-10-19 01:29:38,942:INFO:Uploading results into container
2025-10-19 01:29:38,943:INFO:Uploading model into container now
2025-10-19 01:29:38,943:INFO:_master_model_container: 10
2025-10-19 01:29:38,944:INFO:_display_container: 2
2025-10-19 01:29:38,945:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 01:29:38,945:INFO:create_model() successfully completed......................................
2025-10-19 01:29:39,162:INFO:SubProcess create_model() end ==================================
2025-10-19 01:29:39,162:INFO:Creating metrics dataframe
2025-10-19 01:29:39,170:INFO:Initializing Linear Discriminant Analysis
2025-10-19 01:29:39,170:INFO:Total runtime is 3.1559590021769206 minutes
2025-10-19 01:29:39,174:INFO:SubProcess create_model() called ==================================
2025-10-19 01:29:39,176:INFO:Initializing create_model()
2025-10-19 01:29:39,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:29:39,176:INFO:Checking exceptions
2025-10-19 01:29:39,176:INFO:Importing libraries
2025-10-19 01:29:39,176:INFO:Copying training dataset
2025-10-19 01:29:39,208:INFO:Defining folds
2025-10-19 01:29:39,208:INFO:Declaring metric variables
2025-10-19 01:29:39,213:INFO:Importing untrained model
2025-10-19 01:29:39,219:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 01:29:39,227:INFO:Starting cross validation
2025-10-19 01:29:39,234:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:29:47,815:INFO:Calculating mean and std
2025-10-19 01:29:47,818:INFO:Creating metrics dataframe
2025-10-19 01:29:47,822:INFO:Uploading results into container
2025-10-19 01:29:47,823:INFO:Uploading model into container now
2025-10-19 01:29:47,823:INFO:_master_model_container: 11
2025-10-19 01:29:47,823:INFO:_display_container: 2
2025-10-19 01:29:47,824:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 01:29:47,824:INFO:create_model() successfully completed......................................
2025-10-19 01:29:48,072:INFO:SubProcess create_model() end ==================================
2025-10-19 01:29:48,072:INFO:Creating metrics dataframe
2025-10-19 01:29:48,081:INFO:Initializing Extra Trees Classifier
2025-10-19 01:29:48,081:INFO:Total runtime is 3.3044683655103047 minutes
2025-10-19 01:29:48,085:INFO:SubProcess create_model() called ==================================
2025-10-19 01:29:48,087:INFO:Initializing create_model()
2025-10-19 01:29:48,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:29:48,087:INFO:Checking exceptions
2025-10-19 01:29:48,087:INFO:Importing libraries
2025-10-19 01:29:48,087:INFO:Copying training dataset
2025-10-19 01:29:48,118:INFO:Defining folds
2025-10-19 01:29:48,119:INFO:Declaring metric variables
2025-10-19 01:29:48,124:INFO:Importing untrained model
2025-10-19 01:29:48,130:INFO:Extra Trees Classifier Imported successfully
2025-10-19 01:29:48,139:INFO:Starting cross validation
2025-10-19 01:29:48,146:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:30:12,202:INFO:Calculating mean and std
2025-10-19 01:30:12,204:INFO:Creating metrics dataframe
2025-10-19 01:30:12,207:INFO:Uploading results into container
2025-10-19 01:30:12,208:INFO:Uploading model into container now
2025-10-19 01:30:12,209:INFO:_master_model_container: 12
2025-10-19 01:30:12,209:INFO:_display_container: 2
2025-10-19 01:30:12,210:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-19 01:30:12,210:INFO:create_model() successfully completed......................................
2025-10-19 01:30:12,472:INFO:SubProcess create_model() end ==================================
2025-10-19 01:30:12,472:INFO:Creating metrics dataframe
2025-10-19 01:30:12,484:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 01:30:12,484:INFO:Total runtime is 3.711198019981384 minutes
2025-10-19 01:30:12,490:INFO:SubProcess create_model() called ==================================
2025-10-19 01:30:12,491:INFO:Initializing create_model()
2025-10-19 01:30:12,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:30:12,492:INFO:Checking exceptions
2025-10-19 01:30:12,492:INFO:Importing libraries
2025-10-19 01:30:12,492:INFO:Copying training dataset
2025-10-19 01:30:12,531:INFO:Defining folds
2025-10-19 01:30:12,531:INFO:Declaring metric variables
2025-10-19 01:30:12,535:INFO:Importing untrained model
2025-10-19 01:30:12,542:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 01:30:12,548:INFO:Starting cross validation
2025-10-19 01:30:12,557:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:30:21,191:INFO:Calculating mean and std
2025-10-19 01:30:21,193:INFO:Creating metrics dataframe
2025-10-19 01:30:21,196:INFO:Uploading results into container
2025-10-19 01:30:21,197:INFO:Uploading model into container now
2025-10-19 01:30:21,197:INFO:_master_model_container: 13
2025-10-19 01:30:21,197:INFO:_display_container: 2
2025-10-19 01:30:21,198:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 01:30:21,199:INFO:create_model() successfully completed......................................
2025-10-19 01:30:21,435:INFO:SubProcess create_model() end ==================================
2025-10-19 01:30:21,435:INFO:Creating metrics dataframe
2025-10-19 01:30:21,444:INFO:Initializing CatBoost Classifier
2025-10-19 01:30:21,444:INFO:Total runtime is 3.8605153242746986 minutes
2025-10-19 01:30:21,447:INFO:SubProcess create_model() called ==================================
2025-10-19 01:30:21,449:INFO:Initializing create_model()
2025-10-19 01:30:21,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:30:21,449:INFO:Checking exceptions
2025-10-19 01:30:21,449:INFO:Importing libraries
2025-10-19 01:30:21,449:INFO:Copying training dataset
2025-10-19 01:30:21,495:INFO:Defining folds
2025-10-19 01:30:21,495:INFO:Declaring metric variables
2025-10-19 01:30:21,499:INFO:Importing untrained model
2025-10-19 01:30:21,505:INFO:CatBoost Classifier Imported successfully
2025-10-19 01:30:21,513:INFO:Starting cross validation
2025-10-19 01:30:21,521:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:31:51,232:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5023, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5072, in _catboost._CatBoost._train
_catboost.CatBoostError: catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info


2025-10-19 01:31:51,232:INFO:Calculating mean and std
2025-10-19 01:31:51,233:INFO:Creating metrics dataframe
2025-10-19 01:31:51,236:INFO:Uploading results into container
2025-10-19 01:31:51,237:INFO:Uploading model into container now
2025-10-19 01:31:51,238:INFO:_master_model_container: 14
2025-10-19 01:31:51,238:INFO:_display_container: 2
2025-10-19 01:31:51,238:INFO:<catboost.core.CatBoostClassifier object at 0x000002120766DC10>
2025-10-19 01:31:51,240:INFO:create_model() successfully completed......................................
2025-10-19 01:31:51,464:INFO:SubProcess create_model() end ==================================
2025-10-19 01:31:51,464:INFO:Creating metrics dataframe
2025-10-19 01:31:51,475:INFO:Initializing Dummy Classifier
2025-10-19 01:31:51,475:INFO:Total runtime is 5.361039384206135 minutes
2025-10-19 01:31:51,478:INFO:SubProcess create_model() called ==================================
2025-10-19 01:31:51,480:INFO:Initializing create_model()
2025-10-19 01:31:51,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B083D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:31:51,480:INFO:Checking exceptions
2025-10-19 01:31:51,481:INFO:Importing libraries
2025-10-19 01:31:51,481:INFO:Copying training dataset
2025-10-19 01:31:51,521:INFO:Defining folds
2025-10-19 01:31:51,521:INFO:Declaring metric variables
2025-10-19 01:31:51,527:INFO:Importing untrained model
2025-10-19 01:31:51,532:INFO:Dummy Classifier Imported successfully
2025-10-19 01:31:51,545:INFO:Starting cross validation
2025-10-19 01:31:51,554:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:31:56,295:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 01:31:56,306:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 01:31:56,364:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 01:31:56,381:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 01:31:56,381:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 01:31:56,399:INFO:Calculating mean and std
2025-10-19 01:31:56,400:INFO:Creating metrics dataframe
2025-10-19 01:31:56,401:INFO:Uploading results into container
2025-10-19 01:31:56,402:INFO:Uploading model into container now
2025-10-19 01:31:56,402:INFO:_master_model_container: 15
2025-10-19 01:31:56,402:INFO:_display_container: 2
2025-10-19 01:31:56,403:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-19 01:31:56,403:INFO:create_model() successfully completed......................................
2025-10-19 01:31:56,624:INFO:SubProcess create_model() end ==================================
2025-10-19 01:31:56,624:INFO:Creating metrics dataframe
2025-10-19 01:31:56,634:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 01:31:56,647:INFO:Initializing create_model()
2025-10-19 01:31:56,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:31:56,647:INFO:Checking exceptions
2025-10-19 01:31:56,649:INFO:Importing libraries
2025-10-19 01:31:56,649:INFO:Copying training dataset
2025-10-19 01:31:56,676:INFO:Defining folds
2025-10-19 01:31:56,676:INFO:Declaring metric variables
2025-10-19 01:31:56,676:INFO:Importing untrained model
2025-10-19 01:31:56,676:INFO:Declaring custom model
2025-10-19 01:31:56,677:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 01:31:56,685:INFO:Cross validation set to False
2025-10-19 01:31:56,685:INFO:Fitting Model
2025-10-19 01:32:31,095:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 01:32:31,095:INFO:create_model() successfully completed......................................
2025-10-19 01:32:31,287:INFO:Initializing create_model()
2025-10-19 01:32:31,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:32:31,287:INFO:Checking exceptions
2025-10-19 01:32:31,290:INFO:Importing libraries
2025-10-19 01:32:31,291:INFO:Copying training dataset
2025-10-19 01:32:31,326:INFO:Defining folds
2025-10-19 01:32:31,326:INFO:Declaring metric variables
2025-10-19 01:32:31,328:INFO:Importing untrained model
2025-10-19 01:32:31,328:INFO:Declaring custom model
2025-10-19 01:32:31,328:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 01:32:31,333:INFO:Cross validation set to False
2025-10-19 01:32:31,333:INFO:Fitting Model
2025-10-19 01:32:34,013:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 01:32:34,013:INFO:[LightGBM] [Info] Number of positive: 35574, number of negative: 35574
2025-10-19 01:32:34,045:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016198 seconds.
2025-10-19 01:32:34,045:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 01:32:34,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 01:32:34,046:INFO:[LightGBM] [Info] Total Bins 23129
2025-10-19 01:32:34,047:INFO:[LightGBM] [Info] Number of data points in the train set: 71148, number of used features: 95
2025-10-19 01:32:34,048:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-19 01:32:34,881:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 01:32:34,881:INFO:create_model() successfully completed......................................
2025-10-19 01:32:35,118:INFO:Initializing create_model()
2025-10-19 01:32:35,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:32:35,118:INFO:Checking exceptions
2025-10-19 01:32:35,120:INFO:Importing libraries
2025-10-19 01:32:35,120:INFO:Copying training dataset
2025-10-19 01:32:35,158:INFO:Defining folds
2025-10-19 01:32:35,158:INFO:Declaring metric variables
2025-10-19 01:32:35,159:INFO:Importing untrained model
2025-10-19 01:32:35,160:INFO:Declaring custom model
2025-10-19 01:32:35,160:INFO:Ridge Classifier Imported successfully
2025-10-19 01:32:35,165:INFO:Cross validation set to False
2025-10-19 01:32:35,165:INFO:Fitting Model
2025-10-19 01:32:37,973:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 01:32:37,973:INFO:create_model() successfully completed......................................
2025-10-19 01:32:38,260:INFO:_master_model_container: 15
2025-10-19 01:32:38,260:INFO:_display_container: 2
2025-10-19 01:32:38,262:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)]
2025-10-19 01:32:38,263:INFO:compare_models() successfully completed......................................
2025-10-19 01:32:38,263:INFO:Initializing tune_model()
2025-10-19 01:32:38,263:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 01:32:38,265:INFO:Checking exceptions
2025-10-19 01:32:38,356:INFO:Copying training dataset
2025-10-19 01:32:38,419:INFO:Checking base model
2025-10-19 01:32:38,419:INFO:Base model : Gradient Boosting Classifier
2025-10-19 01:32:38,423:INFO:Declaring metric variables
2025-10-19 01:32:38,428:INFO:Defining Hyperparameters
2025-10-19 01:32:38,683:INFO:Tuning with n_jobs=-1
2025-10-19 01:32:38,683:INFO:Initializing RandomizedSearchCV
2025-10-19 01:34:30,519:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 270, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.05}
2025-10-19 01:34:30,520:INFO:Hyperparameter search completed
2025-10-19 01:34:30,521:INFO:SubProcess create_model() called ==================================
2025-10-19 01:34:30,523:INFO:Initializing create_model()
2025-10-19 01:34:30,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021259021490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 270, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 6, 'learning_rate': 0.05})
2025-10-19 01:34:30,524:INFO:Checking exceptions
2025-10-19 01:34:30,524:INFO:Importing libraries
2025-10-19 01:34:30,524:INFO:Copying training dataset
2025-10-19 01:34:30,557:INFO:Defining folds
2025-10-19 01:34:30,557:INFO:Declaring metric variables
2025-10-19 01:34:30,560:INFO:Importing untrained model
2025-10-19 01:34:30,561:INFO:Declaring custom model
2025-10-19 01:34:30,565:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 01:34:30,572:INFO:Starting cross validation
2025-10-19 01:34:30,580:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:34:50,245:INFO:Calculating mean and std
2025-10-19 01:34:50,246:INFO:Creating metrics dataframe
2025-10-19 01:34:50,251:INFO:Finalizing model
2025-10-19 01:35:06,881:INFO:Uploading results into container
2025-10-19 01:35:06,883:INFO:Uploading model into container now
2025-10-19 01:35:06,884:INFO:_master_model_container: 16
2025-10-19 01:35:06,884:INFO:_display_container: 3
2025-10-19 01:35:06,885:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 01:35:06,885:INFO:create_model() successfully completed......................................
2025-10-19 01:35:07,099:INFO:SubProcess create_model() end ==================================
2025-10-19 01:35:07,099:INFO:choose_better activated
2025-10-19 01:35:07,103:INFO:SubProcess create_model() called ==================================
2025-10-19 01:35:07,104:INFO:Initializing create_model()
2025-10-19 01:35:07,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:35:07,105:INFO:Checking exceptions
2025-10-19 01:35:07,106:INFO:Importing libraries
2025-10-19 01:35:07,107:INFO:Copying training dataset
2025-10-19 01:35:07,137:INFO:Defining folds
2025-10-19 01:35:07,137:INFO:Declaring metric variables
2025-10-19 01:35:07,137:INFO:Importing untrained model
2025-10-19 01:35:07,137:INFO:Declaring custom model
2025-10-19 01:35:07,137:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 01:35:07,138:INFO:Starting cross validation
2025-10-19 01:35:07,142:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:35:48,832:INFO:Calculating mean and std
2025-10-19 01:35:48,832:INFO:Creating metrics dataframe
2025-10-19 01:35:48,833:INFO:Finalizing model
2025-10-19 01:36:23,628:INFO:Uploading results into container
2025-10-19 01:36:23,629:INFO:Uploading model into container now
2025-10-19 01:36:23,630:INFO:_master_model_container: 17
2025-10-19 01:36:23,630:INFO:_display_container: 4
2025-10-19 01:36:23,630:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 01:36:23,630:INFO:create_model() successfully completed......................................
2025-10-19 01:36:23,838:INFO:SubProcess create_model() end ==================================
2025-10-19 01:36:23,839:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9334
2025-10-19 01:36:23,839:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9334
2025-10-19 01:36:23,840:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-19 01:36:23,840:INFO:choose_better completed
2025-10-19 01:36:23,841:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 01:36:23,850:INFO:_master_model_container: 17
2025-10-19 01:36:23,851:INFO:_display_container: 3
2025-10-19 01:36:23,851:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 01:36:23,852:INFO:tune_model() successfully completed......................................
2025-10-19 01:36:24,086:INFO:Initializing tune_model()
2025-10-19 01:36:24,087:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 01:36:24,087:INFO:Checking exceptions
2025-10-19 01:36:24,116:INFO:Copying training dataset
2025-10-19 01:36:24,151:INFO:Checking base model
2025-10-19 01:36:24,151:INFO:Base model : Light Gradient Boosting Machine
2025-10-19 01:36:24,159:INFO:Declaring metric variables
2025-10-19 01:36:24,166:INFO:Defining Hyperparameters
2025-10-19 01:36:24,391:INFO:Tuning with n_jobs=-1
2025-10-19 01:36:24,391:INFO:Initializing RandomizedSearchCV
2025-10-19 01:38:06,718:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 86, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.6}
2025-10-19 01:38:06,720:INFO:Hyperparameter search completed
2025-10-19 01:38:06,720:INFO:SubProcess create_model() called ==================================
2025-10-19 01:38:06,723:INFO:Initializing create_model()
2025-10-19 01:38:06,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120793FD10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 2, 'num_leaves': 40, 'n_estimators': 130, 'min_split_gain': 0.9, 'min_child_samples': 86, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 5, 'bagging_fraction': 0.6})
2025-10-19 01:38:06,723:INFO:Checking exceptions
2025-10-19 01:38:06,723:INFO:Importing libraries
2025-10-19 01:38:06,723:INFO:Copying training dataset
2025-10-19 01:38:06,772:INFO:Defining folds
2025-10-19 01:38:06,772:INFO:Declaring metric variables
2025-10-19 01:38:06,813:INFO:Importing untrained model
2025-10-19 01:38:06,814:INFO:Declaring custom model
2025-10-19 01:38:06,822:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 01:38:06,837:INFO:Starting cross validation
2025-10-19 01:38:06,850:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:38:17,968:INFO:Calculating mean and std
2025-10-19 01:38:17,968:INFO:Creating metrics dataframe
2025-10-19 01:38:17,974:INFO:Finalizing model
2025-10-19 01:38:20,406:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 01:38:20,407:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-10-19 01:38:20,407:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-10-19 01:38:20,539:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 01:38:20,540:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 01:38:20,540:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-10-19 01:38:20,540:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-10-19 01:38:20,540:INFO:[LightGBM] [Info] Number of positive: 35574, number of negative: 35574
2025-10-19 01:38:20,552:WARNING:Exception in thread Thread-5:
2025-10-19 01:38:20,554:WARNING:Traceback (most recent call last):
2025-10-19 01:38:20,554:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\threading.py", line 1045, in _bootstrap_inner
2025-10-19 01:38:20,559:WARNING:    self.run()
2025-10-19 01:38:20,560:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\tqdm\_monitor.py", line 84, in run
2025-10-19 01:38:20,560:WARNING:    instance.refresh(nolock=True)
2025-10-19 01:38:20,560:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\tqdm\std.py", line 1347, in refresh
2025-10-19 01:38:20,562:WARNING:    self.display()
2025-10-19 01:38:20,562:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\display\progress_bar.py", line 71, in display
2025-10-19 01:38:20,563:WARNING:    super().display(msg, pos, close, bar_style, check_delay)
2025-10-19 01:38:20,563:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\tqdm\notebook.py", line 157, in display
2025-10-19 01:38:20,564:WARNING:    pbar.value = self.n
2025-10-19 01:38:20,564:WARNING:    ^^^^^^^^^^
2025-10-19 01:38:20,564:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\traitlets\traitlets.py", line 716, in __set__
2025-10-19 01:38:20,565:WARNING:    self.set(obj, value)
2025-10-19 01:38:20,565:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\traitlets\traitlets.py", line 706, in set
2025-10-19 01:38:20,566:WARNING:    obj._notify_trait(self.name, old_value, new_value)
2025-10-19 01:38:20,566:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\traitlets\traitlets.py", line 1513, in _notify_trait
2025-10-19 01:38:20,567:WARNING:    self.notify_change(
2025-10-19 01:38:20,567:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\ipywidgets\widgets\widget.py", line 700, in notify_change
2025-10-19 01:38:20,568:WARNING:    self.send_state(key=name)
2025-10-19 01:38:20,568:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\ipywidgets\widgets\widget.py", line 586, in send_state
2025-10-19 01:38:20,568:WARNING:    self._send(msg, buffers=buffers)
2025-10-19 01:38:20,568:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\ipywidgets\widgets\widget.py", line 825, in _send
2025-10-19 01:38:20,569:WARNING:    self.comm.send(data=msg, buffers=buffers)
2025-10-19 01:38:20,569:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\comm\base_comm.py", line 144, in send
2025-10-19 01:38:20,569:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018834 seconds.
2025-10-19 01:38:20,570:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-19 01:38:20,570:WARNING:    self.publish_msg(
2025-10-19 01:38:20,570:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\ipykernel\comm\comm.py", line 42, in publish_msg
2025-10-19 01:38:20,570:INFO:[LightGBM] [Info] Total Bins 23129
2025-10-19 01:38:20,570:WARNING:    parent=self.kernel.get_parent(),
2025-10-19 01:38:20,571:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^
2025-10-19 01:38:20,571:WARNING:  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\ipykernel\kernelbase.py", line 797, in get_parent
2025-10-19 01:38:20,572:INFO:[LightGBM] [Info] Number of data points in the train set: 71148, number of used features: 95
2025-10-19 01:38:20,572:WARNING:    return self._shell_parent.get()
2025-10-19 01:38:20,572:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^
2025-10-19 01:38:20,572:WARNING:LookupError: <ContextVar name='shell_parent' at 0x0000021248ACAD90>
2025-10-19 01:38:20,573:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-19 01:38:21,550:INFO:Uploading results into container
2025-10-19 01:38:21,551:INFO:Uploading model into container now
2025-10-19 01:38:21,551:INFO:_master_model_container: 18
2025-10-19 01:38:21,551:INFO:_display_container: 4
2025-10-19 01:38:21,552:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 01:38:21,552:INFO:create_model() successfully completed......................................
2025-10-19 01:38:21,832:INFO:SubProcess create_model() end ==================================
2025-10-19 01:38:21,833:INFO:choose_better activated
2025-10-19 01:38:21,836:INFO:SubProcess create_model() called ==================================
2025-10-19 01:38:21,837:INFO:Initializing create_model()
2025-10-19 01:38:21,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:38:21,837:INFO:Checking exceptions
2025-10-19 01:38:21,838:INFO:Importing libraries
2025-10-19 01:38:21,838:INFO:Copying training dataset
2025-10-19 01:38:21,867:INFO:Defining folds
2025-10-19 01:38:21,868:INFO:Declaring metric variables
2025-10-19 01:38:21,868:INFO:Importing untrained model
2025-10-19 01:38:21,868:INFO:Declaring custom model
2025-10-19 01:38:21,869:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 01:38:21,869:INFO:Starting cross validation
2025-10-19 01:38:21,873:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:38:30,836:INFO:Calculating mean and std
2025-10-19 01:38:30,836:INFO:Creating metrics dataframe
2025-10-19 01:38:30,838:INFO:Finalizing model
2025-10-19 01:38:33,750:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 01:38:33,751:INFO:[LightGBM] [Info] Number of positive: 35574, number of negative: 35574
2025-10-19 01:38:33,778:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017041 seconds.
2025-10-19 01:38:33,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-19 01:38:33,779:INFO:[LightGBM] [Info] Total Bins 23129
2025-10-19 01:38:33,781:INFO:[LightGBM] [Info] Number of data points in the train set: 71148, number of used features: 95
2025-10-19 01:38:33,782:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-19 01:38:34,632:INFO:Uploading results into container
2025-10-19 01:38:34,633:INFO:Uploading model into container now
2025-10-19 01:38:34,633:INFO:_master_model_container: 19
2025-10-19 01:38:34,633:INFO:_display_container: 5
2025-10-19 01:38:34,634:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 01:38:34,634:INFO:create_model() successfully completed......................................
2025-10-19 01:38:34,861:INFO:SubProcess create_model() end ==================================
2025-10-19 01:38:34,861:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9333
2025-10-19 01:38:34,863:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9336
2025-10-19 01:38:34,863:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-19 01:38:34,863:INFO:choose_better completed
2025-10-19 01:38:34,875:INFO:_master_model_container: 19
2025-10-19 01:38:34,875:INFO:_display_container: 4
2025-10-19 01:38:34,876:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 01:38:34,876:INFO:tune_model() successfully completed......................................
2025-10-19 01:38:35,102:INFO:Initializing tune_model()
2025-10-19 01:38:35,103:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 01:38:35,103:INFO:Checking exceptions
2025-10-19 01:38:35,131:INFO:Copying training dataset
2025-10-19 01:38:35,160:INFO:Checking base model
2025-10-19 01:38:35,160:INFO:Base model : Ridge Classifier
2025-10-19 01:38:35,165:INFO:Declaring metric variables
2025-10-19 01:38:35,171:INFO:Defining Hyperparameters
2025-10-19 01:38:35,392:INFO:Tuning with n_jobs=-1
2025-10-19 01:38:35,392:INFO:Initializing RandomizedSearchCV
2025-10-19 01:39:15,851:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.3}
2025-10-19 01:39:15,852:INFO:Hyperparameter search completed
2025-10-19 01:39:15,852:INFO:SubProcess create_model() called ==================================
2025-10-19 01:39:15,853:INFO:Initializing create_model()
2025-10-19 01:39:15,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021259042F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 7.3})
2025-10-19 01:39:15,853:INFO:Checking exceptions
2025-10-19 01:39:15,854:INFO:Importing libraries
2025-10-19 01:39:15,854:INFO:Copying training dataset
2025-10-19 01:39:15,888:INFO:Defining folds
2025-10-19 01:39:15,888:INFO:Declaring metric variables
2025-10-19 01:39:15,891:INFO:Importing untrained model
2025-10-19 01:39:15,891:INFO:Declaring custom model
2025-10-19 01:39:15,894:INFO:Ridge Classifier Imported successfully
2025-10-19 01:39:15,902:INFO:Starting cross validation
2025-10-19 01:39:15,908:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:39:20,512:INFO:Calculating mean and std
2025-10-19 01:39:20,514:INFO:Creating metrics dataframe
2025-10-19 01:39:20,521:INFO:Finalizing model
2025-10-19 01:39:23,164:INFO:Uploading results into container
2025-10-19 01:39:23,165:INFO:Uploading model into container now
2025-10-19 01:39:23,167:INFO:_master_model_container: 20
2025-10-19 01:39:23,167:INFO:_display_container: 5
2025-10-19 01:39:23,168:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 01:39:23,168:INFO:create_model() successfully completed......................................
2025-10-19 01:39:23,361:INFO:SubProcess create_model() end ==================================
2025-10-19 01:39:23,361:INFO:choose_better activated
2025-10-19 01:39:23,366:INFO:SubProcess create_model() called ==================================
2025-10-19 01:39:23,368:INFO:Initializing create_model()
2025-10-19 01:39:23,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:39:23,368:INFO:Checking exceptions
2025-10-19 01:39:23,370:INFO:Importing libraries
2025-10-19 01:39:23,370:INFO:Copying training dataset
2025-10-19 01:39:23,392:INFO:Defining folds
2025-10-19 01:39:23,392:INFO:Declaring metric variables
2025-10-19 01:39:23,392:INFO:Importing untrained model
2025-10-19 01:39:23,392:INFO:Declaring custom model
2025-10-19 01:39:23,393:INFO:Ridge Classifier Imported successfully
2025-10-19 01:39:23,394:INFO:Starting cross validation
2025-10-19 01:39:23,399:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:39:28,076:INFO:Calculating mean and std
2025-10-19 01:39:28,076:INFO:Creating metrics dataframe
2025-10-19 01:39:28,078:INFO:Finalizing model
2025-10-19 01:39:30,830:INFO:Uploading results into container
2025-10-19 01:39:30,831:INFO:Uploading model into container now
2025-10-19 01:39:30,831:INFO:_master_model_container: 21
2025-10-19 01:39:30,831:INFO:_display_container: 6
2025-10-19 01:39:30,831:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 01:39:30,831:INFO:create_model() successfully completed......................................
2025-10-19 01:39:31,036:INFO:SubProcess create_model() end ==================================
2025-10-19 01:39:31,036:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.931
2025-10-19 01:39:31,036:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9311
2025-10-19 01:39:31,037:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) is best model
2025-10-19 01:39:31,037:INFO:choose_better completed
2025-10-19 01:39:31,046:INFO:_master_model_container: 21
2025-10-19 01:39:31,047:INFO:_display_container: 5
2025-10-19 01:39:31,047:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 01:39:31,047:INFO:tune_model() successfully completed......................................
2025-10-19 01:39:31,274:INFO:Initializing blend_models()
2025-10-19 01:39:31,274:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-19 01:39:31,274:INFO:Checking exceptions
2025-10-19 01:39:31,274:INFO:Estimator RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-19 01:39:31,303:INFO:Importing libraries
2025-10-19 01:39:31,303:INFO:Copying training dataset
2025-10-19 01:39:31,308:INFO:Getting model names
2025-10-19 01:39:31,314:INFO:SubProcess create_model() called ==================================
2025-10-19 01:39:31,321:INFO:Initializing create_model()
2025-10-19 01:39:31,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002127DDAD710>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             num_leaves=40, objective=None,
                                             random_state=42, reg_alpha=2,
                                             reg_lambda=0.001, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=7.3, class_weight=None,
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: category
Categories (9586, object): ['U00003', 'U00004', 'U00005', 'U00006', ..., 'U11997', 'U11998', 'U11999', 'U12000'], refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002127D743FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:39:31,322:INFO:Checking exceptions
2025-10-19 01:39:31,322:INFO:Importing libraries
2025-10-19 01:39:31,322:INFO:Copying training dataset
2025-10-19 01:39:31,366:INFO:Defining folds
2025-10-19 01:39:31,367:INFO:Declaring metric variables
2025-10-19 01:39:31,371:INFO:Importing untrained model
2025-10-19 01:39:31,372:INFO:Declaring custom model
2025-10-19 01:39:31,380:INFO:Voting Classifier Imported successfully
2025-10-19 01:39:31,388:INFO:Starting cross validation
2025-10-19 01:39:31,393:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 01:40:33,502:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-19 01:40:33,522:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-19 01:40:33,542:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-19 01:40:33,781:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-19 01:40:33,802:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2025-10-19 01:40:33,837:INFO:Calculating mean and std
2025-10-19 01:40:33,840:INFO:Creating metrics dataframe
2025-10-19 01:40:33,849:INFO:Finalizing model
2025-10-19 01:43:24,224:INFO:PyCaret ClassificationExperiment
2025-10-19 01:43:24,224:INFO:Logging name: clf-default-name
2025-10-19 01:43:24,226:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 01:43:24,226:INFO:version 3.3.2
2025-10-19 01:43:24,226:INFO:Initializing setup()
2025-10-19 01:43:24,226:INFO:self.USI: 2fd1
2025-10-19 01:43:24,226:INFO:self._variable_keys: {'USI', 'seed', 'memory', 'html_param', 'X_test', 'target_param', 'logging_param', 'fold_groups_param', 'exp_id', 'exp_name_log', 'fix_imbalance', 'is_multiclass', 'log_plots_param', 'y_train', 'y', 'X', 'fold_generator', 'fold_shuffle_param', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', '_available_plots', 'idx', 'data', 'pipeline', 'X_train', '_ml_usecase', 'y_test'}
2025-10-19 01:43:24,226:INFO:Checking environment
2025-10-19 01:43:24,226:INFO:python_version: 3.11.13
2025-10-19 01:43:24,226:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 01:43:24,226:INFO:machine: AMD64
2025-10-19 01:43:24,226:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 01:43:24,233:INFO:Memory: svmem(total=16856211456, available=4968230912, percent=70.5, used=11887980544, free=4968230912)
2025-10-19 01:43:24,233:INFO:Physical Core: 4
2025-10-19 01:43:24,233:INFO:Logical Core: 8
2025-10-19 01:43:24,234:INFO:Checking libraries
2025-10-19 01:43:24,234:INFO:System:
2025-10-19 01:43:24,234:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 01:43:24,234:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 01:43:24,234:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 01:43:24,234:INFO:PyCaret required dependencies:
2025-10-19 01:43:24,234:INFO:                 pip: 25.2
2025-10-19 01:43:24,234:INFO:          setuptools: 80.9.0
2025-10-19 01:43:24,234:INFO:             pycaret: 3.3.2
2025-10-19 01:43:24,234:INFO:             IPython: 9.6.0
2025-10-19 01:43:24,234:INFO:          ipywidgets: 8.1.7
2025-10-19 01:43:24,234:INFO:                tqdm: 4.67.1
2025-10-19 01:43:24,234:INFO:               numpy: 1.26.4
2025-10-19 01:43:24,234:INFO:              pandas: 2.1.4
2025-10-19 01:43:24,234:INFO:              jinja2: 3.1.6
2025-10-19 01:43:24,234:INFO:               scipy: 1.11.4
2025-10-19 01:43:24,234:INFO:              joblib: 1.3.2
2025-10-19 01:43:24,234:INFO:             sklearn: 1.4.2
2025-10-19 01:43:24,234:INFO:                pyod: 2.0.5
2025-10-19 01:43:24,234:INFO:            imblearn: 0.14.0
2025-10-19 01:43:24,234:INFO:   category_encoders: 2.7.0
2025-10-19 01:43:24,234:INFO:            lightgbm: 4.6.0
2025-10-19 01:43:24,234:INFO:               numba: 0.61.0
2025-10-19 01:43:24,235:INFO:            requests: 2.32.5
2025-10-19 01:43:24,235:INFO:          matplotlib: 3.7.5
2025-10-19 01:43:24,235:INFO:          scikitplot: 0.3.7
2025-10-19 01:43:24,235:INFO:         yellowbrick: 1.5
2025-10-19 01:43:24,235:INFO:              plotly: 5.24.1
2025-10-19 01:43:24,235:INFO:    plotly-resampler: Not installed
2025-10-19 01:43:24,235:INFO:             kaleido: 1.1.0
2025-10-19 01:43:24,235:INFO:           schemdraw: 0.15
2025-10-19 01:43:24,235:INFO:         statsmodels: 0.14.5
2025-10-19 01:43:24,235:INFO:              sktime: 0.26.0
2025-10-19 01:43:24,235:INFO:               tbats: 1.1.3
2025-10-19 01:43:24,235:INFO:            pmdarima: 2.0.4
2025-10-19 01:43:24,235:INFO:              psutil: 7.1.0
2025-10-19 01:43:24,235:INFO:          markupsafe: 3.0.3
2025-10-19 01:43:24,235:INFO:             pickle5: Not installed
2025-10-19 01:43:24,235:INFO:         cloudpickle: 3.1.1
2025-10-19 01:43:24,235:INFO:         deprecation: 2.1.0
2025-10-19 01:43:24,235:INFO:              xxhash: 3.6.0
2025-10-19 01:43:24,235:INFO:           wurlitzer: Not installed
2025-10-19 01:43:24,235:INFO:PyCaret optional dependencies:
2025-10-19 01:43:24,236:INFO:                shap: 0.44.1
2025-10-19 01:43:24,236:INFO:           interpret: 0.7.3
2025-10-19 01:43:24,236:INFO:                umap: 0.5.7
2025-10-19 01:43:24,236:INFO:     ydata_profiling: 4.17.0
2025-10-19 01:43:24,236:INFO:  explainerdashboard: 0.5.1
2025-10-19 01:43:24,236:INFO:             autoviz: Not installed
2025-10-19 01:43:24,236:INFO:           fairlearn: 0.7.0
2025-10-19 01:43:24,236:INFO:          deepchecks: Not installed
2025-10-19 01:43:24,236:INFO:             xgboost: Not installed
2025-10-19 01:43:24,236:INFO:            catboost: 1.2.8
2025-10-19 01:43:24,236:INFO:              kmodes: 0.12.2
2025-10-19 01:43:24,236:INFO:             mlxtend: 0.23.4
2025-10-19 01:43:24,236:INFO:       statsforecast: 1.5.0
2025-10-19 01:43:24,236:INFO:        tune_sklearn: Not installed
2025-10-19 01:43:24,236:INFO:                 ray: Not installed
2025-10-19 01:43:24,236:INFO:            hyperopt: 0.2.7
2025-10-19 01:43:24,236:INFO:              optuna: 4.5.0
2025-10-19 01:43:24,237:INFO:               skopt: 0.10.2
2025-10-19 01:43:24,237:INFO:              mlflow: 3.5.0
2025-10-19 01:43:24,237:INFO:              gradio: 5.49.1
2025-10-19 01:43:24,237:INFO:             fastapi: 0.119.0
2025-10-19 01:43:24,237:INFO:             uvicorn: 0.38.0
2025-10-19 01:43:24,237:INFO:              m2cgen: 0.10.0
2025-10-19 01:43:24,237:INFO:           evidently: 0.4.40
2025-10-19 01:43:24,237:INFO:               fugue: 0.8.7
2025-10-19 01:43:24,237:INFO:           streamlit: Not installed
2025-10-19 01:43:24,237:INFO:             prophet: Not installed
2025-10-19 01:43:24,237:INFO:None
2025-10-19 01:43:24,237:INFO:Set up data.
2025-10-19 01:43:24,398:INFO:Set up folding strategy.
2025-10-19 01:43:24,640:INFO:Set up train/test split.
2025-10-19 01:43:24,845:INFO:Set up index.
2025-10-19 01:43:24,861:INFO:Assigning column types.
2025-10-19 01:43:25,126:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 01:43:25,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 01:43:25,177:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:43:25,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:43:25,207:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:43:25,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 01:43:25,256:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:43:25,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:43:25,292:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:43:25,293:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 01:43:25,341:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:43:25,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:43:25,367:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:43:25,413:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 01:43:25,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:43:25,445:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:43:25,446:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 01:43:25,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:43:25,515:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:43:25,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:43:25,590:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:43:25,591:INFO:Preparing preprocessing pipeline...
2025-10-19 01:43:25,625:INFO:Set up simple imputation.
2025-10-19 01:43:25,772:INFO:Set up encoding of ordinal features.
2025-10-19 01:43:25,845:INFO:Set up encoding of categorical features.
2025-10-19 01:43:25,849:INFO:Set up removing multicollinearity.
2025-10-19 01:43:25,881:INFO:Set up column name cleaning.
2025-10-19 01:43:29,956:INFO:Finished creating preprocessing pipeline.
2025-10-19 01:43:29,973:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 01:43:29,973:INFO:Creating final display dataframe.
2025-10-19 01:43:32,992:INFO:Setup _display_container:                     Description             Value
0                    Session id              5654
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (63955, 28)
4        Transformed data shape       (63955, 96)
5   Transformed train set shape       (44768, 96)
6    Transformed test set shape       (19187, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              2fd1
2025-10-19 01:43:33,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:43:33,061:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:43:33,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 01:43:33,133:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 01:43:33,137:INFO:setup() successfully completed in 8.92s...............
2025-10-19 01:43:33,138:INFO:Initializing compare_models()
2025-10-19 01:43:33,138:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 01:43:33,138:INFO:Checking exceptions
2025-10-19 01:43:33,278:INFO:Preparing display monitor
2025-10-19 01:43:33,326:INFO:Initializing Logistic Regression
2025-10-19 01:43:33,326:INFO:Total runtime is 0.0 minutes
2025-10-19 01:43:33,378:INFO:SubProcess create_model() called ==================================
2025-10-19 01:43:33,379:INFO:Initializing create_model()
2025-10-19 01:43:33,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:43:33,379:INFO:Checking exceptions
2025-10-19 01:43:33,379:INFO:Importing libraries
2025-10-19 01:43:33,379:INFO:Copying training dataset
2025-10-19 01:43:33,610:INFO:Defining folds
2025-10-19 01:43:33,610:INFO:Declaring metric variables
2025-10-19 01:43:33,613:INFO:Importing untrained model
2025-10-19 01:43:33,617:INFO:Logistic Regression Imported successfully
2025-10-19 01:43:33,625:INFO:Starting cross validation
2025-10-19 01:43:33,630:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:43:41,935:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 01:43:51,790:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 01:44:03,443:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 01:44:11,830:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 01:44:19,747:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 01:44:19,999:INFO:Calculating mean and std
2025-10-19 01:44:20,000:INFO:Creating metrics dataframe
2025-10-19 01:44:20,001:INFO:Uploading results into container
2025-10-19 01:44:20,002:INFO:Uploading model into container now
2025-10-19 01:44:20,002:INFO:_master_model_container: 1
2025-10-19 01:44:20,002:INFO:_display_container: 2
2025-10-19 01:44:20,002:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5654, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 01:44:20,002:INFO:create_model() successfully completed......................................
2025-10-19 01:44:20,258:INFO:SubProcess create_model() end ==================================
2025-10-19 01:44:20,258:INFO:Creating metrics dataframe
2025-10-19 01:44:20,266:INFO:Initializing K Neighbors Classifier
2025-10-19 01:44:20,266:INFO:Total runtime is 0.7823221166928609 minutes
2025-10-19 01:44:20,270:INFO:SubProcess create_model() called ==================================
2025-10-19 01:44:20,272:INFO:Initializing create_model()
2025-10-19 01:44:20,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:44:20,272:INFO:Checking exceptions
2025-10-19 01:44:20,272:INFO:Importing libraries
2025-10-19 01:44:20,272:INFO:Copying training dataset
2025-10-19 01:44:20,468:INFO:Defining folds
2025-10-19 01:44:20,468:INFO:Declaring metric variables
2025-10-19 01:44:20,472:INFO:Importing untrained model
2025-10-19 01:44:20,478:INFO:K Neighbors Classifier Imported successfully
2025-10-19 01:44:20,485:INFO:Starting cross validation
2025-10-19 01:44:20,489:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:44:41,932:INFO:Calculating mean and std
2025-10-19 01:44:41,934:INFO:Creating metrics dataframe
2025-10-19 01:44:41,936:INFO:Uploading results into container
2025-10-19 01:44:41,937:INFO:Uploading model into container now
2025-10-19 01:44:41,937:INFO:_master_model_container: 2
2025-10-19 01:44:41,937:INFO:_display_container: 2
2025-10-19 01:44:41,938:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 01:44:41,938:INFO:create_model() successfully completed......................................
2025-10-19 01:44:42,184:INFO:SubProcess create_model() end ==================================
2025-10-19 01:44:42,184:INFO:Creating metrics dataframe
2025-10-19 01:44:42,190:INFO:Initializing Naive Bayes
2025-10-19 01:44:42,191:INFO:Total runtime is 1.1477384130160013 minutes
2025-10-19 01:44:42,195:INFO:SubProcess create_model() called ==================================
2025-10-19 01:44:42,197:INFO:Initializing create_model()
2025-10-19 01:44:42,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:44:42,197:INFO:Checking exceptions
2025-10-19 01:44:42,197:INFO:Importing libraries
2025-10-19 01:44:42,198:INFO:Copying training dataset
2025-10-19 01:44:42,420:INFO:Defining folds
2025-10-19 01:44:42,421:INFO:Declaring metric variables
2025-10-19 01:44:42,423:INFO:Importing untrained model
2025-10-19 01:44:42,428:INFO:Naive Bayes Imported successfully
2025-10-19 01:44:42,437:INFO:Starting cross validation
2025-10-19 01:44:42,443:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:44:49,446:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 01:44:51,824:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 01:44:54,290:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 01:44:54,306:INFO:Calculating mean and std
2025-10-19 01:44:54,308:INFO:Creating metrics dataframe
2025-10-19 01:44:54,310:INFO:Uploading results into container
2025-10-19 01:44:54,311:INFO:Uploading model into container now
2025-10-19 01:44:54,312:INFO:_master_model_container: 3
2025-10-19 01:44:54,312:INFO:_display_container: 2
2025-10-19 01:44:54,313:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 01:44:54,313:INFO:create_model() successfully completed......................................
2025-10-19 01:44:54,565:INFO:SubProcess create_model() end ==================================
2025-10-19 01:44:54,565:INFO:Creating metrics dataframe
2025-10-19 01:44:54,573:INFO:Initializing Decision Tree Classifier
2025-10-19 01:44:54,573:INFO:Total runtime is 1.3541199326515196 minutes
2025-10-19 01:44:54,577:INFO:SubProcess create_model() called ==================================
2025-10-19 01:44:54,578:INFO:Initializing create_model()
2025-10-19 01:44:54,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:44:54,578:INFO:Checking exceptions
2025-10-19 01:44:54,578:INFO:Importing libraries
2025-10-19 01:44:54,579:INFO:Copying training dataset
2025-10-19 01:44:54,793:INFO:Defining folds
2025-10-19 01:44:54,793:INFO:Declaring metric variables
2025-10-19 01:44:54,797:INFO:Importing untrained model
2025-10-19 01:44:54,803:INFO:Decision Tree Classifier Imported successfully
2025-10-19 01:44:54,811:INFO:Starting cross validation
2025-10-19 01:44:54,816:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:45:10,206:INFO:Calculating mean and std
2025-10-19 01:45:10,207:INFO:Creating metrics dataframe
2025-10-19 01:45:10,209:INFO:Uploading results into container
2025-10-19 01:45:10,209:INFO:Uploading model into container now
2025-10-19 01:45:10,209:INFO:_master_model_container: 4
2025-10-19 01:45:10,210:INFO:_display_container: 2
2025-10-19 01:45:10,210:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5654, splitter='best')
2025-10-19 01:45:10,210:INFO:create_model() successfully completed......................................
2025-10-19 01:45:10,445:INFO:SubProcess create_model() end ==================================
2025-10-19 01:45:10,445:INFO:Creating metrics dataframe
2025-10-19 01:45:10,455:INFO:Initializing SVM - Linear Kernel
2025-10-19 01:45:10,456:INFO:Total runtime is 1.618823985258738 minutes
2025-10-19 01:45:10,460:INFO:SubProcess create_model() called ==================================
2025-10-19 01:45:10,461:INFO:Initializing create_model()
2025-10-19 01:45:10,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:45:10,461:INFO:Checking exceptions
2025-10-19 01:45:10,461:INFO:Importing libraries
2025-10-19 01:45:10,461:INFO:Copying training dataset
2025-10-19 01:45:10,674:INFO:Defining folds
2025-10-19 01:45:10,674:INFO:Declaring metric variables
2025-10-19 01:45:10,677:INFO:Importing untrained model
2025-10-19 01:45:10,682:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 01:45:10,693:INFO:Starting cross validation
2025-10-19 01:45:10,697:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:45:17,092:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 01:45:35,702:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 01:45:42,872:INFO:Calculating mean and std
2025-10-19 01:45:42,874:INFO:Creating metrics dataframe
2025-10-19 01:45:42,876:INFO:Uploading results into container
2025-10-19 01:45:42,877:INFO:Uploading model into container now
2025-10-19 01:45:42,878:INFO:_master_model_container: 5
2025-10-19 01:45:42,878:INFO:_display_container: 2
2025-10-19 01:45:42,879:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=5654, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 01:45:42,880:INFO:create_model() successfully completed......................................
2025-10-19 01:45:43,110:INFO:SubProcess create_model() end ==================================
2025-10-19 01:45:43,110:INFO:Creating metrics dataframe
2025-10-19 01:45:43,117:INFO:Initializing Ridge Classifier
2025-10-19 01:45:43,117:INFO:Total runtime is 2.1631866971651714 minutes
2025-10-19 01:45:43,122:INFO:SubProcess create_model() called ==================================
2025-10-19 01:45:43,123:INFO:Initializing create_model()
2025-10-19 01:45:43,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:45:43,124:INFO:Checking exceptions
2025-10-19 01:45:43,124:INFO:Importing libraries
2025-10-19 01:45:43,124:INFO:Copying training dataset
2025-10-19 01:45:43,376:INFO:Defining folds
2025-10-19 01:45:43,376:INFO:Declaring metric variables
2025-10-19 01:45:43,379:INFO:Importing untrained model
2025-10-19 01:45:43,383:INFO:Ridge Classifier Imported successfully
2025-10-19 01:45:43,392:INFO:Starting cross validation
2025-10-19 01:45:43,396:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:45:54,984:INFO:Calculating mean and std
2025-10-19 01:45:54,985:INFO:Creating metrics dataframe
2025-10-19 01:45:54,987:INFO:Uploading results into container
2025-10-19 01:45:54,987:INFO:Uploading model into container now
2025-10-19 01:45:54,988:INFO:_master_model_container: 6
2025-10-19 01:45:54,988:INFO:_display_container: 2
2025-10-19 01:45:54,988:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001)
2025-10-19 01:45:54,988:INFO:create_model() successfully completed......................................
2025-10-19 01:45:55,232:INFO:SubProcess create_model() end ==================================
2025-10-19 01:45:55,232:INFO:Creating metrics dataframe
2025-10-19 01:45:55,244:INFO:Initializing Random Forest Classifier
2025-10-19 01:45:55,244:INFO:Total runtime is 2.3652913769086203 minutes
2025-10-19 01:45:55,249:INFO:SubProcess create_model() called ==================================
2025-10-19 01:45:55,250:INFO:Initializing create_model()
2025-10-19 01:45:55,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:45:55,251:INFO:Checking exceptions
2025-10-19 01:45:55,251:INFO:Importing libraries
2025-10-19 01:45:55,251:INFO:Copying training dataset
2025-10-19 01:45:55,449:INFO:Defining folds
2025-10-19 01:45:55,449:INFO:Declaring metric variables
2025-10-19 01:45:55,455:INFO:Importing untrained model
2025-10-19 01:45:55,461:INFO:Random Forest Classifier Imported successfully
2025-10-19 01:45:55,467:INFO:Starting cross validation
2025-10-19 01:45:55,474:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:46:36,693:INFO:Calculating mean and std
2025-10-19 01:46:36,694:INFO:Creating metrics dataframe
2025-10-19 01:46:36,697:INFO:Uploading results into container
2025-10-19 01:46:36,698:INFO:Uploading model into container now
2025-10-19 01:46:36,698:INFO:_master_model_container: 7
2025-10-19 01:46:36,699:INFO:_display_container: 2
2025-10-19 01:46:36,699:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=5654, verbose=0,
                       warm_start=False)
2025-10-19 01:46:36,699:INFO:create_model() successfully completed......................................
2025-10-19 01:46:36,986:INFO:SubProcess create_model() end ==================================
2025-10-19 01:46:36,986:INFO:Creating metrics dataframe
2025-10-19 01:46:37,000:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 01:46:37,000:INFO:Total runtime is 3.061225398381551 minutes
2025-10-19 01:46:37,004:INFO:SubProcess create_model() called ==================================
2025-10-19 01:46:37,004:INFO:Initializing create_model()
2025-10-19 01:46:37,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:46:37,005:INFO:Checking exceptions
2025-10-19 01:46:37,005:INFO:Importing libraries
2025-10-19 01:46:37,005:INFO:Copying training dataset
2025-10-19 01:46:37,226:INFO:Defining folds
2025-10-19 01:46:37,227:INFO:Declaring metric variables
2025-10-19 01:46:37,233:INFO:Importing untrained model
2025-10-19 01:46:37,238:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 01:46:37,244:INFO:Starting cross validation
2025-10-19 01:46:37,251:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:46:39,788:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 01:46:42,637:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 01:46:45,326:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 01:46:48,007:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 01:46:50,804:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 01:46:51,169:INFO:Calculating mean and std
2025-10-19 01:46:51,170:INFO:Creating metrics dataframe
2025-10-19 01:46:51,172:INFO:Uploading results into container
2025-10-19 01:46:51,173:INFO:Uploading model into container now
2025-10-19 01:46:51,173:INFO:_master_model_container: 8
2025-10-19 01:46:51,174:INFO:_display_container: 2
2025-10-19 01:46:51,174:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 01:46:51,174:INFO:create_model() successfully completed......................................
2025-10-19 01:46:51,409:INFO:SubProcess create_model() end ==================================
2025-10-19 01:46:51,410:INFO:Creating metrics dataframe
2025-10-19 01:46:51,419:INFO:Initializing Ada Boost Classifier
2025-10-19 01:46:51,419:INFO:Total runtime is 3.3015382488568625 minutes
2025-10-19 01:46:51,422:INFO:SubProcess create_model() called ==================================
2025-10-19 01:46:51,423:INFO:Initializing create_model()
2025-10-19 01:46:51,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:46:51,423:INFO:Checking exceptions
2025-10-19 01:46:51,423:INFO:Importing libraries
2025-10-19 01:46:51,424:INFO:Copying training dataset
2025-10-19 01:46:51,654:INFO:Defining folds
2025-10-19 01:46:51,654:INFO:Declaring metric variables
2025-10-19 01:46:51,658:INFO:Importing untrained model
2025-10-19 01:46:51,663:INFO:Ada Boost Classifier Imported successfully
2025-10-19 01:46:51,675:INFO:Starting cross validation
2025-10-19 01:46:51,680:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:46:53,958:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 01:46:59,457:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 01:47:05,231:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 01:47:10,676:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 01:47:15,939:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 01:47:19,131:INFO:Calculating mean and std
2025-10-19 01:47:19,133:INFO:Creating metrics dataframe
2025-10-19 01:47:19,134:INFO:Uploading results into container
2025-10-19 01:47:19,135:INFO:Uploading model into container now
2025-10-19 01:47:19,135:INFO:_master_model_container: 9
2025-10-19 01:47:19,135:INFO:_display_container: 2
2025-10-19 01:47:19,136:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5654)
2025-10-19 01:47:19,136:INFO:create_model() successfully completed......................................
2025-10-19 01:47:19,390:INFO:SubProcess create_model() end ==================================
2025-10-19 01:47:19,390:INFO:Creating metrics dataframe
2025-10-19 01:47:19,402:INFO:Initializing Gradient Boosting Classifier
2025-10-19 01:47:19,402:INFO:Total runtime is 3.767935077349345 minutes
2025-10-19 01:47:19,408:INFO:SubProcess create_model() called ==================================
2025-10-19 01:47:19,409:INFO:Initializing create_model()
2025-10-19 01:47:19,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:47:19,409:INFO:Checking exceptions
2025-10-19 01:47:19,410:INFO:Importing libraries
2025-10-19 01:47:19,410:INFO:Copying training dataset
2025-10-19 01:47:19,632:INFO:Defining folds
2025-10-19 01:47:19,633:INFO:Declaring metric variables
2025-10-19 01:47:19,641:INFO:Importing untrained model
2025-10-19 01:47:19,647:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 01:47:19,658:INFO:Starting cross validation
2025-10-19 01:47:19,663:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:48:14,021:INFO:Calculating mean and std
2025-10-19 01:48:14,022:INFO:Creating metrics dataframe
2025-10-19 01:48:14,025:INFO:Uploading results into container
2025-10-19 01:48:14,026:INFO:Uploading model into container now
2025-10-19 01:48:14,027:INFO:_master_model_container: 10
2025-10-19 01:48:14,027:INFO:_display_container: 2
2025-10-19 01:48:14,028:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 01:48:14,028:INFO:create_model() successfully completed......................................
2025-10-19 01:48:14,270:INFO:SubProcess create_model() end ==================================
2025-10-19 01:48:14,270:INFO:Creating metrics dataframe
2025-10-19 01:48:14,279:INFO:Initializing Linear Discriminant Analysis
2025-10-19 01:48:14,279:INFO:Total runtime is 4.68253835439682 minutes
2025-10-19 01:48:14,283:INFO:SubProcess create_model() called ==================================
2025-10-19 01:48:14,284:INFO:Initializing create_model()
2025-10-19 01:48:14,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:48:14,285:INFO:Checking exceptions
2025-10-19 01:48:14,285:INFO:Importing libraries
2025-10-19 01:48:14,285:INFO:Copying training dataset
2025-10-19 01:48:14,477:INFO:Defining folds
2025-10-19 01:48:14,477:INFO:Declaring metric variables
2025-10-19 01:48:14,481:INFO:Importing untrained model
2025-10-19 01:48:14,487:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 01:48:14,494:INFO:Starting cross validation
2025-10-19 01:48:14,500:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:48:29,130:INFO:Calculating mean and std
2025-10-19 01:48:29,132:INFO:Creating metrics dataframe
2025-10-19 01:48:29,134:INFO:Uploading results into container
2025-10-19 01:48:29,135:INFO:Uploading model into container now
2025-10-19 01:48:29,135:INFO:_master_model_container: 11
2025-10-19 01:48:29,136:INFO:_display_container: 2
2025-10-19 01:48:29,136:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 01:48:29,137:INFO:create_model() successfully completed......................................
2025-10-19 01:48:29,387:INFO:SubProcess create_model() end ==================================
2025-10-19 01:48:29,387:INFO:Creating metrics dataframe
2025-10-19 01:48:29,399:INFO:Initializing Extra Trees Classifier
2025-10-19 01:48:29,399:INFO:Total runtime is 4.934549311796824 minutes
2025-10-19 01:48:29,403:INFO:SubProcess create_model() called ==================================
2025-10-19 01:48:29,404:INFO:Initializing create_model()
2025-10-19 01:48:29,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:48:29,404:INFO:Checking exceptions
2025-10-19 01:48:29,404:INFO:Importing libraries
2025-10-19 01:48:29,404:INFO:Copying training dataset
2025-10-19 01:48:29,626:INFO:Defining folds
2025-10-19 01:48:29,627:INFO:Declaring metric variables
2025-10-19 01:48:29,633:INFO:Importing untrained model
2025-10-19 01:48:29,637:INFO:Extra Trees Classifier Imported successfully
2025-10-19 01:48:29,645:INFO:Starting cross validation
2025-10-19 01:48:29,652:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:49:17,716:INFO:Calculating mean and std
2025-10-19 01:49:17,718:INFO:Creating metrics dataframe
2025-10-19 01:49:17,722:INFO:Uploading results into container
2025-10-19 01:49:17,723:INFO:Uploading model into container now
2025-10-19 01:49:17,724:INFO:_master_model_container: 12
2025-10-19 01:49:17,724:INFO:_display_container: 2
2025-10-19 01:49:17,725:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=5654, verbose=0,
                     warm_start=False)
2025-10-19 01:49:17,725:INFO:create_model() successfully completed......................................
2025-10-19 01:49:17,983:INFO:SubProcess create_model() end ==================================
2025-10-19 01:49:17,983:INFO:Creating metrics dataframe
2025-10-19 01:49:17,995:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 01:49:17,995:INFO:Total runtime is 5.744484555721283 minutes
2025-10-19 01:49:17,998:INFO:SubProcess create_model() called ==================================
2025-10-19 01:49:18,000:INFO:Initializing create_model()
2025-10-19 01:49:18,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:49:18,000:INFO:Checking exceptions
2025-10-19 01:49:18,000:INFO:Importing libraries
2025-10-19 01:49:18,000:INFO:Copying training dataset
2025-10-19 01:49:18,238:INFO:Defining folds
2025-10-19 01:49:18,238:INFO:Declaring metric variables
2025-10-19 01:49:18,243:INFO:Importing untrained model
2025-10-19 01:49:18,247:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 01:49:18,256:INFO:Starting cross validation
2025-10-19 01:49:18,262:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:49:20,631:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 01:49:20,633:INFO:[LightGBM] [Info] Number of positive: 7344, number of negative: 28470
2025-10-19 01:49:20,648:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005546 seconds.
2025-10-19 01:49:20,649:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 01:49:20,649:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 01:49:20,649:INFO:[LightGBM] [Info] Total Bins 1407
2025-10-19 01:49:20,649:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 01:49:20,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205059 -> initscore=-1.354967
2025-10-19 01:49:20,650:INFO:[LightGBM] [Info] Start training from score -1.354967
2025-10-19 01:49:23,742:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 01:49:23,743:INFO:[LightGBM] [Info] Number of positive: 7356, number of negative: 28458
2025-10-19 01:49:23,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007582 seconds.
2025-10-19 01:49:23,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 01:49:23,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 01:49:23,764:INFO:[LightGBM] [Info] Total Bins 1406
2025-10-19 01:49:23,764:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 01:49:23,764:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205395 -> initscore=-1.352913
2025-10-19 01:49:23,764:INFO:[LightGBM] [Info] Start training from score -1.352913
2025-10-19 01:49:26,882:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 01:49:26,883:INFO:[LightGBM] [Info] Number of positive: 7379, number of negative: 28435
2025-10-19 01:49:26,905:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009945 seconds.
2025-10-19 01:49:26,905:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 01:49:26,905:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 01:49:26,905:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 01:49:26,905:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 01:49:26,906:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206037 -> initscore=-1.348983
2025-10-19 01:49:26,906:INFO:[LightGBM] [Info] Start training from score -1.348983
2025-10-19 01:49:29,982:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 01:49:29,985:INFO:[LightGBM] [Info] Number of positive: 7400, number of negative: 28415
2025-10-19 01:49:30,002:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007004 seconds.
2025-10-19 01:49:30,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 01:49:30,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 01:49:30,003:INFO:[LightGBM] [Info] Total Bins 1406
2025-10-19 01:49:30,003:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 01:49:30,004:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206617 -> initscore=-1.345437
2025-10-19 01:49:30,004:INFO:[LightGBM] [Info] Start training from score -1.345437
2025-10-19 01:49:33,447:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 01:49:33,449:INFO:[LightGBM] [Info] Number of positive: 7297, number of negative: 28518
2025-10-19 01:49:33,466:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006679 seconds.
2025-10-19 01:49:33,466:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 01:49:33,466:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 01:49:33,467:INFO:[LightGBM] [Info] Total Bins 1406
2025-10-19 01:49:33,467:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 01:49:33,467:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203741 -> initscore=-1.363072
2025-10-19 01:49:33,467:INFO:[LightGBM] [Info] Start training from score -1.363072
2025-10-19 01:49:34,294:INFO:Calculating mean and std
2025-10-19 01:49:34,295:INFO:Creating metrics dataframe
2025-10-19 01:49:34,297:INFO:Uploading results into container
2025-10-19 01:49:34,297:INFO:Uploading model into container now
2025-10-19 01:49:34,297:INFO:_master_model_container: 13
2025-10-19 01:49:34,298:INFO:_display_container: 2
2025-10-19 01:49:34,298:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=5654, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 01:49:34,298:INFO:create_model() successfully completed......................................
2025-10-19 01:49:34,564:INFO:SubProcess create_model() end ==================================
2025-10-19 01:49:34,564:INFO:Creating metrics dataframe
2025-10-19 01:49:34,577:INFO:Initializing CatBoost Classifier
2025-10-19 01:49:34,577:INFO:Total runtime is 6.0208510756492615 minutes
2025-10-19 01:49:34,581:INFO:SubProcess create_model() called ==================================
2025-10-19 01:49:34,582:INFO:Initializing create_model()
2025-10-19 01:49:34,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:49:34,582:INFO:Checking exceptions
2025-10-19 01:49:34,582:INFO:Importing libraries
2025-10-19 01:49:34,582:INFO:Copying training dataset
2025-10-19 01:49:34,810:INFO:Defining folds
2025-10-19 01:49:34,810:INFO:Declaring metric variables
2025-10-19 01:49:34,815:INFO:Importing untrained model
2025-10-19 01:49:34,819:INFO:CatBoost Classifier Imported successfully
2025-10-19 01:49:34,828:INFO:Starting cross validation
2025-10-19 01:49:34,834:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:51:55,171:INFO:Calculating mean and std
2025-10-19 01:51:55,173:INFO:Creating metrics dataframe
2025-10-19 01:51:55,175:INFO:Uploading results into container
2025-10-19 01:51:55,176:INFO:Uploading model into container now
2025-10-19 01:51:55,176:INFO:_master_model_container: 14
2025-10-19 01:51:55,176:INFO:_display_container: 2
2025-10-19 01:51:55,176:INFO:<catboost.core.CatBoostClassifier object at 0x000002120E82C0D0>
2025-10-19 01:51:55,176:INFO:create_model() successfully completed......................................
2025-10-19 01:51:55,430:INFO:SubProcess create_model() end ==================================
2025-10-19 01:51:55,431:INFO:Creating metrics dataframe
2025-10-19 01:51:55,441:INFO:Initializing Dummy Classifier
2025-10-19 01:51:55,442:INFO:Total runtime is 8.368600944677988 minutes
2025-10-19 01:51:55,446:INFO:SubProcess create_model() called ==================================
2025-10-19 01:51:55,447:INFO:Initializing create_model()
2025-10-19 01:51:55,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120EB71790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:51:55,447:INFO:Checking exceptions
2025-10-19 01:51:55,447:INFO:Importing libraries
2025-10-19 01:51:55,447:INFO:Copying training dataset
2025-10-19 01:51:55,651:INFO:Defining folds
2025-10-19 01:51:55,652:INFO:Declaring metric variables
2025-10-19 01:51:55,654:INFO:Importing untrained model
2025-10-19 01:51:55,662:INFO:Dummy Classifier Imported successfully
2025-10-19 01:51:55,670:INFO:Starting cross validation
2025-10-19 01:51:55,673:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 01:51:58,073:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 01:52:00,484:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 01:52:02,867:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 01:52:05,295:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 01:52:07,701:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 01:52:07,717:INFO:Calculating mean and std
2025-10-19 01:52:07,718:INFO:Creating metrics dataframe
2025-10-19 01:52:07,721:INFO:Uploading results into container
2025-10-19 01:52:07,722:INFO:Uploading model into container now
2025-10-19 01:52:07,722:INFO:_master_model_container: 15
2025-10-19 01:52:07,723:INFO:_display_container: 2
2025-10-19 01:52:07,723:INFO:DummyClassifier(constant=None, random_state=5654, strategy='prior')
2025-10-19 01:52:07,723:INFO:create_model() successfully completed......................................
2025-10-19 01:52:07,964:INFO:SubProcess create_model() end ==================================
2025-10-19 01:52:07,965:INFO:Creating metrics dataframe
2025-10-19 01:52:07,978:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 01:52:07,991:INFO:Initializing create_model()
2025-10-19 01:52:07,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:52:07,991:INFO:Checking exceptions
2025-10-19 01:52:07,994:INFO:Importing libraries
2025-10-19 01:52:07,994:INFO:Copying training dataset
2025-10-19 01:52:08,196:INFO:Defining folds
2025-10-19 01:52:08,196:INFO:Declaring metric variables
2025-10-19 01:52:08,196:INFO:Importing untrained model
2025-10-19 01:52:08,196:INFO:Declaring custom model
2025-10-19 01:52:08,197:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 01:52:08,200:INFO:Cross validation set to False
2025-10-19 01:52:08,200:INFO:Fitting Model
2025-10-19 01:52:20,496:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 01:52:20,496:INFO:create_model() successfully completed......................................
2025-10-19 01:52:20,727:INFO:Initializing create_model()
2025-10-19 01:52:20,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:52:20,728:INFO:Checking exceptions
2025-10-19 01:52:20,730:INFO:Importing libraries
2025-10-19 01:52:20,730:INFO:Copying training dataset
2025-10-19 01:52:20,915:INFO:Defining folds
2025-10-19 01:52:20,916:INFO:Declaring metric variables
2025-10-19 01:52:20,916:INFO:Importing untrained model
2025-10-19 01:52:20,916:INFO:Declaring custom model
2025-10-19 01:52:20,916:INFO:Ridge Classifier Imported successfully
2025-10-19 01:52:20,919:INFO:Cross validation set to False
2025-10-19 01:52:20,919:INFO:Fitting Model
2025-10-19 01:52:23,583:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001)
2025-10-19 01:52:23,583:INFO:create_model() successfully completed......................................
2025-10-19 01:52:23,822:INFO:Initializing create_model()
2025-10-19 01:52:23,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 01:52:23,823:INFO:Checking exceptions
2025-10-19 01:52:23,825:INFO:Importing libraries
2025-10-19 01:52:23,825:INFO:Copying training dataset
2025-10-19 01:52:24,038:INFO:Defining folds
2025-10-19 01:52:24,038:INFO:Declaring metric variables
2025-10-19 01:52:24,038:INFO:Importing untrained model
2025-10-19 01:52:24,038:INFO:Declaring custom model
2025-10-19 01:52:24,039:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 01:52:24,042:INFO:Cross validation set to False
2025-10-19 01:52:24,042:INFO:Fitting Model
2025-10-19 01:52:27,086:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 01:52:27,086:INFO:create_model() successfully completed......................................
2025-10-19 01:52:27,356:INFO:_master_model_container: 15
2025-10-19 01:52:27,356:INFO:_display_container: 2
2025-10-19 01:52:27,358:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2025-10-19 01:52:27,359:INFO:compare_models() successfully completed......................................
2025-10-19 01:52:27,360:INFO:Initializing tune_model()
2025-10-19 01:52:27,360:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 01:52:27,360:INFO:Checking exceptions
2025-10-19 01:52:27,468:INFO:Copying training dataset
2025-10-19 01:52:27,630:INFO:Checking base model
2025-10-19 01:52:27,630:INFO:Base model : Gradient Boosting Classifier
2025-10-19 01:52:27,634:INFO:Declaring metric variables
2025-10-19 01:52:27,637:INFO:Defining Hyperparameters
2025-10-19 01:52:27,867:INFO:Tuning with n_jobs=1
2025-10-19 01:52:27,868:INFO:Initializing RandomizedSearchCV
2025-10-19 02:04:07,961:INFO:best_params: {'actual_estimator__subsample': 0.9, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__learning_rate': 0.1}
2025-10-19 02:04:07,962:INFO:Hyperparameter search completed
2025-10-19 02:04:07,962:INFO:SubProcess create_model() called ==================================
2025-10-19 02:04:07,963:INFO:Initializing create_model()
2025-10-19 02:04:07,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207932390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.9, 'n_estimators': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 4, 'learning_rate': 0.1})
2025-10-19 02:04:07,963:INFO:Checking exceptions
2025-10-19 02:04:07,963:INFO:Importing libraries
2025-10-19 02:04:07,963:INFO:Copying training dataset
2025-10-19 02:04:08,135:INFO:Defining folds
2025-10-19 02:04:08,135:INFO:Declaring metric variables
2025-10-19 02:04:08,138:INFO:Importing untrained model
2025-10-19 02:04:08,139:INFO:Declaring custom model
2025-10-19 02:04:08,146:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 02:04:08,152:INFO:Starting cross validation
2025-10-19 02:04:08,158:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 02:04:35,016:INFO:Calculating mean and std
2025-10-19 02:04:35,017:INFO:Creating metrics dataframe
2025-10-19 02:04:35,023:INFO:Finalizing model
2025-10-19 02:04:41,592:INFO:Uploading results into container
2025-10-19 02:04:41,594:INFO:Uploading model into container now
2025-10-19 02:04:41,595:INFO:_master_model_container: 16
2025-10-19 02:04:41,596:INFO:_display_container: 3
2025-10-19 02:04:41,597:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=4,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.0001, min_samples_leaf=5,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=5654, subsample=0.9, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 02:04:41,597:INFO:create_model() successfully completed......................................
2025-10-19 02:04:41,859:INFO:SubProcess create_model() end ==================================
2025-10-19 02:04:41,859:INFO:choose_better activated
2025-10-19 02:04:41,862:INFO:SubProcess create_model() called ==================================
2025-10-19 02:04:41,864:INFO:Initializing create_model()
2025-10-19 02:04:41,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 02:04:41,865:INFO:Checking exceptions
2025-10-19 02:04:41,866:INFO:Importing libraries
2025-10-19 02:04:41,866:INFO:Copying training dataset
2025-10-19 02:04:42,107:INFO:Defining folds
2025-10-19 02:04:42,107:INFO:Declaring metric variables
2025-10-19 02:04:42,107:INFO:Importing untrained model
2025-10-19 02:04:42,107:INFO:Declaring custom model
2025-10-19 02:04:42,108:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 02:04:42,108:INFO:Starting cross validation
2025-10-19 02:04:42,113:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 02:05:33,636:INFO:Calculating mean and std
2025-10-19 02:05:33,637:INFO:Creating metrics dataframe
2025-10-19 02:05:33,638:INFO:Finalizing model
2025-10-19 02:05:46,492:INFO:Uploading results into container
2025-10-19 02:05:46,492:INFO:Uploading model into container now
2025-10-19 02:05:46,493:INFO:_master_model_container: 17
2025-10-19 02:05:46,493:INFO:_display_container: 4
2025-10-19 02:05:46,493:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 02:05:46,493:INFO:create_model() successfully completed......................................
2025-10-19 02:05:46,730:INFO:SubProcess create_model() end ==================================
2025-10-19 02:05:46,731:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9326
2025-10-19 02:05:46,731:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=4,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.0001, min_samples_leaf=5,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=5654, subsample=0.9, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9316
2025-10-19 02:05:46,731:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-19 02:05:46,731:INFO:choose_better completed
2025-10-19 02:05:46,732:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 02:05:46,744:INFO:_master_model_container: 17
2025-10-19 02:05:46,744:INFO:_display_container: 3
2025-10-19 02:05:46,744:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 02:05:46,744:INFO:tune_model() successfully completed......................................
2025-10-19 02:05:46,978:INFO:Initializing tune_model()
2025-10-19 02:05:46,978:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 02:05:46,978:INFO:Checking exceptions
2025-10-19 02:05:47,067:INFO:Copying training dataset
2025-10-19 02:05:47,181:INFO:Checking base model
2025-10-19 02:05:47,181:INFO:Base model : Ridge Classifier
2025-10-19 02:05:47,185:INFO:Declaring metric variables
2025-10-19 02:05:47,188:INFO:Defining Hyperparameters
2025-10-19 02:05:47,399:INFO:Tuning with n_jobs=1
2025-10-19 02:05:47,399:INFO:Initializing RandomizedSearchCV
2025-10-19 02:05:49,507:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.40462e-17): result may not be accurate.

2025-10-19 02:05:51,853:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.44933e-17): result may not be accurate.

2025-10-19 02:05:54,177:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.46229e-17): result may not be accurate.

2025-10-19 02:05:56,452:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.39643e-17): result may not be accurate.

2025-10-19 02:05:58,807:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.49914e-17): result may not be accurate.

2025-10-19 02:07:44,040:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 8.47}
2025-10-19 02:07:44,041:INFO:Hyperparameter search completed
2025-10-19 02:07:44,041:INFO:SubProcess create_model() called ==================================
2025-10-19 02:07:44,042:INFO:Initializing create_model()
2025-10-19 02:07:44,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002127212D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 8.47})
2025-10-19 02:07:44,043:INFO:Checking exceptions
2025-10-19 02:07:44,043:INFO:Importing libraries
2025-10-19 02:07:44,043:INFO:Copying training dataset
2025-10-19 02:07:44,233:INFO:Defining folds
2025-10-19 02:07:44,234:INFO:Declaring metric variables
2025-10-19 02:07:44,237:INFO:Importing untrained model
2025-10-19 02:07:44,237:INFO:Declaring custom model
2025-10-19 02:07:44,243:INFO:Ridge Classifier Imported successfully
2025-10-19 02:07:44,250:INFO:Starting cross validation
2025-10-19 02:07:44,256:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 02:07:55,765:INFO:Calculating mean and std
2025-10-19 02:07:55,766:INFO:Creating metrics dataframe
2025-10-19 02:07:55,771:INFO:Finalizing model
2025-10-19 02:07:58,254:INFO:Uploading results into container
2025-10-19 02:07:58,255:INFO:Uploading model into container now
2025-10-19 02:07:58,256:INFO:_master_model_container: 18
2025-10-19 02:07:58,256:INFO:_display_container: 4
2025-10-19 02:07:58,256:INFO:RidgeClassifier(alpha=8.47, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001)
2025-10-19 02:07:58,258:INFO:create_model() successfully completed......................................
2025-10-19 02:07:58,503:INFO:SubProcess create_model() end ==================================
2025-10-19 02:07:58,503:INFO:choose_better activated
2025-10-19 02:07:58,507:INFO:SubProcess create_model() called ==================================
2025-10-19 02:07:58,508:INFO:Initializing create_model()
2025-10-19 02:07:58,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 02:07:58,509:INFO:Checking exceptions
2025-10-19 02:07:58,510:INFO:Importing libraries
2025-10-19 02:07:58,511:INFO:Copying training dataset
2025-10-19 02:07:58,727:INFO:Defining folds
2025-10-19 02:07:58,727:INFO:Declaring metric variables
2025-10-19 02:07:58,727:INFO:Importing untrained model
2025-10-19 02:07:58,727:INFO:Declaring custom model
2025-10-19 02:07:58,728:INFO:Ridge Classifier Imported successfully
2025-10-19 02:07:58,728:INFO:Starting cross validation
2025-10-19 02:07:58,731:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 02:08:10,993:INFO:Calculating mean and std
2025-10-19 02:08:10,993:INFO:Creating metrics dataframe
2025-10-19 02:08:10,995:INFO:Finalizing model
2025-10-19 02:08:13,577:INFO:Uploading results into container
2025-10-19 02:08:13,577:INFO:Uploading model into container now
2025-10-19 02:08:13,577:INFO:_master_model_container: 19
2025-10-19 02:08:13,578:INFO:_display_container: 5
2025-10-19 02:08:13,578:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001)
2025-10-19 02:08:13,578:INFO:create_model() successfully completed......................................
2025-10-19 02:08:13,812:INFO:SubProcess create_model() end ==================================
2025-10-19 02:08:13,813:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001) result for AUC is 0.9317
2025-10-19 02:08:13,813:INFO:RidgeClassifier(alpha=8.47, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001) result for AUC is 0.9319
2025-10-19 02:08:13,813:INFO:RidgeClassifier(alpha=8.47, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001) is best model
2025-10-19 02:08:13,813:INFO:choose_better completed
2025-10-19 02:08:13,823:INFO:_master_model_container: 19
2025-10-19 02:08:13,823:INFO:_display_container: 4
2025-10-19 02:08:13,823:INFO:RidgeClassifier(alpha=8.47, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001)
2025-10-19 02:08:13,823:INFO:tune_model() successfully completed......................................
2025-10-19 02:08:14,053:INFO:Initializing tune_model()
2025-10-19 02:08:14,053:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 02:08:14,053:INFO:Checking exceptions
2025-10-19 02:08:14,159:INFO:Copying training dataset
2025-10-19 02:08:14,319:INFO:Checking base model
2025-10-19 02:08:14,319:INFO:Base model : Linear Discriminant Analysis
2025-10-19 02:08:14,323:INFO:Declaring metric variables
2025-10-19 02:08:14,327:INFO:Defining Hyperparameters
2025-10-19 02:08:14,570:INFO:Tuning with n_jobs=1
2025-10-19 02:08:14,570:INFO:Initializing RandomizedSearchCV
2025-10-19 02:10:11,184:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
10 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'shrinkage' parameter of LinearDiscriminantAnalysis must be a str among {'auto'}, a float in the range [0.0, 1.0] or None. Got 'empirical' instead.


2025-10-19 02:10:11,187:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.93180341 0.48885906 0.48885906 0.48773182
 0.48773182 0.48886587 0.49207627 0.49331712]

2025-10-19 02:10:11,188:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 'auto'}
2025-10-19 02:10:11,189:INFO:Hyperparameter search completed
2025-10-19 02:10:11,189:INFO:SubProcess create_model() called ==================================
2025-10-19 02:10:11,190:INFO:Initializing create_model()
2025-10-19 02:10:11,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002127DD13B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 'auto'})
2025-10-19 02:10:11,190:INFO:Checking exceptions
2025-10-19 02:10:11,191:INFO:Importing libraries
2025-10-19 02:10:11,191:INFO:Copying training dataset
2025-10-19 02:10:11,374:INFO:Defining folds
2025-10-19 02:10:11,375:INFO:Declaring metric variables
2025-10-19 02:10:11,379:INFO:Importing untrained model
2025-10-19 02:10:11,380:INFO:Declaring custom model
2025-10-19 02:10:11,384:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 02:10:11,396:INFO:Starting cross validation
2025-10-19 02:10:11,404:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 02:10:23,620:INFO:Calculating mean and std
2025-10-19 02:10:23,621:INFO:Creating metrics dataframe
2025-10-19 02:10:23,625:INFO:Finalizing model
2025-10-19 02:10:26,415:INFO:Uploading results into container
2025-10-19 02:10:26,416:INFO:Uploading model into container now
2025-10-19 02:10:26,418:INFO:_master_model_container: 20
2025-10-19 02:10:26,418:INFO:_display_container: 5
2025-10-19 02:10:26,419:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-19 02:10:26,419:INFO:create_model() successfully completed......................................
2025-10-19 02:10:26,649:INFO:SubProcess create_model() end ==================================
2025-10-19 02:10:26,650:INFO:choose_better activated
2025-10-19 02:10:26,654:INFO:SubProcess create_model() called ==================================
2025-10-19 02:10:26,655:INFO:Initializing create_model()
2025-10-19 02:10:26,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 02:10:26,655:INFO:Checking exceptions
2025-10-19 02:10:26,657:INFO:Importing libraries
2025-10-19 02:10:26,657:INFO:Copying training dataset
2025-10-19 02:10:26,862:INFO:Defining folds
2025-10-19 02:10:26,862:INFO:Declaring metric variables
2025-10-19 02:10:26,862:INFO:Importing untrained model
2025-10-19 02:10:26,862:INFO:Declaring custom model
2025-10-19 02:10:26,863:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 02:10:26,863:INFO:Starting cross validation
2025-10-19 02:10:26,866:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 02:10:41,128:INFO:Calculating mean and std
2025-10-19 02:10:41,129:INFO:Creating metrics dataframe
2025-10-19 02:10:41,130:INFO:Finalizing model
2025-10-19 02:10:44,396:INFO:Uploading results into container
2025-10-19 02:10:44,396:INFO:Uploading model into container now
2025-10-19 02:10:44,397:INFO:_master_model_container: 21
2025-10-19 02:10:44,397:INFO:_display_container: 6
2025-10-19 02:10:44,397:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 02:10:44,398:INFO:create_model() successfully completed......................................
2025-10-19 02:10:44,645:INFO:SubProcess create_model() end ==================================
2025-10-19 02:10:44,646:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9316
2025-10-19 02:10:44,646:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9318
2025-10-19 02:10:44,646:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) is best model
2025-10-19 02:10:44,646:INFO:choose_better completed
2025-10-19 02:10:44,656:INFO:_master_model_container: 21
2025-10-19 02:10:44,657:INFO:_display_container: 5
2025-10-19 02:10:44,657:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-19 02:10:44,657:INFO:tune_model() successfully completed......................................
2025-10-19 02:10:44,894:INFO:Initializing blend_models()
2025-10-19 02:10:44,894:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5654, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=8.47, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-19 02:10:44,894:INFO:Checking exceptions
2025-10-19 02:10:44,895:INFO:Estimator RidgeClassifier(alpha=8.47, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5654, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-19 02:10:44,989:INFO:Importing libraries
2025-10-19 02:10:44,990:INFO:Copying training dataset
2025-10-19 02:10:44,995:INFO:Getting model names
2025-10-19 02:10:45,000:INFO:SubProcess create_model() called ==================================
2025-10-19 02:10:45,005:INFO:Initializing create_model()
2025-10-19 02:10:45,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5654, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
55312    U05723
59320    U03401
12890    U02808
48680    U08174
18351    U01567
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212077E9910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 02:10:45,006:INFO:Checking exceptions
2025-10-19 02:10:45,006:INFO:Importing libraries
2025-10-19 02:10:45,006:INFO:Copying training dataset
2025-10-19 02:10:45,209:INFO:Defining folds
2025-10-19 02:10:45,209:INFO:Declaring metric variables
2025-10-19 02:10:45,212:INFO:Importing untrained model
2025-10-19 02:10:45,213:INFO:Declaring custom model
2025-10-19 02:10:45,221:INFO:Voting Classifier Imported successfully
2025-10-19 02:10:45,229:INFO:Starting cross validation
2025-10-19 02:10:45,234:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 02:10:55,738:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 02:11:06,830:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 02:11:17,555:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 02:11:28,184:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 02:11:39,215:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 02:11:39,232:INFO:Calculating mean and std
2025-10-19 02:11:39,233:INFO:Creating metrics dataframe
2025-10-19 02:11:39,238:INFO:Finalizing model
2025-10-19 02:11:52,137:INFO:Uploading results into container
2025-10-19 02:11:52,138:INFO:Uploading model into container now
2025-10-19 02:11:52,139:INFO:_master_model_container: 22
2025-10-19 02:11:52,139:INFO:_display_container: 6
2025-10-19 02:11:52,141:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5654, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-19 02:11:52,142:INFO:create_model() successfully completed......................................
2025-10-19 02:11:52,393:INFO:SubProcess create_model() end ==================================
2025-10-19 02:11:52,405:INFO:_master_model_container: 22
2025-10-19 02:11:52,405:INFO:_display_container: 6
2025-10-19 02:11:52,409:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5654, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-19 02:11:52,410:INFO:blend_models() successfully completed......................................
2025-10-19 02:11:52,642:INFO:Initializing finalize_model()
2025-10-19 02:11:52,642:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5654, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-19 02:11:52,645:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5654, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-19 02:11:52,779:INFO:Initializing create_model()
2025-10-19 02:11:52,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5654, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=14874    U00174
6876     U00004
44850    U05918
10348    U03774
24585    U06996
          ...  
42996    U01657
6696     U10258
16513    U10296
56670    U05189
17214    U07750
Name: id_usuario, Length: 63955, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 02:11:52,780:INFO:Checking exceptions
2025-10-19 02:11:52,781:INFO:Importing libraries
2025-10-19 02:11:52,781:INFO:Copying training dataset
2025-10-19 02:11:52,806:INFO:Defining folds
2025-10-19 02:11:52,806:INFO:Declaring metric variables
2025-10-19 02:11:52,806:INFO:Importing untrained model
2025-10-19 02:11:52,806:INFO:Declaring custom model
2025-10-19 02:11:52,807:INFO:Voting Classifier Imported successfully
2025-10-19 02:11:52,810:INFO:Cross validation set to False
2025-10-19 02:11:52,810:INFO:Fitting Model
2025-10-19 02:12:11,772:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=5654,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-19 02:12:11,773:INFO:create_model() successfully completed......................................
2025-10-19 02:12:12,018:INFO:_master_model_container: 22
2025-10-19 02:12:12,018:INFO:_display_container: 6
2025-10-19 02:12:12,044:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=5654,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-19 02:12:12,045:INFO:finalize_model() successfully completed......................................
2025-10-19 02:12:12,308:INFO:Initializing save_model()
2025-10-19 02:12:12,308:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=5654,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), model_name=modelo_cls_like_v2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-19 02:12:12,308:INFO:Adding model into prep_pipe
2025-10-19 02:12:12,308:WARNING:Only Model saved as it was a pipeline.
2025-10-19 02:12:12,346:INFO:modelo_cls_like_v2.pkl saved in current working directory
2025-10-19 02:12:12,366:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=5654,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-19 02:12:12,366:INFO:save_model() successfully completed......................................
2025-10-19 06:19:19,889:INFO:PyCaret RegressionExperiment
2025-10-19 06:19:19,889:INFO:Logging name: reg-default-name
2025-10-19 06:19:19,889:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-19 06:19:19,889:INFO:version 3.3.2
2025-10-19 06:19:19,889:INFO:Initializing setup()
2025-10-19 06:19:19,889:INFO:self.USI: 646b
2025-10-19 06:19:19,889:INFO:self._variable_keys: {'USI', 'seed', 'memory', 'html_param', 'X_test', 'target_param', 'transform_target_param', 'logging_param', 'fold_groups_param', 'exp_id', 'exp_name_log', 'log_plots_param', 'y_train', 'y', 'X', 'fold_generator', 'fold_shuffle_param', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', '_available_plots', 'idx', 'data', 'pipeline', 'X_train', '_ml_usecase', 'y_test'}
2025-10-19 06:19:19,890:INFO:Checking environment
2025-10-19 06:19:19,890:INFO:python_version: 3.11.13
2025-10-19 06:19:19,890:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 06:19:19,890:INFO:machine: AMD64
2025-10-19 06:19:19,890:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 06:19:19,898:INFO:Memory: svmem(total=16856211456, available=3698262016, percent=78.1, used=13157949440, free=3698262016)
2025-10-19 06:19:19,898:INFO:Physical Core: 4
2025-10-19 06:19:19,898:INFO:Logical Core: 8
2025-10-19 06:19:19,898:INFO:Checking libraries
2025-10-19 06:19:19,898:INFO:System:
2025-10-19 06:19:19,898:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 06:19:19,898:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 06:19:19,898:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 06:19:19,898:INFO:PyCaret required dependencies:
2025-10-19 06:19:19,899:INFO:                 pip: 25.2
2025-10-19 06:19:19,899:INFO:          setuptools: 80.9.0
2025-10-19 06:19:19,899:INFO:             pycaret: 3.3.2
2025-10-19 06:19:19,899:INFO:             IPython: 9.6.0
2025-10-19 06:19:19,899:INFO:          ipywidgets: 8.1.7
2025-10-19 06:19:19,899:INFO:                tqdm: 4.67.1
2025-10-19 06:19:19,899:INFO:               numpy: 1.26.4
2025-10-19 06:19:19,899:INFO:              pandas: 2.1.4
2025-10-19 06:19:19,899:INFO:              jinja2: 3.1.6
2025-10-19 06:19:19,899:INFO:               scipy: 1.11.4
2025-10-19 06:19:19,900:INFO:              joblib: 1.3.2
2025-10-19 06:19:19,900:INFO:             sklearn: 1.4.2
2025-10-19 06:19:19,900:INFO:                pyod: 2.0.5
2025-10-19 06:19:19,900:INFO:            imblearn: 0.14.0
2025-10-19 06:19:19,900:INFO:   category_encoders: 2.7.0
2025-10-19 06:19:19,900:INFO:            lightgbm: 4.6.0
2025-10-19 06:19:19,900:INFO:               numba: 0.61.0
2025-10-19 06:19:19,900:INFO:            requests: 2.32.5
2025-10-19 06:19:19,900:INFO:          matplotlib: 3.7.5
2025-10-19 06:19:19,900:INFO:          scikitplot: 0.3.7
2025-10-19 06:19:19,900:INFO:         yellowbrick: 1.5
2025-10-19 06:19:19,900:INFO:              plotly: 5.24.1
2025-10-19 06:19:19,900:INFO:    plotly-resampler: Not installed
2025-10-19 06:19:19,900:INFO:             kaleido: 1.1.0
2025-10-19 06:19:19,900:INFO:           schemdraw: 0.15
2025-10-19 06:19:19,900:INFO:         statsmodels: 0.14.5
2025-10-19 06:19:19,900:INFO:              sktime: 0.26.0
2025-10-19 06:19:19,900:INFO:               tbats: 1.1.3
2025-10-19 06:19:19,900:INFO:            pmdarima: 2.0.4
2025-10-19 06:19:19,900:INFO:              psutil: 7.1.0
2025-10-19 06:19:19,900:INFO:          markupsafe: 3.0.3
2025-10-19 06:19:19,900:INFO:             pickle5: Not installed
2025-10-19 06:19:19,900:INFO:         cloudpickle: 3.1.1
2025-10-19 06:19:19,900:INFO:         deprecation: 2.1.0
2025-10-19 06:19:19,900:INFO:              xxhash: 3.6.0
2025-10-19 06:19:19,900:INFO:           wurlitzer: Not installed
2025-10-19 06:19:19,900:INFO:PyCaret optional dependencies:
2025-10-19 06:19:19,901:INFO:                shap: 0.44.1
2025-10-19 06:19:19,901:INFO:           interpret: 0.7.3
2025-10-19 06:19:19,901:INFO:                umap: 0.5.7
2025-10-19 06:19:19,901:INFO:     ydata_profiling: 4.17.0
2025-10-19 06:19:19,901:INFO:  explainerdashboard: 0.5.1
2025-10-19 06:19:19,901:INFO:             autoviz: Not installed
2025-10-19 06:19:19,901:INFO:           fairlearn: 0.7.0
2025-10-19 06:19:19,901:INFO:          deepchecks: Not installed
2025-10-19 06:19:19,901:INFO:             xgboost: Not installed
2025-10-19 06:19:19,901:INFO:            catboost: 1.2.8
2025-10-19 06:19:19,901:INFO:              kmodes: 0.12.2
2025-10-19 06:19:19,901:INFO:             mlxtend: 0.23.4
2025-10-19 06:19:19,901:INFO:       statsforecast: 1.5.0
2025-10-19 06:19:19,901:INFO:        tune_sklearn: Not installed
2025-10-19 06:19:19,901:INFO:                 ray: Not installed
2025-10-19 06:19:19,901:INFO:            hyperopt: 0.2.7
2025-10-19 06:19:19,901:INFO:              optuna: 4.5.0
2025-10-19 06:19:19,901:INFO:               skopt: 0.10.2
2025-10-19 06:19:19,901:INFO:              mlflow: 3.5.0
2025-10-19 06:19:19,901:INFO:              gradio: 5.49.1
2025-10-19 06:19:19,901:INFO:             fastapi: 0.119.0
2025-10-19 06:19:19,902:INFO:             uvicorn: 0.38.0
2025-10-19 06:19:19,902:INFO:              m2cgen: 0.10.0
2025-10-19 06:19:19,902:INFO:           evidently: 0.4.40
2025-10-19 06:19:19,902:INFO:               fugue: 0.8.7
2025-10-19 06:19:19,902:INFO:           streamlit: Not installed
2025-10-19 06:19:19,902:INFO:             prophet: Not installed
2025-10-19 06:19:19,902:INFO:None
2025-10-19 06:19:19,902:INFO:Set up data.
2025-10-19 06:19:20,074:INFO:Set up folding strategy.
2025-10-19 06:19:20,218:INFO:Set up train/test split.
2025-10-19 06:19:20,439:INFO:Set up index.
2025-10-19 06:19:20,455:INFO:Assigning column types.
2025-10-19 06:19:20,698:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 06:19:20,700:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-19 06:19:20,704:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 06:19:20,709:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:19:20,967:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,019:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:21,021:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:21,022:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,026:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,032:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,248:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,283:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:21,283:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:21,284:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-19 06:19:21,288:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,291:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,527:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:21,528:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:21,533:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,536:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,765:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:21,801:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:21,802:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-19 06:19:21,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:19:21,993:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:19:22,029:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:19:22,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:22,030:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:22,037:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:19:22,225:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:19:22,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:19:22,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:22,260:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:22,261:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-19 06:19:22,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:19:22,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:19:22,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:22,486:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:22,712:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:19:22,749:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:19:22,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:22,750:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:22,750:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 06:19:22,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:19:22,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:22,974:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:23,158:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:19:23,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:23,196:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:23,197:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-19 06:19:23,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:23,433:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:23,674:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:19:23,675:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:19:23,681:INFO:Preparing preprocessing pipeline...
2025-10-19 06:19:23,681:INFO:Set up simple imputation.
2025-10-19 06:19:23,813:INFO:Set up encoding of ordinal features.
2025-10-19 06:19:23,874:INFO:Set up encoding of categorical features.
2025-10-19 06:19:23,879:INFO:Set up removing multicollinearity.
2025-10-19 06:19:23,906:INFO:Set up column name cleaning.
2025-10-19 06:25:01,977:INFO:PyCaret RegressionExperiment
2025-10-19 06:25:01,978:INFO:Logging name: reg-default-name
2025-10-19 06:25:01,978:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-19 06:25:01,978:INFO:version 3.3.2
2025-10-19 06:25:01,978:INFO:Initializing setup()
2025-10-19 06:25:01,978:INFO:self.USI: 0513
2025-10-19 06:25:01,978:INFO:self._variable_keys: {'USI', 'seed', 'memory', 'html_param', 'X_test', 'target_param', 'transform_target_param', 'logging_param', 'fold_groups_param', 'exp_id', 'exp_name_log', 'log_plots_param', 'y_train', 'y', 'X', 'fold_generator', 'fold_shuffle_param', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', '_available_plots', 'idx', 'data', 'pipeline', 'X_train', '_ml_usecase', 'y_test'}
2025-10-19 06:25:01,978:INFO:Checking environment
2025-10-19 06:25:01,978:INFO:python_version: 3.11.13
2025-10-19 06:25:01,978:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 06:25:01,978:INFO:machine: AMD64
2025-10-19 06:25:01,978:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 06:25:01,987:INFO:Memory: svmem(total=16856211456, available=3498115072, percent=79.2, used=13358096384, free=3498115072)
2025-10-19 06:25:01,987:INFO:Physical Core: 4
2025-10-19 06:25:01,987:INFO:Logical Core: 8
2025-10-19 06:25:01,987:INFO:Checking libraries
2025-10-19 06:25:01,987:INFO:System:
2025-10-19 06:25:01,987:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 06:25:01,987:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 06:25:01,987:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 06:25:01,987:INFO:PyCaret required dependencies:
2025-10-19 06:25:01,987:INFO:                 pip: 25.2
2025-10-19 06:25:01,987:INFO:          setuptools: 80.9.0
2025-10-19 06:25:01,987:INFO:             pycaret: 3.3.2
2025-10-19 06:25:01,987:INFO:             IPython: 9.6.0
2025-10-19 06:25:01,987:INFO:          ipywidgets: 8.1.7
2025-10-19 06:25:01,987:INFO:                tqdm: 4.67.1
2025-10-19 06:25:01,987:INFO:               numpy: 1.26.4
2025-10-19 06:25:01,987:INFO:              pandas: 2.1.4
2025-10-19 06:25:01,987:INFO:              jinja2: 3.1.6
2025-10-19 06:25:01,987:INFO:               scipy: 1.11.4
2025-10-19 06:25:01,987:INFO:              joblib: 1.3.2
2025-10-19 06:25:01,987:INFO:             sklearn: 1.4.2
2025-10-19 06:25:01,987:INFO:                pyod: 2.0.5
2025-10-19 06:25:01,987:INFO:            imblearn: 0.14.0
2025-10-19 06:25:01,987:INFO:   category_encoders: 2.7.0
2025-10-19 06:25:01,988:INFO:            lightgbm: 4.6.0
2025-10-19 06:25:01,988:INFO:               numba: 0.61.0
2025-10-19 06:25:01,988:INFO:            requests: 2.32.5
2025-10-19 06:25:01,988:INFO:          matplotlib: 3.7.5
2025-10-19 06:25:01,988:INFO:          scikitplot: 0.3.7
2025-10-19 06:25:01,988:INFO:         yellowbrick: 1.5
2025-10-19 06:25:01,988:INFO:              plotly: 5.24.1
2025-10-19 06:25:01,988:INFO:    plotly-resampler: Not installed
2025-10-19 06:25:01,988:INFO:             kaleido: 1.1.0
2025-10-19 06:25:01,988:INFO:           schemdraw: 0.15
2025-10-19 06:25:01,988:INFO:         statsmodels: 0.14.5
2025-10-19 06:25:01,988:INFO:              sktime: 0.26.0
2025-10-19 06:25:01,988:INFO:               tbats: 1.1.3
2025-10-19 06:25:01,988:INFO:            pmdarima: 2.0.4
2025-10-19 06:25:01,988:INFO:              psutil: 7.1.0
2025-10-19 06:25:01,988:INFO:          markupsafe: 3.0.3
2025-10-19 06:25:01,988:INFO:             pickle5: Not installed
2025-10-19 06:25:01,988:INFO:         cloudpickle: 3.1.1
2025-10-19 06:25:01,988:INFO:         deprecation: 2.1.0
2025-10-19 06:25:01,988:INFO:              xxhash: 3.6.0
2025-10-19 06:25:01,988:INFO:           wurlitzer: Not installed
2025-10-19 06:25:01,988:INFO:PyCaret optional dependencies:
2025-10-19 06:25:01,988:INFO:                shap: 0.44.1
2025-10-19 06:25:01,988:INFO:           interpret: 0.7.3
2025-10-19 06:25:01,988:INFO:                umap: 0.5.7
2025-10-19 06:25:01,988:INFO:     ydata_profiling: 4.17.0
2025-10-19 06:25:01,988:INFO:  explainerdashboard: 0.5.1
2025-10-19 06:25:01,988:INFO:             autoviz: Not installed
2025-10-19 06:25:01,988:INFO:           fairlearn: 0.7.0
2025-10-19 06:25:01,989:INFO:          deepchecks: Not installed
2025-10-19 06:25:01,989:INFO:             xgboost: Not installed
2025-10-19 06:25:01,989:INFO:            catboost: 1.2.8
2025-10-19 06:25:01,989:INFO:              kmodes: 0.12.2
2025-10-19 06:25:01,989:INFO:             mlxtend: 0.23.4
2025-10-19 06:25:01,989:INFO:       statsforecast: 1.5.0
2025-10-19 06:25:01,989:INFO:        tune_sklearn: Not installed
2025-10-19 06:25:01,989:INFO:                 ray: Not installed
2025-10-19 06:25:01,989:INFO:            hyperopt: 0.2.7
2025-10-19 06:25:01,989:INFO:              optuna: 4.5.0
2025-10-19 06:25:01,989:INFO:               skopt: 0.10.2
2025-10-19 06:25:01,989:INFO:              mlflow: 3.5.0
2025-10-19 06:25:01,989:INFO:              gradio: 5.49.1
2025-10-19 06:25:01,989:INFO:             fastapi: 0.119.0
2025-10-19 06:25:01,989:INFO:             uvicorn: 0.38.0
2025-10-19 06:25:01,989:INFO:              m2cgen: 0.10.0
2025-10-19 06:25:01,989:INFO:           evidently: 0.4.40
2025-10-19 06:25:01,989:INFO:               fugue: 0.8.7
2025-10-19 06:25:01,989:INFO:           streamlit: Not installed
2025-10-19 06:25:01,989:INFO:             prophet: Not installed
2025-10-19 06:25:01,989:INFO:None
2025-10-19 06:25:01,989:INFO:Set up data.
2025-10-19 06:25:02,142:INFO:Set up folding strategy.
2025-10-19 06:25:02,295:INFO:Set up train/test split.
2025-10-19 06:25:02,474:INFO:Set up index.
2025-10-19 06:25:02,486:INFO:Assigning column types.
2025-10-19 06:25:02,705:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 06:25:02,705:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-19 06:25:02,710:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 06:25:02,719:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:25:02,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:25:02,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:25:02,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:02,974:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:02,974:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-19 06:25:02,978:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 06:25:02,985:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,204:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,244:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:03,244:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:03,247:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-19 06:25:03,253:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,257:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,473:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:03,513:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:03,518:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,522:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,729:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:25:03,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:03,770:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:03,771:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-19 06:25:03,782:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,013:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,053:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:04,054:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:04,062:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,266:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:04,304:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:04,304:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-19 06:25:04,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:04,543:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:04,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:04,776:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:04,777:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 06:25:04,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:25:04,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:04,999:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:05,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 06:25:05,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:05,269:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:05,271:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-19 06:25:05,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:05,502:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:05,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:05,728:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:05,731:INFO:Preparing preprocessing pipeline...
2025-10-19 06:25:05,731:INFO:Set up simple imputation.
2025-10-19 06:25:05,852:INFO:Set up encoding of ordinal features.
2025-10-19 06:25:05,905:INFO:Set up encoding of categorical features.
2025-10-19 06:25:05,908:INFO:Set up removing multicollinearity.
2025-10-19 06:25:05,934:INFO:Set up column name cleaning.
2025-10-19 06:25:09,955:INFO:Finished creating preprocessing pipeline.
2025-10-19 06:25:09,974:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 06:25:09,974:INFO:Creating final display dataframe.
2025-10-19 06:25:12,378:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target    rating_usuario
2                   Target type        Regression
3           Original data shape       (63955, 28)
4        Transformed data shape       (63955, 96)
5   Transformed train set shape       (44768, 96)
6    Transformed test set shape       (19187, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              0513
2025-10-19 06:25:12,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:12,589:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:12,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 06:25:12,834:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 06:25:12,837:INFO:setup() successfully completed in 10.87s...............
2025-10-19 06:25:12,838:INFO:Initializing compare_models()
2025-10-19 06:25:12,838:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-19 06:25:12,838:INFO:Checking exceptions
2025-10-19 06:25:12,945:INFO:Preparing display monitor
2025-10-19 06:25:13,004:INFO:Initializing Linear Regression
2025-10-19 06:25:13,005:INFO:Total runtime is 1.6677379608154298e-05 minutes
2025-10-19 06:25:13,024:INFO:SubProcess create_model() called ==================================
2025-10-19 06:25:13,027:INFO:Initializing create_model()
2025-10-19 06:25:13,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:25:13,027:INFO:Checking exceptions
2025-10-19 06:25:13,027:INFO:Importing libraries
2025-10-19 06:25:13,027:INFO:Copying training dataset
2025-10-19 06:25:13,239:INFO:Defining folds
2025-10-19 06:25:13,239:INFO:Declaring metric variables
2025-10-19 06:25:13,242:INFO:Importing untrained model
2025-10-19 06:25:13,247:INFO:Linear Regression Imported successfully
2025-10-19 06:25:13,253:INFO:Starting cross validation
2025-10-19 06:25:13,257:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:25:25,425:INFO:Calculating mean and std
2025-10-19 06:25:25,426:INFO:Creating metrics dataframe
2025-10-19 06:25:25,428:INFO:Uploading results into container
2025-10-19 06:25:25,428:INFO:Uploading model into container now
2025-10-19 06:25:25,429:INFO:_master_model_container: 1
2025-10-19 06:25:25,429:INFO:_display_container: 2
2025-10-19 06:25:25,429:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, positive=False)
2025-10-19 06:25:25,429:INFO:create_model() successfully completed......................................
2025-10-19 06:25:25,997:INFO:SubProcess create_model() end ==================================
2025-10-19 06:25:25,997:INFO:Creating metrics dataframe
2025-10-19 06:25:26,005:INFO:Initializing Lasso Regression
2025-10-19 06:25:26,005:INFO:Total runtime is 0.21667664448420207 minutes
2025-10-19 06:25:26,007:INFO:SubProcess create_model() called ==================================
2025-10-19 06:25:26,009:INFO:Initializing create_model()
2025-10-19 06:25:26,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=lasso, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:25:26,009:INFO:Checking exceptions
2025-10-19 06:25:26,009:INFO:Importing libraries
2025-10-19 06:25:26,009:INFO:Copying training dataset
2025-10-19 06:25:26,213:INFO:Defining folds
2025-10-19 06:25:26,214:INFO:Declaring metric variables
2025-10-19 06:25:26,220:INFO:Importing untrained model
2025-10-19 06:25:26,226:INFO:Lasso Regression Imported successfully
2025-10-19 06:25:26,237:INFO:Starting cross validation
2025-10-19 06:25:26,243:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:25:38,142:INFO:Calculating mean and std
2025-10-19 06:25:38,143:INFO:Creating metrics dataframe
2025-10-19 06:25:38,145:INFO:Uploading results into container
2025-10-19 06:25:38,146:INFO:Uploading model into container now
2025-10-19 06:25:38,147:INFO:_master_model_container: 2
2025-10-19 06:25:38,147:INFO:_display_container: 2
2025-10-19 06:25:38,148:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=42, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-10-19 06:25:38,148:INFO:create_model() successfully completed......................................
2025-10-19 06:25:38,379:INFO:SubProcess create_model() end ==================================
2025-10-19 06:25:38,379:INFO:Creating metrics dataframe
2025-10-19 06:25:38,387:INFO:Initializing Ridge Regression
2025-10-19 06:25:38,387:INFO:Total runtime is 0.4230397621790568 minutes
2025-10-19 06:25:38,389:INFO:SubProcess create_model() called ==================================
2025-10-19 06:25:38,390:INFO:Initializing create_model()
2025-10-19 06:25:38,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:25:38,390:INFO:Checking exceptions
2025-10-19 06:25:38,391:INFO:Importing libraries
2025-10-19 06:25:38,391:INFO:Copying training dataset
2025-10-19 06:25:38,564:INFO:Defining folds
2025-10-19 06:25:38,564:INFO:Declaring metric variables
2025-10-19 06:25:38,570:INFO:Importing untrained model
2025-10-19 06:25:38,574:INFO:Ridge Regression Imported successfully
2025-10-19 06:25:38,580:INFO:Starting cross validation
2025-10-19 06:25:38,587:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:25:49,702:INFO:Calculating mean and std
2025-10-19 06:25:49,705:INFO:Creating metrics dataframe
2025-10-19 06:25:49,706:INFO:Uploading results into container
2025-10-19 06:25:49,706:INFO:Uploading model into container now
2025-10-19 06:25:49,706:INFO:_master_model_container: 3
2025-10-19 06:25:49,710:INFO:_display_container: 2
2025-10-19 06:25:49,711:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001)
2025-10-19 06:25:49,711:INFO:create_model() successfully completed......................................
2025-10-19 06:25:49,937:INFO:SubProcess create_model() end ==================================
2025-10-19 06:25:49,937:INFO:Creating metrics dataframe
2025-10-19 06:25:49,942:INFO:Initializing Elastic Net
2025-10-19 06:25:49,942:INFO:Total runtime is 0.615628433227539 minutes
2025-10-19 06:25:49,944:INFO:SubProcess create_model() called ==================================
2025-10-19 06:25:49,946:INFO:Initializing create_model()
2025-10-19 06:25:49,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=en, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:25:49,946:INFO:Checking exceptions
2025-10-19 06:25:49,946:INFO:Importing libraries
2025-10-19 06:25:49,946:INFO:Copying training dataset
2025-10-19 06:25:50,128:INFO:Defining folds
2025-10-19 06:25:50,128:INFO:Declaring metric variables
2025-10-19 06:25:50,131:INFO:Importing untrained model
2025-10-19 06:25:50,136:INFO:Elastic Net Imported successfully
2025-10-19 06:25:50,144:INFO:Starting cross validation
2025-10-19 06:25:50,150:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:26:01,242:INFO:Calculating mean and std
2025-10-19 06:26:01,242:INFO:Creating metrics dataframe
2025-10-19 06:26:01,244:INFO:Uploading results into container
2025-10-19 06:26:01,244:INFO:Uploading model into container now
2025-10-19 06:26:01,245:INFO:_master_model_container: 4
2025-10-19 06:26:01,245:INFO:_display_container: 2
2025-10-19 06:26:01,245:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=42,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-10-19 06:26:01,245:INFO:create_model() successfully completed......................................
2025-10-19 06:26:01,478:INFO:SubProcess create_model() end ==================================
2025-10-19 06:26:01,478:INFO:Creating metrics dataframe
2025-10-19 06:26:01,487:INFO:Initializing Least Angle Regression
2025-10-19 06:26:01,488:INFO:Total runtime is 0.8080559412638346 minutes
2025-10-19 06:26:01,492:INFO:SubProcess create_model() called ==================================
2025-10-19 06:26:01,494:INFO:Initializing create_model()
2025-10-19 06:26:01,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=lar, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:26:01,494:INFO:Checking exceptions
2025-10-19 06:26:01,494:INFO:Importing libraries
2025-10-19 06:26:01,494:INFO:Copying training dataset
2025-10-19 06:26:01,716:INFO:Defining folds
2025-10-19 06:26:01,716:INFO:Declaring metric variables
2025-10-19 06:26:01,720:INFO:Importing untrained model
2025-10-19 06:26:01,727:INFO:Least Angle Regression Imported successfully
2025-10-19 06:26:01,735:INFO:Starting cross validation
2025-10-19 06:26:01,741:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:26:12,934:INFO:Calculating mean and std
2025-10-19 06:26:12,935:INFO:Creating metrics dataframe
2025-10-19 06:26:12,937:INFO:Uploading results into container
2025-10-19 06:26:12,938:INFO:Uploading model into container now
2025-10-19 06:26:12,939:INFO:_master_model_container: 5
2025-10-19 06:26:12,939:INFO:_display_container: 2
2025-10-19 06:26:12,939:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=42,
     verbose=False)
2025-10-19 06:26:12,940:INFO:create_model() successfully completed......................................
2025-10-19 06:26:13,172:INFO:SubProcess create_model() end ==================================
2025-10-19 06:26:13,172:INFO:Creating metrics dataframe
2025-10-19 06:26:13,178:INFO:Initializing Lasso Least Angle Regression
2025-10-19 06:26:13,178:INFO:Total runtime is 1.0028849800427755 minutes
2025-10-19 06:26:13,182:INFO:SubProcess create_model() called ==================================
2025-10-19 06:26:13,182:INFO:Initializing create_model()
2025-10-19 06:26:13,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=llar, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:26:13,183:INFO:Checking exceptions
2025-10-19 06:26:13,183:INFO:Importing libraries
2025-10-19 06:26:13,183:INFO:Copying training dataset
2025-10-19 06:26:13,346:INFO:Defining folds
2025-10-19 06:26:13,346:INFO:Declaring metric variables
2025-10-19 06:26:13,351:INFO:Importing untrained model
2025-10-19 06:26:13,356:INFO:Lasso Least Angle Regression Imported successfully
2025-10-19 06:26:13,362:INFO:Starting cross validation
2025-10-19 06:26:13,366:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:26:24,780:INFO:Calculating mean and std
2025-10-19 06:26:24,782:INFO:Creating metrics dataframe
2025-10-19 06:26:24,785:INFO:Uploading results into container
2025-10-19 06:26:24,785:INFO:Uploading model into container now
2025-10-19 06:26:24,786:INFO:_master_model_container: 6
2025-10-19 06:26:24,786:INFO:_display_container: 2
2025-10-19 06:26:24,787:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=42, verbose=False)
2025-10-19 06:26:24,787:INFO:create_model() successfully completed......................................
2025-10-19 06:26:25,014:INFO:SubProcess create_model() end ==================================
2025-10-19 06:26:25,014:INFO:Creating metrics dataframe
2025-10-19 06:26:25,020:INFO:Initializing Orthogonal Matching Pursuit
2025-10-19 06:26:25,021:INFO:Total runtime is 1.20028102795283 minutes
2025-10-19 06:26:25,026:INFO:SubProcess create_model() called ==================================
2025-10-19 06:26:25,028:INFO:Initializing create_model()
2025-10-19 06:26:25,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=omp, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:26:25,028:INFO:Checking exceptions
2025-10-19 06:26:25,028:INFO:Importing libraries
2025-10-19 06:26:25,028:INFO:Copying training dataset
2025-10-19 06:26:25,216:INFO:Defining folds
2025-10-19 06:26:25,216:INFO:Declaring metric variables
2025-10-19 06:26:25,222:INFO:Importing untrained model
2025-10-19 06:26:25,225:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-19 06:26:25,232:INFO:Starting cross validation
2025-10-19 06:26:25,238:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:26:37,173:INFO:Calculating mean and std
2025-10-19 06:26:37,174:INFO:Creating metrics dataframe
2025-10-19 06:26:37,176:INFO:Uploading results into container
2025-10-19 06:26:37,177:INFO:Uploading model into container now
2025-10-19 06:26:37,177:INFO:_master_model_container: 7
2025-10-19 06:26:37,177:INFO:_display_container: 2
2025-10-19 06:26:37,178:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-10-19 06:26:37,178:INFO:create_model() successfully completed......................................
2025-10-19 06:26:37,445:INFO:SubProcess create_model() end ==================================
2025-10-19 06:26:37,445:INFO:Creating metrics dataframe
2025-10-19 06:26:37,453:INFO:Initializing Bayesian Ridge
2025-10-19 06:26:37,454:INFO:Total runtime is 1.4074882785479228 minutes
2025-10-19 06:26:37,457:INFO:SubProcess create_model() called ==================================
2025-10-19 06:26:37,459:INFO:Initializing create_model()
2025-10-19 06:26:37,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=br, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:26:37,459:INFO:Checking exceptions
2025-10-19 06:26:37,459:INFO:Importing libraries
2025-10-19 06:26:37,459:INFO:Copying training dataset
2025-10-19 06:26:37,672:INFO:Defining folds
2025-10-19 06:26:37,672:INFO:Declaring metric variables
2025-10-19 06:26:37,675:INFO:Importing untrained model
2025-10-19 06:26:37,681:INFO:Bayesian Ridge Imported successfully
2025-10-19 06:26:37,691:INFO:Starting cross validation
2025-10-19 06:26:37,695:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:26:50,431:INFO:Calculating mean and std
2025-10-19 06:26:50,432:INFO:Creating metrics dataframe
2025-10-19 06:26:50,435:INFO:Uploading results into container
2025-10-19 06:26:50,436:INFO:Uploading model into container now
2025-10-19 06:26:50,437:INFO:_master_model_container: 8
2025-10-19 06:26:50,437:INFO:_display_container: 2
2025-10-19 06:26:50,438:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-10-19 06:26:50,438:INFO:create_model() successfully completed......................................
2025-10-19 06:26:50,692:INFO:SubProcess create_model() end ==================================
2025-10-19 06:26:50,692:INFO:Creating metrics dataframe
2025-10-19 06:26:50,702:INFO:Initializing Passive Aggressive Regressor
2025-10-19 06:26:50,702:INFO:Total runtime is 1.628298044204712 minutes
2025-10-19 06:26:50,706:INFO:SubProcess create_model() called ==================================
2025-10-19 06:26:50,707:INFO:Initializing create_model()
2025-10-19 06:26:50,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=par, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:26:50,707:INFO:Checking exceptions
2025-10-19 06:26:50,707:INFO:Importing libraries
2025-10-19 06:26:50,707:INFO:Copying training dataset
2025-10-19 06:26:50,888:INFO:Defining folds
2025-10-19 06:26:50,888:INFO:Declaring metric variables
2025-10-19 06:26:50,892:INFO:Importing untrained model
2025-10-19 06:26:50,896:INFO:Passive Aggressive Regressor Imported successfully
2025-10-19 06:26:50,902:INFO:Starting cross validation
2025-10-19 06:26:50,907:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:27:07,632:INFO:Calculating mean and std
2025-10-19 06:27:07,633:INFO:Creating metrics dataframe
2025-10-19 06:27:07,634:INFO:Uploading results into container
2025-10-19 06:27:07,635:INFO:Uploading model into container now
2025-10-19 06:27:07,635:INFO:_master_model_container: 9
2025-10-19 06:27:07,636:INFO:_display_container: 2
2025-10-19 06:27:07,636:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=42, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 06:27:07,636:INFO:create_model() successfully completed......................................
2025-10-19 06:27:07,878:INFO:SubProcess create_model() end ==================================
2025-10-19 06:27:07,878:INFO:Creating metrics dataframe
2025-10-19 06:27:07,888:INFO:Initializing Huber Regressor
2025-10-19 06:27:07,888:INFO:Total runtime is 1.9147247592608134 minutes
2025-10-19 06:27:07,891:INFO:SubProcess create_model() called ==================================
2025-10-19 06:27:07,893:INFO:Initializing create_model()
2025-10-19 06:27:07,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=huber, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:27:07,894:INFO:Checking exceptions
2025-10-19 06:27:07,894:INFO:Importing libraries
2025-10-19 06:27:07,894:INFO:Copying training dataset
2025-10-19 06:27:08,071:INFO:Defining folds
2025-10-19 06:27:08,071:INFO:Declaring metric variables
2025-10-19 06:27:08,074:INFO:Importing untrained model
2025-10-19 06:27:08,079:INFO:Huber Regressor Imported successfully
2025-10-19 06:27:08,085:INFO:Starting cross validation
2025-10-19 06:27:08,090:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:27:28,259:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2025-10-19 06:27:28,478:INFO:Calculating mean and std
2025-10-19 06:27:28,479:INFO:Creating metrics dataframe
2025-10-19 06:27:28,480:INFO:Uploading results into container
2025-10-19 06:27:28,481:INFO:Uploading model into container now
2025-10-19 06:27:28,481:INFO:_master_model_container: 10
2025-10-19 06:27:28,481:INFO:_display_container: 2
2025-10-19 06:27:28,481:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-10-19 06:27:28,482:INFO:create_model() successfully completed......................................
2025-10-19 06:27:28,717:INFO:SubProcess create_model() end ==================================
2025-10-19 06:27:28,717:INFO:Creating metrics dataframe
2025-10-19 06:27:28,726:INFO:Initializing K Neighbors Regressor
2025-10-19 06:27:28,726:INFO:Total runtime is 2.262022308508555 minutes
2025-10-19 06:27:28,729:INFO:SubProcess create_model() called ==================================
2025-10-19 06:27:28,730:INFO:Initializing create_model()
2025-10-19 06:27:28,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:27:28,731:INFO:Checking exceptions
2025-10-19 06:27:28,731:INFO:Importing libraries
2025-10-19 06:27:28,731:INFO:Copying training dataset
2025-10-19 06:27:28,918:INFO:Defining folds
2025-10-19 06:27:28,918:INFO:Declaring metric variables
2025-10-19 06:27:28,924:INFO:Importing untrained model
2025-10-19 06:27:28,928:INFO:K Neighbors Regressor Imported successfully
2025-10-19 06:27:28,934:INFO:Starting cross validation
2025-10-19 06:27:28,939:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:27:43,259:INFO:Calculating mean and std
2025-10-19 06:27:43,260:INFO:Creating metrics dataframe
2025-10-19 06:27:43,262:INFO:Uploading results into container
2025-10-19 06:27:43,262:INFO:Uploading model into container now
2025-10-19 06:27:43,263:INFO:_master_model_container: 11
2025-10-19 06:27:43,263:INFO:_display_container: 2
2025-10-19 06:27:43,263:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                    weights='uniform')
2025-10-19 06:27:43,263:INFO:create_model() successfully completed......................................
2025-10-19 06:27:43,508:INFO:SubProcess create_model() end ==================================
2025-10-19 06:27:43,508:INFO:Creating metrics dataframe
2025-10-19 06:27:43,515:INFO:Initializing Decision Tree Regressor
2025-10-19 06:27:43,515:INFO:Total runtime is 2.508507263660431 minutes
2025-10-19 06:27:43,518:INFO:SubProcess create_model() called ==================================
2025-10-19 06:27:43,519:INFO:Initializing create_model()
2025-10-19 06:27:43,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:27:43,520:INFO:Checking exceptions
2025-10-19 06:27:43,520:INFO:Importing libraries
2025-10-19 06:27:43,520:INFO:Copying training dataset
2025-10-19 06:27:43,704:INFO:Defining folds
2025-10-19 06:27:43,705:INFO:Declaring metric variables
2025-10-19 06:27:43,710:INFO:Importing untrained model
2025-10-19 06:27:43,714:INFO:Decision Tree Regressor Imported successfully
2025-10-19 06:27:43,720:INFO:Starting cross validation
2025-10-19 06:27:43,726:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:27:58,315:INFO:Calculating mean and std
2025-10-19 06:27:58,316:INFO:Creating metrics dataframe
2025-10-19 06:27:58,317:INFO:Uploading results into container
2025-10-19 06:27:58,318:INFO:Uploading model into container now
2025-10-19 06:27:58,318:INFO:_master_model_container: 12
2025-10-19 06:27:58,318:INFO:_display_container: 2
2025-10-19 06:27:58,319:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=42, splitter='best')
2025-10-19 06:27:58,319:INFO:create_model() successfully completed......................................
2025-10-19 06:27:58,533:INFO:SubProcess create_model() end ==================================
2025-10-19 06:27:58,534:INFO:Creating metrics dataframe
2025-10-19 06:27:58,543:INFO:Initializing Random Forest Regressor
2025-10-19 06:27:58,543:INFO:Total runtime is 2.758967781066895 minutes
2025-10-19 06:27:58,546:INFO:SubProcess create_model() called ==================================
2025-10-19 06:27:58,547:INFO:Initializing create_model()
2025-10-19 06:27:58,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:27:58,547:INFO:Checking exceptions
2025-10-19 06:27:58,547:INFO:Importing libraries
2025-10-19 06:27:58,547:INFO:Copying training dataset
2025-10-19 06:27:58,746:INFO:Defining folds
2025-10-19 06:27:58,746:INFO:Declaring metric variables
2025-10-19 06:27:58,750:INFO:Importing untrained model
2025-10-19 06:27:58,754:INFO:Random Forest Regressor Imported successfully
2025-10-19 06:27:58,761:INFO:Starting cross validation
2025-10-19 06:27:58,766:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:32:07,082:INFO:Calculating mean and std
2025-10-19 06:32:07,083:INFO:Creating metrics dataframe
2025-10-19 06:32:07,085:INFO:Uploading results into container
2025-10-19 06:32:07,085:INFO:Uploading model into container now
2025-10-19 06:32:07,086:INFO:_master_model_container: 13
2025-10-19 06:32:07,086:INFO:_display_container: 2
2025-10-19 06:32:07,086:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=1, oob_score=False,
                      random_state=42, verbose=0, warm_start=False)
2025-10-19 06:32:07,087:INFO:create_model() successfully completed......................................
2025-10-19 06:32:07,323:INFO:SubProcess create_model() end ==================================
2025-10-19 06:32:07,323:INFO:Creating metrics dataframe
2025-10-19 06:32:07,334:INFO:Initializing Extra Trees Regressor
2025-10-19 06:32:07,334:INFO:Total runtime is 6.905495087305705 minutes
2025-10-19 06:32:07,339:INFO:SubProcess create_model() called ==================================
2025-10-19 06:32:07,341:INFO:Initializing create_model()
2025-10-19 06:32:07,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:32:07,341:INFO:Checking exceptions
2025-10-19 06:32:07,341:INFO:Importing libraries
2025-10-19 06:32:07,341:INFO:Copying training dataset
2025-10-19 06:32:07,532:INFO:Defining folds
2025-10-19 06:32:07,532:INFO:Declaring metric variables
2025-10-19 06:32:07,536:INFO:Importing untrained model
2025-10-19 06:32:07,542:INFO:Extra Trees Regressor Imported successfully
2025-10-19 06:32:07,547:INFO:Starting cross validation
2025-10-19 06:32:07,552:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:36:10,210:INFO:Calculating mean and std
2025-10-19 06:36:10,212:INFO:Creating metrics dataframe
2025-10-19 06:36:10,213:INFO:Uploading results into container
2025-10-19 06:36:10,214:INFO:Uploading model into container now
2025-10-19 06:36:10,214:INFO:_master_model_container: 14
2025-10-19 06:36:10,214:INFO:_display_container: 2
2025-10-19 06:36:10,214:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=1, oob_score=False,
                    random_state=42, verbose=0, warm_start=False)
2025-10-19 06:36:10,214:INFO:create_model() successfully completed......................................
2025-10-19 06:36:10,462:INFO:SubProcess create_model() end ==================================
2025-10-19 06:36:10,463:INFO:Creating metrics dataframe
2025-10-19 06:36:10,473:INFO:Initializing AdaBoost Regressor
2025-10-19 06:36:10,473:INFO:Total runtime is 10.957803312937418 minutes
2025-10-19 06:36:10,477:INFO:SubProcess create_model() called ==================================
2025-10-19 06:36:10,478:INFO:Initializing create_model()
2025-10-19 06:36:10,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:36:10,478:INFO:Checking exceptions
2025-10-19 06:36:10,478:INFO:Importing libraries
2025-10-19 06:36:10,478:INFO:Copying training dataset
2025-10-19 06:36:10,695:INFO:Defining folds
2025-10-19 06:36:10,695:INFO:Declaring metric variables
2025-10-19 06:36:10,700:INFO:Importing untrained model
2025-10-19 06:36:10,705:INFO:AdaBoost Regressor Imported successfully
2025-10-19 06:36:10,711:INFO:Starting cross validation
2025-10-19 06:36:10,716:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:36:45,588:INFO:Calculating mean and std
2025-10-19 06:36:45,589:INFO:Creating metrics dataframe
2025-10-19 06:36:45,591:INFO:Uploading results into container
2025-10-19 06:36:45,591:INFO:Uploading model into container now
2025-10-19 06:36:45,591:INFO:_master_model_container: 15
2025-10-19 06:36:45,591:INFO:_display_container: 2
2025-10-19 06:36:45,592:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=42)
2025-10-19 06:36:45,592:INFO:create_model() successfully completed......................................
2025-10-19 06:36:45,820:INFO:SubProcess create_model() end ==================================
2025-10-19 06:36:45,820:INFO:Creating metrics dataframe
2025-10-19 06:36:45,830:INFO:Initializing Gradient Boosting Regressor
2025-10-19 06:36:45,832:INFO:Total runtime is 11.547118616104125 minutes
2025-10-19 06:36:45,834:INFO:SubProcess create_model() called ==================================
2025-10-19 06:36:45,836:INFO:Initializing create_model()
2025-10-19 06:36:45,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=gbr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:36:45,836:INFO:Checking exceptions
2025-10-19 06:36:45,836:INFO:Importing libraries
2025-10-19 06:36:45,836:INFO:Copying training dataset
2025-10-19 06:36:46,020:INFO:Defining folds
2025-10-19 06:36:46,020:INFO:Declaring metric variables
2025-10-19 06:36:46,026:INFO:Importing untrained model
2025-10-19 06:36:46,030:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 06:36:46,037:INFO:Starting cross validation
2025-10-19 06:36:46,044:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:37:33,549:INFO:Calculating mean and std
2025-10-19 06:37:33,550:INFO:Creating metrics dataframe
2025-10-19 06:37:33,551:INFO:Uploading results into container
2025-10-19 06:37:33,552:INFO:Uploading model into container now
2025-10-19 06:37:33,552:INFO:_master_model_container: 16
2025-10-19 06:37:33,552:INFO:_display_container: 2
2025-10-19 06:37:33,553:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 06:37:33,553:INFO:create_model() successfully completed......................................
2025-10-19 06:37:33,774:INFO:SubProcess create_model() end ==================================
2025-10-19 06:37:33,774:INFO:Creating metrics dataframe
2025-10-19 06:37:33,783:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 06:37:33,783:INFO:Total runtime is 12.346310627460479 minutes
2025-10-19 06:37:33,786:INFO:SubProcess create_model() called ==================================
2025-10-19 06:37:33,788:INFO:Initializing create_model()
2025-10-19 06:37:33,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:37:33,788:INFO:Checking exceptions
2025-10-19 06:37:33,788:INFO:Importing libraries
2025-10-19 06:37:33,788:INFO:Copying training dataset
2025-10-19 06:37:34,000:INFO:Defining folds
2025-10-19 06:37:34,000:INFO:Declaring metric variables
2025-10-19 06:37:34,003:INFO:Importing untrained model
2025-10-19 06:37:34,010:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 06:37:34,019:INFO:Starting cross validation
2025-10-19 06:37:34,026:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:37:36,256:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:37:36,280:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007540 seconds.
2025-10-19 06:37:36,280:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:37:36,280:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:37:36,280:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 06:37:36,280:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:37:36,286:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 06:37:38,994:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:37:39,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006768 seconds.
2025-10-19 06:37:39,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:37:39,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:37:39,012:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 06:37:39,012:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:37:39,013:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 06:37:41,648:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:37:41,669:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006868 seconds.
2025-10-19 06:37:41,669:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:37:41,669:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:37:41,669:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:37:41,669:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:37:41,670:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 06:37:44,255:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:37:44,272:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006376 seconds.
2025-10-19 06:37:44,272:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:37:44,272:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:37:44,272:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:37:44,273:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 06:37:44,273:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 06:37:46,804:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:37:46,822:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006941 seconds.
2025-10-19 06:37:46,822:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:37:46,822:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:37:46,822:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:37:46,823:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 06:37:46,823:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 06:37:47,406:INFO:Calculating mean and std
2025-10-19 06:37:47,408:INFO:Creating metrics dataframe
2025-10-19 06:37:47,409:INFO:Uploading results into container
2025-10-19 06:37:47,410:INFO:Uploading model into container now
2025-10-19 06:37:47,410:INFO:_master_model_container: 17
2025-10-19 06:37:47,410:INFO:_display_container: 2
2025-10-19 06:37:47,411:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 06:37:47,411:INFO:create_model() successfully completed......................................
2025-10-19 06:37:47,631:INFO:SubProcess create_model() end ==================================
2025-10-19 06:37:47,631:INFO:Creating metrics dataframe
2025-10-19 06:37:47,642:INFO:Initializing CatBoost Regressor
2025-10-19 06:37:47,643:INFO:Total runtime is 12.577308285236358 minutes
2025-10-19 06:37:47,646:INFO:SubProcess create_model() called ==================================
2025-10-19 06:37:47,647:INFO:Initializing create_model()
2025-10-19 06:37:47,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:37:47,647:INFO:Checking exceptions
2025-10-19 06:37:47,648:INFO:Importing libraries
2025-10-19 06:37:47,648:INFO:Copying training dataset
2025-10-19 06:37:47,836:INFO:Defining folds
2025-10-19 06:37:47,837:INFO:Declaring metric variables
2025-10-19 06:37:47,840:INFO:Importing untrained model
2025-10-19 06:37:47,845:INFO:CatBoost Regressor Imported successfully
2025-10-19 06:37:47,851:INFO:Starting cross validation
2025-10-19 06:37:47,856:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:39:17,210:INFO:Calculating mean and std
2025-10-19 06:39:17,213:INFO:Creating metrics dataframe
2025-10-19 06:39:17,215:INFO:Uploading results into container
2025-10-19 06:39:17,216:INFO:Uploading model into container now
2025-10-19 06:39:17,216:INFO:_master_model_container: 18
2025-10-19 06:39:17,216:INFO:_display_container: 2
2025-10-19 06:39:17,216:INFO:<catboost.core.CatBoostRegressor object at 0x000002120E91F050>
2025-10-19 06:39:17,216:INFO:create_model() successfully completed......................................
2025-10-19 06:39:17,465:INFO:SubProcess create_model() end ==================================
2025-10-19 06:39:17,465:INFO:Creating metrics dataframe
2025-10-19 06:39:17,477:INFO:Initializing Dummy Regressor
2025-10-19 06:39:17,477:INFO:Total runtime is 14.074538314342497 minutes
2025-10-19 06:39:17,482:INFO:SubProcess create_model() called ==================================
2025-10-19 06:39:17,483:INFO:Initializing create_model()
2025-10-19 06:39:17,483:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212241271D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:39:17,483:INFO:Checking exceptions
2025-10-19 06:39:17,483:INFO:Importing libraries
2025-10-19 06:39:17,483:INFO:Copying training dataset
2025-10-19 06:39:17,703:INFO:Defining folds
2025-10-19 06:39:17,703:INFO:Declaring metric variables
2025-10-19 06:39:17,706:INFO:Importing untrained model
2025-10-19 06:39:17,710:INFO:Dummy Regressor Imported successfully
2025-10-19 06:39:17,719:INFO:Starting cross validation
2025-10-19 06:39:17,724:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:39:28,635:INFO:Calculating mean and std
2025-10-19 06:39:28,636:INFO:Creating metrics dataframe
2025-10-19 06:39:28,637:INFO:Uploading results into container
2025-10-19 06:39:28,638:INFO:Uploading model into container now
2025-10-19 06:39:28,638:INFO:_master_model_container: 19
2025-10-19 06:39:28,638:INFO:_display_container: 2
2025-10-19 06:39:28,639:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-10-19 06:39:28,639:INFO:create_model() successfully completed......................................
2025-10-19 06:39:28,883:INFO:SubProcess create_model() end ==================================
2025-10-19 06:39:28,883:INFO:Creating metrics dataframe
2025-10-19 06:39:28,894:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 06:39:28,906:INFO:Initializing create_model()
2025-10-19 06:39:28,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:39:28,907:INFO:Checking exceptions
2025-10-19 06:39:28,909:INFO:Importing libraries
2025-10-19 06:39:28,909:INFO:Copying training dataset
2025-10-19 06:39:29,119:INFO:Defining folds
2025-10-19 06:39:29,119:INFO:Declaring metric variables
2025-10-19 06:39:29,119:INFO:Importing untrained model
2025-10-19 06:39:29,119:INFO:Declaring custom model
2025-10-19 06:39:29,119:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 06:39:29,122:INFO:Cross validation set to False
2025-10-19 06:39:29,122:INFO:Fitting Model
2025-10-19 06:39:40,995:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 06:39:40,995:INFO:create_model() successfully completed......................................
2025-10-19 06:39:41,239:INFO:Initializing create_model()
2025-10-19 06:39:41,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:39:41,239:INFO:Checking exceptions
2025-10-19 06:39:41,241:INFO:Importing libraries
2025-10-19 06:39:41,241:INFO:Copying training dataset
2025-10-19 06:39:41,411:INFO:Defining folds
2025-10-19 06:39:41,411:INFO:Declaring metric variables
2025-10-19 06:39:41,412:INFO:Importing untrained model
2025-10-19 06:39:41,412:INFO:Declaring custom model
2025-10-19 06:39:41,413:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 06:39:41,417:INFO:Cross validation set to False
2025-10-19 06:39:41,417:INFO:Fitting Model
2025-10-19 06:39:43,972:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:39:43,996:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008828 seconds.
2025-10-19 06:39:43,996:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:39:43,996:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:39:43,997:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 06:39:43,997:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 06:39:43,998:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 06:39:44,463:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 06:39:44,463:INFO:create_model() successfully completed......................................
2025-10-19 06:39:44,688:INFO:Initializing create_model()
2025-10-19 06:39:44,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=<catboost.core.CatBoostRegressor object at 0x000002120E91F050>, fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:39:44,688:INFO:Checking exceptions
2025-10-19 06:39:44,691:INFO:Importing libraries
2025-10-19 06:39:44,691:INFO:Copying training dataset
2025-10-19 06:39:44,870:INFO:Defining folds
2025-10-19 06:39:44,870:INFO:Declaring metric variables
2025-10-19 06:39:44,870:INFO:Importing untrained model
2025-10-19 06:39:44,870:INFO:Declaring custom model
2025-10-19 06:39:44,870:INFO:CatBoost Regressor Imported successfully
2025-10-19 06:39:44,873:INFO:Cross validation set to False
2025-10-19 06:39:44,873:INFO:Fitting Model
2025-10-19 06:40:05,697:INFO:<catboost.core.CatBoostRegressor object at 0x000002120EB3C690>
2025-10-19 06:40:05,697:INFO:create_model() successfully completed......................................
2025-10-19 06:40:05,962:INFO:_master_model_container: 19
2025-10-19 06:40:05,962:INFO:_display_container: 2
2025-10-19 06:40:05,963:INFO:[GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostRegressor object at 0x000002120EB3C690>]
2025-10-19 06:40:05,963:INFO:compare_models() successfully completed......................................
2025-10-19 06:40:05,981:INFO:Initializing tune_model()
2025-10-19 06:40:05,981:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 06:40:05,981:INFO:Checking exceptions
2025-10-19 06:40:06,076:INFO:Copying training dataset
2025-10-19 06:40:06,219:INFO:Checking base model
2025-10-19 06:40:06,219:INFO:Base model : Gradient Boosting Regressor
2025-10-19 06:40:06,222:INFO:Declaring metric variables
2025-10-19 06:40:06,226:INFO:Defining Hyperparameters
2025-10-19 06:40:06,455:INFO:Tuning with n_jobs=1
2025-10-19 06:40:06,455:INFO:Initializing RandomizedSearchCV
2025-10-19 06:43:48,585:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 270, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.05}
2025-10-19 06:43:48,586:INFO:Hyperparameter search completed
2025-10-19 06:43:48,586:INFO:SubProcess create_model() called ==================================
2025-10-19 06:43:48,587:INFO:Initializing create_model()
2025-10-19 06:43:48,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002127DDE1490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 270, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 6, 'learning_rate': 0.05})
2025-10-19 06:43:48,588:INFO:Checking exceptions
2025-10-19 06:43:48,588:INFO:Importing libraries
2025-10-19 06:43:48,588:INFO:Copying training dataset
2025-10-19 06:43:48,771:INFO:Defining folds
2025-10-19 06:43:48,772:INFO:Declaring metric variables
2025-10-19 06:43:48,776:INFO:Importing untrained model
2025-10-19 06:43:48,777:INFO:Declaring custom model
2025-10-19 06:43:48,782:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 06:43:48,788:INFO:Starting cross validation
2025-10-19 06:43:48,793:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:44:18,562:INFO:Calculating mean and std
2025-10-19 06:44:18,563:INFO:Creating metrics dataframe
2025-10-19 06:44:18,569:INFO:Finalizing model
2025-10-19 06:44:26,092:INFO:Uploading results into container
2025-10-19 06:44:26,093:INFO:Uploading model into container now
2025-10-19 06:44:26,096:INFO:_master_model_container: 20
2025-10-19 06:44:26,096:INFO:_display_container: 3
2025-10-19 06:44:26,097:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.05, loss='squared_error',
                          max_depth=6, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.3, min_samples_leaf=4,
                          min_samples_split=10, min_weight_fraction_leaf=0.0,
                          n_estimators=270, n_iter_no_change=None,
                          random_state=42, subsample=0.7, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 06:44:26,097:INFO:create_model() successfully completed......................................
2025-10-19 06:44:26,361:INFO:SubProcess create_model() end ==================================
2025-10-19 06:44:26,361:INFO:choose_better activated
2025-10-19 06:44:26,366:INFO:SubProcess create_model() called ==================================
2025-10-19 06:44:26,367:INFO:Initializing create_model()
2025-10-19 06:44:26,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:44:26,367:INFO:Checking exceptions
2025-10-19 06:44:26,369:INFO:Importing libraries
2025-10-19 06:44:26,369:INFO:Copying training dataset
2025-10-19 06:44:26,542:INFO:Defining folds
2025-10-19 06:44:26,543:INFO:Declaring metric variables
2025-10-19 06:44:26,543:INFO:Importing untrained model
2025-10-19 06:44:26,543:INFO:Declaring custom model
2025-10-19 06:44:26,543:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 06:44:26,544:INFO:Starting cross validation
2025-10-19 06:44:26,548:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:45:15,071:INFO:Calculating mean and std
2025-10-19 06:45:15,071:INFO:Creating metrics dataframe
2025-10-19 06:45:15,074:INFO:Finalizing model
2025-10-19 06:45:26,667:INFO:Uploading results into container
2025-10-19 06:45:26,668:INFO:Uploading model into container now
2025-10-19 06:45:26,668:INFO:_master_model_container: 21
2025-10-19 06:45:26,668:INFO:_display_container: 4
2025-10-19 06:45:26,669:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 06:45:26,669:INFO:create_model() successfully completed......................................
2025-10-19 06:45:26,911:INFO:SubProcess create_model() end ==================================
2025-10-19 06:45:26,911:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for RMSE is 0.475
2025-10-19 06:45:26,912:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.05, loss='squared_error',
                          max_depth=6, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.3, min_samples_leaf=4,
                          min_samples_split=10, min_weight_fraction_leaf=0.0,
                          n_estimators=270, n_iter_no_change=None,
                          random_state=42, subsample=0.7, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for RMSE is 0.4755
2025-10-19 06:45:26,912:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) is best model
2025-10-19 06:45:26,912:INFO:choose_better completed
2025-10-19 06:45:26,912:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 06:45:26,923:INFO:_master_model_container: 21
2025-10-19 06:45:26,924:INFO:_display_container: 3
2025-10-19 06:45:26,924:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 06:45:26,924:INFO:tune_model() successfully completed......................................
2025-10-19 06:45:27,171:INFO:Initializing tune_model()
2025-10-19 06:45:27,171:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 06:45:27,171:INFO:Checking exceptions
2025-10-19 06:45:27,254:INFO:Copying training dataset
2025-10-19 06:45:27,388:INFO:Checking base model
2025-10-19 06:45:27,388:INFO:Base model : Light Gradient Boosting Machine
2025-10-19 06:45:27,392:INFO:Declaring metric variables
2025-10-19 06:45:27,394:INFO:Defining Hyperparameters
2025-10-19 06:45:27,611:INFO:Tuning with n_jobs=1
2025-10-19 06:45:27,611:INFO:Initializing RandomizedSearchCV
2025-10-19 06:47:55,570:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2025-10-19 06:47:55,571:INFO:Hyperparameter search completed
2025-10-19 06:47:55,571:INFO:SubProcess create_model() called ==================================
2025-10-19 06:47:55,572:INFO:Initializing create_model()
2025-10-19 06:47:55,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B90E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 5, 'reg_alpha': 0.001, 'num_leaves': 30, 'n_estimators': 100, 'min_split_gain': 0.6, 'min_child_samples': 6, 'learning_rate': 0.2, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2025-10-19 06:47:55,572:INFO:Checking exceptions
2025-10-19 06:47:55,572:INFO:Importing libraries
2025-10-19 06:47:55,572:INFO:Copying training dataset
2025-10-19 06:47:55,774:INFO:Defining folds
2025-10-19 06:47:55,774:INFO:Declaring metric variables
2025-10-19 06:47:55,779:INFO:Importing untrained model
2025-10-19 06:47:55,779:INFO:Declaring custom model
2025-10-19 06:47:55,786:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 06:47:55,797:INFO:Starting cross validation
2025-10-19 06:47:55,801:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:47:57,772:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:47:57,772:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:47:57,773:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:47:57,867:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:47:57,870:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:47:57,870:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:47:57,870:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:47:57,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004483 seconds.
2025-10-19 06:47:57,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:47:57,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:47:57,883:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 06:47:57,883:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:47:57,883:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 06:47:58,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,116:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,117:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,117:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,119:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,120:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,120:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,123:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,124:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,126:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,127:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,130:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,131:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,133:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,134:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,136:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,137:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,139:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,140:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,141:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,143:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,145:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,147:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,148:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,149:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,151:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,152:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,153:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,155:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,157:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,157:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,160:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,162:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,163:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,164:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,166:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,167:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,168:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,170:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,172:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,173:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,174:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,177:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,179:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,180:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,181:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:47:58,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:47:58,403:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:47:58,403:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:47:58,403:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:00,379:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:00,379:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:00,379:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:00,462:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:00,464:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:00,464:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:00,464:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:00,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006549 seconds.
2025-10-19 06:48:00,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:00,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:00,482:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 06:48:00,482:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:48:00,482:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 06:48:00,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,763:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,764:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,767:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,768:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,770:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,783:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,783:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,784:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,785:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,785:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,790:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,790:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,804:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,806:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:00,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:00,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:01,021:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:01,021:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:01,021:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:03,069:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:03,069:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:03,069:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:03,154:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:03,156:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:03,156:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:03,156:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:03,172:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006728 seconds.
2025-10-19 06:48:03,172:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:03,172:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:03,172:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:48:03,172:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:48:03,173:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 06:48:03,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,415:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,472:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,480:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,481:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,482:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,496:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,497:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,499:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,500:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,502:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,503:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,505:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,507:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,509:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,511:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,513:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,514:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,516:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,517:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,525:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,526:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:03,737:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:03,737:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:03,737:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:05,676:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:05,676:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:05,676:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:05,763:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:05,763:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:05,763:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:05,763:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:05,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005737 seconds.
2025-10-19 06:48:05,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:05,781:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:05,781:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:48:05,781:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 06:48:05,782:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 06:48:05,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:05,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,041:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,042:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,079:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,081:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,082:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,084:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,115:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:06,116:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:06,316:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:06,316:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:06,316:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:08,257:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:08,257:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:08,257:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:08,344:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:08,345:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:08,346:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:08,346:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:08,361:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006865 seconds.
2025-10-19 06:48:08,361:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:08,361:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:08,361:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:48:08,362:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 06:48:08,362:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 06:48:08,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,589:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,602:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,603:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,605:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,608:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,610:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,612:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,627:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,629:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,630:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,632:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,633:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,635:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,636:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,657:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,661:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,676:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,677:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:08,679:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:08,887:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:08,887:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:08,887:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:08,916:INFO:Calculating mean and std
2025-10-19 06:48:08,918:INFO:Creating metrics dataframe
2025-10-19 06:48:08,925:INFO:Finalizing model
2025-10-19 06:48:11,399:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:11,399:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:11,399:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:11,518:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:11,520:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 06:48:11,521:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 06:48:11,521:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 06:48:11,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010546 seconds.
2025-10-19 06:48:11,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:11,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:11,547:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 06:48:11,548:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 06:48:11,548:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 06:48:11,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,845:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,852:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,855:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,857:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,860:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,862:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,865:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,867:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,869:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,871:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,872:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,874:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,879:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,880:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,886:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,887:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,889:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,894:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,897:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,906:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,909:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,913:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,915:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,919:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,923:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 06:48:11,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 06:48:11,954:INFO:Uploading results into container
2025-10-19 06:48:11,956:INFO:Uploading model into container now
2025-10-19 06:48:11,957:INFO:_master_model_container: 22
2025-10-19 06:48:11,958:INFO:_display_container: 4
2025-10-19 06:48:11,959:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
              importance_type='split', learning_rate=0.2, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.6,
              n_estimators=100, n_jobs=1, num_leaves=30, objective=None,
              random_state=42, reg_alpha=0.001, reg_lambda=5, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 06:48:11,959:INFO:create_model() successfully completed......................................
2025-10-19 06:48:12,228:INFO:SubProcess create_model() end ==================================
2025-10-19 06:48:12,229:INFO:choose_better activated
2025-10-19 06:48:12,233:INFO:SubProcess create_model() called ==================================
2025-10-19 06:48:12,235:INFO:Initializing create_model()
2025-10-19 06:48:12,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:48:12,236:INFO:Checking exceptions
2025-10-19 06:48:12,237:INFO:Importing libraries
2025-10-19 06:48:12,237:INFO:Copying training dataset
2025-10-19 06:48:12,432:INFO:Defining folds
2025-10-19 06:48:12,432:INFO:Declaring metric variables
2025-10-19 06:48:12,432:INFO:Importing untrained model
2025-10-19 06:48:12,432:INFO:Declaring custom model
2025-10-19 06:48:12,433:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 06:48:12,434:INFO:Starting cross validation
2025-10-19 06:48:12,436:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:48:14,664:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:14,682:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007128 seconds.
2025-10-19 06:48:14,682:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:14,682:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:14,683:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 06:48:14,683:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:48:14,683:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 06:48:17,271:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:17,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005048 seconds.
2025-10-19 06:48:17,287:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:17,287:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:17,287:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 06:48:17,287:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:48:17,288:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 06:48:19,925:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:19,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007175 seconds.
2025-10-19 06:48:19,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:19,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:19,944:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:48:19,944:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:48:19,945:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 06:48:22,489:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:22,507:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007003 seconds.
2025-10-19 06:48:22,507:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:22,507:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:22,507:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:48:22,507:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 06:48:22,508:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 06:48:25,079:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:25,099:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007412 seconds.
2025-10-19 06:48:25,099:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:25,099:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:25,099:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:48:25,100:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 06:48:25,100:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 06:48:25,713:INFO:Calculating mean and std
2025-10-19 06:48:25,714:INFO:Creating metrics dataframe
2025-10-19 06:48:25,715:INFO:Finalizing model
2025-10-19 06:48:28,143:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:48:28,159:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005227 seconds.
2025-10-19 06:48:28,160:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:48:28,160:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:48:28,160:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 06:48:28,160:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 06:48:28,161:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 06:48:28,622:INFO:Uploading results into container
2025-10-19 06:48:28,622:INFO:Uploading model into container now
2025-10-19 06:48:28,623:INFO:_master_model_container: 23
2025-10-19 06:48:28,623:INFO:_display_container: 5
2025-10-19 06:48:28,623:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 06:48:28,623:INFO:create_model() successfully completed......................................
2025-10-19 06:48:28,845:INFO:SubProcess create_model() end ==================================
2025-10-19 06:48:28,846:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for RMSE is 0.4751
2025-10-19 06:48:28,846:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
              importance_type='split', learning_rate=0.2, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.6,
              n_estimators=100, n_jobs=1, num_leaves=30, objective=None,
              random_state=42, reg_alpha=0.001, reg_lambda=5, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for RMSE is 0.476
2025-10-19 06:48:28,847:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-19 06:48:28,847:INFO:choose_better completed
2025-10-19 06:48:28,847:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 06:48:28,856:INFO:_master_model_container: 23
2025-10-19 06:48:28,856:INFO:_display_container: 4
2025-10-19 06:48:28,857:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 06:48:28,857:INFO:tune_model() successfully completed......................................
2025-10-19 06:48:29,141:INFO:Initializing tune_model()
2025-10-19 06:48:29,141:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=<catboost.core.CatBoostRegressor object at 0x000002120EB3C690>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 06:48:29,141:INFO:Checking exceptions
2025-10-19 06:48:29,234:INFO:Copying training dataset
2025-10-19 06:48:29,378:INFO:Checking base model
2025-10-19 06:48:29,378:INFO:Base model : CatBoost Regressor
2025-10-19 06:48:29,382:INFO:Declaring metric variables
2025-10-19 06:48:29,386:INFO:Defining Hyperparameters
2025-10-19 06:48:29,622:INFO:Tuning with n_jobs=1
2025-10-19 06:48:29,622:INFO:Initializing RandomizedSearchCV
2025-10-19 06:52:40,334:INFO:best_params: {'actual_estimator__random_strength': 0.5, 'actual_estimator__n_estimators': 280, 'actual_estimator__l2_leaf_reg': 200, 'actual_estimator__eta': 0.05, 'actual_estimator__depth': 5}
2025-10-19 06:52:40,335:INFO:Hyperparameter search completed
2025-10-19 06:52:40,335:INFO:SubProcess create_model() called ==================================
2025-10-19 06:52:40,337:INFO:Initializing create_model()
2025-10-19 06:52:40,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=<catboost.core.CatBoostRegressor object at 0x00000212077E9410>, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120794B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.5, 'n_estimators': 280, 'l2_leaf_reg': 200, 'eta': 0.05, 'depth': 5})
2025-10-19 06:52:40,337:INFO:Checking exceptions
2025-10-19 06:52:40,337:INFO:Importing libraries
2025-10-19 06:52:40,337:INFO:Copying training dataset
2025-10-19 06:52:40,518:INFO:Defining folds
2025-10-19 06:52:40,519:INFO:Declaring metric variables
2025-10-19 06:52:40,525:INFO:Importing untrained model
2025-10-19 06:52:40,525:INFO:Declaring custom model
2025-10-19 06:52:40,530:INFO:CatBoost Regressor Imported successfully
2025-10-19 06:52:40,537:INFO:Starting cross validation
2025-10-19 06:52:40,543:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:53:09,792:INFO:Calculating mean and std
2025-10-19 06:53:09,797:INFO:Creating metrics dataframe
2025-10-19 06:53:09,805:INFO:Finalizing model
2025-10-19 06:53:17,017:INFO:Uploading results into container
2025-10-19 06:53:17,018:INFO:Uploading model into container now
2025-10-19 06:53:17,019:INFO:_master_model_container: 24
2025-10-19 06:53:17,020:INFO:_display_container: 5
2025-10-19 06:53:17,020:INFO:<catboost.core.CatBoostRegressor object at 0x00000212076097D0>
2025-10-19 06:53:17,020:INFO:create_model() successfully completed......................................
2025-10-19 06:53:17,329:INFO:SubProcess create_model() end ==================================
2025-10-19 06:53:17,329:INFO:choose_better activated
2025-10-19 06:53:17,333:INFO:SubProcess create_model() called ==================================
2025-10-19 06:53:17,334:INFO:Initializing create_model()
2025-10-19 06:53:17,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=<catboost.core.CatBoostRegressor object at 0x000002120EB3C690>, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:53:17,334:INFO:Checking exceptions
2025-10-19 06:53:17,336:INFO:Importing libraries
2025-10-19 06:53:17,336:INFO:Copying training dataset
2025-10-19 06:53:17,517:INFO:Defining folds
2025-10-19 06:53:17,517:INFO:Declaring metric variables
2025-10-19 06:53:17,517:INFO:Importing untrained model
2025-10-19 06:53:17,517:INFO:Declaring custom model
2025-10-19 06:53:17,517:INFO:CatBoost Regressor Imported successfully
2025-10-19 06:53:17,518:INFO:Starting cross validation
2025-10-19 06:53:17,520:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:54:46,874:INFO:Calculating mean and std
2025-10-19 06:54:46,874:INFO:Creating metrics dataframe
2025-10-19 06:54:46,875:INFO:Finalizing model
2025-10-19 06:55:07,811:INFO:Uploading results into container
2025-10-19 06:55:07,812:INFO:Uploading model into container now
2025-10-19 06:55:07,812:INFO:_master_model_container: 25
2025-10-19 06:55:07,812:INFO:_display_container: 6
2025-10-19 06:55:07,813:INFO:<catboost.core.CatBoostRegressor object at 0x000002120EA95690>
2025-10-19 06:55:07,813:INFO:create_model() successfully completed......................................
2025-10-19 06:55:08,084:INFO:SubProcess create_model() end ==================================
2025-10-19 06:55:08,084:INFO:<catboost.core.CatBoostRegressor object at 0x000002120EA95690> result for RMSE is 0.4774
2025-10-19 06:55:08,084:INFO:<catboost.core.CatBoostRegressor object at 0x00000212076097D0> result for RMSE is 0.4747
2025-10-19 06:55:08,084:INFO:<catboost.core.CatBoostRegressor object at 0x00000212076097D0> is best model
2025-10-19 06:55:08,084:INFO:choose_better completed
2025-10-19 06:55:08,092:INFO:_master_model_container: 25
2025-10-19 06:55:08,092:INFO:_display_container: 5
2025-10-19 06:55:08,093:INFO:<catboost.core.CatBoostRegressor object at 0x00000212076097D0>
2025-10-19 06:55:08,093:INFO:tune_model() successfully completed......................................
2025-10-19 06:55:08,341:INFO:Initializing blend_models()
2025-10-19 06:55:08,341:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator_list=[GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostRegressor object at 0x00000212076097D0>], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-19 06:55:08,341:INFO:Checking exceptions
2025-10-19 06:55:08,425:INFO:Importing libraries
2025-10-19 06:55:08,425:INFO:Copying training dataset
2025-10-19 06:55:08,431:INFO:Getting model names
2025-10-19 06:55:08,437:INFO:SubProcess create_model() called ==================================
2025-10-19 06:55:08,445:INFO:Initializing create_model()
2025-10-19 06:55:08,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x00000212076097D0>)],
                n_jobs=1, verbose=False, weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212061F1F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:55:08,446:INFO:Checking exceptions
2025-10-19 06:55:08,446:INFO:Importing libraries
2025-10-19 06:55:08,446:INFO:Copying training dataset
2025-10-19 06:55:08,669:INFO:Defining folds
2025-10-19 06:55:08,669:INFO:Declaring metric variables
2025-10-19 06:55:08,672:INFO:Importing untrained model
2025-10-19 06:55:08,672:INFO:Declaring custom model
2025-10-19 06:55:08,678:INFO:Voting Regressor Imported successfully
2025-10-19 06:55:08,685:INFO:Starting cross validation
2025-10-19 06:55:08,690:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 06:55:18,665:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:55:18,684:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007080 seconds.
2025-10-19 06:55:18,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:55:18,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:55:18,684:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 06:55:18,684:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:55:18,685:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 06:55:32,372:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:55:32,390:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007512 seconds.
2025-10-19 06:55:32,390:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:55:32,391:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:55:32,391:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 06:55:32,391:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:55:32,391:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 06:55:46,112:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:55:46,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004045 seconds.
2025-10-19 06:55:46,125:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:55:46,125:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:55:46,126:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:55:46,126:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 06:55:46,126:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 06:55:59,739:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:55:59,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007264 seconds.
2025-10-19 06:55:59,757:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:55:59,757:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:55:59,757:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:55:59,757:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 06:55:59,757:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 06:56:13,626:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:56:13,643:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004724 seconds.
2025-10-19 06:56:13,643:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:56:13,643:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:56:13,643:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:56:13,643:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 06:56:13,644:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 06:56:18,085:INFO:Calculating mean and std
2025-10-19 06:56:18,086:INFO:Creating metrics dataframe
2025-10-19 06:56:18,092:INFO:Finalizing model
2025-10-19 06:56:30,062:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:56:30,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008524 seconds.
2025-10-19 06:56:30,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:56:30,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:56:30,084:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 06:56:30,084:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 06:56:30,085:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 06:56:35,196:INFO:Uploading results into container
2025-10-19 06:56:35,196:INFO:Uploading model into container now
2025-10-19 06:56:35,198:INFO:_master_model_container: 26
2025-10-19 06:56:35,198:INFO:_display_container: 6
2025-10-19 06:56:35,202:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x000002120EB718D0>)],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 06:56:35,202:INFO:create_model() successfully completed......................................
2025-10-19 06:56:35,478:INFO:SubProcess create_model() end ==================================
2025-10-19 06:56:35,487:INFO:_master_model_container: 26
2025-10-19 06:56:35,487:INFO:_display_container: 6
2025-10-19 06:56:35,494:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x000002120EB718D0>)],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 06:56:35,494:INFO:blend_models() successfully completed......................................
2025-10-19 06:56:35,806:INFO:Initializing finalize_model()
2025-10-19 06:56:35,806:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x000002120EB718D0>)],
                n_jobs=1, verbose=False, weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-19 06:56:35,810:INFO:Finalizing VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x000002120EB718D0>)],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 06:56:35,974:INFO:Initializing create_model()
2025-10-19 06:56:35,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x000002120EB718D0>)],
                n_jobs=1, verbose=False, weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62296    U09331
28248    U08761
48600    U06118
8049     U04657
48533    U06931
Name: id_usuario, Length: 63955, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 06:56:35,975:INFO:Checking exceptions
2025-10-19 06:56:35,976:INFO:Importing libraries
2025-10-19 06:56:35,976:INFO:Copying training dataset
2025-10-19 06:56:36,002:INFO:Defining folds
2025-10-19 06:56:36,002:INFO:Declaring metric variables
2025-10-19 06:56:36,002:INFO:Importing untrained model
2025-10-19 06:56:36,002:INFO:Declaring custom model
2025-10-19 06:56:36,005:INFO:Voting Regressor Imported successfully
2025-10-19 06:56:36,010:INFO:Cross validation set to False
2025-10-19 06:56:36,010:INFO:Fitting Model
2025-10-19 06:56:55,366:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 06:56:55,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012723 seconds.
2025-10-19 06:56:55,398:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 06:56:55,398:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 06:56:55,398:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 06:56:55,398:INFO:[LightGBM] [Info] Number of data points in the train set: 63955, number of used features: 95
2025-10-19 06:56:55,399:INFO:[LightGBM] [Info] Start training from score 3.320833
2025-10-19 06:57:02,291:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000021206D492D0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 06:57:02,291:INFO:create_model() successfully completed......................................
2025-10-19 06:57:02,546:INFO:_master_model_container: 26
2025-10-19 06:57:02,546:INFO:_display_container: 6
2025-10-19 06:57:02,570:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000021206D492D0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 06:57:02,570:INFO:finalize_model() successfully completed......................................
2025-10-19 06:57:02,835:INFO:Initializing save_model()
2025-10-19 06:57:02,835:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000021206D492D0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), model_name=modelo_reg_rating_v2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-10-19 06:57:02,835:INFO:Adding model into prep_pipe
2025-10-19 06:57:02,835:WARNING:Only Model saved as it was a pipeline.
2025-10-19 06:57:02,869:INFO:modelo_reg_rating_v2.pkl saved in current working directory
2025-10-19 06:57:02,893:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000021206D492D0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 06:57:02,893:INFO:save_model() successfully completed......................................
2025-10-19 06:57:03,215:INFO:Initializing predict_model()
2025-10-19 06:57:03,215:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002127C4A7A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000021206D492D0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002120AEC0180>)
2025-10-19 06:57:03,216:INFO:Checking exceptions
2025-10-19 06:57:03,216:INFO:Preloading libraries
2025-10-19 06:57:03,218:INFO:Set up data.
2025-10-19 06:57:03,244:INFO:Set up index.
2025-10-19 07:01:27,033:INFO:PyCaret RegressionExperiment
2025-10-19 07:01:27,034:INFO:Logging name: reg-default-name
2025-10-19 07:01:27,034:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-19 07:01:27,034:INFO:version 3.3.2
2025-10-19 07:01:27,034:INFO:Initializing setup()
2025-10-19 07:01:27,034:INFO:self.USI: 9135
2025-10-19 07:01:27,034:INFO:self._variable_keys: {'USI', 'seed', 'memory', 'html_param', 'X_test', 'target_param', 'transform_target_param', 'logging_param', 'fold_groups_param', 'exp_id', 'exp_name_log', 'log_plots_param', 'y_train', 'y', 'X', 'fold_generator', 'fold_shuffle_param', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', '_available_plots', 'idx', 'data', 'pipeline', 'X_train', '_ml_usecase', 'y_test'}
2025-10-19 07:01:27,034:INFO:Checking environment
2025-10-19 07:01:27,034:INFO:python_version: 3.11.13
2025-10-19 07:01:27,034:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 07:01:27,034:INFO:machine: AMD64
2025-10-19 07:01:27,034:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 07:01:27,042:INFO:Memory: svmem(total=16856211456, available=3708514304, percent=78.0, used=13147697152, free=3708514304)
2025-10-19 07:01:27,042:INFO:Physical Core: 4
2025-10-19 07:01:27,042:INFO:Logical Core: 8
2025-10-19 07:01:27,042:INFO:Checking libraries
2025-10-19 07:01:27,042:INFO:System:
2025-10-19 07:01:27,042:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 07:01:27,042:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 07:01:27,042:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 07:01:27,042:INFO:PyCaret required dependencies:
2025-10-19 07:01:27,043:INFO:                 pip: 25.2
2025-10-19 07:01:27,043:INFO:          setuptools: 80.9.0
2025-10-19 07:01:27,043:INFO:             pycaret: 3.3.2
2025-10-19 07:01:27,043:INFO:             IPython: 9.6.0
2025-10-19 07:01:27,043:INFO:          ipywidgets: 8.1.7
2025-10-19 07:01:27,043:INFO:                tqdm: 4.67.1
2025-10-19 07:01:27,043:INFO:               numpy: 1.26.4
2025-10-19 07:01:27,043:INFO:              pandas: 2.1.4
2025-10-19 07:01:27,043:INFO:              jinja2: 3.1.6
2025-10-19 07:01:27,043:INFO:               scipy: 1.11.4
2025-10-19 07:01:27,043:INFO:              joblib: 1.3.2
2025-10-19 07:01:27,043:INFO:             sklearn: 1.4.2
2025-10-19 07:01:27,043:INFO:                pyod: 2.0.5
2025-10-19 07:01:27,043:INFO:            imblearn: 0.14.0
2025-10-19 07:01:27,043:INFO:   category_encoders: 2.7.0
2025-10-19 07:01:27,043:INFO:            lightgbm: 4.6.0
2025-10-19 07:01:27,043:INFO:               numba: 0.61.0
2025-10-19 07:01:27,043:INFO:            requests: 2.32.5
2025-10-19 07:01:27,043:INFO:          matplotlib: 3.7.5
2025-10-19 07:01:27,043:INFO:          scikitplot: 0.3.7
2025-10-19 07:01:27,043:INFO:         yellowbrick: 1.5
2025-10-19 07:01:27,043:INFO:              plotly: 5.24.1
2025-10-19 07:01:27,043:INFO:    plotly-resampler: Not installed
2025-10-19 07:01:27,043:INFO:             kaleido: 1.1.0
2025-10-19 07:01:27,043:INFO:           schemdraw: 0.15
2025-10-19 07:01:27,043:INFO:         statsmodels: 0.14.5
2025-10-19 07:01:27,043:INFO:              sktime: 0.26.0
2025-10-19 07:01:27,043:INFO:               tbats: 1.1.3
2025-10-19 07:01:27,043:INFO:            pmdarima: 2.0.4
2025-10-19 07:01:27,043:INFO:              psutil: 7.1.0
2025-10-19 07:01:27,043:INFO:          markupsafe: 3.0.3
2025-10-19 07:01:27,044:INFO:             pickle5: Not installed
2025-10-19 07:01:27,044:INFO:         cloudpickle: 3.1.1
2025-10-19 07:01:27,044:INFO:         deprecation: 2.1.0
2025-10-19 07:01:27,044:INFO:              xxhash: 3.6.0
2025-10-19 07:01:27,044:INFO:           wurlitzer: Not installed
2025-10-19 07:01:27,044:INFO:PyCaret optional dependencies:
2025-10-19 07:01:27,044:INFO:                shap: 0.44.1
2025-10-19 07:01:27,044:INFO:           interpret: 0.7.3
2025-10-19 07:01:27,044:INFO:                umap: 0.5.7
2025-10-19 07:01:27,044:INFO:     ydata_profiling: 4.17.0
2025-10-19 07:01:27,044:INFO:  explainerdashboard: 0.5.1
2025-10-19 07:01:27,044:INFO:             autoviz: Not installed
2025-10-19 07:01:27,044:INFO:           fairlearn: 0.7.0
2025-10-19 07:01:27,044:INFO:          deepchecks: Not installed
2025-10-19 07:01:27,044:INFO:             xgboost: Not installed
2025-10-19 07:01:27,044:INFO:            catboost: 1.2.8
2025-10-19 07:01:27,044:INFO:              kmodes: 0.12.2
2025-10-19 07:01:27,044:INFO:             mlxtend: 0.23.4
2025-10-19 07:01:27,044:INFO:       statsforecast: 1.5.0
2025-10-19 07:01:27,044:INFO:        tune_sklearn: Not installed
2025-10-19 07:01:27,044:INFO:                 ray: Not installed
2025-10-19 07:01:27,044:INFO:            hyperopt: 0.2.7
2025-10-19 07:01:27,044:INFO:              optuna: 4.5.0
2025-10-19 07:01:27,044:INFO:               skopt: 0.10.2
2025-10-19 07:01:27,044:INFO:              mlflow: 3.5.0
2025-10-19 07:01:27,044:INFO:              gradio: 5.49.1
2025-10-19 07:01:27,044:INFO:             fastapi: 0.119.0
2025-10-19 07:01:27,044:INFO:             uvicorn: 0.38.0
2025-10-19 07:01:27,044:INFO:              m2cgen: 0.10.0
2025-10-19 07:01:27,044:INFO:           evidently: 0.4.40
2025-10-19 07:01:27,045:INFO:               fugue: 0.8.7
2025-10-19 07:01:27,045:INFO:           streamlit: Not installed
2025-10-19 07:01:27,045:INFO:             prophet: Not installed
2025-10-19 07:01:27,045:INFO:None
2025-10-19 07:01:27,045:INFO:Set up data.
2025-10-19 07:01:27,197:INFO:Set up folding strategy.
2025-10-19 07:01:27,383:INFO:Set up train/test split.
2025-10-19 07:01:27,577:INFO:Set up index.
2025-10-19 07:01:27,590:INFO:Assigning column types.
2025-10-19 07:01:27,800:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 07:01:27,801:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-19 07:01:27,808:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 07:01:27,812:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,060:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:28,107:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:28,108:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,112:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,116:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,335:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,378:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:28,379:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:28,380:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-19 07:01:28,383:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,391:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,591:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,689:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:28,690:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:28,697:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,909:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 07:01:28,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:28,945:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:28,946:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-19 07:01:28,953:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 07:01:29,135:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 07:01:29,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 07:01:29,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:29,173:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:29,180:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 07:01:29,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 07:01:29,384:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 07:01:29,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:29,384:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:29,385:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-19 07:01:29,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 07:01:29,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 07:01:29,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:29,591:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:29,766:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 07:01:29,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 07:01:29,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:29,800:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:29,801:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 07:01:29,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 07:01:30,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:30,020:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:30,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 07:01:30,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:30,241:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:30,241:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-19 07:01:30,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:30,451:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:30,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:30,672:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:30,673:INFO:Preparing preprocessing pipeline...
2025-10-19 07:01:30,673:INFO:Set up simple imputation.
2025-10-19 07:01:30,803:INFO:Set up encoding of ordinal features.
2025-10-19 07:01:30,861:INFO:Set up encoding of categorical features.
2025-10-19 07:01:30,863:INFO:Set up removing multicollinearity.
2025-10-19 07:01:30,889:INFO:Set up column name cleaning.
2025-10-19 07:01:32,282:INFO:Finished creating preprocessing pipeline.
2025-10-19 07:01:32,299:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 07:01:32,299:INFO:Creating final display dataframe.
2025-10-19 07:01:34,864:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target    rating_usuario
2                   Target type        Regression
3           Original data shape       (63955, 28)
4        Transformed data shape       (63955, 96)
5   Transformed train set shape       (44768, 96)
6    Transformed test set shape       (19187, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              9135
2025-10-19 07:01:35,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:35,066:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:35,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 07:01:35,277:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 07:01:35,277:INFO:setup() successfully completed in 8.26s...............
2025-10-19 07:01:35,278:INFO:Initializing compare_models()
2025-10-19 07:01:35,278:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-19 07:01:35,278:INFO:Checking exceptions
2025-10-19 07:01:35,347:INFO:Preparing display monitor
2025-10-19 07:01:35,377:INFO:Initializing Linear Regression
2025-10-19 07:01:35,377:INFO:Total runtime is 0.0 minutes
2025-10-19 07:01:35,381:INFO:SubProcess create_model() called ==================================
2025-10-19 07:01:35,383:INFO:Initializing create_model()
2025-10-19 07:01:35,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:01:35,384:INFO:Checking exceptions
2025-10-19 07:01:35,384:INFO:Importing libraries
2025-10-19 07:01:35,384:INFO:Copying training dataset
2025-10-19 07:01:35,584:INFO:Defining folds
2025-10-19 07:01:35,584:INFO:Declaring metric variables
2025-10-19 07:01:35,589:INFO:Importing untrained model
2025-10-19 07:01:35,591:INFO:Linear Regression Imported successfully
2025-10-19 07:01:35,598:INFO:Starting cross validation
2025-10-19 07:01:35,603:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:01:47,488:INFO:Calculating mean and std
2025-10-19 07:01:47,491:INFO:Creating metrics dataframe
2025-10-19 07:01:47,493:INFO:Uploading results into container
2025-10-19 07:01:47,494:INFO:Uploading model into container now
2025-10-19 07:01:47,495:INFO:_master_model_container: 1
2025-10-19 07:01:47,495:INFO:_display_container: 2
2025-10-19 07:01:47,495:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, positive=False)
2025-10-19 07:01:47,495:INFO:create_model() successfully completed......................................
2025-10-19 07:01:47,816:INFO:SubProcess create_model() end ==================================
2025-10-19 07:01:47,817:INFO:Creating metrics dataframe
2025-10-19 07:01:47,823:INFO:Initializing Lasso Regression
2025-10-19 07:01:47,823:INFO:Total runtime is 0.20744049549102783 minutes
2025-10-19 07:01:47,828:INFO:SubProcess create_model() called ==================================
2025-10-19 07:01:47,829:INFO:Initializing create_model()
2025-10-19 07:01:47,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=lasso, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:01:47,829:INFO:Checking exceptions
2025-10-19 07:01:47,829:INFO:Importing libraries
2025-10-19 07:01:47,829:INFO:Copying training dataset
2025-10-19 07:01:48,046:INFO:Defining folds
2025-10-19 07:01:48,047:INFO:Declaring metric variables
2025-10-19 07:01:48,052:INFO:Importing untrained model
2025-10-19 07:01:48,057:INFO:Lasso Regression Imported successfully
2025-10-19 07:01:48,068:INFO:Starting cross validation
2025-10-19 07:01:48,075:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:01:59,196:INFO:Calculating mean and std
2025-10-19 07:01:59,197:INFO:Creating metrics dataframe
2025-10-19 07:01:59,199:INFO:Uploading results into container
2025-10-19 07:01:59,199:INFO:Uploading model into container now
2025-10-19 07:01:59,199:INFO:_master_model_container: 2
2025-10-19 07:01:59,200:INFO:_display_container: 2
2025-10-19 07:01:59,200:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=42, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-10-19 07:01:59,200:INFO:create_model() successfully completed......................................
2025-10-19 07:01:59,428:INFO:SubProcess create_model() end ==================================
2025-10-19 07:01:59,428:INFO:Creating metrics dataframe
2025-10-19 07:01:59,435:INFO:Initializing Ridge Regression
2025-10-19 07:01:59,435:INFO:Total runtime is 0.4009608586629232 minutes
2025-10-19 07:01:59,437:INFO:SubProcess create_model() called ==================================
2025-10-19 07:01:59,438:INFO:Initializing create_model()
2025-10-19 07:01:59,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:01:59,438:INFO:Checking exceptions
2025-10-19 07:01:59,438:INFO:Importing libraries
2025-10-19 07:01:59,439:INFO:Copying training dataset
2025-10-19 07:01:59,614:INFO:Defining folds
2025-10-19 07:01:59,614:INFO:Declaring metric variables
2025-10-19 07:01:59,619:INFO:Importing untrained model
2025-10-19 07:01:59,624:INFO:Ridge Regression Imported successfully
2025-10-19 07:01:59,631:INFO:Starting cross validation
2025-10-19 07:01:59,636:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:02:10,631:INFO:Calculating mean and std
2025-10-19 07:02:10,632:INFO:Creating metrics dataframe
2025-10-19 07:02:10,633:INFO:Uploading results into container
2025-10-19 07:02:10,634:INFO:Uploading model into container now
2025-10-19 07:02:10,634:INFO:_master_model_container: 3
2025-10-19 07:02:10,634:INFO:_display_container: 2
2025-10-19 07:02:10,635:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001)
2025-10-19 07:02:10,635:INFO:create_model() successfully completed......................................
2025-10-19 07:02:10,895:INFO:SubProcess create_model() end ==================================
2025-10-19 07:02:10,895:INFO:Creating metrics dataframe
2025-10-19 07:02:10,902:INFO:Initializing Elastic Net
2025-10-19 07:02:10,902:INFO:Total runtime is 0.5920827547709148 minutes
2025-10-19 07:02:10,905:INFO:SubProcess create_model() called ==================================
2025-10-19 07:02:10,907:INFO:Initializing create_model()
2025-10-19 07:02:10,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=en, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:02:10,907:INFO:Checking exceptions
2025-10-19 07:02:10,907:INFO:Importing libraries
2025-10-19 07:02:10,907:INFO:Copying training dataset
2025-10-19 07:02:11,108:INFO:Defining folds
2025-10-19 07:02:11,108:INFO:Declaring metric variables
2025-10-19 07:02:11,113:INFO:Importing untrained model
2025-10-19 07:02:11,118:INFO:Elastic Net Imported successfully
2025-10-19 07:02:11,126:INFO:Starting cross validation
2025-10-19 07:02:11,131:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:02:22,040:INFO:Calculating mean and std
2025-10-19 07:02:22,041:INFO:Creating metrics dataframe
2025-10-19 07:02:22,043:INFO:Uploading results into container
2025-10-19 07:02:22,044:INFO:Uploading model into container now
2025-10-19 07:02:22,045:INFO:_master_model_container: 4
2025-10-19 07:02:22,045:INFO:_display_container: 2
2025-10-19 07:02:22,046:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=42,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-10-19 07:02:22,046:INFO:create_model() successfully completed......................................
2025-10-19 07:02:22,279:INFO:SubProcess create_model() end ==================================
2025-10-19 07:02:22,279:INFO:Creating metrics dataframe
2025-10-19 07:02:22,285:INFO:Initializing Least Angle Regression
2025-10-19 07:02:22,286:INFO:Total runtime is 0.7818121075630189 minutes
2025-10-19 07:02:22,289:INFO:SubProcess create_model() called ==================================
2025-10-19 07:02:22,291:INFO:Initializing create_model()
2025-10-19 07:02:22,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=lar, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:02:22,292:INFO:Checking exceptions
2025-10-19 07:02:22,292:INFO:Importing libraries
2025-10-19 07:02:22,292:INFO:Copying training dataset
2025-10-19 07:02:22,490:INFO:Defining folds
2025-10-19 07:02:22,491:INFO:Declaring metric variables
2025-10-19 07:02:22,497:INFO:Importing untrained model
2025-10-19 07:02:22,503:INFO:Least Angle Regression Imported successfully
2025-10-19 07:02:22,512:INFO:Starting cross validation
2025-10-19 07:02:22,517:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:02:33,540:INFO:Calculating mean and std
2025-10-19 07:02:33,542:INFO:Creating metrics dataframe
2025-10-19 07:02:33,545:INFO:Uploading results into container
2025-10-19 07:02:33,546:INFO:Uploading model into container now
2025-10-19 07:02:33,548:INFO:_master_model_container: 5
2025-10-19 07:02:33,548:INFO:_display_container: 2
2025-10-19 07:02:33,548:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=42,
     verbose=False)
2025-10-19 07:02:33,549:INFO:create_model() successfully completed......................................
2025-10-19 07:02:33,811:INFO:SubProcess create_model() end ==================================
2025-10-19 07:02:33,812:INFO:Creating metrics dataframe
2025-10-19 07:02:33,818:INFO:Initializing Lasso Least Angle Regression
2025-10-19 07:02:33,818:INFO:Total runtime is 0.9740180174509685 minutes
2025-10-19 07:02:33,821:INFO:SubProcess create_model() called ==================================
2025-10-19 07:02:33,822:INFO:Initializing create_model()
2025-10-19 07:02:33,823:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=llar, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:02:33,823:INFO:Checking exceptions
2025-10-19 07:02:33,823:INFO:Importing libraries
2025-10-19 07:02:33,823:INFO:Copying training dataset
2025-10-19 07:02:34,014:INFO:Defining folds
2025-10-19 07:02:34,014:INFO:Declaring metric variables
2025-10-19 07:02:34,017:INFO:Importing untrained model
2025-10-19 07:02:34,022:INFO:Lasso Least Angle Regression Imported successfully
2025-10-19 07:02:34,032:INFO:Starting cross validation
2025-10-19 07:02:34,036:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:02:44,861:INFO:Calculating mean and std
2025-10-19 07:02:44,862:INFO:Creating metrics dataframe
2025-10-19 07:02:44,863:INFO:Uploading results into container
2025-10-19 07:02:44,864:INFO:Uploading model into container now
2025-10-19 07:02:44,864:INFO:_master_model_container: 6
2025-10-19 07:02:44,864:INFO:_display_container: 2
2025-10-19 07:02:44,864:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=42, verbose=False)
2025-10-19 07:02:44,864:INFO:create_model() successfully completed......................................
2025-10-19 07:02:45,095:INFO:SubProcess create_model() end ==================================
2025-10-19 07:02:45,096:INFO:Creating metrics dataframe
2025-10-19 07:02:45,102:INFO:Initializing Orthogonal Matching Pursuit
2025-10-19 07:02:45,102:INFO:Total runtime is 1.162090047200521 minutes
2025-10-19 07:02:45,104:INFO:SubProcess create_model() called ==================================
2025-10-19 07:02:45,106:INFO:Initializing create_model()
2025-10-19 07:02:45,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=omp, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:02:45,106:INFO:Checking exceptions
2025-10-19 07:02:45,106:INFO:Importing libraries
2025-10-19 07:02:45,106:INFO:Copying training dataset
2025-10-19 07:02:45,304:INFO:Defining folds
2025-10-19 07:02:45,304:INFO:Declaring metric variables
2025-10-19 07:02:45,309:INFO:Importing untrained model
2025-10-19 07:02:45,315:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-19 07:02:45,321:INFO:Starting cross validation
2025-10-19 07:02:45,326:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:02:56,280:INFO:Calculating mean and std
2025-10-19 07:02:56,281:INFO:Creating metrics dataframe
2025-10-19 07:02:56,282:INFO:Uploading results into container
2025-10-19 07:02:56,283:INFO:Uploading model into container now
2025-10-19 07:02:56,283:INFO:_master_model_container: 7
2025-10-19 07:02:56,283:INFO:_display_container: 2
2025-10-19 07:02:56,284:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-10-19 07:02:56,284:INFO:create_model() successfully completed......................................
2025-10-19 07:02:56,508:INFO:SubProcess create_model() end ==================================
2025-10-19 07:02:56,509:INFO:Creating metrics dataframe
2025-10-19 07:02:56,519:INFO:Initializing Bayesian Ridge
2025-10-19 07:02:56,519:INFO:Total runtime is 1.3523698290189108 minutes
2025-10-19 07:02:56,521:INFO:SubProcess create_model() called ==================================
2025-10-19 07:02:56,524:INFO:Initializing create_model()
2025-10-19 07:02:56,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=br, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:02:56,524:INFO:Checking exceptions
2025-10-19 07:02:56,524:INFO:Importing libraries
2025-10-19 07:02:56,525:INFO:Copying training dataset
2025-10-19 07:02:56,715:INFO:Defining folds
2025-10-19 07:02:56,715:INFO:Declaring metric variables
2025-10-19 07:02:56,720:INFO:Importing untrained model
2025-10-19 07:02:56,723:INFO:Bayesian Ridge Imported successfully
2025-10-19 07:02:56,733:INFO:Starting cross validation
2025-10-19 07:02:56,736:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:03:09,194:INFO:Calculating mean and std
2025-10-19 07:03:09,195:INFO:Creating metrics dataframe
2025-10-19 07:03:09,196:INFO:Uploading results into container
2025-10-19 07:03:09,196:INFO:Uploading model into container now
2025-10-19 07:03:09,197:INFO:_master_model_container: 8
2025-10-19 07:03:09,197:INFO:_display_container: 2
2025-10-19 07:03:09,197:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-10-19 07:03:09,197:INFO:create_model() successfully completed......................................
2025-10-19 07:03:09,425:INFO:SubProcess create_model() end ==================================
2025-10-19 07:03:09,426:INFO:Creating metrics dataframe
2025-10-19 07:03:09,436:INFO:Initializing Passive Aggressive Regressor
2025-10-19 07:03:09,436:INFO:Total runtime is 1.567656397819519 minutes
2025-10-19 07:03:09,438:INFO:SubProcess create_model() called ==================================
2025-10-19 07:03:09,439:INFO:Initializing create_model()
2025-10-19 07:03:09,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=par, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:03:09,440:INFO:Checking exceptions
2025-10-19 07:03:09,440:INFO:Importing libraries
2025-10-19 07:03:09,440:INFO:Copying training dataset
2025-10-19 07:03:09,630:INFO:Defining folds
2025-10-19 07:03:09,630:INFO:Declaring metric variables
2025-10-19 07:03:09,634:INFO:Importing untrained model
2025-10-19 07:03:09,639:INFO:Passive Aggressive Regressor Imported successfully
2025-10-19 07:03:09,645:INFO:Starting cross validation
2025-10-19 07:03:09,651:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:03:26,157:INFO:Calculating mean and std
2025-10-19 07:03:26,158:INFO:Creating metrics dataframe
2025-10-19 07:03:26,160:INFO:Uploading results into container
2025-10-19 07:03:26,160:INFO:Uploading model into container now
2025-10-19 07:03:26,161:INFO:_master_model_container: 9
2025-10-19 07:03:26,161:INFO:_display_container: 2
2025-10-19 07:03:26,162:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=42, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 07:03:26,162:INFO:create_model() successfully completed......................................
2025-10-19 07:03:26,399:INFO:SubProcess create_model() end ==================================
2025-10-19 07:03:26,399:INFO:Creating metrics dataframe
2025-10-19 07:03:26,407:INFO:Initializing Huber Regressor
2025-10-19 07:03:26,407:INFO:Total runtime is 1.8505025784174602 minutes
2025-10-19 07:03:26,410:INFO:SubProcess create_model() called ==================================
2025-10-19 07:03:26,412:INFO:Initializing create_model()
2025-10-19 07:03:26,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=huber, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:03:26,412:INFO:Checking exceptions
2025-10-19 07:03:26,413:INFO:Importing libraries
2025-10-19 07:03:26,413:INFO:Copying training dataset
2025-10-19 07:03:26,589:INFO:Defining folds
2025-10-19 07:03:26,590:INFO:Declaring metric variables
2025-10-19 07:03:26,595:INFO:Importing untrained model
2025-10-19 07:03:26,599:INFO:Huber Regressor Imported successfully
2025-10-19 07:03:26,605:INFO:Starting cross validation
2025-10-19 07:03:26,609:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:03:46,578:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2025-10-19 07:03:46,838:INFO:Calculating mean and std
2025-10-19 07:03:46,839:INFO:Creating metrics dataframe
2025-10-19 07:03:46,841:INFO:Uploading results into container
2025-10-19 07:03:46,842:INFO:Uploading model into container now
2025-10-19 07:03:46,842:INFO:_master_model_container: 10
2025-10-19 07:03:46,842:INFO:_display_container: 2
2025-10-19 07:03:46,843:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-10-19 07:03:46,843:INFO:create_model() successfully completed......................................
2025-10-19 07:03:47,137:INFO:SubProcess create_model() end ==================================
2025-10-19 07:03:47,138:INFO:Creating metrics dataframe
2025-10-19 07:03:47,150:INFO:Initializing K Neighbors Regressor
2025-10-19 07:03:47,150:INFO:Total runtime is 2.196216873327891 minutes
2025-10-19 07:03:47,156:INFO:SubProcess create_model() called ==================================
2025-10-19 07:03:47,157:INFO:Initializing create_model()
2025-10-19 07:03:47,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:03:47,157:INFO:Checking exceptions
2025-10-19 07:03:47,157:INFO:Importing libraries
2025-10-19 07:03:47,157:INFO:Copying training dataset
2025-10-19 07:03:47,398:INFO:Defining folds
2025-10-19 07:03:47,398:INFO:Declaring metric variables
2025-10-19 07:03:47,403:INFO:Importing untrained model
2025-10-19 07:03:47,407:INFO:K Neighbors Regressor Imported successfully
2025-10-19 07:03:47,418:INFO:Starting cross validation
2025-10-19 07:03:47,422:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:04:01,719:INFO:Calculating mean and std
2025-10-19 07:04:01,721:INFO:Creating metrics dataframe
2025-10-19 07:04:01,724:INFO:Uploading results into container
2025-10-19 07:04:01,725:INFO:Uploading model into container now
2025-10-19 07:04:01,725:INFO:_master_model_container: 11
2025-10-19 07:04:01,725:INFO:_display_container: 2
2025-10-19 07:04:01,726:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                    weights='uniform')
2025-10-19 07:04:01,726:INFO:create_model() successfully completed......................................
2025-10-19 07:04:01,978:INFO:SubProcess create_model() end ==================================
2025-10-19 07:04:01,978:INFO:Creating metrics dataframe
2025-10-19 07:04:01,986:INFO:Initializing Decision Tree Regressor
2025-10-19 07:04:01,986:INFO:Total runtime is 2.443488085269928 minutes
2025-10-19 07:04:01,991:INFO:SubProcess create_model() called ==================================
2025-10-19 07:04:01,992:INFO:Initializing create_model()
2025-10-19 07:04:01,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:04:01,992:INFO:Checking exceptions
2025-10-19 07:04:01,992:INFO:Importing libraries
2025-10-19 07:04:01,992:INFO:Copying training dataset
2025-10-19 07:04:02,188:INFO:Defining folds
2025-10-19 07:04:02,188:INFO:Declaring metric variables
2025-10-19 07:04:02,193:INFO:Importing untrained model
2025-10-19 07:04:02,199:INFO:Decision Tree Regressor Imported successfully
2025-10-19 07:04:02,207:INFO:Starting cross validation
2025-10-19 07:04:02,214:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:04:16,442:INFO:Calculating mean and std
2025-10-19 07:04:16,443:INFO:Creating metrics dataframe
2025-10-19 07:04:16,445:INFO:Uploading results into container
2025-10-19 07:04:16,445:INFO:Uploading model into container now
2025-10-19 07:04:16,445:INFO:_master_model_container: 12
2025-10-19 07:04:16,445:INFO:_display_container: 2
2025-10-19 07:04:16,446:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=42, splitter='best')
2025-10-19 07:04:16,446:INFO:create_model() successfully completed......................................
2025-10-19 07:04:16,705:INFO:SubProcess create_model() end ==================================
2025-10-19 07:04:16,705:INFO:Creating metrics dataframe
2025-10-19 07:04:16,716:INFO:Initializing Random Forest Regressor
2025-10-19 07:04:16,717:INFO:Total runtime is 2.688999048868815 minutes
2025-10-19 07:04:16,723:INFO:SubProcess create_model() called ==================================
2025-10-19 07:04:16,724:INFO:Initializing create_model()
2025-10-19 07:04:16,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:04:16,724:INFO:Checking exceptions
2025-10-19 07:04:16,724:INFO:Importing libraries
2025-10-19 07:04:16,724:INFO:Copying training dataset
2025-10-19 07:04:16,932:INFO:Defining folds
2025-10-19 07:04:16,932:INFO:Declaring metric variables
2025-10-19 07:04:16,935:INFO:Importing untrained model
2025-10-19 07:04:16,941:INFO:Random Forest Regressor Imported successfully
2025-10-19 07:04:16,951:INFO:Starting cross validation
2025-10-19 07:04:16,956:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:08:19,979:INFO:Calculating mean and std
2025-10-19 07:08:19,981:INFO:Creating metrics dataframe
2025-10-19 07:08:19,984:INFO:Uploading results into container
2025-10-19 07:08:19,985:INFO:Uploading model into container now
2025-10-19 07:08:19,985:INFO:_master_model_container: 13
2025-10-19 07:08:19,986:INFO:_display_container: 2
2025-10-19 07:08:19,986:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=1, oob_score=False,
                      random_state=42, verbose=0, warm_start=False)
2025-10-19 07:08:19,986:INFO:create_model() successfully completed......................................
2025-10-19 07:08:20,248:INFO:SubProcess create_model() end ==================================
2025-10-19 07:08:20,248:INFO:Creating metrics dataframe
2025-10-19 07:08:20,257:INFO:Initializing Extra Trees Regressor
2025-10-19 07:08:20,257:INFO:Total runtime is 6.748003494739532 minutes
2025-10-19 07:08:20,262:INFO:SubProcess create_model() called ==================================
2025-10-19 07:08:20,265:INFO:Initializing create_model()
2025-10-19 07:08:20,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:08:20,265:INFO:Checking exceptions
2025-10-19 07:08:20,265:INFO:Importing libraries
2025-10-19 07:08:20,265:INFO:Copying training dataset
2025-10-19 07:08:20,449:INFO:Defining folds
2025-10-19 07:08:20,450:INFO:Declaring metric variables
2025-10-19 07:08:20,454:INFO:Importing untrained model
2025-10-19 07:08:20,457:INFO:Extra Trees Regressor Imported successfully
2025-10-19 07:08:20,466:INFO:Starting cross validation
2025-10-19 07:08:20,471:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:12:20,893:INFO:Calculating mean and std
2025-10-19 07:12:20,895:INFO:Creating metrics dataframe
2025-10-19 07:12:20,898:INFO:Uploading results into container
2025-10-19 07:12:20,899:INFO:Uploading model into container now
2025-10-19 07:12:20,900:INFO:_master_model_container: 14
2025-10-19 07:12:20,900:INFO:_display_container: 2
2025-10-19 07:12:20,901:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=1, oob_score=False,
                    random_state=42, verbose=0, warm_start=False)
2025-10-19 07:12:20,901:INFO:create_model() successfully completed......................................
2025-10-19 07:12:21,145:INFO:SubProcess create_model() end ==================================
2025-10-19 07:12:21,145:INFO:Creating metrics dataframe
2025-10-19 07:12:21,152:INFO:Initializing AdaBoost Regressor
2025-10-19 07:12:21,152:INFO:Total runtime is 10.762915329138437 minutes
2025-10-19 07:12:21,154:INFO:SubProcess create_model() called ==================================
2025-10-19 07:12:21,156:INFO:Initializing create_model()
2025-10-19 07:12:21,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:12:21,156:INFO:Checking exceptions
2025-10-19 07:12:21,156:INFO:Importing libraries
2025-10-19 07:12:21,156:INFO:Copying training dataset
2025-10-19 07:12:21,351:INFO:Defining folds
2025-10-19 07:12:21,351:INFO:Declaring metric variables
2025-10-19 07:12:21,355:INFO:Importing untrained model
2025-10-19 07:12:21,361:INFO:AdaBoost Regressor Imported successfully
2025-10-19 07:12:21,366:INFO:Starting cross validation
2025-10-19 07:12:21,371:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:12:55,429:INFO:Calculating mean and std
2025-10-19 07:12:55,430:INFO:Creating metrics dataframe
2025-10-19 07:12:55,431:INFO:Uploading results into container
2025-10-19 07:12:55,431:INFO:Uploading model into container now
2025-10-19 07:12:55,432:INFO:_master_model_container: 15
2025-10-19 07:12:55,432:INFO:_display_container: 2
2025-10-19 07:12:55,432:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=42)
2025-10-19 07:12:55,432:INFO:create_model() successfully completed......................................
2025-10-19 07:12:55,700:INFO:SubProcess create_model() end ==================================
2025-10-19 07:12:55,700:INFO:Creating metrics dataframe
2025-10-19 07:12:55,712:INFO:Initializing Gradient Boosting Regressor
2025-10-19 07:12:55,713:INFO:Total runtime is 11.338940592606862 minutes
2025-10-19 07:12:55,720:INFO:SubProcess create_model() called ==================================
2025-10-19 07:12:55,721:INFO:Initializing create_model()
2025-10-19 07:12:55,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=gbr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:12:55,721:INFO:Checking exceptions
2025-10-19 07:12:55,721:INFO:Importing libraries
2025-10-19 07:12:55,721:INFO:Copying training dataset
2025-10-19 07:12:55,923:INFO:Defining folds
2025-10-19 07:12:55,923:INFO:Declaring metric variables
2025-10-19 07:12:55,928:INFO:Importing untrained model
2025-10-19 07:12:55,932:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 07:12:55,939:INFO:Starting cross validation
2025-10-19 07:12:55,943:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:13:43,344:INFO:Calculating mean and std
2025-10-19 07:13:43,346:INFO:Creating metrics dataframe
2025-10-19 07:13:43,348:INFO:Uploading results into container
2025-10-19 07:13:43,349:INFO:Uploading model into container now
2025-10-19 07:13:43,349:INFO:_master_model_container: 16
2025-10-19 07:13:43,349:INFO:_display_container: 2
2025-10-19 07:13:43,349:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 07:13:43,349:INFO:create_model() successfully completed......................................
2025-10-19 07:13:43,579:INFO:SubProcess create_model() end ==================================
2025-10-19 07:13:43,579:INFO:Creating metrics dataframe
2025-10-19 07:13:43,592:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 07:13:43,592:INFO:Total runtime is 12.136914614836375 minutes
2025-10-19 07:13:43,596:INFO:SubProcess create_model() called ==================================
2025-10-19 07:13:43,599:INFO:Initializing create_model()
2025-10-19 07:13:43,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:13:43,600:INFO:Checking exceptions
2025-10-19 07:13:43,600:INFO:Importing libraries
2025-10-19 07:13:43,600:INFO:Copying training dataset
2025-10-19 07:13:43,787:INFO:Defining folds
2025-10-19 07:13:43,787:INFO:Declaring metric variables
2025-10-19 07:13:43,790:INFO:Importing untrained model
2025-10-19 07:13:43,794:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 07:13:43,804:INFO:Starting cross validation
2025-10-19 07:13:43,807:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:13:45,944:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:13:45,958:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004265 seconds.
2025-10-19 07:13:45,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:13:45,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:13:45,958:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 07:13:45,958:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:13:45,959:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 07:13:48,547:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:13:48,560:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004025 seconds.
2025-10-19 07:13:48,560:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:13:48,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:13:48,560:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 07:13:48,561:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:13:48,561:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 07:13:51,160:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:13:51,178:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006993 seconds.
2025-10-19 07:13:51,178:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:13:51,178:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:13:51,178:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:13:51,178:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:13:51,179:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 07:13:53,792:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:13:53,808:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006369 seconds.
2025-10-19 07:13:53,808:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:13:53,809:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:13:53,809:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:13:53,809:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 07:13:53,809:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 07:13:56,411:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:13:56,429:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006996 seconds.
2025-10-19 07:13:56,429:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:13:56,429:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:13:56,429:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:13:56,429:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 07:13:56,430:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 07:13:57,018:INFO:Calculating mean and std
2025-10-19 07:13:57,019:INFO:Creating metrics dataframe
2025-10-19 07:13:57,021:INFO:Uploading results into container
2025-10-19 07:13:57,021:INFO:Uploading model into container now
2025-10-19 07:13:57,021:INFO:_master_model_container: 17
2025-10-19 07:13:57,022:INFO:_display_container: 2
2025-10-19 07:13:57,022:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 07:13:57,022:INFO:create_model() successfully completed......................................
2025-10-19 07:13:57,252:INFO:SubProcess create_model() end ==================================
2025-10-19 07:13:57,252:INFO:Creating metrics dataframe
2025-10-19 07:13:57,261:INFO:Initializing CatBoost Regressor
2025-10-19 07:13:57,261:INFO:Total runtime is 12.36473567088445 minutes
2025-10-19 07:13:57,267:INFO:SubProcess create_model() called ==================================
2025-10-19 07:13:57,268:INFO:Initializing create_model()
2025-10-19 07:13:57,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:13:57,269:INFO:Checking exceptions
2025-10-19 07:13:57,269:INFO:Importing libraries
2025-10-19 07:13:57,269:INFO:Copying training dataset
2025-10-19 07:13:57,459:INFO:Defining folds
2025-10-19 07:13:57,459:INFO:Declaring metric variables
2025-10-19 07:13:57,463:INFO:Importing untrained model
2025-10-19 07:13:57,468:INFO:CatBoost Regressor Imported successfully
2025-10-19 07:13:57,473:INFO:Starting cross validation
2025-10-19 07:13:57,478:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:15:25,812:INFO:Calculating mean and std
2025-10-19 07:15:25,813:INFO:Creating metrics dataframe
2025-10-19 07:15:25,814:INFO:Uploading results into container
2025-10-19 07:15:25,815:INFO:Uploading model into container now
2025-10-19 07:15:25,815:INFO:_master_model_container: 18
2025-10-19 07:15:25,815:INFO:_display_container: 2
2025-10-19 07:15:25,815:INFO:<catboost.core.CatBoostRegressor object at 0x000002120763C210>
2025-10-19 07:15:25,815:INFO:create_model() successfully completed......................................
2025-10-19 07:15:26,040:INFO:SubProcess create_model() end ==================================
2025-10-19 07:15:26,040:INFO:Creating metrics dataframe
2025-10-19 07:15:26,049:INFO:Initializing Dummy Regressor
2025-10-19 07:15:26,049:INFO:Total runtime is 13.844537977377573 minutes
2025-10-19 07:15:26,054:INFO:SubProcess create_model() called ==================================
2025-10-19 07:15:26,057:INFO:Initializing create_model()
2025-10-19 07:15:26,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B0B510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:15:26,057:INFO:Checking exceptions
2025-10-19 07:15:26,057:INFO:Importing libraries
2025-10-19 07:15:26,057:INFO:Copying training dataset
2025-10-19 07:15:26,238:INFO:Defining folds
2025-10-19 07:15:26,238:INFO:Declaring metric variables
2025-10-19 07:15:26,242:INFO:Importing untrained model
2025-10-19 07:15:26,247:INFO:Dummy Regressor Imported successfully
2025-10-19 07:15:26,253:INFO:Starting cross validation
2025-10-19 07:15:26,259:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:15:36,812:INFO:Calculating mean and std
2025-10-19 07:15:36,813:INFO:Creating metrics dataframe
2025-10-19 07:15:36,814:INFO:Uploading results into container
2025-10-19 07:15:36,814:INFO:Uploading model into container now
2025-10-19 07:15:36,815:INFO:_master_model_container: 19
2025-10-19 07:15:36,815:INFO:_display_container: 2
2025-10-19 07:15:36,815:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-10-19 07:15:36,815:INFO:create_model() successfully completed......................................
2025-10-19 07:15:37,058:INFO:SubProcess create_model() end ==================================
2025-10-19 07:15:37,058:INFO:Creating metrics dataframe
2025-10-19 07:15:37,068:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 07:15:37,081:INFO:Initializing create_model()
2025-10-19 07:15:37,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:15:37,081:INFO:Checking exceptions
2025-10-19 07:15:37,083:INFO:Importing libraries
2025-10-19 07:15:37,083:INFO:Copying training dataset
2025-10-19 07:15:37,281:INFO:Defining folds
2025-10-19 07:15:37,281:INFO:Declaring metric variables
2025-10-19 07:15:37,281:INFO:Importing untrained model
2025-10-19 07:15:37,282:INFO:Declaring custom model
2025-10-19 07:15:37,282:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 07:15:37,285:INFO:Cross validation set to False
2025-10-19 07:15:37,286:INFO:Fitting Model
2025-10-19 07:15:48,990:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 07:15:48,990:INFO:create_model() successfully completed......................................
2025-10-19 07:15:49,250:INFO:Initializing create_model()
2025-10-19 07:15:49,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:15:49,251:INFO:Checking exceptions
2025-10-19 07:15:49,254:INFO:Importing libraries
2025-10-19 07:15:49,255:INFO:Copying training dataset
2025-10-19 07:15:49,467:INFO:Defining folds
2025-10-19 07:15:49,467:INFO:Declaring metric variables
2025-10-19 07:15:49,467:INFO:Importing untrained model
2025-10-19 07:15:49,467:INFO:Declaring custom model
2025-10-19 07:15:49,469:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 07:15:49,472:INFO:Cross validation set to False
2025-10-19 07:15:49,472:INFO:Fitting Model
2025-10-19 07:15:52,223:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:15:52,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009189 seconds.
2025-10-19 07:15:52,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:15:52,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:15:52,248:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 07:15:52,248:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 07:15:52,249:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 07:15:52,714:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 07:15:52,714:INFO:create_model() successfully completed......................................
2025-10-19 07:15:52,948:INFO:Initializing create_model()
2025-10-19 07:15:52,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=<catboost.core.CatBoostRegressor object at 0x000002120763C210>, fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:15:52,948:INFO:Checking exceptions
2025-10-19 07:15:52,951:INFO:Importing libraries
2025-10-19 07:15:52,951:INFO:Copying training dataset
2025-10-19 07:15:53,149:INFO:Defining folds
2025-10-19 07:15:53,149:INFO:Declaring metric variables
2025-10-19 07:15:53,149:INFO:Importing untrained model
2025-10-19 07:15:53,149:INFO:Declaring custom model
2025-10-19 07:15:53,150:INFO:CatBoost Regressor Imported successfully
2025-10-19 07:15:53,152:INFO:Cross validation set to False
2025-10-19 07:15:53,152:INFO:Fitting Model
2025-10-19 07:16:13,835:INFO:<catboost.core.CatBoostRegressor object at 0x0000021207A01790>
2025-10-19 07:16:13,835:INFO:create_model() successfully completed......................................
2025-10-19 07:16:14,090:INFO:_master_model_container: 19
2025-10-19 07:16:14,090:INFO:_display_container: 2
2025-10-19 07:16:14,092:INFO:[GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostRegressor object at 0x0000021207A01790>]
2025-10-19 07:16:14,092:INFO:compare_models() successfully completed......................................
2025-10-19 07:16:14,098:INFO:Initializing tune_model()
2025-10-19 07:16:14,098:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 07:16:14,098:INFO:Checking exceptions
2025-10-19 07:16:14,190:INFO:Copying training dataset
2025-10-19 07:16:14,326:INFO:Checking base model
2025-10-19 07:16:14,327:INFO:Base model : Gradient Boosting Regressor
2025-10-19 07:16:14,330:INFO:Declaring metric variables
2025-10-19 07:16:14,331:INFO:Defining Hyperparameters
2025-10-19 07:16:14,565:INFO:Tuning with n_jobs=1
2025-10-19 07:16:14,565:INFO:Initializing RandomizedSearchCV
2025-10-19 07:19:56,794:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 270, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.05}
2025-10-19 07:19:56,795:INFO:Hyperparameter search completed
2025-10-19 07:19:56,795:INFO:SubProcess create_model() called ==================================
2025-10-19 07:19:56,796:INFO:Initializing create_model()
2025-10-19 07:19:56,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120602BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 270, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 6, 'learning_rate': 0.05})
2025-10-19 07:19:56,796:INFO:Checking exceptions
2025-10-19 07:19:56,796:INFO:Importing libraries
2025-10-19 07:19:56,797:INFO:Copying training dataset
2025-10-19 07:19:56,971:INFO:Defining folds
2025-10-19 07:19:56,971:INFO:Declaring metric variables
2025-10-19 07:19:56,975:INFO:Importing untrained model
2025-10-19 07:19:56,975:INFO:Declaring custom model
2025-10-19 07:19:56,980:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 07:19:56,989:INFO:Starting cross validation
2025-10-19 07:19:56,993:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:20:28,348:INFO:Calculating mean and std
2025-10-19 07:20:28,350:INFO:Creating metrics dataframe
2025-10-19 07:20:28,355:INFO:Finalizing model
2025-10-19 07:20:35,514:INFO:Uploading results into container
2025-10-19 07:20:35,515:INFO:Uploading model into container now
2025-10-19 07:20:35,516:INFO:_master_model_container: 20
2025-10-19 07:20:35,516:INFO:_display_container: 3
2025-10-19 07:20:35,516:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.05, loss='squared_error',
                          max_depth=6, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.3, min_samples_leaf=4,
                          min_samples_split=10, min_weight_fraction_leaf=0.0,
                          n_estimators=270, n_iter_no_change=None,
                          random_state=42, subsample=0.7, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 07:20:35,517:INFO:create_model() successfully completed......................................
2025-10-19 07:20:35,760:INFO:SubProcess create_model() end ==================================
2025-10-19 07:20:35,760:INFO:choose_better activated
2025-10-19 07:20:35,763:INFO:SubProcess create_model() called ==================================
2025-10-19 07:20:35,764:INFO:Initializing create_model()
2025-10-19 07:20:35,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:20:35,764:INFO:Checking exceptions
2025-10-19 07:20:35,766:INFO:Importing libraries
2025-10-19 07:20:35,766:INFO:Copying training dataset
2025-10-19 07:20:35,926:INFO:Defining folds
2025-10-19 07:20:35,927:INFO:Declaring metric variables
2025-10-19 07:20:35,927:INFO:Importing untrained model
2025-10-19 07:20:35,927:INFO:Declaring custom model
2025-10-19 07:20:35,927:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 07:20:35,928:INFO:Starting cross validation
2025-10-19 07:20:35,930:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:21:23,336:INFO:Calculating mean and std
2025-10-19 07:21:23,337:INFO:Creating metrics dataframe
2025-10-19 07:21:23,339:INFO:Finalizing model
2025-10-19 07:21:34,947:INFO:Uploading results into container
2025-10-19 07:21:34,948:INFO:Uploading model into container now
2025-10-19 07:21:34,948:INFO:_master_model_container: 21
2025-10-19 07:21:34,948:INFO:_display_container: 4
2025-10-19 07:21:34,949:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 07:21:34,949:INFO:create_model() successfully completed......................................
2025-10-19 07:21:35,181:INFO:SubProcess create_model() end ==================================
2025-10-19 07:21:35,181:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for RMSE is 0.475
2025-10-19 07:21:35,182:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.05, loss='squared_error',
                          max_depth=6, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.3, min_samples_leaf=4,
                          min_samples_split=10, min_weight_fraction_leaf=0.0,
                          n_estimators=270, n_iter_no_change=None,
                          random_state=42, subsample=0.7, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for RMSE is 0.4755
2025-10-19 07:21:35,182:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) is best model
2025-10-19 07:21:35,182:INFO:choose_better completed
2025-10-19 07:21:35,182:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 07:21:35,192:INFO:_master_model_container: 21
2025-10-19 07:21:35,192:INFO:_display_container: 3
2025-10-19 07:21:35,193:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 07:21:35,193:INFO:tune_model() successfully completed......................................
2025-10-19 07:21:35,418:INFO:Initializing tune_model()
2025-10-19 07:21:35,418:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 07:21:35,418:INFO:Checking exceptions
2025-10-19 07:21:35,505:INFO:Copying training dataset
2025-10-19 07:21:35,633:INFO:Checking base model
2025-10-19 07:21:35,633:INFO:Base model : Light Gradient Boosting Machine
2025-10-19 07:21:35,636:INFO:Declaring metric variables
2025-10-19 07:21:35,639:INFO:Defining Hyperparameters
2025-10-19 07:21:35,864:INFO:Tuning with n_jobs=1
2025-10-19 07:21:35,864:INFO:Initializing RandomizedSearchCV
2025-10-19 07:24:00,918:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2025-10-19 07:24:00,919:INFO:Hyperparameter search completed
2025-10-19 07:24:00,919:INFO:SubProcess create_model() called ==================================
2025-10-19 07:24:00,920:INFO:Initializing create_model()
2025-10-19 07:24:00,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207791810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 5, 'reg_alpha': 0.001, 'num_leaves': 30, 'n_estimators': 100, 'min_split_gain': 0.6, 'min_child_samples': 6, 'learning_rate': 0.2, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2025-10-19 07:24:00,921:INFO:Checking exceptions
2025-10-19 07:24:00,921:INFO:Importing libraries
2025-10-19 07:24:00,921:INFO:Copying training dataset
2025-10-19 07:24:01,112:INFO:Defining folds
2025-10-19 07:24:01,113:INFO:Declaring metric variables
2025-10-19 07:24:01,120:INFO:Importing untrained model
2025-10-19 07:24:01,120:INFO:Declaring custom model
2025-10-19 07:24:01,126:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 07:24:01,143:INFO:Starting cross validation
2025-10-19 07:24:01,148:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:24:03,099:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:03,099:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:03,099:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:03,192:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:03,193:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:03,193:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:03,193:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:03,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007371 seconds.
2025-10-19 07:24:03,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:03,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:03,211:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 07:24:03,212:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:24:03,212:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 07:24:03,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,440:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,441:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,443:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,445:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,446:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,448:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,450:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,451:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,452:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,454:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,464:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,466:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,467:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,469:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,470:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,472:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,473:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,475:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,476:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,478:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,479:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,481:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,483:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,496:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,498:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,500:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,501:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,503:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,504:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,505:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,507:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,509:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,510:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,512:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,513:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,515:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,516:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,518:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:03,525:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:03,722:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:03,722:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:03,722:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:05,668:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:05,668:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:05,668:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:05,752:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:05,753:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:05,753:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:05,753:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:05,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007041 seconds.
2025-10-19 07:24:05,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:05,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:05,770:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 07:24:05,770:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:24:05,771:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 07:24:05,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:05,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,031:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,034:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,036:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,038:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,041:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,042:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,079:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,081:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:06,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:06,298:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:06,298:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:06,299:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:08,326:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:08,326:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:08,326:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:08,412:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:08,413:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:08,413:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:08,413:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:08,430:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006666 seconds.
2025-10-19 07:24:08,430:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:08,430:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:08,430:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:24:08,430:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:24:08,431:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 07:24:08,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,675:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,719:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,720:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,746:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,746:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:08,763:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:08,953:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:08,953:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:08,953:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:11,000:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:11,000:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:11,000:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:11,084:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:11,086:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:11,086:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:11,086:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:11,099:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005064 seconds.
2025-10-19 07:24:11,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:11,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:11,100:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:24:11,100:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 07:24:11,101:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 07:24:11,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,345:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,354:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,355:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,357:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,358:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,360:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,361:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,362:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,364:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,366:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,376:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,377:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,382:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,387:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:11,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:11,613:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:11,613:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:11,613:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:13,525:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:13,525:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:13,525:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:13,610:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:13,611:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:13,611:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:13,611:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:13,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006378 seconds.
2025-10-19 07:24:13,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:13,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:13,628:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:24:13,628:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 07:24:13,628:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 07:24:13,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,845:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,852:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,854:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,856:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,857:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,859:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,860:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,862:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,863:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,865:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,866:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,868:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,870:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,871:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,873:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,874:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,876:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,878:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,880:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,881:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,885:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,887:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,888:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,891:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,894:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,897:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,902:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,905:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,906:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,909:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,914:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,915:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,919:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:13,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:13,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:14,118:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:14,118:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:14,118:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:14,143:INFO:Calculating mean and std
2025-10-19 07:24:14,144:INFO:Creating metrics dataframe
2025-10-19 07:24:14,148:INFO:Finalizing model
2025-10-19 07:24:16,500:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:16,500:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:16,500:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:16,621:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:16,622:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 07:24:16,622:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 07:24:16,623:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 07:24:16,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008114 seconds.
2025-10-19 07:24:16,642:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:16,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:16,643:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 07:24:16,643:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 07:24:16,644:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 07:24:16,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,952:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,954:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,956:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,958:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,960:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,961:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,965:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,967:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,971:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,972:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,974:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,976:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,980:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,981:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,983:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:16,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:16,999:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,001:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,003:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,018:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,031:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,034:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,041:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,043:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 07:24:17,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 07:24:17,058:INFO:Uploading results into container
2025-10-19 07:24:17,059:INFO:Uploading model into container now
2025-10-19 07:24:17,060:INFO:_master_model_container: 22
2025-10-19 07:24:17,060:INFO:_display_container: 4
2025-10-19 07:24:17,061:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
              importance_type='split', learning_rate=0.2, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.6,
              n_estimators=100, n_jobs=1, num_leaves=30, objective=None,
              random_state=42, reg_alpha=0.001, reg_lambda=5, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 07:24:17,061:INFO:create_model() successfully completed......................................
2025-10-19 07:24:17,295:INFO:SubProcess create_model() end ==================================
2025-10-19 07:24:17,295:INFO:choose_better activated
2025-10-19 07:24:17,297:INFO:SubProcess create_model() called ==================================
2025-10-19 07:24:17,299:INFO:Initializing create_model()
2025-10-19 07:24:17,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:24:17,299:INFO:Checking exceptions
2025-10-19 07:24:17,301:INFO:Importing libraries
2025-10-19 07:24:17,301:INFO:Copying training dataset
2025-10-19 07:24:17,472:INFO:Defining folds
2025-10-19 07:24:17,472:INFO:Declaring metric variables
2025-10-19 07:24:17,472:INFO:Importing untrained model
2025-10-19 07:24:17,472:INFO:Declaring custom model
2025-10-19 07:24:17,474:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 07:24:17,474:INFO:Starting cross validation
2025-10-19 07:24:17,477:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:24:19,487:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:19,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004924 seconds.
2025-10-19 07:24:19,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:19,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:19,504:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 07:24:19,504:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:24:19,504:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 07:24:22,068:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:22,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008407 seconds.
2025-10-19 07:24:22,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:22,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:22,089:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 07:24:22,090:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:24:22,091:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 07:24:24,720:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:24,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006718 seconds.
2025-10-19 07:24:24,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:24,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:24,739:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:24:24,739:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:24:24,739:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 07:24:27,298:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:27,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006530 seconds.
2025-10-19 07:24:27,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:27,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:27,316:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:24:27,316:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 07:24:27,316:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 07:24:30,178:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:30,197:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007742 seconds.
2025-10-19 07:24:30,197:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:30,197:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:30,197:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:24:30,197:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 07:24:30,198:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 07:24:30,840:INFO:Calculating mean and std
2025-10-19 07:24:30,840:INFO:Creating metrics dataframe
2025-10-19 07:24:30,841:INFO:Finalizing model
2025-10-19 07:24:33,343:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:24:33,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007625 seconds.
2025-10-19 07:24:33,364:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:24:33,365:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:24:33,365:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 07:24:33,365:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 07:24:33,365:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 07:24:33,829:INFO:Uploading results into container
2025-10-19 07:24:33,829:INFO:Uploading model into container now
2025-10-19 07:24:33,831:INFO:_master_model_container: 23
2025-10-19 07:24:33,831:INFO:_display_container: 5
2025-10-19 07:24:33,831:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 07:24:33,831:INFO:create_model() successfully completed......................................
2025-10-19 07:24:34,062:INFO:SubProcess create_model() end ==================================
2025-10-19 07:24:34,063:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for RMSE is 0.4751
2025-10-19 07:24:34,064:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
              importance_type='split', learning_rate=0.2, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.6,
              n_estimators=100, n_jobs=1, num_leaves=30, objective=None,
              random_state=42, reg_alpha=0.001, reg_lambda=5, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for RMSE is 0.476
2025-10-19 07:24:34,064:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-19 07:24:34,064:INFO:choose_better completed
2025-10-19 07:24:34,065:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 07:24:34,074:INFO:_master_model_container: 23
2025-10-19 07:24:34,074:INFO:_display_container: 4
2025-10-19 07:24:34,075:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 07:24:34,076:INFO:tune_model() successfully completed......................................
2025-10-19 07:24:34,324:INFO:Initializing tune_model()
2025-10-19 07:24:34,324:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000021207A01790>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 07:24:34,324:INFO:Checking exceptions
2025-10-19 07:24:34,417:INFO:Copying training dataset
2025-10-19 07:24:34,553:INFO:Checking base model
2025-10-19 07:24:34,554:INFO:Base model : CatBoost Regressor
2025-10-19 07:24:34,557:INFO:Declaring metric variables
2025-10-19 07:24:34,559:INFO:Defining Hyperparameters
2025-10-19 07:24:34,797:INFO:Tuning with n_jobs=1
2025-10-19 07:24:34,797:INFO:Initializing RandomizedSearchCV
2025-10-19 07:28:46,878:INFO:best_params: {'actual_estimator__random_strength': 0.5, 'actual_estimator__n_estimators': 280, 'actual_estimator__l2_leaf_reg': 200, 'actual_estimator__eta': 0.05, 'actual_estimator__depth': 5}
2025-10-19 07:28:46,879:INFO:Hyperparameter search completed
2025-10-19 07:28:46,879:INFO:SubProcess create_model() called ==================================
2025-10-19 07:28:46,880:INFO:Initializing create_model()
2025-10-19 07:28:46,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=<catboost.core.CatBoostRegressor object at 0x00000212076DD110>, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120775C750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.5, 'n_estimators': 280, 'l2_leaf_reg': 200, 'eta': 0.05, 'depth': 5})
2025-10-19 07:28:46,881:INFO:Checking exceptions
2025-10-19 07:28:46,881:INFO:Importing libraries
2025-10-19 07:28:46,881:INFO:Copying training dataset
2025-10-19 07:28:47,071:INFO:Defining folds
2025-10-19 07:28:47,072:INFO:Declaring metric variables
2025-10-19 07:28:47,076:INFO:Importing untrained model
2025-10-19 07:28:47,077:INFO:Declaring custom model
2025-10-19 07:28:47,082:INFO:CatBoost Regressor Imported successfully
2025-10-19 07:28:47,089:INFO:Starting cross validation
2025-10-19 07:28:47,095:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:29:17,068:INFO:Calculating mean and std
2025-10-19 07:29:17,070:INFO:Creating metrics dataframe
2025-10-19 07:29:17,077:INFO:Finalizing model
2025-10-19 07:29:24,647:INFO:Uploading results into container
2025-10-19 07:29:24,648:INFO:Uploading model into container now
2025-10-19 07:29:24,649:INFO:_master_model_container: 24
2025-10-19 07:29:24,649:INFO:_display_container: 5
2025-10-19 07:29:24,649:INFO:<catboost.core.CatBoostRegressor object at 0x0000021207647490>
2025-10-19 07:29:24,649:INFO:create_model() successfully completed......................................
2025-10-19 07:29:24,977:INFO:SubProcess create_model() end ==================================
2025-10-19 07:29:24,977:INFO:choose_better activated
2025-10-19 07:29:24,981:INFO:SubProcess create_model() called ==================================
2025-10-19 07:29:24,982:INFO:Initializing create_model()
2025-10-19 07:29:24,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000021207A01790>, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:29:24,982:INFO:Checking exceptions
2025-10-19 07:29:24,985:INFO:Importing libraries
2025-10-19 07:29:24,985:INFO:Copying training dataset
2025-10-19 07:29:25,175:INFO:Defining folds
2025-10-19 07:29:25,175:INFO:Declaring metric variables
2025-10-19 07:29:25,175:INFO:Importing untrained model
2025-10-19 07:29:25,175:INFO:Declaring custom model
2025-10-19 07:29:25,175:INFO:CatBoost Regressor Imported successfully
2025-10-19 07:29:25,175:INFO:Starting cross validation
2025-10-19 07:29:25,178:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:30:52,694:INFO:Calculating mean and std
2025-10-19 07:30:52,694:INFO:Creating metrics dataframe
2025-10-19 07:30:52,696:INFO:Finalizing model
2025-10-19 07:31:13,740:INFO:Uploading results into container
2025-10-19 07:31:13,741:INFO:Uploading model into container now
2025-10-19 07:31:13,741:INFO:_master_model_container: 25
2025-10-19 07:31:13,741:INFO:_display_container: 6
2025-10-19 07:31:13,742:INFO:<catboost.core.CatBoostRegressor object at 0x00000212219BFE90>
2025-10-19 07:31:13,742:INFO:create_model() successfully completed......................................
2025-10-19 07:31:13,985:INFO:SubProcess create_model() end ==================================
2025-10-19 07:31:13,985:INFO:<catboost.core.CatBoostRegressor object at 0x00000212219BFE90> result for RMSE is 0.4774
2025-10-19 07:31:13,986:INFO:<catboost.core.CatBoostRegressor object at 0x0000021207647490> result for RMSE is 0.4747
2025-10-19 07:31:13,986:INFO:<catboost.core.CatBoostRegressor object at 0x0000021207647490> is best model
2025-10-19 07:31:13,986:INFO:choose_better completed
2025-10-19 07:31:13,997:INFO:_master_model_container: 25
2025-10-19 07:31:13,997:INFO:_display_container: 5
2025-10-19 07:31:13,997:INFO:<catboost.core.CatBoostRegressor object at 0x0000021207647490>
2025-10-19 07:31:13,997:INFO:tune_model() successfully completed......................................
2025-10-19 07:31:14,243:INFO:Initializing blend_models()
2025-10-19 07:31:14,243:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator_list=[GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostRegressor object at 0x0000021207647490>], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-19 07:31:14,243:INFO:Checking exceptions
2025-10-19 07:31:14,348:INFO:Importing libraries
2025-10-19 07:31:14,348:INFO:Copying training dataset
2025-10-19 07:31:14,353:INFO:Getting model names
2025-10-19 07:31:14,360:INFO:SubProcess create_model() called ==================================
2025-10-19 07:31:14,369:INFO:Initializing create_model()
2025-10-19 07:31:14,370:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x0000021207647490>)],
                n_jobs=1, verbose=False, weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207B98390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:31:14,370:INFO:Checking exceptions
2025-10-19 07:31:14,370:INFO:Importing libraries
2025-10-19 07:31:14,370:INFO:Copying training dataset
2025-10-19 07:31:14,579:INFO:Defining folds
2025-10-19 07:31:14,579:INFO:Declaring metric variables
2025-10-19 07:31:14,582:INFO:Importing untrained model
2025-10-19 07:31:14,582:INFO:Declaring custom model
2025-10-19 07:31:14,587:INFO:Voting Regressor Imported successfully
2025-10-19 07:31:14,595:INFO:Starting cross validation
2025-10-19 07:31:14,599:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 07:31:24,194:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:31:24,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006577 seconds.
2025-10-19 07:31:24,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:31:24,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:31:24,213:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 07:31:24,213:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:31:24,214:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 07:31:37,809:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:31:37,828:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007341 seconds.
2025-10-19 07:31:37,828:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:31:37,828:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:31:37,828:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 07:31:37,828:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:31:37,829:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 07:31:51,619:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:31:51,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006775 seconds.
2025-10-19 07:31:51,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:31:51,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:31:51,637:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:31:51,637:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 07:31:51,638:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 07:32:05,309:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:32:05,326:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006184 seconds.
2025-10-19 07:32:05,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:32:05,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:32:05,326:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:32:05,327:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 07:32:05,327:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 07:32:20,610:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:32:20,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008401 seconds.
2025-10-19 07:32:20,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:32:20,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:32:20,641:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:32:20,643:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 07:32:20,644:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 07:32:25,762:INFO:Calculating mean and std
2025-10-19 07:32:25,765:INFO:Creating metrics dataframe
2025-10-19 07:32:25,773:INFO:Finalizing model
2025-10-19 07:32:46,809:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:32:46,837:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008538 seconds.
2025-10-19 07:32:46,837:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:32:46,837:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:32:46,837:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 07:32:46,838:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 07:32:46,838:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 07:32:52,478:INFO:Uploading results into container
2025-10-19 07:32:52,481:INFO:Uploading model into container now
2025-10-19 07:32:52,482:INFO:_master_model_container: 26
2025-10-19 07:32:52,482:INFO:_display_container: 6
2025-10-19 07:32:52,487:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x000002120AFF1090>)],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 07:32:52,487:INFO:create_model() successfully completed......................................
2025-10-19 07:32:52,772:INFO:SubProcess create_model() end ==================================
2025-10-19 07:32:52,782:INFO:_master_model_container: 26
2025-10-19 07:32:52,783:INFO:_display_container: 6
2025-10-19 07:32:52,787:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x000002120AFF1090>)],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 07:32:52,787:INFO:blend_models() successfully completed......................................
2025-10-19 07:32:53,088:INFO:Initializing finalize_model()
2025-10-19 07:32:53,088:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x000002120AFF1090>)],
                n_jobs=1, verbose=False, weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-19 07:32:53,091:INFO:Finalizing VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x000002120AFF1090>)],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 07:32:53,239:INFO:Initializing create_model()
2025-10-19 07:32:53,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x000002120AFF1090>)],
                n_jobs=1, verbose=False, weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62296    U09331
28248    U08761
48600    U06118
8049     U04657
48533    U06931
Name: id_usuario, Length: 63955, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 07:32:53,239:INFO:Checking exceptions
2025-10-19 07:32:53,241:INFO:Importing libraries
2025-10-19 07:32:53,241:INFO:Copying training dataset
2025-10-19 07:32:53,268:INFO:Defining folds
2025-10-19 07:32:53,268:INFO:Declaring metric variables
2025-10-19 07:32:53,268:INFO:Importing untrained model
2025-10-19 07:32:53,268:INFO:Declaring custom model
2025-10-19 07:32:53,270:INFO:Voting Regressor Imported successfully
2025-10-19 07:32:53,273:INFO:Cross validation set to False
2025-10-19 07:32:53,273:INFO:Fitting Model
2025-10-19 07:33:12,563:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 07:33:12,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013182 seconds.
2025-10-19 07:33:12,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 07:33:12,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 07:33:12,596:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 07:33:12,596:INFO:[LightGBM] [Info] Number of data points in the train set: 63955, number of used features: 95
2025-10-19 07:33:12,598:INFO:[LightGBM] [Info] Start training from score 3.320833
2025-10-19 07:33:20,146:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x000002120EA84DD0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 07:33:20,146:INFO:create_model() successfully completed......................................
2025-10-19 07:33:20,419:INFO:_master_model_container: 26
2025-10-19 07:33:20,419:INFO:_display_container: 6
2025-10-19 07:33:20,453:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x000002120EA84DD0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 07:33:20,453:INFO:finalize_model() successfully completed......................................
2025-10-19 07:33:20,750:INFO:Initializing save_model()
2025-10-19 07:33:20,750:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x000002120EA84DD0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), model_name=modelo_reg_rating_v2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-10-19 07:33:20,750:INFO:Adding model into prep_pipe
2025-10-19 07:33:20,750:WARNING:Only Model saved as it was a pipeline.
2025-10-19 07:33:20,785:INFO:modelo_reg_rating_v2.pkl saved in current working directory
2025-10-19 07:33:20,814:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x000002120EA84DD0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 07:33:20,814:INFO:save_model() successfully completed......................................
2025-10-19 07:33:21,162:INFO:Initializing predict_model()
2025-10-19 07:33:21,162:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x000002120EA84DD0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021221B22CA0>)
2025-10-19 07:33:21,162:INFO:Checking exceptions
2025-10-19 07:33:21,162:INFO:Preloading libraries
2025-10-19 07:33:21,165:INFO:Set up data.
2025-10-19 07:33:21,195:INFO:Set up index.
2025-10-19 07:35:21,782:INFO:Initializing load_model()
2025-10-19 07:35:21,782:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:35:21,810:INFO:Initializing load_model()
2025-10-19 07:35:21,810:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:35:21,867:INFO:Initializing predict_model()
2025-10-19 07:35:21,868:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=5654,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021220625B20>)
2025-10-19 07:35:21,868:INFO:Checking exceptions
2025-10-19 07:35:21,868:INFO:Preloading libraries
2025-10-19 07:35:21,870:INFO:Set up data.
2025-10-19 07:35:21,879:INFO:Set up index.
2025-10-19 07:41:13,591:INFO:Initializing load_model()
2025-10-19 07:41:13,592:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:41:13,628:INFO:Initializing load_model()
2025-10-19 07:41:13,629:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:41:24,922:INFO:Initializing load_model()
2025-10-19 07:41:24,922:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:41:24,955:INFO:Initializing load_model()
2025-10-19 07:41:24,955:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:41:25,014:INFO:Initializing predict_model()
2025-10-19 07:41:25,015:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120E97DBD0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=5654,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002120A057740>)
2025-10-19 07:41:25,015:INFO:Checking exceptions
2025-10-19 07:41:25,015:INFO:Preloading libraries
2025-10-19 07:41:25,017:INFO:Set up data.
2025-10-19 07:41:25,026:INFO:Set up index.
2025-10-19 07:43:02,365:INFO:Initializing load_model()
2025-10-19 07:43:02,365:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:43:02,402:INFO:Initializing load_model()
2025-10-19 07:43:02,403:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:45:31,062:INFO:Initializing load_model()
2025-10-19 07:45:31,064:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:45:31,089:INFO:Initializing load_model()
2025-10-19 07:45:31,089:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:48:01,792:INFO:Initializing load_model()
2025-10-19 07:48:01,792:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:48:01,817:INFO:Initializing load_model()
2025-10-19 07:48:01,818:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:48:02,066:INFO:Initializing predict_model()
2025-10-19 07:48:02,067:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x000002120A935FD0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021225FCA160>)
2025-10-19 07:48:02,067:INFO:Checking exceptions
2025-10-19 07:48:02,067:INFO:Preloading libraries
2025-10-19 07:48:02,073:INFO:Set up data.
2025-10-19 07:48:02,079:INFO:Set up index.
2025-10-19 07:48:56,921:INFO:Initializing load_model()
2025-10-19 07:48:56,922:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:48:56,943:INFO:Initializing load_model()
2025-10-19 07:48:56,943:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:48:57,223:INFO:Initializing predict_model()
2025-10-19 07:48:57,223:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000021221AA5F10>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002120A7587C0>)
2025-10-19 07:48:57,223:INFO:Checking exceptions
2025-10-19 07:48:57,223:INFO:Preloading libraries
2025-10-19 07:48:57,225:INFO:Set up data.
2025-10-19 07:48:57,230:INFO:Set up index.
2025-10-19 07:49:01,197:INFO:Initializing load_model()
2025-10-19 07:49:01,197:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:49:01,226:INFO:Initializing load_model()
2025-10-19 07:49:01,226:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:49:01,550:INFO:Initializing predict_model()
2025-10-19 07:49:01,550:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x000002120A8CC950>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002120A758720>)
2025-10-19 07:49:01,550:INFO:Checking exceptions
2025-10-19 07:49:01,550:INFO:Preloading libraries
2025-10-19 07:49:01,553:INFO:Set up data.
2025-10-19 07:49:01,559:INFO:Set up index.
2025-10-19 07:49:16,754:INFO:Initializing load_model()
2025-10-19 07:49:16,754:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:49:16,804:INFO:Initializing load_model()
2025-10-19 07:49:16,804:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:49:17,139:INFO:Initializing predict_model()
2025-10-19 07:49:17,139:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x000002120A93FF50>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002120A759A80>)
2025-10-19 07:49:17,139:INFO:Checking exceptions
2025-10-19 07:49:17,139:INFO:Preloading libraries
2025-10-19 07:49:17,142:INFO:Set up data.
2025-10-19 07:49:17,148:INFO:Set up index.
2025-10-19 07:49:42,987:INFO:Initializing load_model()
2025-10-19 07:49:42,988:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:49:43,021:INFO:Initializing load_model()
2025-10-19 07:49:43,021:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:49:43,346:INFO:Initializing predict_model()
2025-10-19 07:49:43,346:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x000002120A72F310>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002120A758E00>)
2025-10-19 07:49:43,346:INFO:Checking exceptions
2025-10-19 07:49:43,346:INFO:Preloading libraries
2025-10-19 07:49:43,348:INFO:Set up data.
2025-10-19 07:49:43,358:INFO:Set up index.
2025-10-19 07:51:15,646:INFO:Initializing load_model()
2025-10-19 07:51:15,646:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:51:15,674:INFO:Initializing load_model()
2025-10-19 07:51:15,674:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 07:51:15,829:INFO:Initializing predict_model()
2025-10-19 07:51:15,829:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000212218CEB90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x000002120A312490>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002120A75BCE0>)
2025-10-19 07:51:15,830:INFO:Checking exceptions
2025-10-19 07:51:15,830:INFO:Preloading libraries
2025-10-19 07:51:15,833:INFO:Set up data.
2025-10-19 07:51:15,841:INFO:Set up index.
2025-10-19 08:27:07,338:INFO:PyCaret ClassificationExperiment
2025-10-19 08:27:07,338:INFO:Logging name: clf-default-name
2025-10-19 08:27:07,338:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 08:27:07,338:INFO:version 3.3.2
2025-10-19 08:27:07,338:INFO:Initializing setup()
2025-10-19 08:27:07,338:INFO:self.USI: fcbf
2025-10-19 08:27:07,339:INFO:self._variable_keys: {'USI', 'seed', 'memory', 'html_param', 'X_test', 'target_param', 'logging_param', 'fold_groups_param', 'exp_id', 'exp_name_log', 'fix_imbalance', 'is_multiclass', 'log_plots_param', 'y_train', 'y', 'X', 'fold_generator', 'fold_shuffle_param', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', '_available_plots', 'idx', 'data', 'pipeline', 'X_train', '_ml_usecase', 'y_test'}
2025-10-19 08:27:07,339:INFO:Checking environment
2025-10-19 08:27:07,339:INFO:python_version: 3.11.13
2025-10-19 08:27:07,339:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 08:27:07,339:INFO:machine: AMD64
2025-10-19 08:27:07,339:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 08:27:07,349:INFO:Memory: svmem(total=16856211456, available=3116482560, percent=81.5, used=13739728896, free=3116482560)
2025-10-19 08:27:07,349:INFO:Physical Core: 4
2025-10-19 08:27:07,350:INFO:Logical Core: 8
2025-10-19 08:27:07,350:INFO:Checking libraries
2025-10-19 08:27:07,350:INFO:System:
2025-10-19 08:27:07,350:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 08:27:07,350:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 08:27:07,350:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 08:27:07,350:INFO:PyCaret required dependencies:
2025-10-19 08:27:07,350:INFO:                 pip: 25.2
2025-10-19 08:27:07,350:INFO:          setuptools: 80.9.0
2025-10-19 08:27:07,350:INFO:             pycaret: 3.3.2
2025-10-19 08:27:07,350:INFO:             IPython: 9.6.0
2025-10-19 08:27:07,350:INFO:          ipywidgets: 8.1.7
2025-10-19 08:27:07,351:INFO:                tqdm: 4.67.1
2025-10-19 08:27:07,351:INFO:               numpy: 1.26.4
2025-10-19 08:27:07,351:INFO:              pandas: 2.1.4
2025-10-19 08:27:07,351:INFO:              jinja2: 3.1.6
2025-10-19 08:27:07,351:INFO:               scipy: 1.11.4
2025-10-19 08:27:07,351:INFO:              joblib: 1.3.2
2025-10-19 08:27:07,351:INFO:             sklearn: 1.4.2
2025-10-19 08:27:07,351:INFO:                pyod: 2.0.5
2025-10-19 08:27:07,351:INFO:            imblearn: 0.14.0
2025-10-19 08:27:07,351:INFO:   category_encoders: 2.7.0
2025-10-19 08:27:07,351:INFO:            lightgbm: 4.6.0
2025-10-19 08:27:07,351:INFO:               numba: 0.61.0
2025-10-19 08:27:07,351:INFO:            requests: 2.32.5
2025-10-19 08:27:07,351:INFO:          matplotlib: 3.7.5
2025-10-19 08:27:07,351:INFO:          scikitplot: 0.3.7
2025-10-19 08:27:07,351:INFO:         yellowbrick: 1.5
2025-10-19 08:27:07,351:INFO:              plotly: 5.24.1
2025-10-19 08:27:07,351:INFO:    plotly-resampler: Not installed
2025-10-19 08:27:07,351:INFO:             kaleido: 1.1.0
2025-10-19 08:27:07,351:INFO:           schemdraw: 0.15
2025-10-19 08:27:07,351:INFO:         statsmodels: 0.14.5
2025-10-19 08:27:07,351:INFO:              sktime: 0.26.0
2025-10-19 08:27:07,351:INFO:               tbats: 1.1.3
2025-10-19 08:27:07,351:INFO:            pmdarima: 2.0.4
2025-10-19 08:27:07,351:INFO:              psutil: 7.1.0
2025-10-19 08:27:07,351:INFO:          markupsafe: 3.0.3
2025-10-19 08:27:07,351:INFO:             pickle5: Not installed
2025-10-19 08:27:07,351:INFO:         cloudpickle: 3.1.1
2025-10-19 08:27:07,351:INFO:         deprecation: 2.1.0
2025-10-19 08:27:07,351:INFO:              xxhash: 3.6.0
2025-10-19 08:27:07,351:INFO:           wurlitzer: Not installed
2025-10-19 08:27:07,351:INFO:PyCaret optional dependencies:
2025-10-19 08:27:07,352:INFO:                shap: 0.44.1
2025-10-19 08:27:07,352:INFO:           interpret: 0.7.3
2025-10-19 08:27:07,352:INFO:                umap: 0.5.7
2025-10-19 08:27:07,352:INFO:     ydata_profiling: 4.17.0
2025-10-19 08:27:07,352:INFO:  explainerdashboard: 0.5.1
2025-10-19 08:27:07,352:INFO:             autoviz: Not installed
2025-10-19 08:27:07,352:INFO:           fairlearn: 0.7.0
2025-10-19 08:27:07,352:INFO:          deepchecks: Not installed
2025-10-19 08:27:07,352:INFO:             xgboost: Not installed
2025-10-19 08:27:07,352:INFO:            catboost: 1.2.8
2025-10-19 08:27:07,352:INFO:              kmodes: 0.12.2
2025-10-19 08:27:07,352:INFO:             mlxtend: 0.23.4
2025-10-19 08:27:07,352:INFO:       statsforecast: 1.5.0
2025-10-19 08:27:07,352:INFO:        tune_sklearn: Not installed
2025-10-19 08:27:07,353:INFO:                 ray: Not installed
2025-10-19 08:27:07,353:INFO:            hyperopt: 0.2.7
2025-10-19 08:27:07,353:INFO:              optuna: 4.5.0
2025-10-19 08:27:07,353:INFO:               skopt: 0.10.2
2025-10-19 08:27:07,353:INFO:              mlflow: 3.5.0
2025-10-19 08:27:07,353:INFO:              gradio: 5.49.1
2025-10-19 08:27:07,353:INFO:             fastapi: 0.119.0
2025-10-19 08:27:07,353:INFO:             uvicorn: 0.38.0
2025-10-19 08:27:07,353:INFO:              m2cgen: 0.10.0
2025-10-19 08:27:07,353:INFO:           evidently: 0.4.40
2025-10-19 08:27:07,353:INFO:               fugue: 0.8.7
2025-10-19 08:27:07,353:INFO:           streamlit: Not installed
2025-10-19 08:27:07,353:INFO:             prophet: Not installed
2025-10-19 08:27:07,353:INFO:None
2025-10-19 08:27:07,354:INFO:Set up data.
2025-10-19 08:27:07,564:INFO:Set up folding strategy.
2025-10-19 08:27:07,758:INFO:Set up train/test split.
2025-10-19 08:27:07,934:INFO:Set up index.
2025-10-19 08:27:07,944:INFO:Assigning column types.
2025-10-19 08:27:08,115:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 08:27:08,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 08:27:08,155:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 08:27:08,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 08:27:08,180:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 08:27:08,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 08:27:08,221:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 08:27:08,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 08:27:08,244:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 08:27:08,246:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 08:27:08,286:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 08:27:08,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 08:27:08,353:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 08:27:08,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 08:27:08,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 08:27:08,446:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 08:27:08,447:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 08:27:08,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 08:27:08,517:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 08:27:08,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 08:27:08,578:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 08:27:08,583:INFO:Preparing preprocessing pipeline...
2025-10-19 08:27:08,610:INFO:Set up simple imputation.
2025-10-19 08:27:08,744:INFO:Set up encoding of ordinal features.
2025-10-19 08:27:08,801:INFO:Set up encoding of categorical features.
2025-10-19 08:27:08,803:INFO:Set up removing multicollinearity.
2025-10-19 08:27:08,828:INFO:Set up column name cleaning.
2025-10-19 08:27:12,842:INFO:Finished creating preprocessing pipeline.
2025-10-19 08:27:12,863:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 08:27:12,863:INFO:Creating final display dataframe.
2025-10-19 08:27:15,378:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (63955, 28)
4        Transformed data shape       (63955, 96)
5   Transformed train set shape       (44768, 96)
6    Transformed test set shape       (19187, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              fcbf
2025-10-19 08:27:15,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 08:27:15,437:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 08:27:15,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 08:27:15,496:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 08:27:15,499:INFO:setup() successfully completed in 8.2s...............
2025-10-19 08:27:15,501:INFO:Initializing compare_models()
2025-10-19 08:27:15,501:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 08:27:15,502:INFO:Checking exceptions
2025-10-19 08:27:15,618:INFO:Preparing display monitor
2025-10-19 08:27:15,656:INFO:Initializing Logistic Regression
2025-10-19 08:27:15,656:INFO:Total runtime is 0.0 minutes
2025-10-19 08:27:15,661:INFO:SubProcess create_model() called ==================================
2025-10-19 08:27:15,664:INFO:Initializing create_model()
2025-10-19 08:27:15,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:27:15,664:INFO:Checking exceptions
2025-10-19 08:27:15,664:INFO:Importing libraries
2025-10-19 08:27:15,664:INFO:Copying training dataset
2025-10-19 08:27:15,875:INFO:Defining folds
2025-10-19 08:27:15,875:INFO:Declaring metric variables
2025-10-19 08:27:15,878:INFO:Importing untrained model
2025-10-19 08:27:15,881:INFO:Logistic Regression Imported successfully
2025-10-19 08:27:15,888:INFO:Starting cross validation
2025-10-19 08:27:15,893:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:28:15,404:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 08:28:15,795:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 08:28:15,851:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 08:28:16,064:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 08:28:16,309:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 08:28:16,641:INFO:Calculating mean and std
2025-10-19 08:28:16,642:INFO:Creating metrics dataframe
2025-10-19 08:28:16,644:INFO:Uploading results into container
2025-10-19 08:28:16,644:INFO:Uploading model into container now
2025-10-19 08:28:16,645:INFO:_master_model_container: 1
2025-10-19 08:28:16,646:INFO:_display_container: 2
2025-10-19 08:28:16,646:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 08:28:16,646:INFO:create_model() successfully completed......................................
2025-10-19 08:28:17,239:INFO:SubProcess create_model() end ==================================
2025-10-19 08:28:17,240:INFO:Creating metrics dataframe
2025-10-19 08:28:17,247:INFO:Initializing K Neighbors Classifier
2025-10-19 08:28:17,247:INFO:Total runtime is 1.026520041624705 minutes
2025-10-19 08:28:17,250:INFO:SubProcess create_model() called ==================================
2025-10-19 08:28:17,252:INFO:Initializing create_model()
2025-10-19 08:28:17,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:28:17,252:INFO:Checking exceptions
2025-10-19 08:28:17,252:INFO:Importing libraries
2025-10-19 08:28:17,252:INFO:Copying training dataset
2025-10-19 08:28:17,463:INFO:Defining folds
2025-10-19 08:28:17,463:INFO:Declaring metric variables
2025-10-19 08:28:17,465:INFO:Importing untrained model
2025-10-19 08:28:17,471:INFO:K Neighbors Classifier Imported successfully
2025-10-19 08:28:17,478:INFO:Starting cross validation
2025-10-19 08:28:17,483:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:28:32,248:INFO:Calculating mean and std
2025-10-19 08:28:32,250:INFO:Creating metrics dataframe
2025-10-19 08:28:32,254:INFO:Uploading results into container
2025-10-19 08:28:32,256:INFO:Uploading model into container now
2025-10-19 08:28:32,257:INFO:_master_model_container: 2
2025-10-19 08:28:32,257:INFO:_display_container: 2
2025-10-19 08:28:32,257:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 08:28:32,258:INFO:create_model() successfully completed......................................
2025-10-19 08:28:32,569:INFO:SubProcess create_model() end ==================================
2025-10-19 08:28:32,570:INFO:Creating metrics dataframe
2025-10-19 08:28:32,579:INFO:Initializing Naive Bayes
2025-10-19 08:28:32,579:INFO:Total runtime is 1.2820475260416666 minutes
2025-10-19 08:28:32,582:INFO:SubProcess create_model() called ==================================
2025-10-19 08:28:32,583:INFO:Initializing create_model()
2025-10-19 08:28:32,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:28:32,584:INFO:Checking exceptions
2025-10-19 08:28:32,584:INFO:Importing libraries
2025-10-19 08:28:32,584:INFO:Copying training dataset
2025-10-19 08:28:32,781:INFO:Defining folds
2025-10-19 08:28:32,781:INFO:Declaring metric variables
2025-10-19 08:28:32,786:INFO:Importing untrained model
2025-10-19 08:28:32,790:INFO:Naive Bayes Imported successfully
2025-10-19 08:28:32,798:INFO:Starting cross validation
2025-10-19 08:28:32,803:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:28:37,400:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:28:37,498:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:28:37,523:INFO:Calculating mean and std
2025-10-19 08:28:37,524:INFO:Creating metrics dataframe
2025-10-19 08:28:37,526:INFO:Uploading results into container
2025-10-19 08:28:37,526:INFO:Uploading model into container now
2025-10-19 08:28:37,527:INFO:_master_model_container: 3
2025-10-19 08:28:37,527:INFO:_display_container: 2
2025-10-19 08:28:37,527:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 08:28:37,527:INFO:create_model() successfully completed......................................
2025-10-19 08:28:37,780:INFO:SubProcess create_model() end ==================================
2025-10-19 08:28:37,781:INFO:Creating metrics dataframe
2025-10-19 08:28:37,789:INFO:Initializing Decision Tree Classifier
2025-10-19 08:28:37,790:INFO:Total runtime is 1.368909728527069 minutes
2025-10-19 08:28:37,794:INFO:SubProcess create_model() called ==================================
2025-10-19 08:28:37,795:INFO:Initializing create_model()
2025-10-19 08:28:37,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:28:37,795:INFO:Checking exceptions
2025-10-19 08:28:37,795:INFO:Importing libraries
2025-10-19 08:28:37,795:INFO:Copying training dataset
2025-10-19 08:28:37,995:INFO:Defining folds
2025-10-19 08:28:37,995:INFO:Declaring metric variables
2025-10-19 08:28:38,001:INFO:Importing untrained model
2025-10-19 08:28:38,006:INFO:Decision Tree Classifier Imported successfully
2025-10-19 08:28:38,013:INFO:Starting cross validation
2025-10-19 08:28:38,018:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:28:43,487:INFO:Calculating mean and std
2025-10-19 08:28:43,489:INFO:Creating metrics dataframe
2025-10-19 08:28:43,491:INFO:Uploading results into container
2025-10-19 08:28:43,492:INFO:Uploading model into container now
2025-10-19 08:28:43,493:INFO:_master_model_container: 4
2025-10-19 08:28:43,493:INFO:_display_container: 2
2025-10-19 08:28:43,494:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-19 08:28:43,495:INFO:create_model() successfully completed......................................
2025-10-19 08:28:43,774:INFO:SubProcess create_model() end ==================================
2025-10-19 08:28:43,774:INFO:Creating metrics dataframe
2025-10-19 08:28:43,781:INFO:Initializing SVM - Linear Kernel
2025-10-19 08:28:43,781:INFO:Total runtime is 1.468755050500234 minutes
2025-10-19 08:28:43,784:INFO:SubProcess create_model() called ==================================
2025-10-19 08:28:43,786:INFO:Initializing create_model()
2025-10-19 08:28:43,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:28:43,787:INFO:Checking exceptions
2025-10-19 08:28:43,787:INFO:Importing libraries
2025-10-19 08:28:43,787:INFO:Copying training dataset
2025-10-19 08:28:44,031:INFO:Defining folds
2025-10-19 08:28:44,032:INFO:Declaring metric variables
2025-10-19 08:28:44,036:INFO:Importing untrained model
2025-10-19 08:28:44,043:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 08:28:44,049:INFO:Starting cross validation
2025-10-19 08:28:44,054:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:28:54,697:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:28:54,725:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:28:55,317:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:28:55,481:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:28:55,503:INFO:Calculating mean and std
2025-10-19 08:28:55,505:INFO:Creating metrics dataframe
2025-10-19 08:28:55,507:INFO:Uploading results into container
2025-10-19 08:28:55,507:INFO:Uploading model into container now
2025-10-19 08:28:55,507:INFO:_master_model_container: 5
2025-10-19 08:28:55,507:INFO:_display_container: 2
2025-10-19 08:28:55,508:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 08:28:55,508:INFO:create_model() successfully completed......................................
2025-10-19 08:28:55,765:INFO:SubProcess create_model() end ==================================
2025-10-19 08:28:55,766:INFO:Creating metrics dataframe
2025-10-19 08:28:55,773:INFO:Initializing Ridge Classifier
2025-10-19 08:28:55,773:INFO:Total runtime is 1.6686170379320782 minutes
2025-10-19 08:28:55,777:INFO:SubProcess create_model() called ==================================
2025-10-19 08:28:55,779:INFO:Initializing create_model()
2025-10-19 08:28:55,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:28:55,779:INFO:Checking exceptions
2025-10-19 08:28:55,779:INFO:Importing libraries
2025-10-19 08:28:55,779:INFO:Copying training dataset
2025-10-19 08:28:55,965:INFO:Defining folds
2025-10-19 08:28:55,966:INFO:Declaring metric variables
2025-10-19 08:28:55,971:INFO:Importing untrained model
2025-10-19 08:28:55,977:INFO:Ridge Classifier Imported successfully
2025-10-19 08:28:55,983:INFO:Starting cross validation
2025-10-19 08:28:55,989:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:29:00,539:INFO:Calculating mean and std
2025-10-19 08:29:00,541:INFO:Creating metrics dataframe
2025-10-19 08:29:00,543:INFO:Uploading results into container
2025-10-19 08:29:00,543:INFO:Uploading model into container now
2025-10-19 08:29:00,543:INFO:_master_model_container: 6
2025-10-19 08:29:00,543:INFO:_display_container: 2
2025-10-19 08:29:00,544:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 08:29:00,544:INFO:create_model() successfully completed......................................
2025-10-19 08:29:00,795:INFO:SubProcess create_model() end ==================================
2025-10-19 08:29:00,795:INFO:Creating metrics dataframe
2025-10-19 08:29:00,802:INFO:Initializing Random Forest Classifier
2025-10-19 08:29:00,802:INFO:Total runtime is 1.7524430672327678 minutes
2025-10-19 08:29:00,807:INFO:SubProcess create_model() called ==================================
2025-10-19 08:29:00,809:INFO:Initializing create_model()
2025-10-19 08:29:00,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:29:00,809:INFO:Checking exceptions
2025-10-19 08:29:00,809:INFO:Importing libraries
2025-10-19 08:29:00,809:INFO:Copying training dataset
2025-10-19 08:29:00,987:INFO:Defining folds
2025-10-19 08:29:00,988:INFO:Declaring metric variables
2025-10-19 08:29:00,992:INFO:Importing untrained model
2025-10-19 08:29:00,998:INFO:Random Forest Classifier Imported successfully
2025-10-19 08:29:01,003:INFO:Starting cross validation
2025-10-19 08:29:01,010:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:29:12,374:INFO:Calculating mean and std
2025-10-19 08:29:12,376:INFO:Creating metrics dataframe
2025-10-19 08:29:12,379:INFO:Uploading results into container
2025-10-19 08:29:12,381:INFO:Uploading model into container now
2025-10-19 08:29:12,382:INFO:_master_model_container: 7
2025-10-19 08:29:12,382:INFO:_display_container: 2
2025-10-19 08:29:12,383:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-19 08:29:12,383:INFO:create_model() successfully completed......................................
2025-10-19 08:29:12,669:INFO:SubProcess create_model() end ==================================
2025-10-19 08:29:12,669:INFO:Creating metrics dataframe
2025-10-19 08:29:12,677:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 08:29:12,678:INFO:Total runtime is 1.9503623207410177 minutes
2025-10-19 08:29:12,681:INFO:SubProcess create_model() called ==================================
2025-10-19 08:29:12,682:INFO:Initializing create_model()
2025-10-19 08:29:12,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:29:12,682:INFO:Checking exceptions
2025-10-19 08:29:12,684:INFO:Importing libraries
2025-10-19 08:29:12,684:INFO:Copying training dataset
2025-10-19 08:29:12,877:INFO:Defining folds
2025-10-19 08:29:12,877:INFO:Declaring metric variables
2025-10-19 08:29:12,882:INFO:Importing untrained model
2025-10-19 08:29:12,884:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 08:29:12,893:INFO:Starting cross validation
2025-10-19 08:29:12,898:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:29:17,645:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 08:29:18,020:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 08:29:18,248:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 08:29:18,527:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 08:29:18,670:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 08:29:19,377:INFO:Calculating mean and std
2025-10-19 08:29:19,378:INFO:Creating metrics dataframe
2025-10-19 08:29:19,380:INFO:Uploading results into container
2025-10-19 08:29:19,380:INFO:Uploading model into container now
2025-10-19 08:29:19,381:INFO:_master_model_container: 8
2025-10-19 08:29:19,381:INFO:_display_container: 2
2025-10-19 08:29:19,381:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 08:29:19,381:INFO:create_model() successfully completed......................................
2025-10-19 08:29:19,640:INFO:SubProcess create_model() end ==================================
2025-10-19 08:29:19,641:INFO:Creating metrics dataframe
2025-10-19 08:29:19,648:INFO:Initializing Ada Boost Classifier
2025-10-19 08:29:19,649:INFO:Total runtime is 2.066542975107829 minutes
2025-10-19 08:29:19,653:INFO:SubProcess create_model() called ==================================
2025-10-19 08:29:19,654:INFO:Initializing create_model()
2025-10-19 08:29:19,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:29:19,655:INFO:Checking exceptions
2025-10-19 08:29:19,655:INFO:Importing libraries
2025-10-19 08:29:19,655:INFO:Copying training dataset
2025-10-19 08:29:19,833:INFO:Defining folds
2025-10-19 08:29:19,833:INFO:Declaring metric variables
2025-10-19 08:29:19,836:INFO:Importing untrained model
2025-10-19 08:29:19,843:INFO:Ada Boost Classifier Imported successfully
2025-10-19 08:29:19,850:INFO:Starting cross validation
2025-10-19 08:29:19,857:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:29:23,637:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:29:23,764:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:29:23,830:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:29:23,928:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:29:24,067:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:29:29,067:INFO:Calculating mean and std
2025-10-19 08:29:29,068:INFO:Creating metrics dataframe
2025-10-19 08:29:29,069:INFO:Uploading results into container
2025-10-19 08:29:29,070:INFO:Uploading model into container now
2025-10-19 08:29:29,070:INFO:_master_model_container: 9
2025-10-19 08:29:29,070:INFO:_display_container: 2
2025-10-19 08:29:29,070:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 08:29:29,070:INFO:create_model() successfully completed......................................
2025-10-19 08:29:29,322:INFO:SubProcess create_model() end ==================================
2025-10-19 08:29:29,323:INFO:Creating metrics dataframe
2025-10-19 08:29:29,331:INFO:Initializing Gradient Boosting Classifier
2025-10-19 08:29:29,332:INFO:Total runtime is 2.227942232290904 minutes
2025-10-19 08:29:29,335:INFO:SubProcess create_model() called ==================================
2025-10-19 08:29:29,337:INFO:Initializing create_model()
2025-10-19 08:29:29,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:29:29,338:INFO:Checking exceptions
2025-10-19 08:29:29,338:INFO:Importing libraries
2025-10-19 08:29:29,338:INFO:Copying training dataset
2025-10-19 08:29:29,536:INFO:Defining folds
2025-10-19 08:29:29,536:INFO:Declaring metric variables
2025-10-19 08:29:29,541:INFO:Importing untrained model
2025-10-19 08:29:29,546:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 08:29:29,552:INFO:Starting cross validation
2025-10-19 08:29:29,557:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:29:45,399:INFO:Calculating mean and std
2025-10-19 08:29:45,400:INFO:Creating metrics dataframe
2025-10-19 08:29:45,402:INFO:Uploading results into container
2025-10-19 08:29:45,403:INFO:Uploading model into container now
2025-10-19 08:29:45,403:INFO:_master_model_container: 10
2025-10-19 08:29:45,403:INFO:_display_container: 2
2025-10-19 08:29:45,404:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 08:29:45,404:INFO:create_model() successfully completed......................................
2025-10-19 08:29:45,685:INFO:SubProcess create_model() end ==================================
2025-10-19 08:29:45,685:INFO:Creating metrics dataframe
2025-10-19 08:29:45,696:INFO:Initializing Linear Discriminant Analysis
2025-10-19 08:29:45,696:INFO:Total runtime is 2.5006781935691835 minutes
2025-10-19 08:29:45,699:INFO:SubProcess create_model() called ==================================
2025-10-19 08:29:45,701:INFO:Initializing create_model()
2025-10-19 08:29:45,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:29:45,701:INFO:Checking exceptions
2025-10-19 08:29:45,701:INFO:Importing libraries
2025-10-19 08:29:45,701:INFO:Copying training dataset
2025-10-19 08:29:45,888:INFO:Defining folds
2025-10-19 08:29:45,888:INFO:Declaring metric variables
2025-10-19 08:29:45,894:INFO:Importing untrained model
2025-10-19 08:29:45,897:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 08:29:45,905:INFO:Starting cross validation
2025-10-19 08:29:45,910:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:29:52,756:INFO:Calculating mean and std
2025-10-19 08:29:52,758:INFO:Creating metrics dataframe
2025-10-19 08:29:52,761:INFO:Uploading results into container
2025-10-19 08:29:52,762:INFO:Uploading model into container now
2025-10-19 08:29:52,763:INFO:_master_model_container: 11
2025-10-19 08:29:52,763:INFO:_display_container: 2
2025-10-19 08:29:52,764:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 08:29:52,764:INFO:create_model() successfully completed......................................
2025-10-19 08:29:53,037:INFO:SubProcess create_model() end ==================================
2025-10-19 08:29:53,037:INFO:Creating metrics dataframe
2025-10-19 08:29:53,048:INFO:Initializing Extra Trees Classifier
2025-10-19 08:29:53,048:INFO:Total runtime is 2.6232026537259423 minutes
2025-10-19 08:29:53,051:INFO:SubProcess create_model() called ==================================
2025-10-19 08:29:53,053:INFO:Initializing create_model()
2025-10-19 08:29:53,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:29:53,053:INFO:Checking exceptions
2025-10-19 08:29:53,053:INFO:Importing libraries
2025-10-19 08:29:53,053:INFO:Copying training dataset
2025-10-19 08:29:53,247:INFO:Defining folds
2025-10-19 08:29:53,248:INFO:Declaring metric variables
2025-10-19 08:29:53,253:INFO:Importing untrained model
2025-10-19 08:29:53,257:INFO:Extra Trees Classifier Imported successfully
2025-10-19 08:29:53,266:INFO:Starting cross validation
2025-10-19 08:29:53,269:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:30:07,847:INFO:Calculating mean and std
2025-10-19 08:30:07,848:INFO:Creating metrics dataframe
2025-10-19 08:30:07,850:INFO:Uploading results into container
2025-10-19 08:30:07,850:INFO:Uploading model into container now
2025-10-19 08:30:07,851:INFO:_master_model_container: 12
2025-10-19 08:30:07,851:INFO:_display_container: 2
2025-10-19 08:30:07,851:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-19 08:30:07,852:INFO:create_model() successfully completed......................................
2025-10-19 08:30:08,118:INFO:SubProcess create_model() end ==================================
2025-10-19 08:30:08,118:INFO:Creating metrics dataframe
2025-10-19 08:30:08,127:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 08:30:08,128:INFO:Total runtime is 2.8745339751243595 minutes
2025-10-19 08:30:08,132:INFO:SubProcess create_model() called ==================================
2025-10-19 08:30:08,133:INFO:Initializing create_model()
2025-10-19 08:30:08,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:30:08,133:INFO:Checking exceptions
2025-10-19 08:30:08,133:INFO:Importing libraries
2025-10-19 08:30:08,133:INFO:Copying training dataset
2025-10-19 08:30:08,321:INFO:Defining folds
2025-10-19 08:30:08,321:INFO:Declaring metric variables
2025-10-19 08:30:08,328:INFO:Importing untrained model
2025-10-19 08:30:08,333:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 08:30:08,342:INFO:Starting cross validation
2025-10-19 08:30:08,348:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:30:14,235:INFO:Calculating mean and std
2025-10-19 08:30:14,237:INFO:Creating metrics dataframe
2025-10-19 08:30:14,239:INFO:Uploading results into container
2025-10-19 08:30:14,240:INFO:Uploading model into container now
2025-10-19 08:30:14,241:INFO:_master_model_container: 13
2025-10-19 08:30:14,242:INFO:_display_container: 2
2025-10-19 08:30:14,243:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 08:30:14,244:INFO:create_model() successfully completed......................................
2025-10-19 08:30:14,556:INFO:SubProcess create_model() end ==================================
2025-10-19 08:30:14,556:INFO:Creating metrics dataframe
2025-10-19 08:30:14,568:INFO:Initializing CatBoost Classifier
2025-10-19 08:30:14,568:INFO:Total runtime is 2.9818697690963747 minutes
2025-10-19 08:30:14,571:INFO:SubProcess create_model() called ==================================
2025-10-19 08:30:14,572:INFO:Initializing create_model()
2025-10-19 08:30:14,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:30:14,572:INFO:Checking exceptions
2025-10-19 08:30:14,572:INFO:Importing libraries
2025-10-19 08:30:14,572:INFO:Copying training dataset
2025-10-19 08:30:14,777:INFO:Defining folds
2025-10-19 08:30:14,777:INFO:Declaring metric variables
2025-10-19 08:30:14,781:INFO:Importing untrained model
2025-10-19 08:30:14,785:INFO:CatBoost Classifier Imported successfully
2025-10-19 08:30:14,792:INFO:Starting cross validation
2025-10-19 08:30:14,798:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:30:59,022:INFO:Calculating mean and std
2025-10-19 08:30:59,024:INFO:Creating metrics dataframe
2025-10-19 08:30:59,027:INFO:Uploading results into container
2025-10-19 08:30:59,029:INFO:Uploading model into container now
2025-10-19 08:30:59,030:INFO:_master_model_container: 14
2025-10-19 08:30:59,031:INFO:_display_container: 2
2025-10-19 08:30:59,031:INFO:<catboost.core.CatBoostClassifier object at 0x000002120A8AE2D0>
2025-10-19 08:30:59,032:INFO:create_model() successfully completed......................................
2025-10-19 08:30:59,301:INFO:SubProcess create_model() end ==================================
2025-10-19 08:30:59,301:INFO:Creating metrics dataframe
2025-10-19 08:30:59,314:INFO:Initializing Dummy Classifier
2025-10-19 08:30:59,314:INFO:Total runtime is 3.7276360551516214 minutes
2025-10-19 08:30:59,318:INFO:SubProcess create_model() called ==================================
2025-10-19 08:30:59,320:INFO:Initializing create_model()
2025-10-19 08:30:59,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D7C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:30:59,320:INFO:Checking exceptions
2025-10-19 08:30:59,320:INFO:Importing libraries
2025-10-19 08:30:59,320:INFO:Copying training dataset
2025-10-19 08:30:59,509:INFO:Defining folds
2025-10-19 08:30:59,510:INFO:Declaring metric variables
2025-10-19 08:30:59,516:INFO:Importing untrained model
2025-10-19 08:30:59,519:INFO:Dummy Classifier Imported successfully
2025-10-19 08:30:59,526:INFO:Starting cross validation
2025-10-19 08:30:59,533:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:31:03,842:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:31:03,999:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:31:04,113:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:31:04,284:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:31:04,331:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 08:31:04,349:INFO:Calculating mean and std
2025-10-19 08:31:04,350:INFO:Creating metrics dataframe
2025-10-19 08:31:04,352:INFO:Uploading results into container
2025-10-19 08:31:04,352:INFO:Uploading model into container now
2025-10-19 08:31:04,352:INFO:_master_model_container: 15
2025-10-19 08:31:04,352:INFO:_display_container: 2
2025-10-19 08:31:04,352:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-19 08:31:04,352:INFO:create_model() successfully completed......................................
2025-10-19 08:31:04,613:INFO:SubProcess create_model() end ==================================
2025-10-19 08:31:04,613:INFO:Creating metrics dataframe
2025-10-19 08:31:04,626:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 08:31:04,639:INFO:Initializing create_model()
2025-10-19 08:31:04,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:31:04,640:INFO:Checking exceptions
2025-10-19 08:31:04,642:INFO:Importing libraries
2025-10-19 08:31:04,642:INFO:Copying training dataset
2025-10-19 08:31:04,848:INFO:Defining folds
2025-10-19 08:31:04,848:INFO:Declaring metric variables
2025-10-19 08:31:04,848:INFO:Importing untrained model
2025-10-19 08:31:04,848:INFO:Declaring custom model
2025-10-19 08:31:04,848:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 08:31:04,852:INFO:Cross validation set to False
2025-10-19 08:31:04,852:INFO:Fitting Model
2025-10-19 08:31:17,395:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 08:31:17,395:INFO:create_model() successfully completed......................................
2025-10-19 08:31:17,654:INFO:Initializing create_model()
2025-10-19 08:31:17,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:31:17,654:INFO:Checking exceptions
2025-10-19 08:31:17,657:INFO:Importing libraries
2025-10-19 08:31:17,657:INFO:Copying training dataset
2025-10-19 08:31:17,836:INFO:Defining folds
2025-10-19 08:31:17,837:INFO:Declaring metric variables
2025-10-19 08:31:17,837:INFO:Importing untrained model
2025-10-19 08:31:17,837:INFO:Declaring custom model
2025-10-19 08:31:17,838:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 08:31:17,840:INFO:Cross validation set to False
2025-10-19 08:31:17,840:INFO:Fitting Model
2025-10-19 08:31:20,422:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 08:31:20,424:INFO:[LightGBM] [Info] Number of positive: 9194, number of negative: 35574
2025-10-19 08:31:20,434:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003206 seconds.
2025-10-19 08:31:20,435:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 08:31:20,435:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 08:31:20,435:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 08:31:20,435:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 08:31:20,436:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205370 -> initscore=-1.353064
2025-10-19 08:31:20,436:INFO:[LightGBM] [Info] Start training from score -1.353064
2025-10-19 08:31:20,643:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 08:31:20,643:INFO:create_model() successfully completed......................................
2025-10-19 08:31:20,925:INFO:Initializing create_model()
2025-10-19 08:31:20,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:31:20,925:INFO:Checking exceptions
2025-10-19 08:31:20,928:INFO:Importing libraries
2025-10-19 08:31:20,928:INFO:Copying training dataset
2025-10-19 08:31:21,106:INFO:Defining folds
2025-10-19 08:31:21,106:INFO:Declaring metric variables
2025-10-19 08:31:21,106:INFO:Importing untrained model
2025-10-19 08:31:21,106:INFO:Declaring custom model
2025-10-19 08:31:21,107:INFO:Ridge Classifier Imported successfully
2025-10-19 08:31:21,109:INFO:Cross validation set to False
2025-10-19 08:31:21,109:INFO:Fitting Model
2025-10-19 08:31:23,587:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 08:31:23,587:INFO:create_model() successfully completed......................................
2025-10-19 08:31:23,849:INFO:Initializing create_model()
2025-10-19 08:31:23,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:31:23,850:INFO:Checking exceptions
2025-10-19 08:31:23,852:INFO:Importing libraries
2025-10-19 08:31:23,853:INFO:Copying training dataset
2025-10-19 08:31:24,025:INFO:Defining folds
2025-10-19 08:31:24,025:INFO:Declaring metric variables
2025-10-19 08:31:24,025:INFO:Importing untrained model
2025-10-19 08:31:24,025:INFO:Declaring custom model
2025-10-19 08:31:24,027:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 08:31:24,031:INFO:Cross validation set to False
2025-10-19 08:31:24,031:INFO:Fitting Model
2025-10-19 08:31:27,117:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 08:31:27,117:INFO:create_model() successfully completed......................................
2025-10-19 08:31:27,423:INFO:Initializing create_model()
2025-10-19 08:31:27,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:31:27,423:INFO:Checking exceptions
2025-10-19 08:31:27,426:INFO:Importing libraries
2025-10-19 08:31:27,426:INFO:Copying training dataset
2025-10-19 08:31:27,609:INFO:Defining folds
2025-10-19 08:31:27,610:INFO:Declaring metric variables
2025-10-19 08:31:27,610:INFO:Importing untrained model
2025-10-19 08:31:27,610:INFO:Declaring custom model
2025-10-19 08:31:27,610:INFO:Ada Boost Classifier Imported successfully
2025-10-19 08:31:27,613:INFO:Cross validation set to False
2025-10-19 08:31:27,613:INFO:Fitting Model
2025-10-19 08:31:30,002:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 08:31:33,339:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 08:31:33,340:INFO:create_model() successfully completed......................................
2025-10-19 08:31:33,652:INFO:_master_model_container: 15
2025-10-19 08:31:33,652:INFO:_display_container: 2
2025-10-19 08:31:33,656:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)]
2025-10-19 08:31:33,656:INFO:compare_models() successfully completed......................................
2025-10-19 08:31:33,658:INFO:Initializing tune_model()
2025-10-19 08:31:33,658:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 08:31:33,658:INFO:Checking exceptions
2025-10-19 08:31:33,776:INFO:Copying training dataset
2025-10-19 08:31:33,956:INFO:Checking base model
2025-10-19 08:31:33,956:INFO:Base model : Gradient Boosting Classifier
2025-10-19 08:31:33,960:INFO:Declaring metric variables
2025-10-19 08:31:33,964:INFO:Defining Hyperparameters
2025-10-19 08:31:34,325:INFO:Tuning with n_jobs=-1
2025-10-19 08:31:34,326:INFO:Initializing RandomizedSearchCV
2025-10-19 08:32:48,424:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.4}
2025-10-19 08:32:48,424:INFO:Hyperparameter search completed
2025-10-19 08:32:48,424:INFO:SubProcess create_model() called ==================================
2025-10-19 08:32:48,426:INFO:Initializing create_model()
2025-10-19 08:32:48,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212219DF690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 130, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 1, 'learning_rate': 0.4})
2025-10-19 08:32:48,426:INFO:Checking exceptions
2025-10-19 08:32:48,426:INFO:Importing libraries
2025-10-19 08:32:48,426:INFO:Copying training dataset
2025-10-19 08:32:48,612:INFO:Defining folds
2025-10-19 08:32:48,612:INFO:Declaring metric variables
2025-10-19 08:32:48,616:INFO:Importing untrained model
2025-10-19 08:32:48,616:INFO:Declaring custom model
2025-10-19 08:32:48,623:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 08:32:48,629:INFO:Starting cross validation
2025-10-19 08:32:48,633:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:32:57,166:INFO:Calculating mean and std
2025-10-19 08:32:57,167:INFO:Creating metrics dataframe
2025-10-19 08:32:57,174:INFO:Finalizing model
2025-10-19 08:33:03,047:INFO:Uploading results into container
2025-10-19 08:33:03,049:INFO:Uploading model into container now
2025-10-19 08:33:03,049:INFO:_master_model_container: 16
2025-10-19 08:33:03,049:INFO:_display_container: 3
2025-10-19 08:33:03,050:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 08:33:03,050:INFO:create_model() successfully completed......................................
2025-10-19 08:33:03,322:INFO:SubProcess create_model() end ==================================
2025-10-19 08:33:03,322:INFO:choose_better activated
2025-10-19 08:33:03,326:INFO:SubProcess create_model() called ==================================
2025-10-19 08:33:03,327:INFO:Initializing create_model()
2025-10-19 08:33:03,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:33:03,327:INFO:Checking exceptions
2025-10-19 08:33:03,328:INFO:Importing libraries
2025-10-19 08:33:03,328:INFO:Copying training dataset
2025-10-19 08:33:03,510:INFO:Defining folds
2025-10-19 08:33:03,510:INFO:Declaring metric variables
2025-10-19 08:33:03,510:INFO:Importing untrained model
2025-10-19 08:33:03,511:INFO:Declaring custom model
2025-10-19 08:33:03,511:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 08:33:03,511:INFO:Starting cross validation
2025-10-19 08:33:03,514:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:33:19,166:INFO:Calculating mean and std
2025-10-19 08:33:19,166:INFO:Creating metrics dataframe
2025-10-19 08:33:19,168:INFO:Finalizing model
2025-10-19 08:33:31,584:INFO:Uploading results into container
2025-10-19 08:33:31,585:INFO:Uploading model into container now
2025-10-19 08:33:31,585:INFO:_master_model_container: 17
2025-10-19 08:33:31,585:INFO:_display_container: 4
2025-10-19 08:33:31,585:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 08:33:31,585:INFO:create_model() successfully completed......................................
2025-10-19 08:33:31,835:INFO:SubProcess create_model() end ==================================
2025-10-19 08:33:31,836:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9343
2025-10-19 08:33:31,836:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9338
2025-10-19 08:33:31,836:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-19 08:33:31,837:INFO:choose_better completed
2025-10-19 08:33:31,838:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 08:33:31,847:INFO:_master_model_container: 17
2025-10-19 08:33:31,847:INFO:_display_container: 3
2025-10-19 08:33:31,847:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 08:33:31,847:INFO:tune_model() successfully completed......................................
2025-10-19 08:33:32,112:INFO:Initializing tune_model()
2025-10-19 08:33:32,113:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 08:33:32,113:INFO:Checking exceptions
2025-10-19 08:33:32,214:INFO:Copying training dataset
2025-10-19 08:33:32,347:INFO:Checking base model
2025-10-19 08:33:32,348:INFO:Base model : Light Gradient Boosting Machine
2025-10-19 08:33:32,351:INFO:Declaring metric variables
2025-10-19 08:33:32,355:INFO:Defining Hyperparameters
2025-10-19 08:33:32,606:INFO:Tuning with n_jobs=-1
2025-10-19 08:33:32,606:INFO:Initializing RandomizedSearchCV
2025-10-19 08:34:43,859:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 0.3, 'actual_estimator__num_leaves': 4, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 71, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.6}
2025-10-19 08:34:43,860:INFO:Hyperparameter search completed
2025-10-19 08:34:43,861:INFO:SubProcess create_model() called ==================================
2025-10-19 08:34:43,863:INFO:Initializing create_model()
2025-10-19 08:34:43,863:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120E995AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 4, 'reg_alpha': 0.3, 'num_leaves': 4, 'n_estimators': 130, 'min_split_gain': 0.6, 'min_child_samples': 71, 'learning_rate': 0.1, 'feature_fraction': 1.0, 'bagging_freq': 5, 'bagging_fraction': 0.6})
2025-10-19 08:34:43,863:INFO:Checking exceptions
2025-10-19 08:34:43,863:INFO:Importing libraries
2025-10-19 08:34:43,864:INFO:Copying training dataset
2025-10-19 08:34:44,101:INFO:Defining folds
2025-10-19 08:34:44,101:INFO:Declaring metric variables
2025-10-19 08:34:44,106:INFO:Importing untrained model
2025-10-19 08:34:44,106:INFO:Declaring custom model
2025-10-19 08:34:44,113:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 08:34:44,120:INFO:Starting cross validation
2025-10-19 08:34:44,124:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:34:49,642:INFO:Calculating mean and std
2025-10-19 08:34:49,644:INFO:Creating metrics dataframe
2025-10-19 08:34:49,650:INFO:Finalizing model
2025-10-19 08:34:52,137:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-10-19 08:34:52,137:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-10-19 08:34:52,137:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-10-19 08:34:52,197:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 08:34:52,199:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-10-19 08:34:52,199:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-10-19 08:34:52,199:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-10-19 08:34:52,199:INFO:[LightGBM] [Info] Number of positive: 9194, number of negative: 35574
2025-10-19 08:34:52,206:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001939 seconds.
2025-10-19 08:34:52,206:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 08:34:52,206:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 08:34:52,206:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 08:34:52,206:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 08:34:52,209:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205370 -> initscore=-1.353064
2025-10-19 08:34:52,209:INFO:[LightGBM] [Info] Start training from score -1.353064
2025-10-19 08:34:52,361:INFO:Uploading results into container
2025-10-19 08:34:52,362:INFO:Uploading model into container now
2025-10-19 08:34:52,362:INFO:_master_model_container: 18
2025-10-19 08:34:52,362:INFO:_display_container: 4
2025-10-19 08:34:52,363:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 08:34:52,363:INFO:create_model() successfully completed......................................
2025-10-19 08:34:52,644:INFO:SubProcess create_model() end ==================================
2025-10-19 08:34:52,644:INFO:choose_better activated
2025-10-19 08:34:52,648:INFO:SubProcess create_model() called ==================================
2025-10-19 08:34:52,649:INFO:Initializing create_model()
2025-10-19 08:34:52,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:34:52,649:INFO:Checking exceptions
2025-10-19 08:34:52,652:INFO:Importing libraries
2025-10-19 08:34:52,652:INFO:Copying training dataset
2025-10-19 08:34:52,837:INFO:Defining folds
2025-10-19 08:34:52,837:INFO:Declaring metric variables
2025-10-19 08:34:52,837:INFO:Importing untrained model
2025-10-19 08:34:52,837:INFO:Declaring custom model
2025-10-19 08:34:52,838:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 08:34:52,838:INFO:Starting cross validation
2025-10-19 08:34:52,842:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:34:58,650:INFO:Calculating mean and std
2025-10-19 08:34:58,651:INFO:Creating metrics dataframe
2025-10-19 08:34:58,652:INFO:Finalizing model
2025-10-19 08:35:01,574:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 08:35:01,577:INFO:[LightGBM] [Info] Number of positive: 9194, number of negative: 35574
2025-10-19 08:35:01,585:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002304 seconds.
2025-10-19 08:35:01,585:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 08:35:01,585:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 08:35:01,585:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 08:35:01,585:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 08:35:01,586:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205370 -> initscore=-1.353064
2025-10-19 08:35:01,586:INFO:[LightGBM] [Info] Start training from score -1.353064
2025-10-19 08:35:01,831:INFO:Uploading results into container
2025-10-19 08:35:01,833:INFO:Uploading model into container now
2025-10-19 08:35:01,833:INFO:_master_model_container: 19
2025-10-19 08:35:01,833:INFO:_display_container: 5
2025-10-19 08:35:01,834:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 08:35:01,834:INFO:create_model() successfully completed......................................
2025-10-19 08:35:02,129:INFO:SubProcess create_model() end ==================================
2025-10-19 08:35:02,130:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9332
2025-10-19 08:35:02,131:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9337
2025-10-19 08:35:02,131:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-19 08:35:02,131:INFO:choose_better completed
2025-10-19 08:35:02,139:INFO:_master_model_container: 19
2025-10-19 08:35:02,139:INFO:_display_container: 4
2025-10-19 08:35:02,140:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 08:35:02,141:INFO:tune_model() successfully completed......................................
2025-10-19 08:35:02,393:INFO:Initializing tune_model()
2025-10-19 08:35:02,395:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 08:35:02,395:INFO:Checking exceptions
2025-10-19 08:35:02,477:INFO:Copying training dataset
2025-10-19 08:35:02,608:INFO:Checking base model
2025-10-19 08:35:02,609:INFO:Base model : Ridge Classifier
2025-10-19 08:35:02,614:INFO:Declaring metric variables
2025-10-19 08:35:02,616:INFO:Defining Hyperparameters
2025-10-19 08:35:02,883:INFO:Tuning with n_jobs=-1
2025-10-19 08:35:02,883:INFO:Initializing RandomizedSearchCV
2025-10-19 08:35:44,295:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.3}
2025-10-19 08:35:44,296:INFO:Hyperparameter search completed
2025-10-19 08:35:44,296:INFO:SubProcess create_model() called ==================================
2025-10-19 08:35:44,297:INFO:Initializing create_model()
2025-10-19 08:35:44,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120E995AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 7.3})
2025-10-19 08:35:44,297:INFO:Checking exceptions
2025-10-19 08:35:44,297:INFO:Importing libraries
2025-10-19 08:35:44,298:INFO:Copying training dataset
2025-10-19 08:35:44,488:INFO:Defining folds
2025-10-19 08:35:44,489:INFO:Declaring metric variables
2025-10-19 08:35:44,492:INFO:Importing untrained model
2025-10-19 08:35:44,493:INFO:Declaring custom model
2025-10-19 08:35:44,497:INFO:Ridge Classifier Imported successfully
2025-10-19 08:35:44,504:INFO:Starting cross validation
2025-10-19 08:35:44,508:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:35:48,958:INFO:Calculating mean and std
2025-10-19 08:35:48,959:INFO:Creating metrics dataframe
2025-10-19 08:35:48,966:INFO:Finalizing model
2025-10-19 08:35:51,391:INFO:Uploading results into container
2025-10-19 08:35:51,392:INFO:Uploading model into container now
2025-10-19 08:35:51,392:INFO:_master_model_container: 20
2025-10-19 08:35:51,393:INFO:_display_container: 5
2025-10-19 08:35:51,393:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 08:35:51,393:INFO:create_model() successfully completed......................................
2025-10-19 08:35:51,657:INFO:SubProcess create_model() end ==================================
2025-10-19 08:35:51,657:INFO:choose_better activated
2025-10-19 08:35:51,660:INFO:SubProcess create_model() called ==================================
2025-10-19 08:35:51,662:INFO:Initializing create_model()
2025-10-19 08:35:51,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:35:51,663:INFO:Checking exceptions
2025-10-19 08:35:51,665:INFO:Importing libraries
2025-10-19 08:35:51,665:INFO:Copying training dataset
2025-10-19 08:35:51,862:INFO:Defining folds
2025-10-19 08:35:51,862:INFO:Declaring metric variables
2025-10-19 08:35:51,862:INFO:Importing untrained model
2025-10-19 08:35:51,863:INFO:Declaring custom model
2025-10-19 08:35:51,863:INFO:Ridge Classifier Imported successfully
2025-10-19 08:35:51,864:INFO:Starting cross validation
2025-10-19 08:35:51,867:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:35:56,264:INFO:Calculating mean and std
2025-10-19 08:35:56,264:INFO:Creating metrics dataframe
2025-10-19 08:35:56,265:INFO:Finalizing model
2025-10-19 08:35:58,646:INFO:Uploading results into container
2025-10-19 08:35:58,647:INFO:Uploading model into container now
2025-10-19 08:35:58,648:INFO:_master_model_container: 21
2025-10-19 08:35:58,648:INFO:_display_container: 6
2025-10-19 08:35:58,648:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 08:35:58,648:INFO:create_model() successfully completed......................................
2025-10-19 08:35:58,935:INFO:SubProcess create_model() end ==================================
2025-10-19 08:35:58,935:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9331
2025-10-19 08:35:58,935:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9333
2025-10-19 08:35:58,936:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) is best model
2025-10-19 08:35:58,936:INFO:choose_better completed
2025-10-19 08:35:58,946:INFO:_master_model_container: 21
2025-10-19 08:35:58,946:INFO:_display_container: 5
2025-10-19 08:35:58,947:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 08:35:58,947:INFO:tune_model() successfully completed......................................
2025-10-19 08:35:59,221:INFO:Initializing tune_model()
2025-10-19 08:35:59,221:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 08:35:59,221:INFO:Checking exceptions
2025-10-19 08:35:59,307:INFO:Copying training dataset
2025-10-19 08:35:59,425:INFO:Checking base model
2025-10-19 08:35:59,426:INFO:Base model : Linear Discriminant Analysis
2025-10-19 08:35:59,430:INFO:Declaring metric variables
2025-10-19 08:35:59,434:INFO:Defining Hyperparameters
2025-10-19 08:35:59,676:INFO:Tuning with n_jobs=-1
2025-10-19 08:35:59,677:INFO:Initializing RandomizedSearchCV
2025-10-19 08:36:38,282:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 'auto'}
2025-10-19 08:36:38,283:INFO:Hyperparameter search completed
2025-10-19 08:36:38,283:INFO:SubProcess create_model() called ==================================
2025-10-19 08:36:38,284:INFO:Initializing create_model()
2025-10-19 08:36:38,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002120E7CD290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 'auto'})
2025-10-19 08:36:38,284:INFO:Checking exceptions
2025-10-19 08:36:38,284:INFO:Importing libraries
2025-10-19 08:36:38,285:INFO:Copying training dataset
2025-10-19 08:36:38,542:INFO:Defining folds
2025-10-19 08:36:38,543:INFO:Declaring metric variables
2025-10-19 08:36:38,546:INFO:Importing untrained model
2025-10-19 08:36:38,546:INFO:Declaring custom model
2025-10-19 08:36:38,552:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 08:36:38,557:INFO:Starting cross validation
2025-10-19 08:36:38,563:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:36:43,368:INFO:Calculating mean and std
2025-10-19 08:36:43,370:INFO:Creating metrics dataframe
2025-10-19 08:36:43,377:INFO:Finalizing model
2025-10-19 08:36:46,118:INFO:Uploading results into container
2025-10-19 08:36:46,119:INFO:Uploading model into container now
2025-10-19 08:36:46,120:INFO:_master_model_container: 22
2025-10-19 08:36:46,120:INFO:_display_container: 6
2025-10-19 08:36:46,120:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-19 08:36:46,121:INFO:create_model() successfully completed......................................
2025-10-19 08:36:46,371:INFO:SubProcess create_model() end ==================================
2025-10-19 08:36:46,371:INFO:choose_better activated
2025-10-19 08:36:46,375:INFO:SubProcess create_model() called ==================================
2025-10-19 08:36:46,376:INFO:Initializing create_model()
2025-10-19 08:36:46,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:36:46,376:INFO:Checking exceptions
2025-10-19 08:36:46,377:INFO:Importing libraries
2025-10-19 08:36:46,377:INFO:Copying training dataset
2025-10-19 08:36:46,551:INFO:Defining folds
2025-10-19 08:36:46,551:INFO:Declaring metric variables
2025-10-19 08:36:46,552:INFO:Importing untrained model
2025-10-19 08:36:46,552:INFO:Declaring custom model
2025-10-19 08:36:46,552:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 08:36:46,552:INFO:Starting cross validation
2025-10-19 08:36:46,555:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:36:52,881:INFO:Calculating mean and std
2025-10-19 08:36:52,882:INFO:Creating metrics dataframe
2025-10-19 08:36:52,883:INFO:Finalizing model
2025-10-19 08:36:55,739:INFO:Uploading results into container
2025-10-19 08:36:55,740:INFO:Uploading model into container now
2025-10-19 08:36:55,740:INFO:_master_model_container: 23
2025-10-19 08:36:55,741:INFO:_display_container: 7
2025-10-19 08:36:55,741:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 08:36:55,741:INFO:create_model() successfully completed......................................
2025-10-19 08:36:55,989:INFO:SubProcess create_model() end ==================================
2025-10-19 08:36:55,990:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.933
2025-10-19 08:36:55,990:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9332
2025-10-19 08:36:55,990:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) is best model
2025-10-19 08:36:55,990:INFO:choose_better completed
2025-10-19 08:36:55,998:INFO:_master_model_container: 23
2025-10-19 08:36:55,999:INFO:_display_container: 6
2025-10-19 08:36:55,999:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-19 08:36:56,000:INFO:tune_model() successfully completed......................................
2025-10-19 08:36:56,259:INFO:Initializing tune_model()
2025-10-19 08:36:56,259:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 08:36:56,259:INFO:Checking exceptions
2025-10-19 08:36:56,340:INFO:Copying training dataset
2025-10-19 08:36:56,533:INFO:Checking base model
2025-10-19 08:36:56,533:INFO:Base model : Ada Boost Classifier
2025-10-19 08:36:56,537:INFO:Declaring metric variables
2025-10-19 08:36:56,540:INFO:Defining Hyperparameters
2025-10-19 08:36:56,807:INFO:Tuning with n_jobs=-1
2025-10-19 08:36:56,807:INFO:Initializing RandomizedSearchCV
2025-10-19 08:38:41,295:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__algorithm': 'SAMME'}
2025-10-19 08:38:41,296:INFO:Hyperparameter search completed
2025-10-19 08:38:41,296:INFO:SubProcess create_model() called ==================================
2025-10-19 08:38:41,297:INFO:Initializing create_model()
2025-10-19 08:38:41,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212075F3E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 190, 'learning_rate': 0.3, 'algorithm': 'SAMME'})
2025-10-19 08:38:41,297:INFO:Checking exceptions
2025-10-19 08:38:41,297:INFO:Importing libraries
2025-10-19 08:38:41,297:INFO:Copying training dataset
2025-10-19 08:38:41,478:INFO:Defining folds
2025-10-19 08:38:41,479:INFO:Declaring metric variables
2025-10-19 08:38:41,483:INFO:Importing untrained model
2025-10-19 08:38:41,483:INFO:Declaring custom model
2025-10-19 08:38:41,487:INFO:Ada Boost Classifier Imported successfully
2025-10-19 08:38:41,497:INFO:Starting cross validation
2025-10-19 08:38:41,502:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:39:01,584:INFO:Calculating mean and std
2025-10-19 08:39:01,585:INFO:Creating metrics dataframe
2025-10-19 08:39:01,591:INFO:Finalizing model
2025-10-19 08:39:15,289:INFO:Uploading results into container
2025-10-19 08:39:15,290:INFO:Uploading model into container now
2025-10-19 08:39:15,291:INFO:_master_model_container: 24
2025-10-19 08:39:15,291:INFO:_display_container: 7
2025-10-19 08:39:15,292:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.3,
                   n_estimators=190, random_state=42)
2025-10-19 08:39:15,292:INFO:create_model() successfully completed......................................
2025-10-19 08:39:15,552:INFO:SubProcess create_model() end ==================================
2025-10-19 08:39:15,552:INFO:choose_better activated
2025-10-19 08:39:15,556:INFO:SubProcess create_model() called ==================================
2025-10-19 08:39:15,558:INFO:Initializing create_model()
2025-10-19 08:39:15,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:39:15,558:INFO:Checking exceptions
2025-10-19 08:39:15,559:INFO:Importing libraries
2025-10-19 08:39:15,559:INFO:Copying training dataset
2025-10-19 08:39:15,733:INFO:Defining folds
2025-10-19 08:39:15,733:INFO:Declaring metric variables
2025-10-19 08:39:15,733:INFO:Importing untrained model
2025-10-19 08:39:15,733:INFO:Declaring custom model
2025-10-19 08:39:15,733:INFO:Ada Boost Classifier Imported successfully
2025-10-19 08:39:15,734:INFO:Starting cross validation
2025-10-19 08:39:15,736:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:39:19,292:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:39:19,416:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:39:19,481:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:39:19,575:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:39:19,666:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:39:24,417:INFO:Calculating mean and std
2025-10-19 08:39:24,417:INFO:Creating metrics dataframe
2025-10-19 08:39:24,419:INFO:Finalizing model
2025-10-19 08:39:26,827:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 08:39:29,943:INFO:Uploading results into container
2025-10-19 08:39:29,944:INFO:Uploading model into container now
2025-10-19 08:39:29,944:INFO:_master_model_container: 25
2025-10-19 08:39:29,944:INFO:_display_container: 8
2025-10-19 08:39:29,944:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 08:39:29,944:INFO:create_model() successfully completed......................................
2025-10-19 08:39:30,201:INFO:SubProcess create_model() end ==================================
2025-10-19 08:39:30,201:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for AUC is 0.9325
2025-10-19 08:39:30,201:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.3,
                   n_estimators=190, random_state=42) result for AUC is 0.932
2025-10-19 08:39:30,202:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) is best model
2025-10-19 08:39:30,202:INFO:choose_better completed
2025-10-19 08:39:30,202:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 08:39:30,211:INFO:_master_model_container: 25
2025-10-19 08:39:30,211:INFO:_display_container: 7
2025-10-19 08:39:30,211:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 08:39:30,211:INFO:tune_model() successfully completed......................................
2025-10-19 08:39:30,489:INFO:Initializing blend_models()
2025-10-19 08:39:30,489:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)], fold=None, round=4, choose_better=True, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-19 08:39:30,489:INFO:Checking exceptions
2025-10-19 08:39:30,575:INFO:Importing libraries
2025-10-19 08:39:30,576:INFO:Copying training dataset
2025-10-19 08:39:30,581:INFO:Getting model names
2025-10-19 08:39:30,587:INFO:SubProcess create_model() called ==================================
2025-10-19 08:39:30,595:INFO:Initializing create_model()
2025-10-19 08:39:30,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=42))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021207615550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:39:30,596:INFO:Checking exceptions
2025-10-19 08:39:30,596:INFO:Importing libraries
2025-10-19 08:39:30,596:INFO:Copying training dataset
2025-10-19 08:39:30,788:INFO:Defining folds
2025-10-19 08:39:30,788:INFO:Declaring metric variables
2025-10-19 08:39:30,792:INFO:Importing untrained model
2025-10-19 08:39:30,792:INFO:Declaring custom model
2025-10-19 08:39:30,797:INFO:Voting Classifier Imported successfully
2025-10-19 08:39:30,802:INFO:Starting cross validation
2025-10-19 08:39:30,808:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:39:34,377:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:39:34,640:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:39:34,936:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:39:35,323:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:39:35,405:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:39:53,291:INFO:Calculating mean and std
2025-10-19 08:39:53,293:INFO:Creating metrics dataframe
2025-10-19 08:39:53,297:INFO:Finalizing model
2025-10-19 08:39:55,726:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:40:06,020:INFO:Uploading results into container
2025-10-19 08:40:06,021:INFO:Uploading model into container now
2025-10-19 08:40:06,022:INFO:_master_model_container: 26
2025-10-19 08:40:06,022:INFO:_display_container: 8
2025-10-19 08:40:06,028:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=42))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-10-19 08:40:06,028:INFO:create_model() successfully completed......................................
2025-10-19 08:40:06,284:INFO:SubProcess create_model() end ==================================
2025-10-19 08:40:06,284:INFO:choose_better activated
2025-10-19 08:40:06,292:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=42))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None) result for Accuracy is 0.9072
2025-10-19 08:40:06,292:INFO:SubProcess create_model() called ==================================
2025-10-19 08:40:06,294:INFO:Initializing create_model()
2025-10-19 08:40:06,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:40:06,295:INFO:Checking exceptions
2025-10-19 08:40:06,296:INFO:Importing libraries
2025-10-19 08:40:06,296:INFO:Copying training dataset
2025-10-19 08:40:06,466:INFO:Defining folds
2025-10-19 08:40:06,467:INFO:Declaring metric variables
2025-10-19 08:40:06,467:INFO:Importing untrained model
2025-10-19 08:40:06,467:INFO:Declaring custom model
2025-10-19 08:40:06,467:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 08:40:06,468:INFO:Starting cross validation
2025-10-19 08:40:06,471:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:40:21,304:INFO:Calculating mean and std
2025-10-19 08:40:21,305:INFO:Creating metrics dataframe
2025-10-19 08:40:21,306:INFO:Finalizing model
2025-10-19 08:40:33,244:INFO:Uploading results into container
2025-10-19 08:40:33,245:INFO:Uploading model into container now
2025-10-19 08:40:33,245:INFO:_master_model_container: 27
2025-10-19 08:40:33,246:INFO:_display_container: 9
2025-10-19 08:40:33,246:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 08:40:33,246:INFO:create_model() successfully completed......................................
2025-10-19 08:40:33,506:INFO:SubProcess create_model() end ==================================
2025-10-19 08:40:33,507:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9077
2025-10-19 08:40:33,507:INFO:SubProcess create_model() called ==================================
2025-10-19 08:40:33,508:INFO:Initializing create_model()
2025-10-19 08:40:33,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:40:33,508:INFO:Checking exceptions
2025-10-19 08:40:33,510:INFO:Importing libraries
2025-10-19 08:40:33,510:INFO:Copying training dataset
2025-10-19 08:40:33,696:INFO:Defining folds
2025-10-19 08:40:33,696:INFO:Declaring metric variables
2025-10-19 08:40:33,696:INFO:Importing untrained model
2025-10-19 08:40:33,696:INFO:Declaring custom model
2025-10-19 08:40:33,698:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 08:40:33,698:INFO:Starting cross validation
2025-10-19 08:40:33,701:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:40:38,702:INFO:Calculating mean and std
2025-10-19 08:40:38,703:INFO:Creating metrics dataframe
2025-10-19 08:40:38,705:INFO:Finalizing model
2025-10-19 08:40:41,040:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-10-19 08:40:41,040:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-10-19 08:40:41,040:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-10-19 08:40:41,093:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 08:40:41,095:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-10-19 08:40:41,096:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-10-19 08:40:41,096:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-10-19 08:40:41,096:INFO:[LightGBM] [Info] Number of positive: 9194, number of negative: 35574
2025-10-19 08:40:41,103:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.
2025-10-19 08:40:41,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-19 08:40:41,104:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 08:40:41,105:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 08:40:41,106:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205370 -> initscore=-1.353064
2025-10-19 08:40:41,106:INFO:[LightGBM] [Info] Start training from score -1.353064
2025-10-19 08:40:41,263:INFO:Uploading results into container
2025-10-19 08:40:41,263:INFO:Uploading model into container now
2025-10-19 08:40:41,264:INFO:_master_model_container: 28
2025-10-19 08:40:41,264:INFO:_display_container: 9
2025-10-19 08:40:41,264:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 08:40:41,265:INFO:create_model() successfully completed......................................
2025-10-19 08:40:41,552:INFO:SubProcess create_model() end ==================================
2025-10-19 08:40:41,553:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9072
2025-10-19 08:40:41,553:INFO:SubProcess create_model() called ==================================
2025-10-19 08:40:41,554:INFO:Initializing create_model()
2025-10-19 08:40:41,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:40:41,554:INFO:Checking exceptions
2025-10-19 08:40:41,557:INFO:Importing libraries
2025-10-19 08:40:41,557:INFO:Copying training dataset
2025-10-19 08:40:41,771:INFO:Defining folds
2025-10-19 08:40:41,771:INFO:Declaring metric variables
2025-10-19 08:40:41,771:INFO:Importing untrained model
2025-10-19 08:40:41,771:INFO:Declaring custom model
2025-10-19 08:40:41,772:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 08:40:41,772:INFO:Starting cross validation
2025-10-19 08:40:41,776:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:40:46,449:INFO:Calculating mean and std
2025-10-19 08:40:46,449:INFO:Creating metrics dataframe
2025-10-19 08:40:46,450:INFO:Finalizing model
2025-10-19 08:40:48,973:INFO:Uploading results into container
2025-10-19 08:40:48,973:INFO:Uploading model into container now
2025-10-19 08:40:48,973:INFO:_master_model_container: 29
2025-10-19 08:40:48,973:INFO:_display_container: 9
2025-10-19 08:40:48,974:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-19 08:40:48,974:INFO:create_model() successfully completed......................................
2025-10-19 08:40:49,221:INFO:SubProcess create_model() end ==================================
2025-10-19 08:40:49,222:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for Accuracy is 0.9065
2025-10-19 08:40:49,222:INFO:SubProcess create_model() called ==================================
2025-10-19 08:40:49,223:INFO:Initializing create_model()
2025-10-19 08:40:49,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:40:49,223:INFO:Checking exceptions
2025-10-19 08:40:49,224:INFO:Importing libraries
2025-10-19 08:40:49,224:INFO:Copying training dataset
2025-10-19 08:40:49,399:INFO:Defining folds
2025-10-19 08:40:49,399:INFO:Declaring metric variables
2025-10-19 08:40:49,400:INFO:Importing untrained model
2025-10-19 08:40:49,400:INFO:Declaring custom model
2025-10-19 08:40:49,400:INFO:Ada Boost Classifier Imported successfully
2025-10-19 08:40:49,400:INFO:Starting cross validation
2025-10-19 08:40:49,403:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:40:52,812:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:40:52,916:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:40:52,943:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:40:53,090:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:40:53,172:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 08:40:57,812:INFO:Calculating mean and std
2025-10-19 08:40:57,812:INFO:Creating metrics dataframe
2025-10-19 08:40:57,814:INFO:Finalizing model
2025-10-19 08:41:00,100:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 08:41:03,274:INFO:Uploading results into container
2025-10-19 08:41:03,274:INFO:Uploading model into container now
2025-10-19 08:41:03,274:INFO:_master_model_container: 30
2025-10-19 08:41:03,274:INFO:_display_container: 9
2025-10-19 08:41:03,275:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 08:41:03,275:INFO:create_model() successfully completed......................................
2025-10-19 08:41:03,514:INFO:SubProcess create_model() end ==================================
2025-10-19 08:41:03,515:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for Accuracy is 0.9052
2025-10-19 08:41:03,515:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-19 08:41:03,515:INFO:choose_better completed
2025-10-19 08:41:03,515:INFO:Original model was better than the blended model, hence it will be returned. NOTE: The display metrics are for the blended model (not the original one).
2025-10-19 08:41:03,524:INFO:_master_model_container: 30
2025-10-19 08:41:03,525:INFO:_display_container: 8
2025-10-19 08:41:03,525:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 08:41:03,526:INFO:blend_models() successfully completed......................................
2025-10-19 08:41:03,789:INFO:Initializing calibrate_model()
2025-10-19 08:41:03,789:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), method=isotonic, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2025-10-19 08:41:03,789:INFO:Checking exceptions
2025-10-19 08:41:03,858:INFO:Preloading libraries
2025-10-19 08:41:03,858:INFO:Preparing display monitor
2025-10-19 08:41:03,871:INFO:Getting model name
2025-10-19 08:41:03,871:INFO:Base model : Gradient Boosting Classifier
2025-10-19 08:41:03,880:INFO:Importing untrained CalibratedClassifierCV
2025-10-19 08:41:03,881:INFO:SubProcess create_model() called ==================================
2025-10-19 08:41:03,883:INFO:Initializing create_model()
2025-10-19 08:41:03,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002122D759550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:41:03,883:INFO:Checking exceptions
2025-10-19 08:41:03,883:INFO:Importing libraries
2025-10-19 08:41:03,883:INFO:Copying training dataset
2025-10-19 08:41:04,127:INFO:Defining folds
2025-10-19 08:41:04,127:INFO:Declaring metric variables
2025-10-19 08:41:04,131:INFO:Importing untrained model
2025-10-19 08:41:04,131:INFO:Declaring custom model
2025-10-19 08:41:04,135:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 08:41:04,141:INFO:Starting cross validation
2025-10-19 08:41:04,146:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 08:41:51,398:INFO:Calculating mean and std
2025-10-19 08:41:51,400:INFO:Creating metrics dataframe
2025-10-19 08:41:51,406:INFO:Finalizing model
2025-10-19 08:42:31,992:INFO:Uploading results into container
2025-10-19 08:42:31,993:INFO:Uploading model into container now
2025-10-19 08:42:31,993:INFO:_master_model_container: 31
2025-10-19 08:42:31,994:INFO:_display_container: 9
2025-10-19 08:42:31,995:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None)
2025-10-19 08:42:31,995:INFO:create_model() successfully completed......................................
2025-10-19 08:42:32,245:INFO:SubProcess create_model() end ==================================
2025-10-19 08:42:32,258:INFO:_master_model_container: 31
2025-10-19 08:42:32,259:INFO:_display_container: 9
2025-10-19 08:42:32,260:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None)
2025-10-19 08:42:32,260:INFO:calibrate_model() successfully completed......................................
2025-10-19 08:42:32,514:INFO:Initializing finalize_model()
2025-10-19 08:42:32,514:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-19 08:42:32,515:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None)
2025-10-19 08:42:32,654:INFO:Initializing create_model()
2025-10-19 08:42:32,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002120A90A4D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
52938    U00197
20841    U06433
39708    U10051
60356    U09962
61665    U06888
Name: id_usuario, Length: 63955, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 08:42:32,654:INFO:Checking exceptions
2025-10-19 08:42:32,655:INFO:Importing libraries
2025-10-19 08:42:32,656:INFO:Copying training dataset
2025-10-19 08:42:32,679:INFO:Defining folds
2025-10-19 08:42:32,679:INFO:Declaring metric variables
2025-10-19 08:42:32,680:INFO:Importing untrained model
2025-10-19 08:42:32,680:INFO:Declaring custom model
2025-10-19 08:42:32,680:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 08:42:32,684:INFO:Cross validation set to False
2025-10-19 08:42:32,684:INFO:Fitting Model
2025-10-19 08:43:31,825:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                             learning_rate=0.1,
                                                                             loss='log_loss',
                                                                             max_depth=3,
                                                                             max_features=None,
                                                                             max_leaf_nodes=None,
                                                                             min_impurity_decrease=0.0,
                                                                             min_samples_leaf=1,
                                                                             min_samples_split=2,
                                                                             min_weight_fraction_leaf=0.0,
                                                                             n_estimators=100,
                                                                             n_iter_no_change=None,
                                                                             random_state=42,
                                                                             subsample=1.0,
                                                                             tol=0.0001,
                                                                             validation_fraction=0.1,
                                                                             verbose=0,
                                                                             warm_start=False),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-10-19 08:43:31,825:INFO:create_model() successfully completed......................................
2025-10-19 08:43:32,084:INFO:_master_model_container: 31
2025-10-19 08:43:32,084:INFO:_display_container: 9
2025-10-19 08:43:32,103:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                             learning_rate=0.1,
                                                                             loss='log_loss',
                                                                             max_depth=3,
                                                                             max_features=None,
                                                                             max_leaf_nodes=None,
                                                                             min_impurity_decrease=0.0,
                                                                             min_samples_leaf=1,
                                                                             min_samples_split=2,
                                                                             min_weight_fraction_leaf=0.0,
                                                                             n_estimators=100,
                                                                             n_iter_no_change=None,
                                                                             random_state=42,
                                                                             subsample=1.0,
                                                                             tol=0.0001,
                                                                             validation_fraction=0.1,
                                                                             verbose=0,
                                                                             warm_start=False),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-10-19 08:43:32,103:INFO:finalize_model() successfully completed......................................
2025-10-19 08:43:32,377:INFO:Initializing save_model()
2025-10-19 08:43:32,377:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                             learning_rate=0.1,
                                                                             loss='log_loss',
                                                                             max_depth=3,
                                                                             max_features=None,
                                                                             max_leaf_nodes=None,
                                                                             min_impurity_decrease=0.0,
                                                                             min_samples_leaf=1,
                                                                             min_samples_split=2,
                                                                             min_weight_fraction_leaf=0.0,
                                                                             n_estimators=100,
                                                                             n_iter_no_change=None,
                                                                             random_state=42,
                                                                             subsample=1.0,
                                                                             tol=0.0001,
                                                                             validation_fraction=0.1,
                                                                             verbose=0,
                                                                             warm_start=False),
                                        method='isotonic', n_jobs=None))],
         verbose=False), model_name=modelo_cls_like_soft_v1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-19 08:43:32,377:INFO:Adding model into prep_pipe
2025-10-19 08:43:32,377:WARNING:Only Model saved as it was a pipeline.
2025-10-19 08:43:32,414:INFO:modelo_cls_like_soft_v1.pkl saved in current working directory
2025-10-19 08:43:32,429:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                             learning_rate=0.1,
                                                                             loss='log_loss',
                                                                             max_depth=3,
                                                                             max_features=None,
                                                                             max_leaf_nodes=None,
                                                                             min_impurity_decrease=0.0,
                                                                             min_samples_leaf=1,
                                                                             min_samples_split=2,
                                                                             min_weight_fraction_leaf=0.0,
                                                                             n_estimators=100,
                                                                             n_iter_no_change=None,
                                                                             random_state=42,
                                                                             subsample=1.0,
                                                                             tol=0.0001,
                                                                             validation_fraction=0.1,
                                                                             verbose=0,
                                                                             warm_start=False),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-10-19 08:43:32,429:INFO:save_model() successfully completed......................................
2025-10-19 08:52:19,876:INFO:Initializing load_model()
2025-10-19 08:52:19,876:INFO:load_model(model_name=modelo_cls_like_soft_v1, platform=None, authentication=None, verbose=True)
2025-10-19 11:47:29,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 11:47:29,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 11:47:29,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 11:47:29,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 11:47:42,063:INFO:PyCaret ClassificationExperiment
2025-10-19 11:47:42,063:INFO:Logging name: clf-default-name
2025-10-19 11:47:42,063:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 11:47:42,063:INFO:version 3.3.2
2025-10-19 11:47:42,063:INFO:Initializing setup()
2025-10-19 11:47:42,063:INFO:self.USI: 47b8
2025-10-19 11:47:42,063:INFO:self._variable_keys: {'_available_plots', 'y_test', 'fix_imbalance', 'n_jobs_param', 'fold_generator', 'X_train', '_ml_usecase', 'exp_id', 'is_multiclass', 'y', 'pipeline', 'memory', 'gpu_param', 'fold_groups_param', 'data', 'y_train', 'fold_shuffle_param', 'X_test', 'gpu_n_jobs_param', 'logging_param', 'html_param', 'log_plots_param', 'idx', 'target_param', 'seed', 'USI', 'exp_name_log', 'X'}
2025-10-19 11:47:42,063:INFO:Checking environment
2025-10-19 11:47:42,064:INFO:python_version: 3.11.13
2025-10-19 11:47:42,064:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 11:47:42,064:INFO:machine: AMD64
2025-10-19 11:47:42,064:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 11:47:42,071:INFO:Memory: svmem(total=16856211456, available=3066277888, percent=81.8, used=13789933568, free=3066277888)
2025-10-19 11:47:42,071:INFO:Physical Core: 4
2025-10-19 11:47:42,071:INFO:Logical Core: 8
2025-10-19 11:47:42,071:INFO:Checking libraries
2025-10-19 11:47:42,071:INFO:System:
2025-10-19 11:47:42,071:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 11:47:42,071:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 11:47:42,071:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 11:47:42,071:INFO:PyCaret required dependencies:
2025-10-19 11:47:47,677:INFO:                 pip: 25.2
2025-10-19 11:47:47,677:INFO:          setuptools: 80.9.0
2025-10-19 11:47:47,677:INFO:             pycaret: 3.3.2
2025-10-19 11:47:47,677:INFO:             IPython: 9.6.0
2025-10-19 11:47:47,677:INFO:          ipywidgets: 8.1.7
2025-10-19 11:47:47,677:INFO:                tqdm: 4.67.1
2025-10-19 11:47:47,677:INFO:               numpy: 1.26.4
2025-10-19 11:47:47,677:INFO:              pandas: 2.1.4
2025-10-19 11:47:47,677:INFO:              jinja2: 3.1.6
2025-10-19 11:47:47,677:INFO:               scipy: 1.11.4
2025-10-19 11:47:47,677:INFO:              joblib: 1.3.2
2025-10-19 11:47:47,677:INFO:             sklearn: 1.4.2
2025-10-19 11:47:47,677:INFO:                pyod: 2.0.5
2025-10-19 11:47:47,677:INFO:            imblearn: 0.14.0
2025-10-19 11:47:47,677:INFO:   category_encoders: 2.7.0
2025-10-19 11:47:47,677:INFO:            lightgbm: 4.6.0
2025-10-19 11:47:47,677:INFO:               numba: 0.61.0
2025-10-19 11:47:47,677:INFO:            requests: 2.32.5
2025-10-19 11:47:47,677:INFO:          matplotlib: 3.7.5
2025-10-19 11:47:47,677:INFO:          scikitplot: 0.3.7
2025-10-19 11:47:47,677:INFO:         yellowbrick: 1.5
2025-10-19 11:47:47,677:INFO:              plotly: 5.24.1
2025-10-19 11:47:47,677:INFO:    plotly-resampler: Not installed
2025-10-19 11:47:47,677:INFO:             kaleido: 1.1.0
2025-10-19 11:47:47,677:INFO:           schemdraw: 0.15
2025-10-19 11:47:47,677:INFO:         statsmodels: 0.14.5
2025-10-19 11:47:47,677:INFO:              sktime: 0.26.0
2025-10-19 11:47:47,677:INFO:               tbats: 1.1.3
2025-10-19 11:47:47,677:INFO:            pmdarima: 2.0.4
2025-10-19 11:47:47,677:INFO:              psutil: 7.1.0
2025-10-19 11:47:47,678:INFO:          markupsafe: 3.0.3
2025-10-19 11:47:47,678:INFO:             pickle5: Not installed
2025-10-19 11:47:47,678:INFO:         cloudpickle: 3.1.1
2025-10-19 11:47:47,678:INFO:         deprecation: 2.1.0
2025-10-19 11:47:47,678:INFO:              xxhash: 3.6.0
2025-10-19 11:47:47,678:INFO:           wurlitzer: Not installed
2025-10-19 11:47:47,678:INFO:PyCaret optional dependencies:
2025-10-19 11:48:02,644:INFO:                shap: 0.44.1
2025-10-19 11:48:02,644:INFO:           interpret: 0.7.3
2025-10-19 11:48:02,644:INFO:                umap: 0.5.7
2025-10-19 11:48:02,644:INFO:     ydata_profiling: 4.17.0
2025-10-19 11:48:02,644:INFO:  explainerdashboard: 0.5.1
2025-10-19 11:48:02,645:INFO:             autoviz: Not installed
2025-10-19 11:48:02,645:INFO:           fairlearn: 0.7.0
2025-10-19 11:48:02,645:INFO:          deepchecks: Not installed
2025-10-19 11:48:02,645:INFO:             xgboost: Not installed
2025-10-19 11:48:02,645:INFO:            catboost: 1.2.8
2025-10-19 11:48:02,645:INFO:              kmodes: 0.12.2
2025-10-19 11:48:02,645:INFO:             mlxtend: 0.23.4
2025-10-19 11:48:02,645:INFO:       statsforecast: 1.5.0
2025-10-19 11:48:02,645:INFO:        tune_sklearn: Not installed
2025-10-19 11:48:02,645:INFO:                 ray: Not installed
2025-10-19 11:48:02,645:INFO:            hyperopt: 0.2.7
2025-10-19 11:48:02,645:INFO:              optuna: 4.5.0
2025-10-19 11:48:02,645:INFO:               skopt: 0.10.2
2025-10-19 11:48:02,645:INFO:              mlflow: 3.5.0
2025-10-19 11:48:02,645:INFO:              gradio: 5.49.1
2025-10-19 11:48:02,645:INFO:             fastapi: 0.119.0
2025-10-19 11:48:02,645:INFO:             uvicorn: 0.38.0
2025-10-19 11:48:02,645:INFO:              m2cgen: 0.10.0
2025-10-19 11:48:02,645:INFO:           evidently: 0.4.40
2025-10-19 11:48:02,645:INFO:               fugue: 0.8.7
2025-10-19 11:48:02,645:INFO:           streamlit: Not installed
2025-10-19 11:48:02,645:INFO:             prophet: Not installed
2025-10-19 11:48:02,645:INFO:None
2025-10-19 11:48:02,645:INFO:Set up data.
2025-10-19 11:48:02,822:INFO:Set up folding strategy.
2025-10-19 11:48:03,022:INFO:Set up train/test split.
2025-10-19 11:48:03,223:INFO:Set up index.
2025-10-19 11:48:03,237:INFO:Assigning column types.
2025-10-19 11:48:03,443:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 11:48:03,477:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 11:48:03,490:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 11:48:03,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 11:48:03,538:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 11:48:03,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 11:48:03,991:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 11:48:04,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 11:48:04,012:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 11:48:04,012:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 11:48:04,046:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 11:48:04,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 11:48:04,067:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 11:48:04,101:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 11:48:04,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 11:48:04,122:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 11:48:04,122:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 11:48:04,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 11:48:04,178:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 11:48:04,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 11:48:04,234:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 11:48:04,236:INFO:Preparing preprocessing pipeline...
2025-10-19 11:48:04,270:INFO:Set up simple imputation.
2025-10-19 11:48:04,439:INFO:Set up encoding of ordinal features.
2025-10-19 11:48:04,595:INFO:Set up encoding of categorical features.
2025-10-19 11:48:04,601:INFO:Set up removing multicollinearity.
2025-10-19 11:48:04,638:INFO:Set up column name cleaning.
2025-10-19 11:48:04,980:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:09,060:INFO:Finished creating preprocessing pipeline.
2025-10-19 11:48:09,085:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 11:48:09,085:INFO:Creating final display dataframe.
2025-10-19 11:48:10,712:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:12,043:INFO:Setup _display_container:                     Description             Value
0                    Session id              4643
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (79775, 28)
4        Transformed data shape       (79775, 74)
5   Transformed train set shape       (55842, 74)
6    Transformed test set shape       (23933, 74)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17     Remove multicollinearity              True
18  Multicollinearity threshold              0.95
19               Fold Generator        GroupKFold
20                  Fold Number                 5
21                     CPU Jobs                 1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              47b8
2025-10-19 11:48:12,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 11:48:12,097:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 11:48:12,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 11:48:12,153:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 11:48:12,155:INFO:setup() successfully completed in 30.2s...............
2025-10-19 11:48:12,155:INFO:Initializing compare_models()
2025-10-19 11:48:12,155:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 11:48:12,155:INFO:Checking exceptions
2025-10-19 11:48:12,312:INFO:Preparing display monitor
2025-10-19 11:48:12,345:INFO:Initializing Logistic Regression
2025-10-19 11:48:12,345:INFO:Total runtime is 0.0 minutes
2025-10-19 11:48:12,350:INFO:SubProcess create_model() called ==================================
2025-10-19 11:48:12,351:INFO:Initializing create_model()
2025-10-19 11:48:12,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:48:12,352:INFO:Checking exceptions
2025-10-19 11:48:12,352:INFO:Importing libraries
2025-10-19 11:48:12,352:INFO:Copying training dataset
2025-10-19 11:48:12,647:INFO:Defining folds
2025-10-19 11:48:12,648:INFO:Declaring metric variables
2025-10-19 11:48:12,652:INFO:Importing untrained model
2025-10-19 11:48:12,655:INFO:Logistic Regression Imported successfully
2025-10-19 11:48:12,663:INFO:Starting cross validation
2025-10-19 11:48:12,669:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:48:12,795:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:21,106:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 11:48:21,116:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:21,360:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:48:21,431:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:29,286:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 11:48:29,293:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:29,519:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:48:29,593:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:37,410:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 11:48:37,419:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:37,672:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:48:37,753:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:45,831:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 11:48:45,840:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:46,065:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:48:46,145:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:54,273:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 11:48:54,286:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:54,533:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:48:54,547:INFO:Calculating mean and std
2025-10-19 11:48:54,548:INFO:Creating metrics dataframe
2025-10-19 11:48:54,550:INFO:Uploading results into container
2025-10-19 11:48:54,552:INFO:Uploading model into container now
2025-10-19 11:48:54,552:INFO:_master_model_container: 1
2025-10-19 11:48:54,552:INFO:_display_container: 2
2025-10-19 11:48:54,553:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4643, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 11:48:54,553:INFO:create_model() successfully completed......................................
2025-10-19 11:48:54,721:INFO:SubProcess create_model() end ==================================
2025-10-19 11:48:54,722:INFO:Creating metrics dataframe
2025-10-19 11:48:54,727:INFO:Initializing K Neighbors Classifier
2025-10-19 11:48:54,727:INFO:Total runtime is 0.7063509782155355 minutes
2025-10-19 11:48:54,729:INFO:SubProcess create_model() called ==================================
2025-10-19 11:48:54,731:INFO:Initializing create_model()
2025-10-19 11:48:54,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:48:54,731:INFO:Checking exceptions
2025-10-19 11:48:54,731:INFO:Importing libraries
2025-10-19 11:48:54,731:INFO:Copying training dataset
2025-10-19 11:48:54,979:INFO:Defining folds
2025-10-19 11:48:54,980:INFO:Declaring metric variables
2025-10-19 11:48:54,989:INFO:Importing untrained model
2025-10-19 11:48:55,017:INFO:K Neighbors Classifier Imported successfully
2025-10-19 11:48:55,027:INFO:Starting cross validation
2025-10-19 11:48:55,033:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:48:55,145:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:56,995:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:48:59,642:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:01,555:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:04,054:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:05,992:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:08,506:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:10,365:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:12,858:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:14,774:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:17,239:INFO:Calculating mean and std
2025-10-19 11:49:17,241:INFO:Creating metrics dataframe
2025-10-19 11:49:17,243:INFO:Uploading results into container
2025-10-19 11:49:17,243:INFO:Uploading model into container now
2025-10-19 11:49:17,244:INFO:_master_model_container: 2
2025-10-19 11:49:17,244:INFO:_display_container: 2
2025-10-19 11:49:17,244:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 11:49:17,244:INFO:create_model() successfully completed......................................
2025-10-19 11:49:17,412:INFO:SubProcess create_model() end ==================================
2025-10-19 11:49:17,413:INFO:Creating metrics dataframe
2025-10-19 11:49:17,422:INFO:Initializing Naive Bayes
2025-10-19 11:49:17,422:INFO:Total runtime is 1.084608260790507 minutes
2025-10-19 11:49:17,426:INFO:SubProcess create_model() called ==================================
2025-10-19 11:49:17,427:INFO:Initializing create_model()
2025-10-19 11:49:17,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:49:17,428:INFO:Checking exceptions
2025-10-19 11:49:17,428:INFO:Importing libraries
2025-10-19 11:49:17,428:INFO:Copying training dataset
2025-10-19 11:49:17,690:INFO:Defining folds
2025-10-19 11:49:17,690:INFO:Declaring metric variables
2025-10-19 11:49:17,693:INFO:Importing untrained model
2025-10-19 11:49:17,696:INFO:Naive Bayes Imported successfully
2025-10-19 11:49:17,707:INFO:Starting cross validation
2025-10-19 11:49:17,711:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:49:17,831:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:19,706:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:20,063:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:21,934:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:22,294:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:24,177:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:24,517:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:26,389:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:26,770:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:28,615:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:28,932:INFO:Calculating mean and std
2025-10-19 11:49:28,934:INFO:Creating metrics dataframe
2025-10-19 11:49:28,937:INFO:Uploading results into container
2025-10-19 11:49:28,938:INFO:Uploading model into container now
2025-10-19 11:49:28,938:INFO:_master_model_container: 3
2025-10-19 11:49:28,938:INFO:_display_container: 2
2025-10-19 11:49:28,939:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 11:49:28,939:INFO:create_model() successfully completed......................................
2025-10-19 11:49:29,120:INFO:SubProcess create_model() end ==================================
2025-10-19 11:49:29,121:INFO:Creating metrics dataframe
2025-10-19 11:49:29,127:INFO:Initializing Decision Tree Classifier
2025-10-19 11:49:29,127:INFO:Total runtime is 1.2796984752019247 minutes
2025-10-19 11:49:29,130:INFO:SubProcess create_model() called ==================================
2025-10-19 11:49:29,131:INFO:Initializing create_model()
2025-10-19 11:49:29,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:49:29,131:INFO:Checking exceptions
2025-10-19 11:49:29,132:INFO:Importing libraries
2025-10-19 11:49:29,132:INFO:Copying training dataset
2025-10-19 11:49:29,397:INFO:Defining folds
2025-10-19 11:49:29,398:INFO:Declaring metric variables
2025-10-19 11:49:29,401:INFO:Importing untrained model
2025-10-19 11:49:29,407:INFO:Decision Tree Classifier Imported successfully
2025-10-19 11:49:29,413:INFO:Starting cross validation
2025-10-19 11:49:29,417:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:49:29,529:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:31,617:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:31,898:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:33,970:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:34,302:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:36,397:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:36,706:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:38,917:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:39,222:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:41,456:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:41,693:INFO:Calculating mean and std
2025-10-19 11:49:41,694:INFO:Creating metrics dataframe
2025-10-19 11:49:41,695:INFO:Uploading results into container
2025-10-19 11:49:41,696:INFO:Uploading model into container now
2025-10-19 11:49:41,696:INFO:_master_model_container: 4
2025-10-19 11:49:41,696:INFO:_display_container: 2
2025-10-19 11:49:41,696:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4643, splitter='best')
2025-10-19 11:49:41,697:INFO:create_model() successfully completed......................................
2025-10-19 11:49:41,869:INFO:SubProcess create_model() end ==================================
2025-10-19 11:49:41,869:INFO:Creating metrics dataframe
2025-10-19 11:49:41,875:INFO:Initializing SVM - Linear Kernel
2025-10-19 11:49:41,875:INFO:Total runtime is 1.4921644409497579 minutes
2025-10-19 11:49:41,878:INFO:SubProcess create_model() called ==================================
2025-10-19 11:49:41,879:INFO:Initializing create_model()
2025-10-19 11:49:41,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:49:41,879:INFO:Checking exceptions
2025-10-19 11:49:41,879:INFO:Importing libraries
2025-10-19 11:49:41,879:INFO:Copying training dataset
2025-10-19 11:49:42,121:INFO:Defining folds
2025-10-19 11:49:42,121:INFO:Declaring metric variables
2025-10-19 11:49:42,125:INFO:Importing untrained model
2025-10-19 11:49:42,130:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 11:49:42,138:INFO:Starting cross validation
2025-10-19 11:49:42,145:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:49:42,275:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:46,442:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:46,692:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:49:46,765:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:50,763:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:51,068:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:54,622:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:54,877:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:49:54,955:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:58,454:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:49:58,672:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:49:58,738:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:03,586:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:03,843:INFO:Calculating mean and std
2025-10-19 11:50:03,844:INFO:Creating metrics dataframe
2025-10-19 11:50:03,844:INFO:Uploading results into container
2025-10-19 11:50:03,846:INFO:Uploading model into container now
2025-10-19 11:50:03,846:INFO:_master_model_container: 5
2025-10-19 11:50:03,846:INFO:_display_container: 2
2025-10-19 11:50:03,846:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=4643, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 11:50:03,846:INFO:create_model() successfully completed......................................
2025-10-19 11:50:04,010:INFO:SubProcess create_model() end ==================================
2025-10-19 11:50:04,010:INFO:Creating metrics dataframe
2025-10-19 11:50:04,017:INFO:Initializing Ridge Classifier
2025-10-19 11:50:04,018:INFO:Total runtime is 1.861208172639211 minutes
2025-10-19 11:50:04,023:INFO:SubProcess create_model() called ==================================
2025-10-19 11:50:04,023:INFO:Initializing create_model()
2025-10-19 11:50:04,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:50:04,024:INFO:Checking exceptions
2025-10-19 11:50:04,024:INFO:Importing libraries
2025-10-19 11:50:04,024:INFO:Copying training dataset
2025-10-19 11:50:04,258:INFO:Defining folds
2025-10-19 11:50:04,258:INFO:Declaring metric variables
2025-10-19 11:50:04,263:INFO:Importing untrained model
2025-10-19 11:50:04,267:INFO:Ridge Classifier Imported successfully
2025-10-19 11:50:04,275:INFO:Starting cross validation
2025-10-19 11:50:04,279:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:50:04,405:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:06,282:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:06,527:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:50:06,629:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:08,517:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:08,732:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:50:08,810:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:10,697:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:10,924:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:50:11,013:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:12,853:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:13,062:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:50:13,135:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:15,032:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:15,240:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:50:15,251:INFO:Calculating mean and std
2025-10-19 11:50:15,252:INFO:Creating metrics dataframe
2025-10-19 11:50:15,254:INFO:Uploading results into container
2025-10-19 11:50:15,254:INFO:Uploading model into container now
2025-10-19 11:50:15,255:INFO:_master_model_container: 6
2025-10-19 11:50:15,255:INFO:_display_container: 2
2025-10-19 11:50:15,255:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4643, solver='auto',
                tol=0.0001)
2025-10-19 11:50:15,255:INFO:create_model() successfully completed......................................
2025-10-19 11:50:15,412:INFO:SubProcess create_model() end ==================================
2025-10-19 11:50:15,412:INFO:Creating metrics dataframe
2025-10-19 11:50:15,420:INFO:Initializing Random Forest Classifier
2025-10-19 11:50:15,421:INFO:Total runtime is 2.0512526591618854 minutes
2025-10-19 11:50:15,425:INFO:SubProcess create_model() called ==================================
2025-10-19 11:50:15,426:INFO:Initializing create_model()
2025-10-19 11:50:15,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:50:15,427:INFO:Checking exceptions
2025-10-19 11:50:15,427:INFO:Importing libraries
2025-10-19 11:50:15,427:INFO:Copying training dataset
2025-10-19 11:50:15,687:INFO:Defining folds
2025-10-19 11:50:15,687:INFO:Declaring metric variables
2025-10-19 11:50:15,693:INFO:Importing untrained model
2025-10-19 11:50:15,697:INFO:Random Forest Classifier Imported successfully
2025-10-19 11:50:15,704:INFO:Starting cross validation
2025-10-19 11:50:15,708:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:50:15,822:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:21,356:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:21,794:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:27,317:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:27,736:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:33,348:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:33,695:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:50:33,766:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:39,349:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:39,780:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:45,304:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:45,683:INFO:Calculating mean and std
2025-10-19 11:50:45,683:INFO:Creating metrics dataframe
2025-10-19 11:50:45,685:INFO:Uploading results into container
2025-10-19 11:50:45,685:INFO:Uploading model into container now
2025-10-19 11:50:45,686:INFO:_master_model_container: 7
2025-10-19 11:50:45,686:INFO:_display_container: 2
2025-10-19 11:50:45,686:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=4643, verbose=0,
                       warm_start=False)
2025-10-19 11:50:45,686:INFO:create_model() successfully completed......................................
2025-10-19 11:50:45,876:INFO:SubProcess create_model() end ==================================
2025-10-19 11:50:45,876:INFO:Creating metrics dataframe
2025-10-19 11:50:45,884:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 11:50:45,884:INFO:Total runtime is 2.558970204989115 minutes
2025-10-19 11:50:45,890:INFO:SubProcess create_model() called ==================================
2025-10-19 11:50:45,891:INFO:Initializing create_model()
2025-10-19 11:50:45,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:50:45,891:INFO:Checking exceptions
2025-10-19 11:50:45,892:INFO:Importing libraries
2025-10-19 11:50:45,892:INFO:Copying training dataset
2025-10-19 11:50:46,155:INFO:Defining folds
2025-10-19 11:50:46,155:INFO:Declaring metric variables
2025-10-19 11:50:46,160:INFO:Importing untrained model
2025-10-19 11:50:46,165:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 11:50:46,174:INFO:Starting cross validation
2025-10-19 11:50:46,177:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:50:46,298:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:48,464:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 11:50:48,490:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:48,864:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:51,015:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 11:50:51,048:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:51,404:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:53,552:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 11:50:53,581:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:53,941:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:56,046:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 11:50:56,072:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:56,393:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:58,467:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 11:50:58,496:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:50:58,793:INFO:Calculating mean and std
2025-10-19 11:50:58,794:INFO:Creating metrics dataframe
2025-10-19 11:50:58,796:INFO:Uploading results into container
2025-10-19 11:50:58,797:INFO:Uploading model into container now
2025-10-19 11:50:58,797:INFO:_master_model_container: 8
2025-10-19 11:50:58,797:INFO:_display_container: 2
2025-10-19 11:50:58,797:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 11:50:58,798:INFO:create_model() successfully completed......................................
2025-10-19 11:50:58,978:INFO:SubProcess create_model() end ==================================
2025-10-19 11:50:58,978:INFO:Creating metrics dataframe
2025-10-19 11:50:58,988:INFO:Initializing Ada Boost Classifier
2025-10-19 11:50:58,989:INFO:Total runtime is 2.777377641201019 minutes
2025-10-19 11:50:58,992:INFO:SubProcess create_model() called ==================================
2025-10-19 11:50:58,993:INFO:Initializing create_model()
2025-10-19 11:50:58,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:50:58,994:INFO:Checking exceptions
2025-10-19 11:50:58,994:INFO:Importing libraries
2025-10-19 11:50:58,994:INFO:Copying training dataset
2025-10-19 11:50:59,227:INFO:Defining folds
2025-10-19 11:50:59,228:INFO:Declaring metric variables
2025-10-19 11:50:59,231:INFO:Importing untrained model
2025-10-19 11:50:59,235:INFO:Ada Boost Classifier Imported successfully
2025-10-19 11:50:59,245:INFO:Starting cross validation
2025-10-19 11:50:59,249:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:50:59,357:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:01,236:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 11:51:04,391:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:04,957:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:06,941:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 11:51:10,273:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:10,852:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:12,659:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 11:51:15,879:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:16,368:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:51:16,442:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:18,336:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 11:51:21,477:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:21,997:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:23,888:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 11:51:26,986:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:27,463:INFO:Calculating mean and std
2025-10-19 11:51:27,464:INFO:Creating metrics dataframe
2025-10-19 11:51:27,465:INFO:Uploading results into container
2025-10-19 11:51:27,466:INFO:Uploading model into container now
2025-10-19 11:51:27,466:INFO:_master_model_container: 9
2025-10-19 11:51:27,466:INFO:_display_container: 2
2025-10-19 11:51:27,467:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4643)
2025-10-19 11:51:27,467:INFO:create_model() successfully completed......................................
2025-10-19 11:51:27,631:INFO:SubProcess create_model() end ==================================
2025-10-19 11:51:27,631:INFO:Creating metrics dataframe
2025-10-19 11:51:27,638:INFO:Initializing Gradient Boosting Classifier
2025-10-19 11:51:27,639:INFO:Total runtime is 3.2548948049545285 minutes
2025-10-19 11:51:27,642:INFO:SubProcess create_model() called ==================================
2025-10-19 11:51:27,644:INFO:Initializing create_model()
2025-10-19 11:51:27,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:51:27,644:INFO:Checking exceptions
2025-10-19 11:51:27,645:INFO:Importing libraries
2025-10-19 11:51:27,645:INFO:Copying training dataset
2025-10-19 11:51:27,889:INFO:Defining folds
2025-10-19 11:51:27,889:INFO:Declaring metric variables
2025-10-19 11:51:27,892:INFO:Importing untrained model
2025-10-19 11:51:27,897:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 11:51:27,905:INFO:Starting cross validation
2025-10-19 11:51:27,909:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:51:28,027:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:40,375:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:40,679:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:53,184:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:51:53,527:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:05,884:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:06,200:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:18,755:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:19,080:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:31,383:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:31,634:INFO:Calculating mean and std
2025-10-19 11:52:31,635:INFO:Creating metrics dataframe
2025-10-19 11:52:31,637:INFO:Uploading results into container
2025-10-19 11:52:31,638:INFO:Uploading model into container now
2025-10-19 11:52:31,638:INFO:_master_model_container: 10
2025-10-19 11:52:31,638:INFO:_display_container: 2
2025-10-19 11:52:31,639:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4643, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 11:52:31,639:INFO:create_model() successfully completed......................................
2025-10-19 11:52:31,798:INFO:SubProcess create_model() end ==================================
2025-10-19 11:52:31,798:INFO:Creating metrics dataframe
2025-10-19 11:52:31,805:INFO:Initializing Linear Discriminant Analysis
2025-10-19 11:52:31,805:INFO:Total runtime is 4.324324826399485 minutes
2025-10-19 11:52:31,811:INFO:SubProcess create_model() called ==================================
2025-10-19 11:52:31,811:INFO:Initializing create_model()
2025-10-19 11:52:31,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:52:31,812:INFO:Checking exceptions
2025-10-19 11:52:31,812:INFO:Importing libraries
2025-10-19 11:52:31,812:INFO:Copying training dataset
2025-10-19 11:52:32,048:INFO:Defining folds
2025-10-19 11:52:32,048:INFO:Declaring metric variables
2025-10-19 11:52:32,052:INFO:Importing untrained model
2025-10-19 11:52:32,059:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 11:52:32,065:INFO:Starting cross validation
2025-10-19 11:52:32,069:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:52:32,212:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:34,525:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:34,849:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:37,185:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:37,486:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:39,631:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:39,961:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:42,139:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:42,451:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:44,715:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:44,950:INFO:Calculating mean and std
2025-10-19 11:52:44,951:INFO:Creating metrics dataframe
2025-10-19 11:52:44,953:INFO:Uploading results into container
2025-10-19 11:52:44,953:INFO:Uploading model into container now
2025-10-19 11:52:44,953:INFO:_master_model_container: 11
2025-10-19 11:52:44,953:INFO:_display_container: 2
2025-10-19 11:52:44,955:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 11:52:44,955:INFO:create_model() successfully completed......................................
2025-10-19 11:52:45,125:INFO:SubProcess create_model() end ==================================
2025-10-19 11:52:45,125:INFO:Creating metrics dataframe
2025-10-19 11:52:45,133:INFO:Initializing Extra Trees Classifier
2025-10-19 11:52:45,133:INFO:Total runtime is 4.546465607484181 minutes
2025-10-19 11:52:45,136:INFO:SubProcess create_model() called ==================================
2025-10-19 11:52:45,139:INFO:Initializing create_model()
2025-10-19 11:52:45,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:52:45,139:INFO:Checking exceptions
2025-10-19 11:52:45,139:INFO:Importing libraries
2025-10-19 11:52:45,139:INFO:Copying training dataset
2025-10-19 11:52:45,393:INFO:Defining folds
2025-10-19 11:52:45,393:INFO:Declaring metric variables
2025-10-19 11:52:45,397:INFO:Importing untrained model
2025-10-19 11:52:45,402:INFO:Extra Trees Classifier Imported successfully
2025-10-19 11:52:45,409:INFO:Starting cross validation
2025-10-19 11:52:45,413:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:52:45,529:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:50,928:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:51,455:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:56,696:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:52:57,170:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:02,743:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:03,257:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:08,735:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:09,322:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:14,867:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:15,292:INFO:Calculating mean and std
2025-10-19 11:53:15,293:INFO:Creating metrics dataframe
2025-10-19 11:53:15,294:INFO:Uploading results into container
2025-10-19 11:53:15,294:INFO:Uploading model into container now
2025-10-19 11:53:15,295:INFO:_master_model_container: 12
2025-10-19 11:53:15,295:INFO:_display_container: 2
2025-10-19 11:53:15,295:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=4643, verbose=0,
                     warm_start=False)
2025-10-19 11:53:15,295:INFO:create_model() successfully completed......................................
2025-10-19 11:53:15,455:INFO:SubProcess create_model() end ==================================
2025-10-19 11:53:15,456:INFO:Creating metrics dataframe
2025-10-19 11:53:15,467:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 11:53:15,467:INFO:Total runtime is 5.052020776271819 minutes
2025-10-19 11:53:15,469:INFO:SubProcess create_model() called ==================================
2025-10-19 11:53:15,470:INFO:Initializing create_model()
2025-10-19 11:53:15,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:53:15,470:INFO:Checking exceptions
2025-10-19 11:53:15,471:INFO:Importing libraries
2025-10-19 11:53:15,471:INFO:Copying training dataset
2025-10-19 11:53:15,764:INFO:Defining folds
2025-10-19 11:53:15,764:INFO:Declaring metric variables
2025-10-19 11:53:15,768:INFO:Importing untrained model
2025-10-19 11:53:15,774:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 11:53:15,781:INFO:Starting cross validation
2025-10-19 11:53:15,785:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:53:15,903:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:17,882:INFO:[LightGBM] [Info] Number of positive: 903, number of negative: 43770
2025-10-19 11:53:17,909:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023131 seconds.
2025-10-19 11:53:17,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-19 11:53:17,911:INFO:[LightGBM] [Info] Total Bins 2103
2025-10-19 11:53:17,911:INFO:[LightGBM] [Info] Number of data points in the train set: 44673, number of used features: 73
2025-10-19 11:53:17,912:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020214 -> initscore=-3.880981
2025-10-19 11:53:17,912:INFO:[LightGBM] [Info] Start training from score -3.880981
2025-10-19 11:53:18,515:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:18,855:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:20,883:INFO:[LightGBM] [Info] Number of positive: 900, number of negative: 43773
2025-10-19 11:53:20,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006649 seconds.
2025-10-19 11:53:20,902:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 11:53:20,902:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 11:53:20,902:INFO:[LightGBM] [Info] Total Bins 2099
2025-10-19 11:53:20,902:INFO:[LightGBM] [Info] Number of data points in the train set: 44673, number of used features: 73
2025-10-19 11:53:20,902:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020146 -> initscore=-3.884378
2025-10-19 11:53:20,904:INFO:[LightGBM] [Info] Start training from score -3.884378
2025-10-19 11:53:21,339:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:21,752:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:23,984:INFO:[LightGBM] [Info] Number of positive: 904, number of negative: 43770
2025-10-19 11:53:24,003:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006470 seconds.
2025-10-19 11:53:24,003:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 11:53:24,003:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 11:53:24,003:INFO:[LightGBM] [Info] Total Bins 2109
2025-10-19 11:53:24,003:INFO:[LightGBM] [Info] Number of data points in the train set: 44674, number of used features: 73
2025-10-19 11:53:24,004:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020235 -> initscore=-3.879875
2025-10-19 11:53:24,004:INFO:[LightGBM] [Info] Start training from score -3.879875
2025-10-19 11:53:24,497:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:24,876:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:26,814:INFO:[LightGBM] [Info] Number of positive: 887, number of negative: 43787
2025-10-19 11:53:26,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005967 seconds.
2025-10-19 11:53:26,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 11:53:26,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 11:53:26,833:INFO:[LightGBM] [Info] Total Bins 2087
2025-10-19 11:53:26,833:INFO:[LightGBM] [Info] Number of data points in the train set: 44674, number of used features: 73
2025-10-19 11:53:26,833:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019855 -> initscore=-3.899247
2025-10-19 11:53:26,833:INFO:[LightGBM] [Info] Start training from score -3.899247
2025-10-19 11:53:27,295:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:27,688:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:29,695:INFO:[LightGBM] [Info] Number of positive: 878, number of negative: 43796
2025-10-19 11:53:29,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006164 seconds.
2025-10-19 11:53:29,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 11:53:29,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 11:53:29,714:INFO:[LightGBM] [Info] Total Bins 2085
2025-10-19 11:53:29,714:INFO:[LightGBM] [Info] Number of data points in the train set: 44674, number of used features: 73
2025-10-19 11:53:29,715:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019653 -> initscore=-3.909651
2025-10-19 11:53:29,715:INFO:[LightGBM] [Info] Start training from score -3.909651
2025-10-19 11:53:30,193:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:30,484:INFO:Calculating mean and std
2025-10-19 11:53:30,485:INFO:Creating metrics dataframe
2025-10-19 11:53:30,486:INFO:Uploading results into container
2025-10-19 11:53:30,486:INFO:Uploading model into container now
2025-10-19 11:53:30,487:INFO:_master_model_container: 13
2025-10-19 11:53:30,487:INFO:_display_container: 2
2025-10-19 11:53:30,487:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=4643, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 11:53:30,487:INFO:create_model() successfully completed......................................
2025-10-19 11:53:30,650:INFO:SubProcess create_model() end ==================================
2025-10-19 11:53:30,650:INFO:Creating metrics dataframe
2025-10-19 11:53:30,659:INFO:Initializing CatBoost Classifier
2025-10-19 11:53:30,660:INFO:Total runtime is 5.3052451491355885 minutes
2025-10-19 11:53:30,664:INFO:SubProcess create_model() called ==================================
2025-10-19 11:53:30,665:INFO:Initializing create_model()
2025-10-19 11:53:30,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:53:30,666:INFO:Checking exceptions
2025-10-19 11:53:30,666:INFO:Importing libraries
2025-10-19 11:53:30,666:INFO:Copying training dataset
2025-10-19 11:53:30,887:INFO:Defining folds
2025-10-19 11:53:30,887:INFO:Declaring metric variables
2025-10-19 11:53:30,891:INFO:Importing untrained model
2025-10-19 11:53:30,895:INFO:CatBoost Classifier Imported successfully
2025-10-19 11:53:30,902:INFO:Starting cross validation
2025-10-19 11:53:30,906:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:53:31,019:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:56,844:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:53:57,194:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:54:22,970:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:54:23,270:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:54:48,335:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:54:48,639:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:14,121:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:14,446:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:39,434:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:39,677:INFO:Calculating mean and std
2025-10-19 11:55:39,679:INFO:Creating metrics dataframe
2025-10-19 11:55:39,681:INFO:Uploading results into container
2025-10-19 11:55:39,681:INFO:Uploading model into container now
2025-10-19 11:55:39,682:INFO:_master_model_container: 14
2025-10-19 11:55:39,682:INFO:_display_container: 2
2025-10-19 11:55:39,682:INFO:<catboost.core.CatBoostClassifier object at 0x0000026468DE3650>
2025-10-19 11:55:39,683:INFO:create_model() successfully completed......................................
2025-10-19 11:55:39,838:INFO:SubProcess create_model() end ==================================
2025-10-19 11:55:39,838:INFO:Creating metrics dataframe
2025-10-19 11:55:39,847:INFO:Initializing Dummy Classifier
2025-10-19 11:55:39,847:INFO:Total runtime is 7.45835994084676 minutes
2025-10-19 11:55:39,851:INFO:SubProcess create_model() called ==================================
2025-10-19 11:55:39,852:INFO:Initializing create_model()
2025-10-19 11:55:39,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264675ED650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:55:39,852:INFO:Checking exceptions
2025-10-19 11:55:39,853:INFO:Importing libraries
2025-10-19 11:55:39,853:INFO:Copying training dataset
2025-10-19 11:55:40,091:INFO:Defining folds
2025-10-19 11:55:40,091:INFO:Declaring metric variables
2025-10-19 11:55:40,095:INFO:Importing untrained model
2025-10-19 11:55:40,100:INFO:Dummy Classifier Imported successfully
2025-10-19 11:55:40,107:INFO:Starting cross validation
2025-10-19 11:55:40,113:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 11:55:40,260:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:42,123:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:42,389:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:55:42,476:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:44,265:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:44,479:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:55:44,552:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:46,440:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:46,652:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:55:46,732:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:48,626:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:48,829:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:55:48,904:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:50,724:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:55:50,949:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 11:55:50,962:INFO:Calculating mean and std
2025-10-19 11:55:50,964:INFO:Creating metrics dataframe
2025-10-19 11:55:50,965:INFO:Uploading results into container
2025-10-19 11:55:50,967:INFO:Uploading model into container now
2025-10-19 11:55:50,967:INFO:_master_model_container: 15
2025-10-19 11:55:50,967:INFO:_display_container: 2
2025-10-19 11:55:50,967:INFO:DummyClassifier(constant=None, random_state=4643, strategy='prior')
2025-10-19 11:55:50,967:INFO:create_model() successfully completed......................................
2025-10-19 11:55:51,131:INFO:SubProcess create_model() end ==================================
2025-10-19 11:55:51,131:INFO:Creating metrics dataframe
2025-10-19 11:55:51,140:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 11:55:51,154:INFO:Initializing create_model()
2025-10-19 11:55:51,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4643, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:55:51,154:INFO:Checking exceptions
2025-10-19 11:55:51,156:INFO:Importing libraries
2025-10-19 11:55:51,156:INFO:Copying training dataset
2025-10-19 11:55:51,408:INFO:Defining folds
2025-10-19 11:55:51,409:INFO:Declaring metric variables
2025-10-19 11:55:51,409:INFO:Importing untrained model
2025-10-19 11:55:51,409:INFO:Declaring custom model
2025-10-19 11:55:51,409:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 11:55:51,412:INFO:Cross validation set to False
2025-10-19 11:55:51,413:INFO:Fitting Model
2025-10-19 11:55:51,449:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:07,121:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4643, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 11:56:07,121:INFO:create_model() successfully completed......................................
2025-10-19 11:56:07,289:INFO:Initializing create_model()
2025-10-19 11:56:07,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=4643, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:56:07,289:INFO:Checking exceptions
2025-10-19 11:56:07,292:INFO:Importing libraries
2025-10-19 11:56:07,292:INFO:Copying training dataset
2025-10-19 11:56:07,526:INFO:Defining folds
2025-10-19 11:56:07,526:INFO:Declaring metric variables
2025-10-19 11:56:07,526:INFO:Importing untrained model
2025-10-19 11:56:07,527:INFO:Declaring custom model
2025-10-19 11:56:07,528:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 11:56:07,531:INFO:Cross validation set to False
2025-10-19 11:56:07,531:INFO:Fitting Model
2025-10-19 11:56:07,568:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:10,055:INFO:[LightGBM] [Info] Number of positive: 1118, number of negative: 54724
2025-10-19 11:56:10,077:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008062 seconds.
2025-10-19 11:56:10,078:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 11:56:10,078:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 11:56:10,078:INFO:[LightGBM] [Info] Total Bins 2096
2025-10-19 11:56:10,079:INFO:[LightGBM] [Info] Number of data points in the train set: 55842, number of used features: 73
2025-10-19 11:56:10,080:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020021 -> initscore=-3.890761
2025-10-19 11:56:10,081:INFO:[LightGBM] [Info] Start training from score -3.890761
2025-10-19 11:56:10,644:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=4643, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 11:56:10,644:INFO:create_model() successfully completed......................................
2025-10-19 11:56:10,812:INFO:Initializing create_model()
2025-10-19 11:56:10,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4643), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 11:56:10,813:INFO:Checking exceptions
2025-10-19 11:56:10,814:INFO:Importing libraries
2025-10-19 11:56:10,815:INFO:Copying training dataset
2025-10-19 11:56:11,050:INFO:Defining folds
2025-10-19 11:56:11,050:INFO:Declaring metric variables
2025-10-19 11:56:11,051:INFO:Importing untrained model
2025-10-19 11:56:11,051:INFO:Declaring custom model
2025-10-19 11:56:11,051:INFO:Ada Boost Classifier Imported successfully
2025-10-19 11:56:11,053:INFO:Cross validation set to False
2025-10-19 11:56:11,053:INFO:Fitting Model
2025-10-19 11:56:11,093:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:13,398:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 11:56:17,331:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4643)
2025-10-19 11:56:17,333:INFO:create_model() successfully completed......................................
2025-10-19 11:56:17,554:INFO:_master_model_container: 15
2025-10-19 11:56:17,554:INFO:_display_container: 2
2025-10-19 11:56:17,556:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4643, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=4643, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4643)]
2025-10-19 11:56:17,556:INFO:compare_models() successfully completed......................................
2025-10-19 11:56:17,558:INFO:Initializing tune_model()
2025-10-19 11:56:17,558:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4643, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 11:56:17,558:INFO:Checking exceptions
2025-10-19 11:56:17,688:INFO:Copying training dataset
2025-10-19 11:56:17,885:INFO:Checking base model
2025-10-19 11:56:17,885:INFO:Base model : Gradient Boosting Classifier
2025-10-19 11:56:17,891:INFO:Declaring metric variables
2025-10-19 11:56:17,896:INFO:Defining Hyperparameters
2025-10-19 11:56:18,150:INFO:Tuning with n_jobs=1
2025-10-19 11:56:18,150:INFO:Initializing RandomizedSearchCV
2025-10-19 11:56:18,272:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:22,099:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:22,422:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:26,281:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:26,568:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:30,424:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:30,707:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:34,569:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:34,849:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:38,608:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:38,891:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:42,982:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:43,274:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:47,351:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:47,645:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:51,646:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:51,969:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:56,076:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:56:56,379:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:57:00,305:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:57:00,602:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:57:29,626:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:57:29,925:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:57:59,052:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:57:59,374:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:58:31,645:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:58:32,159:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:59:15,328:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:59:15,717:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:59:50,659:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:59:50,985:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:59:54,955:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:59:55,311:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:59:58,564:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 11:59:58,940:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:02,681:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:02,952:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:06,643:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:06,920:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:11,010:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:11,324:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:16,812:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:17,098:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:22,030:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:22,379:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:26,755:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:27,064:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:31,674:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:32,023:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:36,578:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:36,927:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:40,810:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:41,156:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:44,775:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:45,053:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:48,660:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:48,992:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:52,475:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:52,758:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:56,520:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:00:56,815:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:06,444:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:06,844:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:16,505:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:16,803:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:26,604:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:26,977:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:36,778:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:37,114:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:46,922:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:47,286:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:51,132:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:51,520:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:55,111:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:55,412:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:59,300:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:01:59,646:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:03,510:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:03,843:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:07,766:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:08,088:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:13,617:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:14,008:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:20,164:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:20,597:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:26,797:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:27,170:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:33,421:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:33,848:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:40,113:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:40,522:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:44,898:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:45,255:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:49,884:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:50,262:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:54,784:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:55,127:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:59,603:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:02:59,932:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:04,551:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:04,802:INFO:best_params: {'actual_estimator__subsample': 0.4, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__learning_rate': 1e-06}
2025-10-19 12:03:04,803:INFO:Hyperparameter search completed
2025-10-19 12:03:04,804:INFO:SubProcess create_model() called ==================================
2025-10-19 12:03:04,805:INFO:Initializing create_model()
2025-10-19 12:03:04,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4643, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646B22B590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.4, 'n_estimators': 100, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 4, 'learning_rate': 1e-06})
2025-10-19 12:03:04,805:INFO:Checking exceptions
2025-10-19 12:03:04,805:INFO:Importing libraries
2025-10-19 12:03:04,805:INFO:Copying training dataset
2025-10-19 12:03:05,099:INFO:Defining folds
2025-10-19 12:03:05,100:INFO:Declaring metric variables
2025-10-19 12:03:05,104:INFO:Importing untrained model
2025-10-19 12:03:05,105:INFO:Declaring custom model
2025-10-19 12:03:05,110:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 12:03:05,118:INFO:Starting cross validation
2025-10-19 12:03:05,123:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:03:05,262:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:15,322:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:15,610:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:03:15,694:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:24,996:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:25,303:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:03:25,377:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:34,175:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:34,499:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:03:34,583:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:43,582:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:43,833:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:03:43,907:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:52,925:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:03:53,179:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:03:53,191:INFO:Calculating mean and std
2025-10-19 12:03:53,192:INFO:Creating metrics dataframe
2025-10-19 12:03:53,199:INFO:Finalizing model
2025-10-19 12:03:53,247:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:04:04,142:INFO:Uploading results into container
2025-10-19 12:04:04,143:INFO:Uploading model into container now
2025-10-19 12:04:04,144:INFO:_master_model_container: 16
2025-10-19 12:04:04,145:INFO:_display_container: 3
2025-10-19 12:04:04,145:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=1e-06, loss='log_loss', max_depth=4,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.0001, min_samples_leaf=4,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4643, subsample=0.4, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 12:04:04,146:INFO:create_model() successfully completed......................................
2025-10-19 12:04:04,333:INFO:SubProcess create_model() end ==================================
2025-10-19 12:04:04,333:INFO:choose_better activated
2025-10-19 12:04:04,336:INFO:SubProcess create_model() called ==================================
2025-10-19 12:04:04,337:INFO:Initializing create_model()
2025-10-19 12:04:04,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A8AD290>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4643, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=13132    U14477
56666    U16538
60219    U15709
55379    U13029
58562    U14086
          ...  
9182     U13333
4517     U12701
57251    U13409
19129    U17856
12807    U17637
Name: id_usuario, Length: 55842, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:04:04,337:INFO:Checking exceptions
2025-10-19 12:04:04,339:INFO:Importing libraries
2025-10-19 12:04:04,339:INFO:Copying training dataset
2025-10-19 12:04:04,598:INFO:Defining folds
2025-10-19 12:04:04,598:INFO:Declaring metric variables
2025-10-19 12:04:04,598:INFO:Importing untrained model
2025-10-19 12:04:04,598:INFO:Declaring custom model
2025-10-19 12:04:04,599:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 12:04:04,599:INFO:Starting cross validation
2025-10-19 12:04:04,603:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:04:04,714:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:04:17,524:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:04:17,847:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:04:30,960:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:04:31,292:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:04:44,339:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:04:44,709:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:04:57,367:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:04:57,700:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:05:10,625:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:05:10,881:INFO:Calculating mean and std
2025-10-19 12:05:10,882:INFO:Creating metrics dataframe
2025-10-19 12:05:10,884:INFO:Finalizing model
2025-10-19 12:05:10,921:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:06:27,149:INFO:PyCaret ClassificationExperiment
2025-10-19 12:06:27,149:INFO:Logging name: clf-default-name
2025-10-19 12:06:27,150:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 12:06:27,150:INFO:version 3.3.2
2025-10-19 12:06:27,150:INFO:Initializing setup()
2025-10-19 12:06:27,150:INFO:self.USI: 91a3
2025-10-19 12:06:27,150:INFO:self._variable_keys: {'_available_plots', 'y_test', 'fix_imbalance', 'n_jobs_param', 'fold_generator', 'X_train', '_ml_usecase', 'exp_id', 'is_multiclass', 'y', 'pipeline', 'memory', 'gpu_param', 'fold_groups_param', 'data', 'y_train', 'fold_shuffle_param', 'X_test', 'gpu_n_jobs_param', 'logging_param', 'html_param', 'log_plots_param', 'idx', 'target_param', 'seed', 'USI', 'exp_name_log', 'X'}
2025-10-19 12:06:27,150:INFO:Checking environment
2025-10-19 12:06:27,150:INFO:python_version: 3.11.13
2025-10-19 12:06:27,150:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 12:06:27,150:INFO:machine: AMD64
2025-10-19 12:06:27,150:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 12:06:27,159:INFO:Memory: svmem(total=16856211456, available=2138443776, percent=87.3, used=14717767680, free=2138443776)
2025-10-19 12:06:27,159:INFO:Physical Core: 4
2025-10-19 12:06:27,159:INFO:Logical Core: 8
2025-10-19 12:06:27,160:INFO:Checking libraries
2025-10-19 12:06:27,160:INFO:System:
2025-10-19 12:06:27,160:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 12:06:27,160:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 12:06:27,160:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 12:06:27,160:INFO:PyCaret required dependencies:
2025-10-19 12:06:27,160:INFO:                 pip: 25.2
2025-10-19 12:06:27,160:INFO:          setuptools: 80.9.0
2025-10-19 12:06:27,160:INFO:             pycaret: 3.3.2
2025-10-19 12:06:27,160:INFO:             IPython: 9.6.0
2025-10-19 12:06:27,160:INFO:          ipywidgets: 8.1.7
2025-10-19 12:06:27,160:INFO:                tqdm: 4.67.1
2025-10-19 12:06:27,160:INFO:               numpy: 1.26.4
2025-10-19 12:06:27,160:INFO:              pandas: 2.1.4
2025-10-19 12:06:27,160:INFO:              jinja2: 3.1.6
2025-10-19 12:06:27,160:INFO:               scipy: 1.11.4
2025-10-19 12:06:27,160:INFO:              joblib: 1.3.2
2025-10-19 12:06:27,160:INFO:             sklearn: 1.4.2
2025-10-19 12:06:27,160:INFO:                pyod: 2.0.5
2025-10-19 12:06:27,160:INFO:            imblearn: 0.14.0
2025-10-19 12:06:27,160:INFO:   category_encoders: 2.7.0
2025-10-19 12:06:27,160:INFO:            lightgbm: 4.6.0
2025-10-19 12:06:27,160:INFO:               numba: 0.61.0
2025-10-19 12:06:27,160:INFO:            requests: 2.32.5
2025-10-19 12:06:27,160:INFO:          matplotlib: 3.7.5
2025-10-19 12:06:27,160:INFO:          scikitplot: 0.3.7
2025-10-19 12:06:27,161:INFO:         yellowbrick: 1.5
2025-10-19 12:06:27,161:INFO:              plotly: 5.24.1
2025-10-19 12:06:27,161:INFO:    plotly-resampler: Not installed
2025-10-19 12:06:27,161:INFO:             kaleido: 1.1.0
2025-10-19 12:06:27,161:INFO:           schemdraw: 0.15
2025-10-19 12:06:27,161:INFO:         statsmodels: 0.14.5
2025-10-19 12:06:27,161:INFO:              sktime: 0.26.0
2025-10-19 12:06:27,161:INFO:               tbats: 1.1.3
2025-10-19 12:06:27,161:INFO:            pmdarima: 2.0.4
2025-10-19 12:06:27,161:INFO:              psutil: 7.1.0
2025-10-19 12:06:27,161:INFO:          markupsafe: 3.0.3
2025-10-19 12:06:27,161:INFO:             pickle5: Not installed
2025-10-19 12:06:27,161:INFO:         cloudpickle: 3.1.1
2025-10-19 12:06:27,161:INFO:         deprecation: 2.1.0
2025-10-19 12:06:27,161:INFO:              xxhash: 3.6.0
2025-10-19 12:06:27,161:INFO:           wurlitzer: Not installed
2025-10-19 12:06:27,161:INFO:PyCaret optional dependencies:
2025-10-19 12:06:27,161:INFO:                shap: 0.44.1
2025-10-19 12:06:27,161:INFO:           interpret: 0.7.3
2025-10-19 12:06:27,161:INFO:                umap: 0.5.7
2025-10-19 12:06:27,161:INFO:     ydata_profiling: 4.17.0
2025-10-19 12:06:27,161:INFO:  explainerdashboard: 0.5.1
2025-10-19 12:06:27,161:INFO:             autoviz: Not installed
2025-10-19 12:06:27,161:INFO:           fairlearn: 0.7.0
2025-10-19 12:06:27,161:INFO:          deepchecks: Not installed
2025-10-19 12:06:27,162:INFO:             xgboost: Not installed
2025-10-19 12:06:27,162:INFO:            catboost: 1.2.8
2025-10-19 12:06:27,162:INFO:              kmodes: 0.12.2
2025-10-19 12:06:27,162:INFO:             mlxtend: 0.23.4
2025-10-19 12:06:27,162:INFO:       statsforecast: 1.5.0
2025-10-19 12:06:27,162:INFO:        tune_sklearn: Not installed
2025-10-19 12:06:27,162:INFO:                 ray: Not installed
2025-10-19 12:06:27,162:INFO:            hyperopt: 0.2.7
2025-10-19 12:06:27,162:INFO:              optuna: 4.5.0
2025-10-19 12:06:27,162:INFO:               skopt: 0.10.2
2025-10-19 12:06:27,162:INFO:              mlflow: 3.5.0
2025-10-19 12:06:27,162:INFO:              gradio: 5.49.1
2025-10-19 12:06:27,162:INFO:             fastapi: 0.119.0
2025-10-19 12:06:27,162:INFO:             uvicorn: 0.38.0
2025-10-19 12:06:27,162:INFO:              m2cgen: 0.10.0
2025-10-19 12:06:27,162:INFO:           evidently: 0.4.40
2025-10-19 12:06:27,162:INFO:               fugue: 0.8.7
2025-10-19 12:06:27,162:INFO:           streamlit: Not installed
2025-10-19 12:06:27,162:INFO:             prophet: Not installed
2025-10-19 12:06:27,162:INFO:None
2025-10-19 12:06:27,162:INFO:Set up data.
2025-10-19 12:06:27,365:INFO:Set up folding strategy.
2025-10-19 12:06:27,562:INFO:Set up train/test split.
2025-10-19 12:06:27,818:INFO:Set up index.
2025-10-19 12:06:27,835:INFO:Assigning column types.
2025-10-19 12:06:28,164:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 12:06:28,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 12:06:28,201:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 12:06:28,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:06:28,224:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:06:28,261:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 12:06:28,262:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 12:06:28,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:06:28,285:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:06:28,286:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 12:06:28,321:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 12:06:28,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:06:28,342:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:06:28,379:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 12:06:28,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:06:28,401:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:06:28,402:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 12:06:28,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:06:28,458:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:06:28,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:06:28,516:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:06:28,519:INFO:Preparing preprocessing pipeline...
2025-10-19 12:06:28,554:INFO:Set up simple imputation.
2025-10-19 12:06:28,723:INFO:Set up encoding of ordinal features.
2025-10-19 12:06:28,864:INFO:Set up encoding of categorical features.
2025-10-19 12:06:28,869:INFO:Set up removing multicollinearity.
2025-10-19 12:06:28,908:INFO:Set up column name cleaning.
2025-10-19 12:06:29,242:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:06:33,231:INFO:Finished creating preprocessing pipeline.
2025-10-19 12:06:33,254:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 12:06:33,254:INFO:Creating final display dataframe.
2025-10-19 12:06:35,158:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:06:36,673:INFO:Setup _display_container:                     Description             Value
0                    Session id              1861
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (79775, 28)
4        Transformed data shape       (79775, 74)
5   Transformed train set shape       (55842, 74)
6    Transformed test set shape       (23933, 74)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17     Remove multicollinearity              True
18  Multicollinearity threshold              0.95
19               Fold Generator        GroupKFold
20                  Fold Number                 5
21                     CPU Jobs                 1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              91a3
2025-10-19 12:06:36,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:06:36,730:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:06:36,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:06:36,786:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:06:36,788:INFO:setup() successfully completed in 9.67s...............
2025-10-19 12:06:36,788:INFO:Initializing compare_models()
2025-10-19 12:06:36,788:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 12:06:36,788:INFO:Checking exceptions
2025-10-19 12:06:36,944:INFO:Preparing display monitor
2025-10-19 12:06:36,968:INFO:Initializing Logistic Regression
2025-10-19 12:06:36,968:INFO:Total runtime is 0.0 minutes
2025-10-19 12:06:36,973:INFO:SubProcess create_model() called ==================================
2025-10-19 12:06:36,974:INFO:Initializing create_model()
2025-10-19 12:06:36,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:06:36,974:INFO:Checking exceptions
2025-10-19 12:06:36,974:INFO:Importing libraries
2025-10-19 12:06:36,974:INFO:Copying training dataset
2025-10-19 12:06:37,289:INFO:Defining folds
2025-10-19 12:06:37,289:INFO:Declaring metric variables
2025-10-19 12:06:37,293:INFO:Importing untrained model
2025-10-19 12:06:37,297:INFO:Logistic Regression Imported successfully
2025-10-19 12:06:37,304:INFO:Starting cross validation
2025-10-19 12:06:37,308:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:06:37,435:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:06:46,988:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 12:06:46,995:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:06:47,264:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:06:47,370:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:06:56,131:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 12:06:56,139:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:06:56,358:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:06:56,430:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:05,056:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 12:07:05,064:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:05,338:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:07:05,413:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:13,513:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 12:07:13,524:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:13,751:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:07:13,823:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:22,138:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 12:07:22,145:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:22,370:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:07:22,381:INFO:Calculating mean and std
2025-10-19 12:07:22,382:INFO:Creating metrics dataframe
2025-10-19 12:07:22,383:INFO:Uploading results into container
2025-10-19 12:07:22,384:INFO:Uploading model into container now
2025-10-19 12:07:22,385:INFO:_master_model_container: 1
2025-10-19 12:07:22,385:INFO:_display_container: 2
2025-10-19 12:07:22,386:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1861, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 12:07:22,386:INFO:create_model() successfully completed......................................
2025-10-19 12:07:22,589:INFO:SubProcess create_model() end ==================================
2025-10-19 12:07:22,589:INFO:Creating metrics dataframe
2025-10-19 12:07:22,630:INFO:Initializing K Neighbors Classifier
2025-10-19 12:07:22,630:INFO:Total runtime is 0.7610286553700765 minutes
2025-10-19 12:07:22,638:INFO:SubProcess create_model() called ==================================
2025-10-19 12:07:22,641:INFO:Initializing create_model()
2025-10-19 12:07:22,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:07:22,641:INFO:Checking exceptions
2025-10-19 12:07:22,641:INFO:Importing libraries
2025-10-19 12:07:22,641:INFO:Copying training dataset
2025-10-19 12:07:22,921:INFO:Defining folds
2025-10-19 12:07:22,922:INFO:Declaring metric variables
2025-10-19 12:07:22,927:INFO:Importing untrained model
2025-10-19 12:07:22,931:INFO:K Neighbors Classifier Imported successfully
2025-10-19 12:07:22,940:INFO:Starting cross validation
2025-10-19 12:07:22,944:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:07:23,062:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:25,003:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:27,499:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:29,388:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:31,939:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:33,822:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:36,329:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:38,312:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:40,878:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:42,770:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:45,232:INFO:Calculating mean and std
2025-10-19 12:07:45,234:INFO:Creating metrics dataframe
2025-10-19 12:07:45,236:INFO:Uploading results into container
2025-10-19 12:07:45,237:INFO:Uploading model into container now
2025-10-19 12:07:45,237:INFO:_master_model_container: 2
2025-10-19 12:07:45,237:INFO:_display_container: 2
2025-10-19 12:07:45,237:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 12:07:45,238:INFO:create_model() successfully completed......................................
2025-10-19 12:07:45,451:INFO:SubProcess create_model() end ==================================
2025-10-19 12:07:45,451:INFO:Creating metrics dataframe
2025-10-19 12:07:45,458:INFO:Initializing Naive Bayes
2025-10-19 12:07:45,458:INFO:Total runtime is 1.1414967099825541 minutes
2025-10-19 12:07:45,461:INFO:SubProcess create_model() called ==================================
2025-10-19 12:07:45,462:INFO:Initializing create_model()
2025-10-19 12:07:45,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:07:45,462:INFO:Checking exceptions
2025-10-19 12:07:45,462:INFO:Importing libraries
2025-10-19 12:07:45,463:INFO:Copying training dataset
2025-10-19 12:07:45,696:INFO:Defining folds
2025-10-19 12:07:45,696:INFO:Declaring metric variables
2025-10-19 12:07:45,700:INFO:Importing untrained model
2025-10-19 12:07:45,705:INFO:Naive Bayes Imported successfully
2025-10-19 12:07:45,715:INFO:Starting cross validation
2025-10-19 12:07:45,721:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:07:45,837:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:47,948:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:48,297:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:50,217:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:50,565:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:52,506:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:52,876:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:54,748:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:55,120:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:57,038:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:07:57,352:INFO:Calculating mean and std
2025-10-19 12:07:57,354:INFO:Creating metrics dataframe
2025-10-19 12:07:57,357:INFO:Uploading results into container
2025-10-19 12:07:57,359:INFO:Uploading model into container now
2025-10-19 12:07:57,360:INFO:_master_model_container: 3
2025-10-19 12:07:57,360:INFO:_display_container: 2
2025-10-19 12:07:57,361:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 12:07:57,361:INFO:create_model() successfully completed......................................
2025-10-19 12:07:57,562:INFO:SubProcess create_model() end ==================================
2025-10-19 12:07:57,562:INFO:Creating metrics dataframe
2025-10-19 12:07:57,569:INFO:Initializing Decision Tree Classifier
2025-10-19 12:07:57,569:INFO:Total runtime is 1.3433542132377625 minutes
2025-10-19 12:07:57,573:INFO:SubProcess create_model() called ==================================
2025-10-19 12:07:57,574:INFO:Initializing create_model()
2025-10-19 12:07:57,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:07:57,574:INFO:Checking exceptions
2025-10-19 12:07:57,575:INFO:Importing libraries
2025-10-19 12:07:57,575:INFO:Copying training dataset
2025-10-19 12:07:57,808:INFO:Defining folds
2025-10-19 12:07:57,808:INFO:Declaring metric variables
2025-10-19 12:07:57,812:INFO:Importing untrained model
2025-10-19 12:07:57,816:INFO:Decision Tree Classifier Imported successfully
2025-10-19 12:07:57,823:INFO:Starting cross validation
2025-10-19 12:07:57,828:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:07:57,939:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:00,091:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:00,381:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:02,544:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:02,830:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:04,991:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:05,325:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:07,475:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:07,798:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:09,994:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:10,223:INFO:Calculating mean and std
2025-10-19 12:08:10,224:INFO:Creating metrics dataframe
2025-10-19 12:08:10,227:INFO:Uploading results into container
2025-10-19 12:08:10,227:INFO:Uploading model into container now
2025-10-19 12:08:10,228:INFO:_master_model_container: 4
2025-10-19 12:08:10,228:INFO:_display_container: 2
2025-10-19 12:08:10,228:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1861, splitter='best')
2025-10-19 12:08:10,228:INFO:create_model() successfully completed......................................
2025-10-19 12:08:10,418:INFO:SubProcess create_model() end ==================================
2025-10-19 12:08:10,418:INFO:Creating metrics dataframe
2025-10-19 12:08:10,427:INFO:Initializing SVM - Linear Kernel
2025-10-19 12:08:10,428:INFO:Total runtime is 1.5576454639434816 minutes
2025-10-19 12:08:10,432:INFO:SubProcess create_model() called ==================================
2025-10-19 12:08:10,433:INFO:Initializing create_model()
2025-10-19 12:08:10,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:08:10,433:INFO:Checking exceptions
2025-10-19 12:08:10,433:INFO:Importing libraries
2025-10-19 12:08:10,433:INFO:Copying training dataset
2025-10-19 12:08:10,715:INFO:Defining folds
2025-10-19 12:08:10,715:INFO:Declaring metric variables
2025-10-19 12:08:10,720:INFO:Importing untrained model
2025-10-19 12:08:10,725:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 12:08:10,730:INFO:Starting cross validation
2025-10-19 12:08:10,734:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:08:10,842:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:14,695:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:14,917:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:08:15,011:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:18,959:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:19,274:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:22,982:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:23,198:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:08:23,264:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:27,025:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:27,234:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:08:27,310:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:31,447:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:31,751:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:08:31,769:INFO:Calculating mean and std
2025-10-19 12:08:31,772:INFO:Creating metrics dataframe
2025-10-19 12:08:31,776:INFO:Uploading results into container
2025-10-19 12:08:31,777:INFO:Uploading model into container now
2025-10-19 12:08:31,778:INFO:_master_model_container: 5
2025-10-19 12:08:31,778:INFO:_display_container: 2
2025-10-19 12:08:31,779:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=1861, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 12:08:31,779:INFO:create_model() successfully completed......................................
2025-10-19 12:08:32,035:INFO:SubProcess create_model() end ==================================
2025-10-19 12:08:32,035:INFO:Creating metrics dataframe
2025-10-19 12:08:32,046:INFO:Initializing Ridge Classifier
2025-10-19 12:08:32,046:INFO:Total runtime is 1.917959558963776 minutes
2025-10-19 12:08:32,050:INFO:SubProcess create_model() called ==================================
2025-10-19 12:08:32,051:INFO:Initializing create_model()
2025-10-19 12:08:32,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:08:32,051:INFO:Checking exceptions
2025-10-19 12:08:32,051:INFO:Importing libraries
2025-10-19 12:08:32,051:INFO:Copying training dataset
2025-10-19 12:08:32,398:INFO:Defining folds
2025-10-19 12:08:32,399:INFO:Declaring metric variables
2025-10-19 12:08:32,401:INFO:Importing untrained model
2025-10-19 12:08:32,408:INFO:Ridge Classifier Imported successfully
2025-10-19 12:08:32,416:INFO:Starting cross validation
2025-10-19 12:08:32,420:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:08:32,544:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:34,875:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:35,222:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:08:35,328:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:37,611:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:37,817:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:08:37,884:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:39,679:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:39,880:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:08:39,950:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:41,842:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:42,049:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:08:42,115:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:44,356:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:44,594:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:08:44,608:INFO:Calculating mean and std
2025-10-19 12:08:44,609:INFO:Creating metrics dataframe
2025-10-19 12:08:44,611:INFO:Uploading results into container
2025-10-19 12:08:44,611:INFO:Uploading model into container now
2025-10-19 12:08:44,612:INFO:_master_model_container: 6
2025-10-19 12:08:44,612:INFO:_display_container: 2
2025-10-19 12:08:44,612:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1861, solver='auto',
                tol=0.0001)
2025-10-19 12:08:44,612:INFO:create_model() successfully completed......................................
2025-10-19 12:08:44,819:INFO:SubProcess create_model() end ==================================
2025-10-19 12:08:44,819:INFO:Creating metrics dataframe
2025-10-19 12:08:44,827:INFO:Initializing Random Forest Classifier
2025-10-19 12:08:44,828:INFO:Total runtime is 2.1310063640276593 minutes
2025-10-19 12:08:44,831:INFO:SubProcess create_model() called ==================================
2025-10-19 12:08:44,833:INFO:Initializing create_model()
2025-10-19 12:08:44,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:08:44,834:INFO:Checking exceptions
2025-10-19 12:08:44,834:INFO:Importing libraries
2025-10-19 12:08:44,834:INFO:Copying training dataset
2025-10-19 12:08:45,075:INFO:Defining folds
2025-10-19 12:08:45,075:INFO:Declaring metric variables
2025-10-19 12:08:45,079:INFO:Importing untrained model
2025-10-19 12:08:45,082:INFO:Random Forest Classifier Imported successfully
2025-10-19 12:08:45,090:INFO:Starting cross validation
2025-10-19 12:08:45,094:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:08:45,206:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:50,918:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:51,346:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:57,064:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:08:57,545:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:03,153:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:03,567:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:09,078:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:09,507:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:15,149:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:15,511:INFO:Calculating mean and std
2025-10-19 12:09:15,512:INFO:Creating metrics dataframe
2025-10-19 12:09:15,514:INFO:Uploading results into container
2025-10-19 12:09:15,514:INFO:Uploading model into container now
2025-10-19 12:09:15,514:INFO:_master_model_container: 7
2025-10-19 12:09:15,514:INFO:_display_container: 2
2025-10-19 12:09:15,515:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=1861, verbose=0,
                       warm_start=False)
2025-10-19 12:09:15,515:INFO:create_model() successfully completed......................................
2025-10-19 12:09:15,703:INFO:SubProcess create_model() end ==================================
2025-10-19 12:09:15,703:INFO:Creating metrics dataframe
2025-10-19 12:09:15,710:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 12:09:15,710:INFO:Total runtime is 2.64570791721344 minutes
2025-10-19 12:09:15,713:INFO:SubProcess create_model() called ==================================
2025-10-19 12:09:15,714:INFO:Initializing create_model()
2025-10-19 12:09:15,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:09:15,715:INFO:Checking exceptions
2025-10-19 12:09:15,715:INFO:Importing libraries
2025-10-19 12:09:15,715:INFO:Copying training dataset
2025-10-19 12:09:15,986:INFO:Defining folds
2025-10-19 12:09:15,987:INFO:Declaring metric variables
2025-10-19 12:09:15,992:INFO:Importing untrained model
2025-10-19 12:09:15,996:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 12:09:16,002:INFO:Starting cross validation
2025-10-19 12:09:16,008:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:09:16,118:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:18,304:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 12:09:18,331:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:18,656:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:20,828:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 12:09:20,856:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:21,189:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:23,286:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 12:09:23,313:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:23,630:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:25,761:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 12:09:25,787:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:26,164:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:28,341:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 12:09:28,375:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:28,691:INFO:Calculating mean and std
2025-10-19 12:09:28,693:INFO:Creating metrics dataframe
2025-10-19 12:09:28,694:INFO:Uploading results into container
2025-10-19 12:09:28,695:INFO:Uploading model into container now
2025-10-19 12:09:28,695:INFO:_master_model_container: 8
2025-10-19 12:09:28,695:INFO:_display_container: 2
2025-10-19 12:09:28,695:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 12:09:28,695:INFO:create_model() successfully completed......................................
2025-10-19 12:09:28,897:INFO:SubProcess create_model() end ==================================
2025-10-19 12:09:28,897:INFO:Creating metrics dataframe
2025-10-19 12:09:28,907:INFO:Initializing Ada Boost Classifier
2025-10-19 12:09:28,908:INFO:Total runtime is 2.8656671444574995 minutes
2025-10-19 12:09:28,913:INFO:SubProcess create_model() called ==================================
2025-10-19 12:09:28,914:INFO:Initializing create_model()
2025-10-19 12:09:28,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:09:28,914:INFO:Checking exceptions
2025-10-19 12:09:28,914:INFO:Importing libraries
2025-10-19 12:09:28,915:INFO:Copying training dataset
2025-10-19 12:09:29,156:INFO:Defining folds
2025-10-19 12:09:29,156:INFO:Declaring metric variables
2025-10-19 12:09:29,159:INFO:Importing untrained model
2025-10-19 12:09:29,164:INFO:Ada Boost Classifier Imported successfully
2025-10-19 12:09:29,172:INFO:Starting cross validation
2025-10-19 12:09:29,178:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:09:29,288:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:31,104:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:09:34,636:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:35,352:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:37,462:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:09:40,644:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:41,191:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:43,232:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:09:46,981:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:47,542:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:51,322:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:09:57,865:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:09:58,789:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:10:02,377:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:10:08,191:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:10:09,082:INFO:Calculating mean and std
2025-10-19 12:10:09,085:INFO:Creating metrics dataframe
2025-10-19 12:10:09,087:INFO:Uploading results into container
2025-10-19 12:10:09,089:INFO:Uploading model into container now
2025-10-19 12:10:09,090:INFO:_master_model_container: 9
2025-10-19 12:10:09,090:INFO:_display_container: 2
2025-10-19 12:10:09,091:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861)
2025-10-19 12:10:09,091:INFO:create_model() successfully completed......................................
2025-10-19 12:10:09,467:INFO:SubProcess create_model() end ==================================
2025-10-19 12:10:09,468:INFO:Creating metrics dataframe
2025-10-19 12:10:09,499:INFO:Initializing Gradient Boosting Classifier
2025-10-19 12:10:09,499:INFO:Total runtime is 3.5421847422917687 minutes
2025-10-19 12:10:09,512:INFO:SubProcess create_model() called ==================================
2025-10-19 12:10:09,514:INFO:Initializing create_model()
2025-10-19 12:10:09,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:10:09,515:INFO:Checking exceptions
2025-10-19 12:10:09,515:INFO:Importing libraries
2025-10-19 12:10:09,516:INFO:Copying training dataset
2025-10-19 12:10:10,120:INFO:Defining folds
2025-10-19 12:10:10,121:INFO:Declaring metric variables
2025-10-19 12:10:10,136:INFO:Importing untrained model
2025-10-19 12:10:10,152:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 12:10:10,176:INFO:Starting cross validation
2025-10-19 12:10:10,190:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:10:10,399:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:10:34,310:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:10:35,097:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:10:56,191:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:10:56,622:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:11,051:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:11,391:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:25,314:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:25,749:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:39,381:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:39,671:INFO:Calculating mean and std
2025-10-19 12:11:39,673:INFO:Creating metrics dataframe
2025-10-19 12:11:39,674:INFO:Uploading results into container
2025-10-19 12:11:39,675:INFO:Uploading model into container now
2025-10-19 12:11:39,675:INFO:_master_model_container: 10
2025-10-19 12:11:39,675:INFO:_display_container: 2
2025-10-19 12:11:39,676:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1861, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 12:11:39,676:INFO:create_model() successfully completed......................................
2025-10-19 12:11:39,915:INFO:SubProcess create_model() end ==================================
2025-10-19 12:11:39,916:INFO:Creating metrics dataframe
2025-10-19 12:11:39,925:INFO:Initializing Linear Discriminant Analysis
2025-10-19 12:11:39,926:INFO:Total runtime is 5.04929991165797 minutes
2025-10-19 12:11:39,931:INFO:SubProcess create_model() called ==================================
2025-10-19 12:11:39,933:INFO:Initializing create_model()
2025-10-19 12:11:39,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:11:39,933:INFO:Checking exceptions
2025-10-19 12:11:39,933:INFO:Importing libraries
2025-10-19 12:11:39,933:INFO:Copying training dataset
2025-10-19 12:11:40,219:INFO:Defining folds
2025-10-19 12:11:40,219:INFO:Declaring metric variables
2025-10-19 12:11:40,222:INFO:Importing untrained model
2025-10-19 12:11:40,228:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 12:11:40,237:INFO:Starting cross validation
2025-10-19 12:11:40,240:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:11:40,366:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:42,838:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:43,174:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:45,560:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:45,943:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:48,510:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:48,848:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:51,251:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:51,589:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:54,033:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:11:54,297:INFO:Calculating mean and std
2025-10-19 12:11:54,298:INFO:Creating metrics dataframe
2025-10-19 12:11:54,300:INFO:Uploading results into container
2025-10-19 12:11:54,302:INFO:Uploading model into container now
2025-10-19 12:11:54,302:INFO:_master_model_container: 11
2025-10-19 12:11:54,302:INFO:_display_container: 2
2025-10-19 12:11:54,302:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 12:11:54,302:INFO:create_model() successfully completed......................................
2025-10-19 12:11:54,537:INFO:SubProcess create_model() end ==================================
2025-10-19 12:11:54,538:INFO:Creating metrics dataframe
2025-10-19 12:11:54,550:INFO:Initializing Extra Trees Classifier
2025-10-19 12:11:54,550:INFO:Total runtime is 5.2930289586385095 minutes
2025-10-19 12:11:54,553:INFO:SubProcess create_model() called ==================================
2025-10-19 12:11:54,554:INFO:Initializing create_model()
2025-10-19 12:11:54,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:11:54,555:INFO:Checking exceptions
2025-10-19 12:11:54,555:INFO:Importing libraries
2025-10-19 12:11:54,555:INFO:Copying training dataset
2025-10-19 12:11:54,843:INFO:Defining folds
2025-10-19 12:11:54,843:INFO:Declaring metric variables
2025-10-19 12:11:54,850:INFO:Importing untrained model
2025-10-19 12:11:54,855:INFO:Extra Trees Classifier Imported successfully
2025-10-19 12:11:54,864:INFO:Starting cross validation
2025-10-19 12:11:54,868:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:11:55,025:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:01,176:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:01,804:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:08,281:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:08,935:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:15,825:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:16,531:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:23,788:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:24,520:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:31,454:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:31,976:INFO:Calculating mean and std
2025-10-19 12:12:31,978:INFO:Creating metrics dataframe
2025-10-19 12:12:31,982:INFO:Uploading results into container
2025-10-19 12:12:31,984:INFO:Uploading model into container now
2025-10-19 12:12:31,985:INFO:_master_model_container: 12
2025-10-19 12:12:31,985:INFO:_display_container: 2
2025-10-19 12:12:31,985:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=1861, verbose=0,
                     warm_start=False)
2025-10-19 12:12:31,985:INFO:create_model() successfully completed......................................
2025-10-19 12:12:32,196:INFO:SubProcess create_model() end ==================================
2025-10-19 12:12:32,196:INFO:Creating metrics dataframe
2025-10-19 12:12:32,209:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 12:12:32,209:INFO:Total runtime is 5.920687635739645 minutes
2025-10-19 12:12:32,214:INFO:SubProcess create_model() called ==================================
2025-10-19 12:12:32,216:INFO:Initializing create_model()
2025-10-19 12:12:32,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:12:32,216:INFO:Checking exceptions
2025-10-19 12:12:32,217:INFO:Importing libraries
2025-10-19 12:12:32,217:INFO:Copying training dataset
2025-10-19 12:12:32,498:INFO:Defining folds
2025-10-19 12:12:32,499:INFO:Declaring metric variables
2025-10-19 12:12:32,502:INFO:Importing untrained model
2025-10-19 12:12:32,507:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 12:12:32,517:INFO:Starting cross validation
2025-10-19 12:12:32,521:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:12:32,657:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:35,152:INFO:[LightGBM] [Info] Number of positive: 904, number of negative: 43769
2025-10-19 12:12:35,170:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005866 seconds.
2025-10-19 12:12:35,171:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 12:12:35,171:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 12:12:35,171:INFO:[LightGBM] [Info] Total Bins 2110
2025-10-19 12:12:35,171:INFO:[LightGBM] [Info] Number of data points in the train set: 44673, number of used features: 73
2025-10-19 12:12:35,171:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020236 -> initscore=-3.879852
2025-10-19 12:12:35,171:INFO:[LightGBM] [Info] Start training from score -3.879852
2025-10-19 12:12:35,749:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:36,221:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:38,601:INFO:[LightGBM] [Info] Number of positive: 876, number of negative: 43797
2025-10-19 12:12:38,622:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007351 seconds.
2025-10-19 12:12:38,622:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 12:12:38,622:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 12:12:38,622:INFO:[LightGBM] [Info] Total Bins 2106
2025-10-19 12:12:38,622:INFO:[LightGBM] [Info] Number of data points in the train set: 44673, number of used features: 73
2025-10-19 12:12:38,623:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019609 -> initscore=-3.911955
2025-10-19 12:12:38,623:INFO:[LightGBM] [Info] Start training from score -3.911955
2025-10-19 12:12:39,152:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:39,577:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:41,870:INFO:[LightGBM] [Info] Number of positive: 905, number of negative: 43769
2025-10-19 12:12:41,894:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007718 seconds.
2025-10-19 12:12:41,894:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 12:12:41,894:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 12:12:41,895:INFO:[LightGBM] [Info] Total Bins 2114
2025-10-19 12:12:41,895:INFO:[LightGBM] [Info] Number of data points in the train set: 44674, number of used features: 73
2025-10-19 12:12:41,896:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020258 -> initscore=-3.878746
2025-10-19 12:12:41,896:INFO:[LightGBM] [Info] Start training from score -3.878746
2025-10-19 12:12:42,427:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:42,841:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:45,276:INFO:[LightGBM] [Info] Number of positive: 893, number of negative: 43781
2025-10-19 12:12:45,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007223 seconds.
2025-10-19 12:12:45,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 12:12:45,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 12:12:45,297:INFO:[LightGBM] [Info] Total Bins 2104
2025-10-19 12:12:45,298:INFO:[LightGBM] [Info] Number of data points in the train set: 44674, number of used features: 73
2025-10-19 12:12:45,298:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019989 -> initscore=-3.892369
2025-10-19 12:12:45,298:INFO:[LightGBM] [Info] Start training from score -3.892369
2025-10-19 12:12:45,832:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:46,285:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:48,566:INFO:[LightGBM] [Info] Number of positive: 894, number of negative: 43780
2025-10-19 12:12:48,579:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004003 seconds.
2025-10-19 12:12:48,579:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 12:12:48,579:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 12:12:48,579:INFO:[LightGBM] [Info] Total Bins 2109
2025-10-19 12:12:48,581:INFO:[LightGBM] [Info] Number of data points in the train set: 44674, number of used features: 73
2025-10-19 12:12:48,581:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020012 -> initscore=-3.891227
2025-10-19 12:12:48,582:INFO:[LightGBM] [Info] Start training from score -3.891227
2025-10-19 12:12:49,355:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:12:50,075:INFO:Calculating mean and std
2025-10-19 12:12:50,077:INFO:Creating metrics dataframe
2025-10-19 12:12:50,081:INFO:Uploading results into container
2025-10-19 12:12:50,082:INFO:Uploading model into container now
2025-10-19 12:12:50,082:INFO:_master_model_container: 13
2025-10-19 12:12:50,082:INFO:_display_container: 2
2025-10-19 12:12:50,083:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=1861, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 12:12:50,083:INFO:create_model() successfully completed......................................
2025-10-19 12:12:50,394:INFO:SubProcess create_model() end ==================================
2025-10-19 12:12:50,394:INFO:Creating metrics dataframe
2025-10-19 12:12:50,412:INFO:Initializing CatBoost Classifier
2025-10-19 12:12:50,412:INFO:Total runtime is 6.224061354001364 minutes
2025-10-19 12:12:50,422:INFO:SubProcess create_model() called ==================================
2025-10-19 12:12:50,424:INFO:Initializing create_model()
2025-10-19 12:12:50,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:12:50,424:INFO:Checking exceptions
2025-10-19 12:12:50,424:INFO:Importing libraries
2025-10-19 12:12:50,424:INFO:Copying training dataset
2025-10-19 12:12:50,901:INFO:Defining folds
2025-10-19 12:12:50,901:INFO:Declaring metric variables
2025-10-19 12:12:50,907:INFO:Importing untrained model
2025-10-19 12:12:50,915:INFO:CatBoost Classifier Imported successfully
2025-10-19 12:12:50,931:INFO:Starting cross validation
2025-10-19 12:12:50,936:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:12:51,129:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:13:40,908:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:13:41,497:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:14:30,269:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:14:30,924:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:15:19,832:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:15:20,359:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:16:07,699:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:16:08,441:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:16:52,982:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:16:53,403:INFO:Calculating mean and std
2025-10-19 12:16:53,407:INFO:Creating metrics dataframe
2025-10-19 12:16:53,412:INFO:Uploading results into container
2025-10-19 12:16:53,413:INFO:Uploading model into container now
2025-10-19 12:16:53,413:INFO:_master_model_container: 14
2025-10-19 12:16:53,413:INFO:_display_container: 2
2025-10-19 12:16:53,414:INFO:<catboost.core.CatBoostClassifier object at 0x0000026469EDCFD0>
2025-10-19 12:16:53,414:INFO:create_model() successfully completed......................................
2025-10-19 12:16:53,786:INFO:SubProcess create_model() end ==================================
2025-10-19 12:16:53,786:INFO:Creating metrics dataframe
2025-10-19 12:16:53,820:INFO:Initializing Dummy Classifier
2025-10-19 12:16:53,820:INFO:Total runtime is 10.280873970190685 minutes
2025-10-19 12:16:53,829:INFO:SubProcess create_model() called ==================================
2025-10-19 12:16:53,831:INFO:Initializing create_model()
2025-10-19 12:16:53,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646D909F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:16:53,832:INFO:Checking exceptions
2025-10-19 12:16:53,832:INFO:Importing libraries
2025-10-19 12:16:53,832:INFO:Copying training dataset
2025-10-19 12:16:54,246:INFO:Defining folds
2025-10-19 12:16:54,246:INFO:Declaring metric variables
2025-10-19 12:16:54,254:INFO:Importing untrained model
2025-10-19 12:16:54,264:INFO:Dummy Classifier Imported successfully
2025-10-19 12:16:54,282:INFO:Starting cross validation
2025-10-19 12:16:54,292:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:16:54,470:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:16:57,595:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:16:57,862:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:16:57,943:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:16:59,985:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:00,263:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:17:00,359:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:02,516:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:02,736:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:17:02,812:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:04,829:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:05,072:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:17:05,151:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:07,234:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:07,549:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:17:07,574:INFO:Calculating mean and std
2025-10-19 12:17:07,576:INFO:Creating metrics dataframe
2025-10-19 12:17:07,579:INFO:Uploading results into container
2025-10-19 12:17:07,580:INFO:Uploading model into container now
2025-10-19 12:17:07,581:INFO:_master_model_container: 15
2025-10-19 12:17:07,582:INFO:_display_container: 2
2025-10-19 12:17:07,582:INFO:DummyClassifier(constant=None, random_state=1861, strategy='prior')
2025-10-19 12:17:07,582:INFO:create_model() successfully completed......................................
2025-10-19 12:17:07,815:INFO:SubProcess create_model() end ==================================
2025-10-19 12:17:07,816:INFO:Creating metrics dataframe
2025-10-19 12:17:07,827:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 12:17:07,874:INFO:Initializing create_model()
2025-10-19 12:17:07,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:17:07,874:INFO:Checking exceptions
2025-10-19 12:17:07,877:INFO:Importing libraries
2025-10-19 12:17:07,877:INFO:Copying training dataset
2025-10-19 12:17:08,164:INFO:Defining folds
2025-10-19 12:17:08,164:INFO:Declaring metric variables
2025-10-19 12:17:08,165:INFO:Importing untrained model
2025-10-19 12:17:08,165:INFO:Declaring custom model
2025-10-19 12:17:08,165:INFO:Ada Boost Classifier Imported successfully
2025-10-19 12:17:08,167:INFO:Cross validation set to False
2025-10-19 12:17:08,168:INFO:Fitting Model
2025-10-19 12:17:08,214:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:10,599:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:17:15,193:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861)
2025-10-19 12:17:15,193:INFO:create_model() successfully completed......................................
2025-10-19 12:17:15,436:INFO:Initializing create_model()
2025-10-19 12:17:15,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1861, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:17:15,436:INFO:Checking exceptions
2025-10-19 12:17:15,438:INFO:Importing libraries
2025-10-19 12:17:15,439:INFO:Copying training dataset
2025-10-19 12:17:15,717:INFO:Defining folds
2025-10-19 12:17:15,717:INFO:Declaring metric variables
2025-10-19 12:17:15,718:INFO:Importing untrained model
2025-10-19 12:17:15,718:INFO:Declaring custom model
2025-10-19 12:17:15,718:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 12:17:15,720:INFO:Cross validation set to False
2025-10-19 12:17:15,721:INFO:Fitting Model
2025-10-19 12:17:15,766:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:33,708:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1861, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 12:17:33,709:INFO:create_model() successfully completed......................................
2025-10-19 12:17:33,944:INFO:Initializing create_model()
2025-10-19 12:17:33,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=1861, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:17:33,945:INFO:Checking exceptions
2025-10-19 12:17:33,948:INFO:Importing libraries
2025-10-19 12:17:33,949:INFO:Copying training dataset
2025-10-19 12:17:34,266:INFO:Defining folds
2025-10-19 12:17:34,266:INFO:Declaring metric variables
2025-10-19 12:17:34,267:INFO:Importing untrained model
2025-10-19 12:17:34,269:INFO:Declaring custom model
2025-10-19 12:17:34,271:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 12:17:34,278:INFO:Cross validation set to False
2025-10-19 12:17:34,278:INFO:Fitting Model
2025-10-19 12:17:34,356:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:37,230:INFO:[LightGBM] [Info] Number of positive: 1118, number of negative: 54724
2025-10-19 12:17:37,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008075 seconds.
2025-10-19 12:17:37,253:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 12:17:37,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 12:17:37,254:INFO:[LightGBM] [Info] Total Bins 2099
2025-10-19 12:17:37,254:INFO:[LightGBM] [Info] Number of data points in the train set: 55842, number of used features: 73
2025-10-19 12:17:37,254:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020021 -> initscore=-3.890761
2025-10-19 12:17:37,254:INFO:[LightGBM] [Info] Start training from score -3.890761
2025-10-19 12:17:37,830:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=1861, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 12:17:37,830:INFO:create_model() successfully completed......................................
2025-10-19 12:17:38,064:INFO:_master_model_container: 15
2025-10-19 12:17:38,065:INFO:_display_container: 2
2025-10-19 12:17:38,066:INFO:[AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1861, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=1861, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2025-10-19 12:17:38,067:INFO:compare_models() successfully completed......................................
2025-10-19 12:17:38,068:INFO:Initializing tune_model()
2025-10-19 12:17:38,068:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 12:17:38,069:INFO:Checking exceptions
2025-10-19 12:17:38,197:INFO:Copying training dataset
2025-10-19 12:17:38,384:INFO:Checking base model
2025-10-19 12:17:38,384:INFO:Base model : Ada Boost Classifier
2025-10-19 12:17:38,388:INFO:Declaring metric variables
2025-10-19 12:17:38,394:INFO:Defining Hyperparameters
2025-10-19 12:17:38,619:INFO:Tuning with n_jobs=1
2025-10-19 12:17:38,620:INFO:Initializing RandomizedSearchCV
2025-10-19 12:17:38,788:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:43,654:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:44,135:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:48,813:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:49,245:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:53,721:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:54,130:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:58,706:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:17:59,148:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:18:03,762:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:18:04,198:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:18:19,606:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:18:20,420:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:18:35,213:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:18:36,004:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:18:51,043:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:18:51,802:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:19:08,701:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:19:09,516:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:19:25,388:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:19:26,369:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:19:41,110:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:19:42,044:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:20:07,549:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:20:08,826:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:20:34,827:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:20:36,211:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:21:01,506:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:21:03,150:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:21:29,429:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:21:30,997:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:21:47,412:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:21:48,342:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:22:04,983:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:22:06,176:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:22:23,014:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:22:24,094:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:22:40,627:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:22:41,710:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:22:59,045:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:23:00,074:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:23:25,312:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:23:26,646:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:23:51,766:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:23:53,176:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:24:18,207:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:24:19,642:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:24:45,183:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:24:46,576:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:08,752:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:10,175:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:14,955:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:15,561:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:20,619:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:21,261:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:26,090:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:26,779:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:31,745:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:32,363:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:37,082:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:25:37,668:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:26:04,370:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:26:05,798:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:26:32,732:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:26:34,035:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:27:01,137:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:27:02,690:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:27:33,297:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:27:34,878:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:28:01,555:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:28:02,951:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:28:17,526:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:28:18,348:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:28:31,992:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:28:32,941:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:28:47,461:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:28:48,367:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:29:02,995:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:29:04,111:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:29:19,196:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:29:20,196:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:29:52,132:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:29:53,827:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:30:25,832:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:30:27,511:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:30:57,861:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:30:59,633:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:31:31,432:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:31:33,088:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:32:05,459:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:32:07,235:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:32:46,458:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:32:48,472:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:33:27,539:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:33:29,245:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:34:07,638:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:34:09,544:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:34:50,046:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:34:51,851:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:35:34,392:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:35:36,238:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__algorithm': 'SAMME'}
2025-10-19 12:35:36,240:INFO:Hyperparameter search completed
2025-10-19 12:35:36,240:INFO:SubProcess create_model() called ==================================
2025-10-19 12:35:36,242:INFO:Initializing create_model()
2025-10-19 12:35:36,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002646B22D810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 200, 'learning_rate': 0.1, 'algorithm': 'SAMME'})
2025-10-19 12:35:36,244:INFO:Checking exceptions
2025-10-19 12:35:36,244:INFO:Importing libraries
2025-10-19 12:35:36,244:INFO:Copying training dataset
2025-10-19 12:35:36,653:INFO:Defining folds
2025-10-19 12:35:36,654:INFO:Declaring metric variables
2025-10-19 12:35:36,662:INFO:Importing untrained model
2025-10-19 12:35:36,663:INFO:Declaring custom model
2025-10-19 12:35:36,669:INFO:Ada Boost Classifier Imported successfully
2025-10-19 12:35:36,681:INFO:Starting cross validation
2025-10-19 12:35:36,691:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:35:36,925:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:36:04,935:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:36:06,966:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:36:07,124:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:36:35,260:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:36:37,305:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:36:37,451:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:37:06,050:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:37:08,337:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:37:08,483:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:37:36,901:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:37:39,104:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:37:39,254:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:38:07,780:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:38:10,137:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:38:10,164:INFO:Calculating mean and std
2025-10-19 12:38:10,166:INFO:Creating metrics dataframe
2025-10-19 12:38:10,181:INFO:Finalizing model
2025-10-19 12:38:10,264:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:38:47,644:INFO:Uploading results into container
2025-10-19 12:38:47,647:INFO:Uploading model into container now
2025-10-19 12:38:47,649:INFO:_master_model_container: 16
2025-10-19 12:38:47,649:INFO:_display_container: 3
2025-10-19 12:38:47,650:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=200, random_state=1861)
2025-10-19 12:38:47,650:INFO:create_model() successfully completed......................................
2025-10-19 12:38:47,989:INFO:SubProcess create_model() end ==================================
2025-10-19 12:38:47,990:INFO:choose_better activated
2025-10-19 12:38:47,999:INFO:SubProcess create_model() called ==================================
2025-10-19 12:38:48,003:INFO:Initializing create_model()
2025-10-19 12:38:48,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=50505    U16597
56930    U14509
3541     U18436
10571    U17178
7648     U11753
          ...  
2974     U12274
10484    U11570
32879    U11363
51749    U14136
76223    U14706
Name: id_usuario, Length: 55842, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:38:48,004:INFO:Checking exceptions
2025-10-19 12:38:48,007:INFO:Importing libraries
2025-10-19 12:38:48,007:INFO:Copying training dataset
2025-10-19 12:38:48,477:INFO:Defining folds
2025-10-19 12:38:48,478:INFO:Declaring metric variables
2025-10-19 12:38:48,478:INFO:Importing untrained model
2025-10-19 12:38:48,478:INFO:Declaring custom model
2025-10-19 12:38:48,479:INFO:Ada Boost Classifier Imported successfully
2025-10-19 12:38:48,479:INFO:Starting cross validation
2025-10-19 12:38:48,485:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:38:48,742:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:38:52,556:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:38:58,913:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:38:59,933:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:39:03,756:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:39:10,096:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:39:11,269:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:39:14,941:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:39:21,071:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:39:22,037:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:39:25,579:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:39:31,859:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:39:33,046:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:39:36,634:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:39:42,699:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:39:43,597:INFO:Calculating mean and std
2025-10-19 12:39:43,597:INFO:Creating metrics dataframe
2025-10-19 12:39:43,603:INFO:Finalizing model
2025-10-19 12:39:43,673:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:39:48,297:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 12:39:57,704:INFO:Uploading results into container
2025-10-19 12:39:57,705:INFO:Uploading model into container now
2025-10-19 12:39:57,706:INFO:_master_model_container: 17
2025-10-19 12:39:57,706:INFO:_display_container: 4
2025-10-19 12:39:57,707:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861)
2025-10-19 12:39:57,707:INFO:create_model() successfully completed......................................
2025-10-19 12:39:58,060:INFO:SubProcess create_model() end ==================================
2025-10-19 12:39:58,061:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861) result for AUC is 0.9519
2025-10-19 12:39:58,062:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=200, random_state=1861) result for AUC is 0.9494
2025-10-19 12:39:58,063:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861) is best model
2025-10-19 12:39:58,063:INFO:choose_better completed
2025-10-19 12:39:58,064:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 12:39:58,098:INFO:_master_model_container: 17
2025-10-19 12:39:58,099:INFO:_display_container: 3
2025-10-19 12:39:58,100:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1861)
2025-10-19 12:39:58,100:INFO:tune_model() successfully completed......................................
2025-10-19 12:39:58,502:INFO:Initializing tune_model()
2025-10-19 12:39:58,503:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002645A7B8050>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1861, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 12:39:58,503:INFO:Checking exceptions
2025-10-19 12:39:58,707:INFO:Copying training dataset
2025-10-19 12:39:59,039:INFO:Checking base model
2025-10-19 12:39:59,039:INFO:Base model : Gradient Boosting Classifier
2025-10-19 12:39:59,047:INFO:Declaring metric variables
2025-10-19 12:39:59,054:INFO:Defining Hyperparameters
2025-10-19 12:39:59,443:INFO:Tuning with n_jobs=1
2025-10-19 12:39:59,443:INFO:Initializing RandomizedSearchCV
2025-10-19 12:39:59,680:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:40:23,103:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:40:23,712:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:40:46,644:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:40:47,311:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:41:11,117:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:41:11,693:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:41:35,063:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:41:35,597:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:41:59,398:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:00,013:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:06,044:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:06,620:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:12,329:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:12,815:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:18,546:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:19,229:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:25,127:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:25,738:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:32,220:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:32,819:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:41,713:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:42,364:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:50,830:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:51,515:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:59,258:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:42:59,948:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:43:08,152:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:43:08,850:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:43:17,509:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:43:18,107:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:43:40,579:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:43:41,212:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:44:03,323:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:44:03,831:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:44:26,322:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:44:26,875:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:44:49,823:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:44:50,463:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:45:14,514:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:45:15,122:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:45:27,663:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:45:28,357:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:45:40,405:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:45:41,024:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:45:53,208:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:45:53,838:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:04,960:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:05,686:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:17,672:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:18,261:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:24,767:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:25,377:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:31,763:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:32,460:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:39,227:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:39,743:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:45,651:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:46,192:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:51,940:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:52,510:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:58,272:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:46:58,772:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:47:04,424:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:47:05,112:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:47:10,340:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:47:11,037:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:47:17,430:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:47:17,954:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:47:24,395:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:47:25,080:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['admite_mascotas']. At least one non-missing value is needed for imputation with strategy='mean'.

2025-10-19 12:58:06,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 12:58:06,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 12:58:06,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 12:58:06,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 12:58:09,175:INFO:PyCaret ClassificationExperiment
2025-10-19 12:58:09,177:INFO:Logging name: clf-default-name
2025-10-19 12:58:09,177:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 12:58:09,177:INFO:version 3.3.2
2025-10-19 12:58:09,177:INFO:Initializing setup()
2025-10-19 12:58:09,177:INFO:self.USI: 7cf2
2025-10-19 12:58:09,177:INFO:self._variable_keys: {'log_plots_param', 'seed', 'y', 'is_multiclass', 'logging_param', 'memory', 'exp_name_log', 'gpu_param', '_ml_usecase', 'X_train', 'pipeline', 'gpu_n_jobs_param', 'target_param', 'fix_imbalance', 'X_test', 'fold_groups_param', 'html_param', 'fold_shuffle_param', 'USI', 'y_test', 'exp_id', 'fold_generator', 'n_jobs_param', 'data', '_available_plots', 'X', 'idx', 'y_train'}
2025-10-19 12:58:09,177:INFO:Checking environment
2025-10-19 12:58:09,177:INFO:python_version: 3.11.13
2025-10-19 12:58:09,177:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 12:58:09,177:INFO:machine: AMD64
2025-10-19 12:58:09,177:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 12:58:09,183:INFO:Memory: svmem(total=16856211456, available=2773008384, percent=83.5, used=14083203072, free=2773008384)
2025-10-19 12:58:09,183:INFO:Physical Core: 4
2025-10-19 12:58:09,183:INFO:Logical Core: 8
2025-10-19 12:58:09,183:INFO:Checking libraries
2025-10-19 12:58:09,183:INFO:System:
2025-10-19 12:58:09,183:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 12:58:09,183:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 12:58:09,183:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 12:58:09,183:INFO:PyCaret required dependencies:
2025-10-19 12:58:10,511:INFO:                 pip: 25.2
2025-10-19 12:58:10,511:INFO:          setuptools: 80.9.0
2025-10-19 12:58:10,511:INFO:             pycaret: 3.3.2
2025-10-19 12:58:10,511:INFO:             IPython: 9.6.0
2025-10-19 12:58:10,511:INFO:          ipywidgets: 8.1.7
2025-10-19 12:58:10,511:INFO:                tqdm: 4.67.1
2025-10-19 12:58:10,511:INFO:               numpy: 1.26.4
2025-10-19 12:58:10,511:INFO:              pandas: 2.1.4
2025-10-19 12:58:10,511:INFO:              jinja2: 3.1.6
2025-10-19 12:58:10,511:INFO:               scipy: 1.11.4
2025-10-19 12:58:10,511:INFO:              joblib: 1.3.2
2025-10-19 12:58:10,511:INFO:             sklearn: 1.4.2
2025-10-19 12:58:10,511:INFO:                pyod: 2.0.5
2025-10-19 12:58:10,511:INFO:            imblearn: 0.14.0
2025-10-19 12:58:10,511:INFO:   category_encoders: 2.7.0
2025-10-19 12:58:10,511:INFO:            lightgbm: 4.6.0
2025-10-19 12:58:10,511:INFO:               numba: 0.61.0
2025-10-19 12:58:10,511:INFO:            requests: 2.32.5
2025-10-19 12:58:10,511:INFO:          matplotlib: 3.7.5
2025-10-19 12:58:10,511:INFO:          scikitplot: 0.3.7
2025-10-19 12:58:10,511:INFO:         yellowbrick: 1.5
2025-10-19 12:58:10,511:INFO:              plotly: 5.24.1
2025-10-19 12:58:10,511:INFO:    plotly-resampler: Not installed
2025-10-19 12:58:10,511:INFO:             kaleido: 1.1.0
2025-10-19 12:58:10,511:INFO:           schemdraw: 0.15
2025-10-19 12:58:10,511:INFO:         statsmodels: 0.14.5
2025-10-19 12:58:10,511:INFO:              sktime: 0.26.0
2025-10-19 12:58:10,511:INFO:               tbats: 1.1.3
2025-10-19 12:58:10,511:INFO:            pmdarima: 2.0.4
2025-10-19 12:58:10,511:INFO:              psutil: 7.1.0
2025-10-19 12:58:10,511:INFO:          markupsafe: 3.0.3
2025-10-19 12:58:10,512:INFO:             pickle5: Not installed
2025-10-19 12:58:10,512:INFO:         cloudpickle: 3.1.1
2025-10-19 12:58:10,512:INFO:         deprecation: 2.1.0
2025-10-19 12:58:10,512:INFO:              xxhash: 3.6.0
2025-10-19 12:58:10,512:INFO:           wurlitzer: Not installed
2025-10-19 12:58:10,512:INFO:PyCaret optional dependencies:
2025-10-19 12:58:15,905:INFO:                shap: 0.44.1
2025-10-19 12:58:15,905:INFO:           interpret: 0.7.3
2025-10-19 12:58:15,905:INFO:                umap: 0.5.7
2025-10-19 12:58:15,905:INFO:     ydata_profiling: 4.17.0
2025-10-19 12:58:15,905:INFO:  explainerdashboard: 0.5.1
2025-10-19 12:58:15,905:INFO:             autoviz: Not installed
2025-10-19 12:58:15,905:INFO:           fairlearn: 0.7.0
2025-10-19 12:58:15,905:INFO:          deepchecks: Not installed
2025-10-19 12:58:15,905:INFO:             xgboost: Not installed
2025-10-19 12:58:15,905:INFO:            catboost: 1.2.8
2025-10-19 12:58:15,905:INFO:              kmodes: 0.12.2
2025-10-19 12:58:15,905:INFO:             mlxtend: 0.23.4
2025-10-19 12:58:15,905:INFO:       statsforecast: 1.5.0
2025-10-19 12:58:15,905:INFO:        tune_sklearn: Not installed
2025-10-19 12:58:15,905:INFO:                 ray: Not installed
2025-10-19 12:58:15,905:INFO:            hyperopt: 0.2.7
2025-10-19 12:58:15,905:INFO:              optuna: 4.5.0
2025-10-19 12:58:15,906:INFO:               skopt: 0.10.2
2025-10-19 12:58:15,906:INFO:              mlflow: 3.5.0
2025-10-19 12:58:15,906:INFO:              gradio: 5.49.1
2025-10-19 12:58:15,906:INFO:             fastapi: 0.119.0
2025-10-19 12:58:15,906:INFO:             uvicorn: 0.38.0
2025-10-19 12:58:15,906:INFO:              m2cgen: 0.10.0
2025-10-19 12:58:15,906:INFO:           evidently: 0.4.40
2025-10-19 12:58:15,906:INFO:               fugue: 0.8.7
2025-10-19 12:58:15,906:INFO:           streamlit: Not installed
2025-10-19 12:58:15,906:INFO:             prophet: Not installed
2025-10-19 12:58:15,906:INFO:None
2025-10-19 12:58:15,906:INFO:Set up data.
2025-10-19 12:58:16,113:INFO:Set up folding strategy.
2025-10-19 12:58:16,326:INFO:Set up train/test split.
2025-10-19 12:58:16,542:INFO:Set up index.
2025-10-19 12:58:16,555:INFO:Assigning column types.
2025-10-19 12:58:16,763:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 12:58:16,795:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 12:58:16,800:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 12:58:16,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:58:16,830:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:58:16,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 12:58:16,897:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 12:58:16,919:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:58:16,919:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:58:16,920:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 12:58:16,953:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 12:58:16,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:58:16,976:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:58:17,009:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 12:58:17,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:58:17,030:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:58:17,030:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 12:58:17,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:58:17,086:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:58:17,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:58:17,140:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:58:17,145:INFO:Preparing preprocessing pipeline...
2025-10-19 12:58:17,179:INFO:Set up simple imputation.
2025-10-19 12:58:17,343:INFO:Set up encoding of ordinal features.
2025-10-19 12:58:17,484:INFO:Set up encoding of categorical features.
2025-10-19 12:58:17,489:INFO:Set up removing multicollinearity.
2025-10-19 12:58:17,523:INFO:Set up column name cleaning.
2025-10-19 12:58:21,662:INFO:Finished creating preprocessing pipeline.
2025-10-19 12:58:21,685:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 12:58:21,685:INFO:Creating final display dataframe.
2025-10-19 12:58:24,472:INFO:Setup _display_container:                     Description             Value
0                    Session id              3137
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (79874, 28)
4        Transformed data shape       (79874, 86)
5   Transformed train set shape       (55911, 86)
6    Transformed test set shape       (23963, 86)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              7cf2
2025-10-19 12:58:24,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:58:24,526:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:58:24,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 12:58:24,580:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 12:58:24,582:INFO:setup() successfully completed in 15.5s...............
2025-10-19 12:58:24,582:INFO:Initializing compare_models()
2025-10-19 12:58:24,582:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 12:58:24,582:INFO:Checking exceptions
2025-10-19 12:58:24,739:INFO:Preparing display monitor
2025-10-19 12:58:24,766:INFO:Initializing Logistic Regression
2025-10-19 12:58:24,766:INFO:Total runtime is 0.0 minutes
2025-10-19 12:58:24,770:INFO:SubProcess create_model() called ==================================
2025-10-19 12:58:24,771:INFO:Initializing create_model()
2025-10-19 12:58:24,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:58:24,772:INFO:Checking exceptions
2025-10-19 12:58:24,772:INFO:Importing libraries
2025-10-19 12:58:24,772:INFO:Copying training dataset
2025-10-19 12:58:25,076:INFO:Defining folds
2025-10-19 12:58:25,076:INFO:Declaring metric variables
2025-10-19 12:58:25,079:INFO:Importing untrained model
2025-10-19 12:58:25,081:INFO:Logistic Regression Imported successfully
2025-10-19 12:58:25,090:INFO:Starting cross validation
2025-10-19 12:58:25,094:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:58:34,377:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 12:58:34,635:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:58:43,857:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 12:58:44,132:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:58:53,210:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 12:58:53,458:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:59:02,541:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 12:59:02,773:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:59:11,846:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 12:59:12,084:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:59:12,098:INFO:Calculating mean and std
2025-10-19 12:59:12,099:INFO:Creating metrics dataframe
2025-10-19 12:59:12,100:INFO:Uploading results into container
2025-10-19 12:59:12,101:INFO:Uploading model into container now
2025-10-19 12:59:12,101:INFO:_master_model_container: 1
2025-10-19 12:59:12,101:INFO:_display_container: 2
2025-10-19 12:59:12,102:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3137, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 12:59:12,102:INFO:create_model() successfully completed......................................
2025-10-19 12:59:12,262:INFO:SubProcess create_model() end ==================================
2025-10-19 12:59:12,262:INFO:Creating metrics dataframe
2025-10-19 12:59:12,268:INFO:Initializing K Neighbors Classifier
2025-10-19 12:59:12,268:INFO:Total runtime is 0.7917014956474304 minutes
2025-10-19 12:59:12,275:INFO:SubProcess create_model() called ==================================
2025-10-19 12:59:12,276:INFO:Initializing create_model()
2025-10-19 12:59:12,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:59:12,276:INFO:Checking exceptions
2025-10-19 12:59:12,276:INFO:Importing libraries
2025-10-19 12:59:12,276:INFO:Copying training dataset
2025-10-19 12:59:12,523:INFO:Defining folds
2025-10-19 12:59:12,523:INFO:Declaring metric variables
2025-10-19 12:59:12,526:INFO:Importing untrained model
2025-10-19 12:59:12,530:INFO:K Neighbors Classifier Imported successfully
2025-10-19 12:59:12,538:INFO:Starting cross validation
2025-10-19 12:59:12,543:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:59:37,648:INFO:Calculating mean and std
2025-10-19 12:59:37,650:INFO:Creating metrics dataframe
2025-10-19 12:59:37,652:INFO:Uploading results into container
2025-10-19 12:59:37,652:INFO:Uploading model into container now
2025-10-19 12:59:37,653:INFO:_master_model_container: 2
2025-10-19 12:59:37,653:INFO:_display_container: 2
2025-10-19 12:59:37,653:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 12:59:37,654:INFO:create_model() successfully completed......................................
2025-10-19 12:59:37,813:INFO:SubProcess create_model() end ==================================
2025-10-19 12:59:37,813:INFO:Creating metrics dataframe
2025-10-19 12:59:37,819:INFO:Initializing Naive Bayes
2025-10-19 12:59:37,819:INFO:Total runtime is 1.2175405462582907 minutes
2025-10-19 12:59:37,822:INFO:SubProcess create_model() called ==================================
2025-10-19 12:59:37,824:INFO:Initializing create_model()
2025-10-19 12:59:37,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:59:37,824:INFO:Checking exceptions
2025-10-19 12:59:37,824:INFO:Importing libraries
2025-10-19 12:59:37,824:INFO:Copying training dataset
2025-10-19 12:59:38,059:INFO:Defining folds
2025-10-19 12:59:38,059:INFO:Declaring metric variables
2025-10-19 12:59:38,063:INFO:Importing untrained model
2025-10-19 12:59:38,068:INFO:Naive Bayes Imported successfully
2025-10-19 12:59:38,075:INFO:Starting cross validation
2025-10-19 12:59:38,079:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 12:59:40,543:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:59:42,972:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:59:45,685:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:59:48,765:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:59:51,634:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 12:59:51,652:INFO:Calculating mean and std
2025-10-19 12:59:51,653:INFO:Creating metrics dataframe
2025-10-19 12:59:51,656:INFO:Uploading results into container
2025-10-19 12:59:51,657:INFO:Uploading model into container now
2025-10-19 12:59:51,658:INFO:_master_model_container: 3
2025-10-19 12:59:51,658:INFO:_display_container: 2
2025-10-19 12:59:51,659:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 12:59:51,659:INFO:create_model() successfully completed......................................
2025-10-19 12:59:51,865:INFO:SubProcess create_model() end ==================================
2025-10-19 12:59:51,865:INFO:Creating metrics dataframe
2025-10-19 12:59:51,873:INFO:Initializing Decision Tree Classifier
2025-10-19 12:59:51,873:INFO:Total runtime is 1.4517725904782615 minutes
2025-10-19 12:59:51,878:INFO:SubProcess create_model() called ==================================
2025-10-19 12:59:51,879:INFO:Initializing create_model()
2025-10-19 12:59:51,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 12:59:51,879:INFO:Checking exceptions
2025-10-19 12:59:51,879:INFO:Importing libraries
2025-10-19 12:59:51,879:INFO:Copying training dataset
2025-10-19 12:59:52,128:INFO:Defining folds
2025-10-19 12:59:52,128:INFO:Declaring metric variables
2025-10-19 12:59:52,133:INFO:Importing untrained model
2025-10-19 12:59:52,137:INFO:Decision Tree Classifier Imported successfully
2025-10-19 12:59:52,145:INFO:Starting cross validation
2025-10-19 12:59:52,149:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:00:08,155:INFO:Calculating mean and std
2025-10-19 13:00:08,158:INFO:Creating metrics dataframe
2025-10-19 13:00:08,161:INFO:Uploading results into container
2025-10-19 13:00:08,161:INFO:Uploading model into container now
2025-10-19 13:00:08,162:INFO:_master_model_container: 4
2025-10-19 13:00:08,162:INFO:_display_container: 2
2025-10-19 13:00:08,162:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3137, splitter='best')
2025-10-19 13:00:08,162:INFO:create_model() successfully completed......................................
2025-10-19 13:00:08,317:INFO:SubProcess create_model() end ==================================
2025-10-19 13:00:08,318:INFO:Creating metrics dataframe
2025-10-19 13:00:08,323:INFO:Initializing SVM - Linear Kernel
2025-10-19 13:00:08,323:INFO:Total runtime is 1.7259555260340373 minutes
2025-10-19 13:00:08,329:INFO:SubProcess create_model() called ==================================
2025-10-19 13:00:08,330:INFO:Initializing create_model()
2025-10-19 13:00:08,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:00:08,330:INFO:Checking exceptions
2025-10-19 13:00:08,330:INFO:Importing libraries
2025-10-19 13:00:08,330:INFO:Copying training dataset
2025-10-19 13:00:08,593:INFO:Defining folds
2025-10-19 13:00:08,594:INFO:Declaring metric variables
2025-10-19 13:00:08,598:INFO:Importing untrained model
2025-10-19 13:00:08,602:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 13:00:08,608:INFO:Starting cross validation
2025-10-19 13:00:08,612:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:00:13,986:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:00:20,719:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:00:27,111:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:00:32,317:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:00:38,364:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:00:38,377:INFO:Calculating mean and std
2025-10-19 13:00:38,378:INFO:Creating metrics dataframe
2025-10-19 13:00:38,379:INFO:Uploading results into container
2025-10-19 13:00:38,380:INFO:Uploading model into container now
2025-10-19 13:00:38,380:INFO:_master_model_container: 5
2025-10-19 13:00:38,380:INFO:_display_container: 2
2025-10-19 13:00:38,380:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=3137, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 13:00:38,380:INFO:create_model() successfully completed......................................
2025-10-19 13:00:38,522:INFO:SubProcess create_model() end ==================================
2025-10-19 13:00:38,522:INFO:Creating metrics dataframe
2025-10-19 13:00:38,528:INFO:Initializing Ridge Classifier
2025-10-19 13:00:38,529:INFO:Total runtime is 2.229382566610972 minutes
2025-10-19 13:00:38,532:INFO:SubProcess create_model() called ==================================
2025-10-19 13:00:38,534:INFO:Initializing create_model()
2025-10-19 13:00:38,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:00:38,534:INFO:Checking exceptions
2025-10-19 13:00:38,534:INFO:Importing libraries
2025-10-19 13:00:38,534:INFO:Copying training dataset
2025-10-19 13:00:38,770:INFO:Defining folds
2025-10-19 13:00:38,770:INFO:Declaring metric variables
2025-10-19 13:00:38,774:INFO:Importing untrained model
2025-10-19 13:00:38,777:INFO:Ridge Classifier Imported successfully
2025-10-19 13:00:38,784:INFO:Starting cross validation
2025-10-19 13:00:38,788:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:00:41,348:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:00:43,987:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:00:46,394:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:00:48,784:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:00:51,564:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:00:51,582:INFO:Calculating mean and std
2025-10-19 13:00:51,584:INFO:Creating metrics dataframe
2025-10-19 13:00:51,585:INFO:Uploading results into container
2025-10-19 13:00:51,587:INFO:Uploading model into container now
2025-10-19 13:00:51,588:INFO:_master_model_container: 6
2025-10-19 13:00:51,588:INFO:_display_container: 2
2025-10-19 13:00:51,588:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3137, solver='auto',
                tol=0.0001)
2025-10-19 13:00:51,588:INFO:create_model() successfully completed......................................
2025-10-19 13:00:51,774:INFO:SubProcess create_model() end ==================================
2025-10-19 13:00:51,774:INFO:Creating metrics dataframe
2025-10-19 13:00:51,783:INFO:Initializing Random Forest Classifier
2025-10-19 13:00:51,783:INFO:Total runtime is 2.4502811233202615 minutes
2025-10-19 13:00:51,789:INFO:SubProcess create_model() called ==================================
2025-10-19 13:00:51,789:INFO:Initializing create_model()
2025-10-19 13:00:51,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:00:51,790:INFO:Checking exceptions
2025-10-19 13:00:51,790:INFO:Importing libraries
2025-10-19 13:00:51,790:INFO:Copying training dataset
2025-10-19 13:00:52,057:INFO:Defining folds
2025-10-19 13:00:52,057:INFO:Declaring metric variables
2025-10-19 13:00:52,061:INFO:Importing untrained model
2025-10-19 13:00:52,065:INFO:Random Forest Classifier Imported successfully
2025-10-19 13:00:52,074:INFO:Starting cross validation
2025-10-19 13:00:52,078:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:01:17,311:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:01:42,168:INFO:Calculating mean and std
2025-10-19 13:01:42,169:INFO:Creating metrics dataframe
2025-10-19 13:01:42,171:INFO:Uploading results into container
2025-10-19 13:01:42,172:INFO:Uploading model into container now
2025-10-19 13:01:42,172:INFO:_master_model_container: 7
2025-10-19 13:01:42,173:INFO:_display_container: 2
2025-10-19 13:01:42,173:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=3137, verbose=0,
                       warm_start=False)
2025-10-19 13:01:42,173:INFO:create_model() successfully completed......................................
2025-10-19 13:01:42,345:INFO:SubProcess create_model() end ==================================
2025-10-19 13:01:42,346:INFO:Creating metrics dataframe
2025-10-19 13:01:42,352:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 13:01:42,353:INFO:Total runtime is 3.293119927247365 minutes
2025-10-19 13:01:42,357:INFO:SubProcess create_model() called ==================================
2025-10-19 13:01:42,359:INFO:Initializing create_model()
2025-10-19 13:01:42,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:01:42,359:INFO:Checking exceptions
2025-10-19 13:01:42,359:INFO:Importing libraries
2025-10-19 13:01:42,359:INFO:Copying training dataset
2025-10-19 13:01:42,619:INFO:Defining folds
2025-10-19 13:01:42,619:INFO:Declaring metric variables
2025-10-19 13:01:42,624:INFO:Importing untrained model
2025-10-19 13:01:42,629:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 13:01:42,640:INFO:Starting cross validation
2025-10-19 13:01:42,646:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:01:45,842:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 13:01:49,244:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 13:01:55,133:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 13:01:58,302:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 13:02:01,253:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 13:02:01,637:INFO:Calculating mean and std
2025-10-19 13:02:01,638:INFO:Creating metrics dataframe
2025-10-19 13:02:01,640:INFO:Uploading results into container
2025-10-19 13:02:01,640:INFO:Uploading model into container now
2025-10-19 13:02:01,641:INFO:_master_model_container: 8
2025-10-19 13:02:01,641:INFO:_display_container: 2
2025-10-19 13:02:01,641:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 13:02:01,642:INFO:create_model() successfully completed......................................
2025-10-19 13:02:01,839:INFO:SubProcess create_model() end ==================================
2025-10-19 13:02:01,839:INFO:Creating metrics dataframe
2025-10-19 13:02:01,855:INFO:Initializing Ada Boost Classifier
2025-10-19 13:02:01,856:INFO:Total runtime is 3.6181721488634744 minutes
2025-10-19 13:02:01,861:INFO:SubProcess create_model() called ==================================
2025-10-19 13:02:01,865:INFO:Initializing create_model()
2025-10-19 13:02:01,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:02:01,865:INFO:Checking exceptions
2025-10-19 13:02:01,865:INFO:Importing libraries
2025-10-19 13:02:01,865:INFO:Copying training dataset
2025-10-19 13:02:02,162:INFO:Defining folds
2025-10-19 13:02:02,163:INFO:Declaring metric variables
2025-10-19 13:02:02,169:INFO:Importing untrained model
2025-10-19 13:02:02,172:INFO:Ada Boost Classifier Imported successfully
2025-10-19 13:02:02,179:INFO:Starting cross validation
2025-10-19 13:02:02,185:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:02:04,435:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:02:10,388:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:02:16,701:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:02:23,747:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:02:28,186:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:02:36,526:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:02:41,204:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:02:48,780:INFO:Calculating mean and std
2025-10-19 13:02:48,782:INFO:Creating metrics dataframe
2025-10-19 13:02:48,785:INFO:Uploading results into container
2025-10-19 13:02:48,786:INFO:Uploading model into container now
2025-10-19 13:02:48,786:INFO:_master_model_container: 9
2025-10-19 13:02:48,787:INFO:_display_container: 2
2025-10-19 13:02:48,787:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3137)
2025-10-19 13:02:48,787:INFO:create_model() successfully completed......................................
2025-10-19 13:02:48,955:INFO:SubProcess create_model() end ==================================
2025-10-19 13:02:48,955:INFO:Creating metrics dataframe
2025-10-19 13:02:48,962:INFO:Initializing Gradient Boosting Classifier
2025-10-19 13:02:48,962:INFO:Total runtime is 4.403263986110687 minutes
2025-10-19 13:02:48,965:INFO:SubProcess create_model() called ==================================
2025-10-19 13:02:48,968:INFO:Initializing create_model()
2025-10-19 13:02:48,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:02:48,969:INFO:Checking exceptions
2025-10-19 13:02:48,969:INFO:Importing libraries
2025-10-19 13:02:48,969:INFO:Copying training dataset
2025-10-19 13:02:49,274:INFO:Defining folds
2025-10-19 13:02:49,274:INFO:Declaring metric variables
2025-10-19 13:02:49,278:INFO:Importing untrained model
2025-10-19 13:02:49,284:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 13:02:49,291:INFO:Starting cross validation
2025-10-19 13:02:49,296:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:03:56,393:INFO:Calculating mean and std
2025-10-19 13:03:56,394:INFO:Creating metrics dataframe
2025-10-19 13:03:56,396:INFO:Uploading results into container
2025-10-19 13:03:56,396:INFO:Uploading model into container now
2025-10-19 13:03:56,396:INFO:_master_model_container: 10
2025-10-19 13:03:56,396:INFO:_display_container: 2
2025-10-19 13:03:56,397:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3137, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 13:03:56,397:INFO:create_model() successfully completed......................................
2025-10-19 13:03:56,559:INFO:SubProcess create_model() end ==================================
2025-10-19 13:03:56,559:INFO:Creating metrics dataframe
2025-10-19 13:03:56,568:INFO:Initializing Linear Discriminant Analysis
2025-10-19 13:03:56,569:INFO:Total runtime is 5.5300435543060305 minutes
2025-10-19 13:03:56,574:INFO:SubProcess create_model() called ==================================
2025-10-19 13:03:56,575:INFO:Initializing create_model()
2025-10-19 13:03:56,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:03:56,575:INFO:Checking exceptions
2025-10-19 13:03:56,575:INFO:Importing libraries
2025-10-19 13:03:56,576:INFO:Copying training dataset
2025-10-19 13:03:56,814:INFO:Defining folds
2025-10-19 13:03:56,814:INFO:Declaring metric variables
2025-10-19 13:03:56,819:INFO:Importing untrained model
2025-10-19 13:03:56,824:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 13:03:56,830:INFO:Starting cross validation
2025-10-19 13:03:56,835:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:04:12,161:INFO:Calculating mean and std
2025-10-19 13:04:12,162:INFO:Creating metrics dataframe
2025-10-19 13:04:12,164:INFO:Uploading results into container
2025-10-19 13:04:12,164:INFO:Uploading model into container now
2025-10-19 13:04:12,164:INFO:_master_model_container: 11
2025-10-19 13:04:12,165:INFO:_display_container: 2
2025-10-19 13:04:12,165:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 13:04:12,165:INFO:create_model() successfully completed......................................
2025-10-19 13:04:12,335:INFO:SubProcess create_model() end ==================================
2025-10-19 13:04:12,336:INFO:Creating metrics dataframe
2025-10-19 13:04:12,347:INFO:Initializing Extra Trees Classifier
2025-10-19 13:04:12,347:INFO:Total runtime is 5.7930084307988485 minutes
2025-10-19 13:04:12,351:INFO:SubProcess create_model() called ==================================
2025-10-19 13:04:12,352:INFO:Initializing create_model()
2025-10-19 13:04:12,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:04:12,353:INFO:Checking exceptions
2025-10-19 13:04:12,353:INFO:Importing libraries
2025-10-19 13:04:12,353:INFO:Copying training dataset
2025-10-19 13:04:12,602:INFO:Defining folds
2025-10-19 13:04:12,603:INFO:Declaring metric variables
2025-10-19 13:04:12,608:INFO:Importing untrained model
2025-10-19 13:04:12,612:INFO:Extra Trees Classifier Imported successfully
2025-10-19 13:04:12,618:INFO:Starting cross validation
2025-10-19 13:04:12,623:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:04:50,092:INFO:Calculating mean and std
2025-10-19 13:04:50,093:INFO:Creating metrics dataframe
2025-10-19 13:04:50,095:INFO:Uploading results into container
2025-10-19 13:04:50,095:INFO:Uploading model into container now
2025-10-19 13:04:50,095:INFO:_master_model_container: 12
2025-10-19 13:04:50,095:INFO:_display_container: 2
2025-10-19 13:04:50,096:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=3137, verbose=0,
                     warm_start=False)
2025-10-19 13:04:50,096:INFO:create_model() successfully completed......................................
2025-10-19 13:04:50,253:INFO:SubProcess create_model() end ==================================
2025-10-19 13:04:50,253:INFO:Creating metrics dataframe
2025-10-19 13:04:50,263:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 13:04:50,263:INFO:Total runtime is 6.424949940045675 minutes
2025-10-19 13:04:50,267:INFO:SubProcess create_model() called ==================================
2025-10-19 13:04:50,268:INFO:Initializing create_model()
2025-10-19 13:04:50,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:04:50,268:INFO:Checking exceptions
2025-10-19 13:04:50,268:INFO:Importing libraries
2025-10-19 13:04:50,268:INFO:Copying training dataset
2025-10-19 13:04:50,529:INFO:Defining folds
2025-10-19 13:04:50,529:INFO:Declaring metric variables
2025-10-19 13:04:50,533:INFO:Importing untrained model
2025-10-19 13:04:50,537:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 13:04:50,545:INFO:Starting cross validation
2025-10-19 13:04:50,550:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:04:52,840:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:04:52,842:INFO:[LightGBM] [Info] Number of positive: 1760, number of negative: 42968
2025-10-19 13:04:52,865:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008834 seconds.
2025-10-19 13:04:52,865:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:04:52,865:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:04:52,866:INFO:[LightGBM] [Info] Total Bins 1468
2025-10-19 13:04:52,866:INFO:[LightGBM] [Info] Number of data points in the train set: 44728, number of used features: 85
2025-10-19 13:04:52,866:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039349 -> initscore=-3.195142
2025-10-19 13:04:52,866:INFO:[LightGBM] [Info] Start training from score -3.195142
2025-10-19 13:04:55,938:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:04:55,941:INFO:[LightGBM] [Info] Number of positive: 1763, number of negative: 42966
2025-10-19 13:04:55,961:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007843 seconds.
2025-10-19 13:04:55,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:04:55,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:04:55,962:INFO:[LightGBM] [Info] Total Bins 1472
2025-10-19 13:04:55,962:INFO:[LightGBM] [Info] Number of data points in the train set: 44729, number of used features: 85
2025-10-19 13:04:55,962:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039415 -> initscore=-3.193392
2025-10-19 13:04:55,962:INFO:[LightGBM] [Info] Start training from score -3.193392
2025-10-19 13:04:58,946:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:04:58,948:INFO:[LightGBM] [Info] Number of positive: 1733, number of negative: 42996
2025-10-19 13:04:58,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009309 seconds.
2025-10-19 13:04:58,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:04:58,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:04:58,974:INFO:[LightGBM] [Info] Total Bins 1468
2025-10-19 13:04:58,974:INFO:[LightGBM] [Info] Number of data points in the train set: 44729, number of used features: 85
2025-10-19 13:04:58,974:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038744 -> initscore=-3.211253
2025-10-19 13:04:58,975:INFO:[LightGBM] [Info] Start training from score -3.211253
2025-10-19 13:05:02,062:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:05:02,064:INFO:[LightGBM] [Info] Number of positive: 1770, number of negative: 42959
2025-10-19 13:05:02,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009698 seconds.
2025-10-19 13:05:02,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:05:02,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:05:02,089:INFO:[LightGBM] [Info] Total Bins 1467
2025-10-19 13:05:02,090:INFO:[LightGBM] [Info] Number of data points in the train set: 44729, number of used features: 85
2025-10-19 13:05:02,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039572 -> initscore=-3.189267
2025-10-19 13:05:02,090:INFO:[LightGBM] [Info] Start training from score -3.189267
2025-10-19 13:05:05,121:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:05:05,123:INFO:[LightGBM] [Info] Number of positive: 1762, number of negative: 42967
2025-10-19 13:05:05,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009346 seconds.
2025-10-19 13:05:05,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:05:05,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:05:05,148:INFO:[LightGBM] [Info] Total Bins 1467
2025-10-19 13:05:05,150:INFO:[LightGBM] [Info] Number of data points in the train set: 44729, number of used features: 85
2025-10-19 13:05:05,150:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039393 -> initscore=-3.193983
2025-10-19 13:05:05,150:INFO:[LightGBM] [Info] Start training from score -3.193983
2025-10-19 13:05:05,885:INFO:Calculating mean and std
2025-10-19 13:05:05,886:INFO:Creating metrics dataframe
2025-10-19 13:05:05,888:INFO:Uploading results into container
2025-10-19 13:05:05,889:INFO:Uploading model into container now
2025-10-19 13:05:05,889:INFO:_master_model_container: 13
2025-10-19 13:05:05,889:INFO:_display_container: 2
2025-10-19 13:05:05,890:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=3137, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 13:05:05,890:INFO:create_model() successfully completed......................................
2025-10-19 13:05:06,043:INFO:SubProcess create_model() end ==================================
2025-10-19 13:05:06,043:INFO:Creating metrics dataframe
2025-10-19 13:05:06,054:INFO:Initializing CatBoost Classifier
2025-10-19 13:05:06,054:INFO:Total runtime is 6.688132309913636 minutes
2025-10-19 13:05:06,058:INFO:SubProcess create_model() called ==================================
2025-10-19 13:05:06,059:INFO:Initializing create_model()
2025-10-19 13:05:06,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:05:06,060:INFO:Checking exceptions
2025-10-19 13:05:06,060:INFO:Importing libraries
2025-10-19 13:05:06,060:INFO:Copying training dataset
2025-10-19 13:05:06,285:INFO:Defining folds
2025-10-19 13:05:06,286:INFO:Declaring metric variables
2025-10-19 13:05:06,291:INFO:Importing untrained model
2025-10-19 13:05:06,295:INFO:CatBoost Classifier Imported successfully
2025-10-19 13:05:06,301:INFO:Starting cross validation
2025-10-19 13:05:06,307:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:07:14,473:INFO:Calculating mean and std
2025-10-19 13:07:14,475:INFO:Creating metrics dataframe
2025-10-19 13:07:14,478:INFO:Uploading results into container
2025-10-19 13:07:14,480:INFO:Uploading model into container now
2025-10-19 13:07:14,481:INFO:_master_model_container: 14
2025-10-19 13:07:14,481:INFO:_display_container: 2
2025-10-19 13:07:14,481:INFO:<catboost.core.CatBoostClassifier object at 0x0000027FED9FC210>
2025-10-19 13:07:14,481:INFO:create_model() successfully completed......................................
2025-10-19 13:07:14,692:INFO:SubProcess create_model() end ==================================
2025-10-19 13:07:14,692:INFO:Creating metrics dataframe
2025-10-19 13:07:14,707:INFO:Initializing Dummy Classifier
2025-10-19 13:07:14,708:INFO:Total runtime is 8.832358737786612 minutes
2025-10-19 13:07:14,712:INFO:SubProcess create_model() called ==================================
2025-10-19 13:07:14,713:INFO:Initializing create_model()
2025-10-19 13:07:14,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FEF8019D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:07:14,714:INFO:Checking exceptions
2025-10-19 13:07:14,714:INFO:Importing libraries
2025-10-19 13:07:14,714:INFO:Copying training dataset
2025-10-19 13:07:14,970:INFO:Defining folds
2025-10-19 13:07:14,970:INFO:Declaring metric variables
2025-10-19 13:07:14,974:INFO:Importing untrained model
2025-10-19 13:07:14,980:INFO:Dummy Classifier Imported successfully
2025-10-19 13:07:14,987:INFO:Starting cross validation
2025-10-19 13:07:14,992:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:07:17,556:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:07:20,015:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:07:22,459:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:07:24,858:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:07:27,204:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:07:27,217:INFO:Calculating mean and std
2025-10-19 13:07:27,218:INFO:Creating metrics dataframe
2025-10-19 13:07:27,219:INFO:Uploading results into container
2025-10-19 13:07:27,220:INFO:Uploading model into container now
2025-10-19 13:07:27,220:INFO:_master_model_container: 15
2025-10-19 13:07:27,220:INFO:_display_container: 2
2025-10-19 13:07:27,221:INFO:DummyClassifier(constant=None, random_state=3137, strategy='prior')
2025-10-19 13:07:27,221:INFO:create_model() successfully completed......................................
2025-10-19 13:07:27,381:INFO:SubProcess create_model() end ==================================
2025-10-19 13:07:27,381:INFO:Creating metrics dataframe
2025-10-19 13:07:27,390:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 13:07:27,400:INFO:Initializing create_model()
2025-10-19 13:07:27,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3137, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:07:27,400:INFO:Checking exceptions
2025-10-19 13:07:27,404:INFO:Importing libraries
2025-10-19 13:07:27,404:INFO:Copying training dataset
2025-10-19 13:07:27,638:INFO:Defining folds
2025-10-19 13:07:27,638:INFO:Declaring metric variables
2025-10-19 13:07:27,639:INFO:Importing untrained model
2025-10-19 13:07:27,639:INFO:Declaring custom model
2025-10-19 13:07:27,639:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 13:07:27,642:INFO:Cross validation set to False
2025-10-19 13:07:27,642:INFO:Fitting Model
2025-10-19 13:07:44,818:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3137, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 13:07:44,819:INFO:create_model() successfully completed......................................
2025-10-19 13:07:44,985:INFO:Initializing create_model()
2025-10-19 13:07:44,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3137, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:07:44,986:INFO:Checking exceptions
2025-10-19 13:07:44,989:INFO:Importing libraries
2025-10-19 13:07:44,989:INFO:Copying training dataset
2025-10-19 13:07:45,256:INFO:Defining folds
2025-10-19 13:07:45,256:INFO:Declaring metric variables
2025-10-19 13:07:45,256:INFO:Importing untrained model
2025-10-19 13:07:45,256:INFO:Declaring custom model
2025-10-19 13:07:45,257:INFO:Ridge Classifier Imported successfully
2025-10-19 13:07:45,259:INFO:Cross validation set to False
2025-10-19 13:07:45,259:INFO:Fitting Model
2025-10-19 13:07:48,089:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3137, solver='auto',
                tol=0.0001)
2025-10-19 13:07:48,089:INFO:create_model() successfully completed......................................
2025-10-19 13:07:48,255:INFO:Initializing create_model()
2025-10-19 13:07:48,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=72400    U09583
58830    U03111
51359    U02197
53255    U03595
43892    U01836
          ...  
5606     U07457
38483    U11853
77110    U04415
47842    U02536
41101    U10029
Name: id_usuario, Length: 55911, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:07:48,255:INFO:Checking exceptions
2025-10-19 13:07:48,258:INFO:Importing libraries
2025-10-19 13:07:48,258:INFO:Copying training dataset
2025-10-19 13:07:48,494:INFO:Defining folds
2025-10-19 13:07:48,494:INFO:Declaring metric variables
2025-10-19 13:07:48,495:INFO:Importing untrained model
2025-10-19 13:07:48,495:INFO:Declaring custom model
2025-10-19 13:07:48,495:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 13:07:48,498:INFO:Cross validation set to False
2025-10-19 13:07:48,498:INFO:Fitting Model
2025-10-19 13:07:51,765:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 13:07:51,765:INFO:create_model() successfully completed......................................
2025-10-19 13:07:51,970:INFO:_master_model_container: 15
2025-10-19 13:07:51,970:INFO:_display_container: 2
2025-10-19 13:07:51,971:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3137, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3137, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2025-10-19 13:07:51,971:INFO:compare_models() successfully completed......................................
2025-10-19 13:07:51,973:INFO:Initializing tune_model()
2025-10-19 13:07:51,973:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027FE24CE010>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3137, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 13:07:51,973:INFO:Checking exceptions
2025-10-19 13:07:52,095:INFO:Copying training dataset
2025-10-19 13:07:52,280:INFO:Checking base model
2025-10-19 13:07:52,281:INFO:Base model : Gradient Boosting Classifier
2025-10-19 13:07:52,285:INFO:Declaring metric variables
2025-10-19 13:07:52,288:INFO:Defining Hyperparameters
2025-10-19 13:07:52,496:INFO:Tuning with n_jobs=1
2025-10-19 13:07:52,496:INFO:Initializing RandomizedSearchCV
2025-10-19 13:09:45,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:09:45,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:09:45,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:09:45,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 13:09:47,292:INFO:PyCaret ClassificationExperiment
2025-10-19 13:09:47,292:INFO:Logging name: clf-default-name
2025-10-19 13:09:47,292:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 13:09:47,292:INFO:version 3.3.2
2025-10-19 13:09:47,292:INFO:Initializing setup()
2025-10-19 13:09:47,292:INFO:self.USI: 1125
2025-10-19 13:09:47,292:INFO:self._variable_keys: {'target_param', 'fold_groups_param', 'exp_name_log', 'X_train', 'USI', 'gpu_n_jobs_param', 'X_test', 'log_plots_param', 'fold_shuffle_param', 'is_multiclass', 'gpu_param', 'idx', 'y_train', 'exp_id', 'X', 'logging_param', 'data', 'pipeline', 'y_test', 'n_jobs_param', '_ml_usecase', 'y', 'seed', 'html_param', 'fold_generator', '_available_plots', 'fix_imbalance', 'memory'}
2025-10-19 13:09:47,292:INFO:Checking environment
2025-10-19 13:09:47,292:INFO:python_version: 3.11.13
2025-10-19 13:09:47,292:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 13:09:47,292:INFO:machine: AMD64
2025-10-19 13:09:47,292:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 13:09:47,300:INFO:Memory: svmem(total=16856211456, available=1891008512, percent=88.8, used=14965202944, free=1891008512)
2025-10-19 13:09:47,300:INFO:Physical Core: 4
2025-10-19 13:09:47,300:INFO:Logical Core: 8
2025-10-19 13:09:47,300:INFO:Checking libraries
2025-10-19 13:09:47,300:INFO:System:
2025-10-19 13:09:47,300:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 13:09:47,300:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 13:09:47,300:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 13:09:47,300:INFO:PyCaret required dependencies:
2025-10-19 13:09:48,270:INFO:                 pip: 25.2
2025-10-19 13:09:48,270:INFO:          setuptools: 80.9.0
2025-10-19 13:09:48,270:INFO:             pycaret: 3.3.2
2025-10-19 13:09:48,270:INFO:             IPython: 9.6.0
2025-10-19 13:09:48,270:INFO:          ipywidgets: 8.1.7
2025-10-19 13:09:48,270:INFO:                tqdm: 4.67.1
2025-10-19 13:09:48,270:INFO:               numpy: 1.26.4
2025-10-19 13:09:48,270:INFO:              pandas: 2.1.4
2025-10-19 13:09:48,270:INFO:              jinja2: 3.1.6
2025-10-19 13:09:48,271:INFO:               scipy: 1.11.4
2025-10-19 13:09:48,271:INFO:              joblib: 1.3.2
2025-10-19 13:09:48,271:INFO:             sklearn: 1.4.2
2025-10-19 13:09:48,271:INFO:                pyod: 2.0.5
2025-10-19 13:09:48,271:INFO:            imblearn: 0.14.0
2025-10-19 13:09:48,271:INFO:   category_encoders: 2.7.0
2025-10-19 13:09:48,271:INFO:            lightgbm: 4.6.0
2025-10-19 13:09:48,271:INFO:               numba: 0.61.0
2025-10-19 13:09:48,271:INFO:            requests: 2.32.5
2025-10-19 13:09:48,271:INFO:          matplotlib: 3.7.5
2025-10-19 13:09:48,271:INFO:          scikitplot: 0.3.7
2025-10-19 13:09:48,271:INFO:         yellowbrick: 1.5
2025-10-19 13:09:48,271:INFO:              plotly: 5.24.1
2025-10-19 13:09:48,271:INFO:    plotly-resampler: Not installed
2025-10-19 13:09:48,271:INFO:             kaleido: 1.1.0
2025-10-19 13:09:48,271:INFO:           schemdraw: 0.15
2025-10-19 13:09:48,271:INFO:         statsmodels: 0.14.5
2025-10-19 13:09:48,271:INFO:              sktime: 0.26.0
2025-10-19 13:09:48,271:INFO:               tbats: 1.1.3
2025-10-19 13:09:48,271:INFO:            pmdarima: 2.0.4
2025-10-19 13:09:48,271:INFO:              psutil: 7.1.0
2025-10-19 13:09:48,271:INFO:          markupsafe: 3.0.3
2025-10-19 13:09:48,271:INFO:             pickle5: Not installed
2025-10-19 13:09:48,271:INFO:         cloudpickle: 3.1.1
2025-10-19 13:09:48,271:INFO:         deprecation: 2.1.0
2025-10-19 13:09:48,271:INFO:              xxhash: 3.6.0
2025-10-19 13:09:48,271:INFO:           wurlitzer: Not installed
2025-10-19 13:09:48,271:INFO:PyCaret optional dependencies:
2025-10-19 13:09:53,448:INFO:                shap: 0.44.1
2025-10-19 13:09:53,448:INFO:           interpret: 0.7.3
2025-10-19 13:09:53,448:INFO:                umap: 0.5.7
2025-10-19 13:09:53,448:INFO:     ydata_profiling: 4.17.0
2025-10-19 13:09:53,449:INFO:  explainerdashboard: 0.5.1
2025-10-19 13:09:53,449:INFO:             autoviz: Not installed
2025-10-19 13:09:53,449:INFO:           fairlearn: 0.7.0
2025-10-19 13:09:53,449:INFO:          deepchecks: Not installed
2025-10-19 13:09:53,449:INFO:             xgboost: Not installed
2025-10-19 13:09:53,449:INFO:            catboost: 1.2.8
2025-10-19 13:09:53,449:INFO:              kmodes: 0.12.2
2025-10-19 13:09:53,449:INFO:             mlxtend: 0.23.4
2025-10-19 13:09:53,449:INFO:       statsforecast: 1.5.0
2025-10-19 13:09:53,449:INFO:        tune_sklearn: Not installed
2025-10-19 13:09:53,449:INFO:                 ray: Not installed
2025-10-19 13:09:53,449:INFO:            hyperopt: 0.2.7
2025-10-19 13:09:53,449:INFO:              optuna: 4.5.0
2025-10-19 13:09:53,449:INFO:               skopt: 0.10.2
2025-10-19 13:09:53,449:INFO:              mlflow: 3.5.0
2025-10-19 13:09:53,450:INFO:              gradio: 5.49.1
2025-10-19 13:09:53,450:INFO:             fastapi: 0.119.0
2025-10-19 13:09:53,450:INFO:             uvicorn: 0.38.0
2025-10-19 13:09:53,450:INFO:              m2cgen: 0.10.0
2025-10-19 13:09:53,450:INFO:           evidently: 0.4.40
2025-10-19 13:09:53,450:INFO:               fugue: 0.8.7
2025-10-19 13:09:53,450:INFO:           streamlit: Not installed
2025-10-19 13:09:53,450:INFO:             prophet: Not installed
2025-10-19 13:09:53,450:INFO:None
2025-10-19 13:09:53,450:INFO:Set up data.
2025-10-19 13:09:53,617:INFO:Set up folding strategy.
2025-10-19 13:09:53,787:INFO:Set up train/test split.
2025-10-19 13:09:53,954:INFO:Set up index.
2025-10-19 13:09:53,965:INFO:Assigning column types.
2025-10-19 13:09:54,167:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 13:09:54,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 13:09:54,208:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 13:09:54,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:09:54,245:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:09:54,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 13:09:54,310:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 13:09:54,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:09:54,337:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:09:54,338:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 13:09:54,377:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 13:09:54,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:09:54,404:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:09:54,452:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 13:09:54,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:09:54,474:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:09:54,475:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 13:09:54,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:09:54,547:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:09:54,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:09:54,618:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:09:54,622:INFO:Preparing preprocessing pipeline...
2025-10-19 13:09:54,653:INFO:Set up simple imputation.
2025-10-19 13:09:54,818:INFO:Set up encoding of ordinal features.
2025-10-19 13:09:54,883:INFO:Set up encoding of categorical features.
2025-10-19 13:09:54,889:INFO:Set up removing multicollinearity.
2025-10-19 13:09:54,922:INFO:Set up column name cleaning.
2025-10-19 13:09:59,572:INFO:Finished creating preprocessing pipeline.
2025-10-19 13:09:59,589:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 13:09:59,589:INFO:Creating final display dataframe.
2025-10-19 13:10:02,389:INFO:Setup _display_container:                     Description             Value
0                    Session id              5462
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (63955, 28)
4        Transformed data shape       (63955, 96)
5   Transformed train set shape       (44768, 96)
6    Transformed test set shape       (19187, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              1125
2025-10-19 13:10:02,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:10:02,477:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:10:02,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:10:02,547:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:10:02,548:INFO:setup() successfully completed in 15.31s...............
2025-10-19 13:10:02,548:INFO:Initializing compare_models()
2025-10-19 13:10:02,548:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 13:10:02,548:INFO:Checking exceptions
2025-10-19 13:10:02,694:INFO:Preparing display monitor
2025-10-19 13:10:02,728:INFO:Initializing Logistic Regression
2025-10-19 13:10:02,729:INFO:Total runtime is 1.6589959462483723e-05 minutes
2025-10-19 13:10:02,733:INFO:SubProcess create_model() called ==================================
2025-10-19 13:10:02,738:INFO:Initializing create_model()
2025-10-19 13:10:02,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:10:02,739:INFO:Checking exceptions
2025-10-19 13:10:02,739:INFO:Importing libraries
2025-10-19 13:10:02,739:INFO:Copying training dataset
2025-10-19 13:10:03,008:INFO:Defining folds
2025-10-19 13:10:03,009:INFO:Declaring metric variables
2025-10-19 13:10:03,011:INFO:Importing untrained model
2025-10-19 13:10:03,015:INFO:Logistic Regression Imported successfully
2025-10-19 13:10:03,023:INFO:Starting cross validation
2025-10-19 13:10:03,029:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:10:11,785:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 13:10:20,259:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 13:10:29,012:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 13:10:37,746:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 13:10:46,219:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 13:10:46,482:INFO:Calculating mean and std
2025-10-19 13:10:46,484:INFO:Creating metrics dataframe
2025-10-19 13:10:46,485:INFO:Uploading results into container
2025-10-19 13:10:46,486:INFO:Uploading model into container now
2025-10-19 13:10:46,486:INFO:_master_model_container: 1
2025-10-19 13:10:46,486:INFO:_display_container: 2
2025-10-19 13:10:46,486:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5462, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 13:10:46,487:INFO:create_model() successfully completed......................................
2025-10-19 13:10:46,669:INFO:SubProcess create_model() end ==================================
2025-10-19 13:10:46,669:INFO:Creating metrics dataframe
2025-10-19 13:10:46,678:INFO:Initializing K Neighbors Classifier
2025-10-19 13:10:46,679:INFO:Total runtime is 0.7325198650360107 minutes
2025-10-19 13:10:46,682:INFO:SubProcess create_model() called ==================================
2025-10-19 13:10:46,684:INFO:Initializing create_model()
2025-10-19 13:10:46,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:10:46,684:INFO:Checking exceptions
2025-10-19 13:10:46,684:INFO:Importing libraries
2025-10-19 13:10:46,684:INFO:Copying training dataset
2025-10-19 13:10:46,903:INFO:Defining folds
2025-10-19 13:10:46,903:INFO:Declaring metric variables
2025-10-19 13:10:46,909:INFO:Importing untrained model
2025-10-19 13:10:46,913:INFO:K Neighbors Classifier Imported successfully
2025-10-19 13:10:46,920:INFO:Starting cross validation
2025-10-19 13:10:46,927:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:11:10,391:INFO:Calculating mean and std
2025-10-19 13:11:10,393:INFO:Creating metrics dataframe
2025-10-19 13:11:10,396:INFO:Uploading results into container
2025-10-19 13:11:10,397:INFO:Uploading model into container now
2025-10-19 13:11:10,398:INFO:_master_model_container: 2
2025-10-19 13:11:10,398:INFO:_display_container: 2
2025-10-19 13:11:10,398:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 13:11:10,399:INFO:create_model() successfully completed......................................
2025-10-19 13:11:10,630:INFO:SubProcess create_model() end ==================================
2025-10-19 13:11:10,630:INFO:Creating metrics dataframe
2025-10-19 13:11:10,636:INFO:Initializing Naive Bayes
2025-10-19 13:11:10,636:INFO:Total runtime is 1.1317996422449748 minutes
2025-10-19 13:11:10,644:INFO:SubProcess create_model() called ==================================
2025-10-19 13:11:10,645:INFO:Initializing create_model()
2025-10-19 13:11:10,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:11:10,646:INFO:Checking exceptions
2025-10-19 13:11:10,646:INFO:Importing libraries
2025-10-19 13:11:10,646:INFO:Copying training dataset
2025-10-19 13:11:10,933:INFO:Defining folds
2025-10-19 13:11:10,934:INFO:Declaring metric variables
2025-10-19 13:11:10,938:INFO:Importing untrained model
2025-10-19 13:11:10,942:INFO:Naive Bayes Imported successfully
2025-10-19 13:11:10,950:INFO:Starting cross validation
2025-10-19 13:11:10,954:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:11:13,563:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:11:16,150:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:11:19,569:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:11:22,307:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:11:24,936:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:11:24,954:INFO:Calculating mean and std
2025-10-19 13:11:24,955:INFO:Creating metrics dataframe
2025-10-19 13:11:24,957:INFO:Uploading results into container
2025-10-19 13:11:24,959:INFO:Uploading model into container now
2025-10-19 13:11:24,960:INFO:_master_model_container: 3
2025-10-19 13:11:24,960:INFO:_display_container: 2
2025-10-19 13:11:24,960:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 13:11:24,961:INFO:create_model() successfully completed......................................
2025-10-19 13:11:25,140:INFO:SubProcess create_model() end ==================================
2025-10-19 13:11:25,140:INFO:Creating metrics dataframe
2025-10-19 13:11:25,150:INFO:Initializing Decision Tree Classifier
2025-10-19 13:11:25,150:INFO:Total runtime is 1.3736875454584758 minutes
2025-10-19 13:11:25,154:INFO:SubProcess create_model() called ==================================
2025-10-19 13:11:25,155:INFO:Initializing create_model()
2025-10-19 13:11:25,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:11:25,155:INFO:Checking exceptions
2025-10-19 13:11:25,155:INFO:Importing libraries
2025-10-19 13:11:25,155:INFO:Copying training dataset
2025-10-19 13:11:25,398:INFO:Defining folds
2025-10-19 13:11:25,398:INFO:Declaring metric variables
2025-10-19 13:11:25,403:INFO:Importing untrained model
2025-10-19 13:11:25,408:INFO:Decision Tree Classifier Imported successfully
2025-10-19 13:11:25,417:INFO:Starting cross validation
2025-10-19 13:11:25,421:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:11:42,553:INFO:Calculating mean and std
2025-10-19 13:11:42,554:INFO:Creating metrics dataframe
2025-10-19 13:11:42,556:INFO:Uploading results into container
2025-10-19 13:11:42,556:INFO:Uploading model into container now
2025-10-19 13:11:42,556:INFO:_master_model_container: 4
2025-10-19 13:11:42,557:INFO:_display_container: 2
2025-10-19 13:11:42,557:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5462, splitter='best')
2025-10-19 13:11:42,557:INFO:create_model() successfully completed......................................
2025-10-19 13:11:42,732:INFO:SubProcess create_model() end ==================================
2025-10-19 13:11:42,732:INFO:Creating metrics dataframe
2025-10-19 13:11:42,739:INFO:Initializing SVM - Linear Kernel
2025-10-19 13:11:42,740:INFO:Total runtime is 1.666869652271271 minutes
2025-10-19 13:11:42,746:INFO:SubProcess create_model() called ==================================
2025-10-19 13:11:42,748:INFO:Initializing create_model()
2025-10-19 13:11:42,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:11:42,748:INFO:Checking exceptions
2025-10-19 13:11:42,748:INFO:Importing libraries
2025-10-19 13:11:42,748:INFO:Copying training dataset
2025-10-19 13:11:42,956:INFO:Defining folds
2025-10-19 13:11:42,956:INFO:Declaring metric variables
2025-10-19 13:11:42,960:INFO:Importing untrained model
2025-10-19 13:11:42,966:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 13:11:42,972:INFO:Starting cross validation
2025-10-19 13:11:42,979:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:12:00,837:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:12:07,372:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:12:13,027:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:12:22,417:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:12:22,439:INFO:Calculating mean and std
2025-10-19 13:12:22,447:INFO:Creating metrics dataframe
2025-10-19 13:12:22,452:INFO:Uploading results into container
2025-10-19 13:12:22,453:INFO:Uploading model into container now
2025-10-19 13:12:22,454:INFO:_master_model_container: 5
2025-10-19 13:12:22,454:INFO:_display_container: 2
2025-10-19 13:12:22,454:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=5462, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 13:12:22,454:INFO:create_model() successfully completed......................................
2025-10-19 13:12:22,766:INFO:SubProcess create_model() end ==================================
2025-10-19 13:12:22,766:INFO:Creating metrics dataframe
2025-10-19 13:12:22,774:INFO:Initializing Ridge Classifier
2025-10-19 13:12:22,774:INFO:Total runtime is 2.334100635846456 minutes
2025-10-19 13:12:22,778:INFO:SubProcess create_model() called ==================================
2025-10-19 13:12:22,780:INFO:Initializing create_model()
2025-10-19 13:12:22,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:12:22,780:INFO:Checking exceptions
2025-10-19 13:12:22,781:INFO:Importing libraries
2025-10-19 13:12:22,781:INFO:Copying training dataset
2025-10-19 13:12:23,024:INFO:Defining folds
2025-10-19 13:12:23,024:INFO:Declaring metric variables
2025-10-19 13:12:23,027:INFO:Importing untrained model
2025-10-19 13:12:23,032:INFO:Ridge Classifier Imported successfully
2025-10-19 13:12:23,039:INFO:Starting cross validation
2025-10-19 13:12:23,042:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:12:37,548:INFO:Calculating mean and std
2025-10-19 13:12:37,549:INFO:Creating metrics dataframe
2025-10-19 13:12:37,551:INFO:Uploading results into container
2025-10-19 13:12:37,551:INFO:Uploading model into container now
2025-10-19 13:12:37,552:INFO:_master_model_container: 6
2025-10-19 13:12:37,552:INFO:_display_container: 2
2025-10-19 13:12:37,552:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001)
2025-10-19 13:12:37,552:INFO:create_model() successfully completed......................................
2025-10-19 13:12:37,721:INFO:SubProcess create_model() end ==================================
2025-10-19 13:12:37,722:INFO:Creating metrics dataframe
2025-10-19 13:12:37,730:INFO:Initializing Random Forest Classifier
2025-10-19 13:12:37,730:INFO:Total runtime is 2.5833650310834253 minutes
2025-10-19 13:12:37,734:INFO:SubProcess create_model() called ==================================
2025-10-19 13:12:37,735:INFO:Initializing create_model()
2025-10-19 13:12:37,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:12:37,736:INFO:Checking exceptions
2025-10-19 13:12:37,736:INFO:Importing libraries
2025-10-19 13:12:37,736:INFO:Copying training dataset
2025-10-19 13:12:37,972:INFO:Defining folds
2025-10-19 13:12:37,973:INFO:Declaring metric variables
2025-10-19 13:12:37,976:INFO:Importing untrained model
2025-10-19 13:12:37,982:INFO:Random Forest Classifier Imported successfully
2025-10-19 13:12:37,989:INFO:Starting cross validation
2025-10-19 13:12:37,992:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:13:16,532:INFO:Calculating mean and std
2025-10-19 13:13:16,534:INFO:Creating metrics dataframe
2025-10-19 13:13:16,536:INFO:Uploading results into container
2025-10-19 13:13:16,537:INFO:Uploading model into container now
2025-10-19 13:13:16,537:INFO:_master_model_container: 7
2025-10-19 13:13:16,537:INFO:_display_container: 2
2025-10-19 13:13:16,538:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=5462, verbose=0,
                       warm_start=False)
2025-10-19 13:13:16,538:INFO:create_model() successfully completed......................................
2025-10-19 13:13:16,712:INFO:SubProcess create_model() end ==================================
2025-10-19 13:13:16,712:INFO:Creating metrics dataframe
2025-10-19 13:13:16,721:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 13:13:16,721:INFO:Total runtime is 3.2332121531168623 minutes
2025-10-19 13:13:16,724:INFO:SubProcess create_model() called ==================================
2025-10-19 13:13:16,725:INFO:Initializing create_model()
2025-10-19 13:13:16,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:13:16,725:INFO:Checking exceptions
2025-10-19 13:13:16,725:INFO:Importing libraries
2025-10-19 13:13:16,725:INFO:Copying training dataset
2025-10-19 13:13:16,943:INFO:Defining folds
2025-10-19 13:13:16,943:INFO:Declaring metric variables
2025-10-19 13:13:16,946:INFO:Importing untrained model
2025-10-19 13:13:16,953:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 13:13:16,961:INFO:Starting cross validation
2025-10-19 13:13:16,965:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:13:19,406:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 13:13:21,913:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 13:13:24,464:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 13:13:27,054:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 13:13:29,551:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 13:13:29,919:INFO:Calculating mean and std
2025-10-19 13:13:29,920:INFO:Creating metrics dataframe
2025-10-19 13:13:29,922:INFO:Uploading results into container
2025-10-19 13:13:29,923:INFO:Uploading model into container now
2025-10-19 13:13:29,923:INFO:_master_model_container: 8
2025-10-19 13:13:29,923:INFO:_display_container: 2
2025-10-19 13:13:29,924:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 13:13:29,924:INFO:create_model() successfully completed......................................
2025-10-19 13:13:30,086:INFO:SubProcess create_model() end ==================================
2025-10-19 13:13:30,086:INFO:Creating metrics dataframe
2025-10-19 13:13:30,094:INFO:Initializing Ada Boost Classifier
2025-10-19 13:13:30,094:INFO:Total runtime is 3.4560904105504355 minutes
2025-10-19 13:13:30,100:INFO:SubProcess create_model() called ==================================
2025-10-19 13:13:30,102:INFO:Initializing create_model()
2025-10-19 13:13:30,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:13:30,102:INFO:Checking exceptions
2025-10-19 13:13:30,102:INFO:Importing libraries
2025-10-19 13:13:30,102:INFO:Copying training dataset
2025-10-19 13:13:30,297:INFO:Defining folds
2025-10-19 13:13:30,297:INFO:Declaring metric variables
2025-10-19 13:13:30,302:INFO:Importing untrained model
2025-10-19 13:13:30,306:INFO:Ada Boost Classifier Imported successfully
2025-10-19 13:13:30,313:INFO:Starting cross validation
2025-10-19 13:13:30,318:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:13:32,327:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:13:37,453:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:13:42,475:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:13:47,571:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:13:52,871:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:13:56,074:INFO:Calculating mean and std
2025-10-19 13:13:56,075:INFO:Creating metrics dataframe
2025-10-19 13:13:56,076:INFO:Uploading results into container
2025-10-19 13:13:56,077:INFO:Uploading model into container now
2025-10-19 13:13:56,077:INFO:_master_model_container: 9
2025-10-19 13:13:56,077:INFO:_display_container: 2
2025-10-19 13:13:56,077:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462)
2025-10-19 13:13:56,078:INFO:create_model() successfully completed......................................
2025-10-19 13:13:56,252:INFO:SubProcess create_model() end ==================================
2025-10-19 13:13:56,252:INFO:Creating metrics dataframe
2025-10-19 13:13:56,262:INFO:Initializing Gradient Boosting Classifier
2025-10-19 13:13:56,263:INFO:Total runtime is 3.8922505815823873 minutes
2025-10-19 13:13:56,267:INFO:SubProcess create_model() called ==================================
2025-10-19 13:13:56,270:INFO:Initializing create_model()
2025-10-19 13:13:56,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:13:56,270:INFO:Checking exceptions
2025-10-19 13:13:56,270:INFO:Importing libraries
2025-10-19 13:13:56,270:INFO:Copying training dataset
2025-10-19 13:13:56,505:INFO:Defining folds
2025-10-19 13:13:56,505:INFO:Declaring metric variables
2025-10-19 13:13:56,509:INFO:Importing untrained model
2025-10-19 13:13:56,513:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 13:13:56,523:INFO:Starting cross validation
2025-10-19 13:13:56,527:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:14:46,994:INFO:Calculating mean and std
2025-10-19 13:14:46,995:INFO:Creating metrics dataframe
2025-10-19 13:14:46,997:INFO:Uploading results into container
2025-10-19 13:14:46,998:INFO:Uploading model into container now
2025-10-19 13:14:46,999:INFO:_master_model_container: 10
2025-10-19 13:14:46,999:INFO:_display_container: 2
2025-10-19 13:14:47,000:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 13:14:47,000:INFO:create_model() successfully completed......................................
2025-10-19 13:14:47,155:INFO:SubProcess create_model() end ==================================
2025-10-19 13:14:47,157:INFO:Creating metrics dataframe
2025-10-19 13:14:47,164:INFO:Initializing Linear Discriminant Analysis
2025-10-19 13:14:47,165:INFO:Total runtime is 4.74060648282369 minutes
2025-10-19 13:14:47,169:INFO:SubProcess create_model() called ==================================
2025-10-19 13:14:47,170:INFO:Initializing create_model()
2025-10-19 13:14:47,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:14:47,171:INFO:Checking exceptions
2025-10-19 13:14:47,171:INFO:Importing libraries
2025-10-19 13:14:47,171:INFO:Copying training dataset
2025-10-19 13:14:47,389:INFO:Defining folds
2025-10-19 13:14:47,389:INFO:Declaring metric variables
2025-10-19 13:14:47,392:INFO:Importing untrained model
2025-10-19 13:14:47,397:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 13:14:47,405:INFO:Starting cross validation
2025-10-19 13:14:47,409:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:15:01,044:INFO:Calculating mean and std
2025-10-19 13:15:01,045:INFO:Creating metrics dataframe
2025-10-19 13:15:01,047:INFO:Uploading results into container
2025-10-19 13:15:01,049:INFO:Uploading model into container now
2025-10-19 13:15:01,049:INFO:_master_model_container: 11
2025-10-19 13:15:01,049:INFO:_display_container: 2
2025-10-19 13:15:01,050:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 13:15:01,050:INFO:create_model() successfully completed......................................
2025-10-19 13:15:01,218:INFO:SubProcess create_model() end ==================================
2025-10-19 13:15:01,218:INFO:Creating metrics dataframe
2025-10-19 13:15:01,227:INFO:Initializing Extra Trees Classifier
2025-10-19 13:15:01,228:INFO:Total runtime is 4.97499936024348 minutes
2025-10-19 13:15:01,230:INFO:SubProcess create_model() called ==================================
2025-10-19 13:15:01,232:INFO:Initializing create_model()
2025-10-19 13:15:01,232:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:15:01,232:INFO:Checking exceptions
2025-10-19 13:15:01,233:INFO:Importing libraries
2025-10-19 13:15:01,233:INFO:Copying training dataset
2025-10-19 13:15:01,471:INFO:Defining folds
2025-10-19 13:15:01,471:INFO:Declaring metric variables
2025-10-19 13:15:01,477:INFO:Importing untrained model
2025-10-19 13:15:01,483:INFO:Extra Trees Classifier Imported successfully
2025-10-19 13:15:01,493:INFO:Starting cross validation
2025-10-19 13:15:01,499:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:15:46,421:INFO:Calculating mean and std
2025-10-19 13:15:46,424:INFO:Creating metrics dataframe
2025-10-19 13:15:46,426:INFO:Uploading results into container
2025-10-19 13:15:46,427:INFO:Uploading model into container now
2025-10-19 13:15:46,427:INFO:_master_model_container: 12
2025-10-19 13:15:46,428:INFO:_display_container: 2
2025-10-19 13:15:46,428:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=5462, verbose=0,
                     warm_start=False)
2025-10-19 13:15:46,428:INFO:create_model() successfully completed......................................
2025-10-19 13:15:46,595:INFO:SubProcess create_model() end ==================================
2025-10-19 13:15:46,596:INFO:Creating metrics dataframe
2025-10-19 13:15:46,604:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 13:15:46,604:INFO:Total runtime is 5.731257212162018 minutes
2025-10-19 13:15:46,607:INFO:SubProcess create_model() called ==================================
2025-10-19 13:15:46,608:INFO:Initializing create_model()
2025-10-19 13:15:46,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:15:46,609:INFO:Checking exceptions
2025-10-19 13:15:46,609:INFO:Importing libraries
2025-10-19 13:15:46,609:INFO:Copying training dataset
2025-10-19 13:15:46,818:INFO:Defining folds
2025-10-19 13:15:46,818:INFO:Declaring metric variables
2025-10-19 13:15:46,822:INFO:Importing untrained model
2025-10-19 13:15:46,830:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 13:15:46,837:INFO:Starting cross validation
2025-10-19 13:15:46,841:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:15:49,180:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:15:49,183:INFO:[LightGBM] [Info] Number of positive: 7366, number of negative: 28448
2025-10-19 13:15:49,203:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007954 seconds.
2025-10-19 13:15:49,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:15:49,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:15:49,204:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 13:15:49,204:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 13:15:49,205:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205674 -> initscore=-1.351203
2025-10-19 13:15:49,205:INFO:[LightGBM] [Info] Start training from score -1.351203
2025-10-19 13:15:52,037:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:15:52,040:INFO:[LightGBM] [Info] Number of positive: 7327, number of negative: 28487
2025-10-19 13:15:52,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007091 seconds.
2025-10-19 13:15:52,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:15:52,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:15:52,058:INFO:[LightGBM] [Info] Total Bins 1406
2025-10-19 13:15:52,059:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 13:15:52,059:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204585 -> initscore=-1.357882
2025-10-19 13:15:52,060:INFO:[LightGBM] [Info] Start training from score -1.357882
2025-10-19 13:15:54,980:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:15:54,983:INFO:[LightGBM] [Info] Number of positive: 7298, number of negative: 28516
2025-10-19 13:15:55,001:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007003 seconds.
2025-10-19 13:15:55,001:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:15:55,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:15:55,001:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 13:15:55,001:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 13:15:55,002:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203775 -> initscore=-1.362865
2025-10-19 13:15:55,002:INFO:[LightGBM] [Info] Start training from score -1.362865
2025-10-19 13:15:57,881:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:15:57,883:INFO:[LightGBM] [Info] Number of positive: 7389, number of negative: 28426
2025-10-19 13:15:57,898:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005628 seconds.
2025-10-19 13:15:57,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:15:57,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:15:57,899:INFO:[LightGBM] [Info] Total Bins 1402
2025-10-19 13:15:57,899:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 13:15:57,899:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206310 -> initscore=-1.347312
2025-10-19 13:15:57,899:INFO:[LightGBM] [Info] Start training from score -1.347312
2025-10-19 13:16:00,597:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:16:00,599:INFO:[LightGBM] [Info] Number of positive: 7396, number of negative: 28419
2025-10-19 13:16:00,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005901 seconds.
2025-10-19 13:16:00,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:16:00,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:16:00,615:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 13:16:00,615:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 13:16:00,615:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206506 -> initscore=-1.346119
2025-10-19 13:16:00,615:INFO:[LightGBM] [Info] Start training from score -1.346119
2025-10-19 13:16:01,415:INFO:Calculating mean and std
2025-10-19 13:16:01,416:INFO:Creating metrics dataframe
2025-10-19 13:16:01,418:INFO:Uploading results into container
2025-10-19 13:16:01,418:INFO:Uploading model into container now
2025-10-19 13:16:01,418:INFO:_master_model_container: 13
2025-10-19 13:16:01,418:INFO:_display_container: 2
2025-10-19 13:16:01,419:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=5462, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 13:16:01,419:INFO:create_model() successfully completed......................................
2025-10-19 13:16:01,569:INFO:SubProcess create_model() end ==================================
2025-10-19 13:16:01,570:INFO:Creating metrics dataframe
2025-10-19 13:16:01,581:INFO:Initializing CatBoost Classifier
2025-10-19 13:16:01,582:INFO:Total runtime is 5.980898479620616 minutes
2025-10-19 13:16:01,585:INFO:SubProcess create_model() called ==================================
2025-10-19 13:16:01,586:INFO:Initializing create_model()
2025-10-19 13:16:01,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:16:01,586:INFO:Checking exceptions
2025-10-19 13:16:01,586:INFO:Importing libraries
2025-10-19 13:16:01,586:INFO:Copying training dataset
2025-10-19 13:16:01,777:INFO:Defining folds
2025-10-19 13:16:01,777:INFO:Declaring metric variables
2025-10-19 13:16:01,781:INFO:Importing untrained model
2025-10-19 13:16:01,785:INFO:CatBoost Classifier Imported successfully
2025-10-19 13:16:01,793:INFO:Starting cross validation
2025-10-19 13:16:01,798:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:17:53,743:INFO:Calculating mean and std
2025-10-19 13:17:53,744:INFO:Creating metrics dataframe
2025-10-19 13:17:53,746:INFO:Uploading results into container
2025-10-19 13:17:53,748:INFO:Uploading model into container now
2025-10-19 13:17:53,748:INFO:_master_model_container: 14
2025-10-19 13:17:53,748:INFO:_display_container: 2
2025-10-19 13:17:53,748:INFO:<catboost.core.CatBoostClassifier object at 0x0000010C5E0E4810>
2025-10-19 13:17:53,749:INFO:create_model() successfully completed......................................
2025-10-19 13:17:53,905:INFO:SubProcess create_model() end ==================================
2025-10-19 13:17:53,906:INFO:Creating metrics dataframe
2025-10-19 13:17:53,915:INFO:Initializing Dummy Classifier
2025-10-19 13:17:53,916:INFO:Total runtime is 7.853127145767212 minutes
2025-10-19 13:17:53,919:INFO:SubProcess create_model() called ==================================
2025-10-19 13:17:53,921:INFO:Initializing create_model()
2025-10-19 13:17:53,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E142050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:17:53,921:INFO:Checking exceptions
2025-10-19 13:17:53,921:INFO:Importing libraries
2025-10-19 13:17:53,921:INFO:Copying training dataset
2025-10-19 13:17:54,145:INFO:Defining folds
2025-10-19 13:17:54,145:INFO:Declaring metric variables
2025-10-19 13:17:54,150:INFO:Importing untrained model
2025-10-19 13:17:54,154:INFO:Dummy Classifier Imported successfully
2025-10-19 13:17:54,162:INFO:Starting cross validation
2025-10-19 13:17:54,166:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:17:56,468:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:17:58,759:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:18:01,082:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:18:03,273:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:18:05,641:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 13:18:05,657:INFO:Calculating mean and std
2025-10-19 13:18:05,658:INFO:Creating metrics dataframe
2025-10-19 13:18:05,659:INFO:Uploading results into container
2025-10-19 13:18:05,660:INFO:Uploading model into container now
2025-10-19 13:18:05,660:INFO:_master_model_container: 15
2025-10-19 13:18:05,660:INFO:_display_container: 2
2025-10-19 13:18:05,660:INFO:DummyClassifier(constant=None, random_state=5462, strategy='prior')
2025-10-19 13:18:05,662:INFO:create_model() successfully completed......................................
2025-10-19 13:18:05,849:INFO:SubProcess create_model() end ==================================
2025-10-19 13:18:05,850:INFO:Creating metrics dataframe
2025-10-19 13:18:05,861:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 13:18:05,875:INFO:Initializing create_model()
2025-10-19 13:18:05,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:18:05,875:INFO:Checking exceptions
2025-10-19 13:18:05,877:INFO:Importing libraries
2025-10-19 13:18:05,877:INFO:Copying training dataset
2025-10-19 13:18:06,134:INFO:Defining folds
2025-10-19 13:18:06,134:INFO:Declaring metric variables
2025-10-19 13:18:06,134:INFO:Importing untrained model
2025-10-19 13:18:06,134:INFO:Declaring custom model
2025-10-19 13:18:06,136:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 13:18:06,139:INFO:Cross validation set to False
2025-10-19 13:18:06,140:INFO:Fitting Model
2025-10-19 13:18:18,930:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 13:18:18,930:INFO:create_model() successfully completed......................................
2025-10-19 13:18:19,089:INFO:Initializing create_model()
2025-10-19 13:18:19,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:18:19,090:INFO:Checking exceptions
2025-10-19 13:18:19,092:INFO:Importing libraries
2025-10-19 13:18:19,092:INFO:Copying training dataset
2025-10-19 13:18:19,277:INFO:Defining folds
2025-10-19 13:18:19,277:INFO:Declaring metric variables
2025-10-19 13:18:19,277:INFO:Importing untrained model
2025-10-19 13:18:19,277:INFO:Declaring custom model
2025-10-19 13:18:19,278:INFO:Ridge Classifier Imported successfully
2025-10-19 13:18:19,281:INFO:Cross validation set to False
2025-10-19 13:18:19,281:INFO:Fitting Model
2025-10-19 13:18:21,918:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001)
2025-10-19 13:18:21,918:INFO:create_model() successfully completed......................................
2025-10-19 13:18:22,102:INFO:Initializing create_model()
2025-10-19 13:18:22,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:18:22,103:INFO:Checking exceptions
2025-10-19 13:18:22,105:INFO:Importing libraries
2025-10-19 13:18:22,106:INFO:Copying training dataset
2025-10-19 13:18:22,305:INFO:Defining folds
2025-10-19 13:18:22,305:INFO:Declaring metric variables
2025-10-19 13:18:22,305:INFO:Importing untrained model
2025-10-19 13:18:22,305:INFO:Declaring custom model
2025-10-19 13:18:22,306:INFO:Ada Boost Classifier Imported successfully
2025-10-19 13:18:22,309:INFO:Cross validation set to False
2025-10-19 13:18:22,310:INFO:Fitting Model
2025-10-19 13:18:24,953:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:18:28,163:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462)
2025-10-19 13:18:28,163:INFO:create_model() successfully completed......................................
2025-10-19 13:18:28,458:INFO:_master_model_container: 15
2025-10-19 13:18:28,458:INFO:_display_container: 2
2025-10-19 13:18:28,459:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462)]
2025-10-19 13:18:28,459:INFO:compare_models() successfully completed......................................
2025-10-19 13:18:28,461:INFO:Initializing tune_model()
2025-10-19 13:18:28,462:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 13:18:28,462:INFO:Checking exceptions
2025-10-19 13:18:28,622:INFO:Copying training dataset
2025-10-19 13:18:28,808:INFO:Checking base model
2025-10-19 13:18:28,809:INFO:Base model : Gradient Boosting Classifier
2025-10-19 13:18:28,813:INFO:Declaring metric variables
2025-10-19 13:18:28,818:INFO:Defining Hyperparameters
2025-10-19 13:18:29,104:INFO:Tuning with n_jobs=1
2025-10-19 13:18:29,104:INFO:Initializing RandomizedSearchCV
2025-10-19 13:23:47,345:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 110, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.15}
2025-10-19 13:23:47,346:INFO:Hyperparameter search completed
2025-10-19 13:23:47,346:INFO:SubProcess create_model() called ==================================
2025-10-19 13:23:47,349:INFO:Initializing create_model()
2025-10-19 13:23:47,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C4EE96090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'n_estimators': 110, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 1, 'learning_rate': 0.15})
2025-10-19 13:23:47,349:INFO:Checking exceptions
2025-10-19 13:23:47,350:INFO:Importing libraries
2025-10-19 13:23:47,350:INFO:Copying training dataset
2025-10-19 13:23:47,554:INFO:Defining folds
2025-10-19 13:23:47,554:INFO:Declaring metric variables
2025-10-19 13:23:47,559:INFO:Importing untrained model
2025-10-19 13:23:47,560:INFO:Declaring custom model
2025-10-19 13:23:47,564:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 13:23:47,571:INFO:Starting cross validation
2025-10-19 13:23:47,576:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:24:12,388:INFO:Calculating mean and std
2025-10-19 13:24:12,389:INFO:Creating metrics dataframe
2025-10-19 13:24:12,395:INFO:Finalizing model
2025-10-19 13:24:18,546:INFO:Uploading results into container
2025-10-19 13:24:18,548:INFO:Uploading model into container now
2025-10-19 13:24:18,549:INFO:_master_model_container: 16
2025-10-19 13:24:18,549:INFO:_display_container: 3
2025-10-19 13:24:18,549:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=110, n_iter_no_change=None,
                           random_state=5462, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 13:24:18,549:INFO:create_model() successfully completed......................................
2025-10-19 13:24:18,738:INFO:SubProcess create_model() end ==================================
2025-10-19 13:24:18,739:INFO:choose_better activated
2025-10-19 13:24:18,743:INFO:SubProcess create_model() called ==================================
2025-10-19 13:24:18,745:INFO:Initializing create_model()
2025-10-19 13:24:18,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:24:18,745:INFO:Checking exceptions
2025-10-19 13:24:18,746:INFO:Importing libraries
2025-10-19 13:24:18,746:INFO:Copying training dataset
2025-10-19 13:24:18,954:INFO:Defining folds
2025-10-19 13:24:18,954:INFO:Declaring metric variables
2025-10-19 13:24:18,954:INFO:Importing untrained model
2025-10-19 13:24:18,954:INFO:Declaring custom model
2025-10-19 13:24:18,955:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 13:24:18,955:INFO:Starting cross validation
2025-10-19 13:24:18,960:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:25:11,825:INFO:Calculating mean and std
2025-10-19 13:25:11,825:INFO:Creating metrics dataframe
2025-10-19 13:25:11,828:INFO:Finalizing model
2025-10-19 13:25:24,169:INFO:Uploading results into container
2025-10-19 13:25:24,169:INFO:Uploading model into container now
2025-10-19 13:25:24,170:INFO:_master_model_container: 17
2025-10-19 13:25:24,170:INFO:_display_container: 4
2025-10-19 13:25:24,170:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 13:25:24,170:INFO:create_model() successfully completed......................................
2025-10-19 13:25:24,324:INFO:SubProcess create_model() end ==================================
2025-10-19 13:25:24,326:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9317
2025-10-19 13:25:24,326:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=5,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=110, n_iter_no_change=None,
                           random_state=5462, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.931
2025-10-19 13:25:24,326:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-19 13:25:24,326:INFO:choose_better completed
2025-10-19 13:25:24,326:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 13:25:24,336:INFO:_master_model_container: 17
2025-10-19 13:25:24,337:INFO:_display_container: 3
2025-10-19 13:25:24,337:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 13:25:24,337:INFO:tune_model() successfully completed......................................
2025-10-19 13:25:24,497:INFO:Initializing tune_model()
2025-10-19 13:25:24,497:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 13:25:24,498:INFO:Checking exceptions
2025-10-19 13:25:24,587:INFO:Copying training dataset
2025-10-19 13:25:24,731:INFO:Checking base model
2025-10-19 13:25:24,732:INFO:Base model : Ridge Classifier
2025-10-19 13:25:24,736:INFO:Declaring metric variables
2025-10-19 13:25:24,738:INFO:Defining Hyperparameters
2025-10-19 13:25:24,895:INFO:Tuning with n_jobs=1
2025-10-19 13:25:24,895:INFO:Initializing RandomizedSearchCV
2025-10-19 13:27:07,122:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.34768e-17): result may not be accurate.

2025-10-19 13:27:09,380:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.33099e-17): result may not be accurate.

2025-10-19 13:27:11,640:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.33874e-17): result may not be accurate.

2025-10-19 13:27:13,799:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.30804e-17): result may not be accurate.

2025-10-19 13:27:16,006:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.3585e-17): result may not be accurate.

2025-10-19 13:27:27,528:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 9.17}
2025-10-19 13:27:27,529:INFO:Hyperparameter search completed
2025-10-19 13:27:27,529:INFO:SubProcess create_model() called ==================================
2025-10-19 13:27:27,529:INFO:Initializing create_model()
2025-10-19 13:27:27,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C4FEAE290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 9.17})
2025-10-19 13:27:27,530:INFO:Checking exceptions
2025-10-19 13:27:27,530:INFO:Importing libraries
2025-10-19 13:27:27,530:INFO:Copying training dataset
2025-10-19 13:27:27,734:INFO:Defining folds
2025-10-19 13:27:27,736:INFO:Declaring metric variables
2025-10-19 13:27:27,741:INFO:Importing untrained model
2025-10-19 13:27:27,741:INFO:Declaring custom model
2025-10-19 13:27:27,745:INFO:Ridge Classifier Imported successfully
2025-10-19 13:27:27,751:INFO:Starting cross validation
2025-10-19 13:27:27,756:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:27:39,382:INFO:Calculating mean and std
2025-10-19 13:27:39,383:INFO:Creating metrics dataframe
2025-10-19 13:27:39,391:INFO:Finalizing model
2025-10-19 13:27:41,860:INFO:Uploading results into container
2025-10-19 13:27:41,861:INFO:Uploading model into container now
2025-10-19 13:27:41,862:INFO:_master_model_container: 18
2025-10-19 13:27:41,862:INFO:_display_container: 4
2025-10-19 13:27:41,862:INFO:RidgeClassifier(alpha=9.17, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001)
2025-10-19 13:27:41,863:INFO:create_model() successfully completed......................................
2025-10-19 13:27:42,027:INFO:SubProcess create_model() end ==================================
2025-10-19 13:27:42,027:INFO:choose_better activated
2025-10-19 13:27:42,030:INFO:SubProcess create_model() called ==================================
2025-10-19 13:27:42,031:INFO:Initializing create_model()
2025-10-19 13:27:42,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:27:42,031:INFO:Checking exceptions
2025-10-19 13:27:42,032:INFO:Importing libraries
2025-10-19 13:27:42,032:INFO:Copying training dataset
2025-10-19 13:27:42,216:INFO:Defining folds
2025-10-19 13:27:42,216:INFO:Declaring metric variables
2025-10-19 13:27:42,216:INFO:Importing untrained model
2025-10-19 13:27:42,216:INFO:Declaring custom model
2025-10-19 13:27:42,216:INFO:Ridge Classifier Imported successfully
2025-10-19 13:27:42,216:INFO:Starting cross validation
2025-10-19 13:27:42,221:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:27:53,867:INFO:Calculating mean and std
2025-10-19 13:27:53,868:INFO:Creating metrics dataframe
2025-10-19 13:27:53,870:INFO:Finalizing model
2025-10-19 13:27:56,356:INFO:Uploading results into container
2025-10-19 13:27:56,356:INFO:Uploading model into container now
2025-10-19 13:27:56,357:INFO:_master_model_container: 19
2025-10-19 13:27:56,357:INFO:_display_container: 5
2025-10-19 13:27:56,357:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001)
2025-10-19 13:27:56,357:INFO:create_model() successfully completed......................................
2025-10-19 13:27:56,511:INFO:SubProcess create_model() end ==================================
2025-10-19 13:27:56,511:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001) result for AUC is 0.9301
2025-10-19 13:27:56,512:INFO:RidgeClassifier(alpha=9.17, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001) result for AUC is 0.9306
2025-10-19 13:27:56,512:INFO:RidgeClassifier(alpha=9.17, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001) is best model
2025-10-19 13:27:56,512:INFO:choose_better completed
2025-10-19 13:27:56,520:INFO:_master_model_container: 19
2025-10-19 13:27:56,520:INFO:_display_container: 4
2025-10-19 13:27:56,521:INFO:RidgeClassifier(alpha=9.17, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001)
2025-10-19 13:27:56,521:INFO:tune_model() successfully completed......................................
2025-10-19 13:27:56,711:INFO:Initializing tune_model()
2025-10-19 13:27:56,711:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 13:27:56,712:INFO:Checking exceptions
2025-10-19 13:27:56,804:INFO:Copying training dataset
2025-10-19 13:27:56,964:INFO:Checking base model
2025-10-19 13:27:56,964:INFO:Base model : Ada Boost Classifier
2025-10-19 13:27:56,967:INFO:Declaring metric variables
2025-10-19 13:27:56,972:INFO:Defining Hyperparameters
2025-10-19 13:27:57,141:INFO:Tuning with n_jobs=1
2025-10-19 13:27:57,141:INFO:Initializing RandomizedSearchCV
2025-10-19 13:36:52,215:INFO:best_params: {'actual_estimator__n_estimators': 300, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__algorithm': 'SAMME'}
2025-10-19 13:36:52,216:INFO:Hyperparameter search completed
2025-10-19 13:36:52,216:INFO:SubProcess create_model() called ==================================
2025-10-19 13:36:52,217:INFO:Initializing create_model()
2025-10-19 13:36:52,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5CB39D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 300, 'learning_rate': 0.3, 'algorithm': 'SAMME'})
2025-10-19 13:36:52,218:INFO:Checking exceptions
2025-10-19 13:36:52,218:INFO:Importing libraries
2025-10-19 13:36:52,218:INFO:Copying training dataset
2025-10-19 13:36:52,404:INFO:Defining folds
2025-10-19 13:36:52,405:INFO:Declaring metric variables
2025-10-19 13:36:52,408:INFO:Importing untrained model
2025-10-19 13:36:52,408:INFO:Declaring custom model
2025-10-19 13:36:52,414:INFO:Ada Boost Classifier Imported successfully
2025-10-19 13:36:52,420:INFO:Starting cross validation
2025-10-19 13:36:52,424:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:38:22,323:INFO:Calculating mean and std
2025-10-19 13:38:22,324:INFO:Creating metrics dataframe
2025-10-19 13:38:22,329:INFO:Finalizing model
2025-10-19 13:38:43,689:INFO:Uploading results into container
2025-10-19 13:38:43,690:INFO:Uploading model into container now
2025-10-19 13:38:43,691:INFO:_master_model_container: 20
2025-10-19 13:38:43,691:INFO:_display_container: 5
2025-10-19 13:38:43,691:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.3,
                   n_estimators=300, random_state=5462)
2025-10-19 13:38:43,692:INFO:create_model() successfully completed......................................
2025-10-19 13:38:43,931:INFO:SubProcess create_model() end ==================================
2025-10-19 13:38:43,931:INFO:choose_better activated
2025-10-19 13:38:43,935:INFO:SubProcess create_model() called ==================================
2025-10-19 13:38:43,936:INFO:Initializing create_model()
2025-10-19 13:38:43,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:38:43,936:INFO:Checking exceptions
2025-10-19 13:38:43,938:INFO:Importing libraries
2025-10-19 13:38:43,938:INFO:Copying training dataset
2025-10-19 13:38:44,137:INFO:Defining folds
2025-10-19 13:38:44,137:INFO:Declaring metric variables
2025-10-19 13:38:44,138:INFO:Importing untrained model
2025-10-19 13:38:44,138:INFO:Declaring custom model
2025-10-19 13:38:44,138:INFO:Ada Boost Classifier Imported successfully
2025-10-19 13:38:44,138:INFO:Starting cross validation
2025-10-19 13:38:44,141:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:38:46,298:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:38:51,607:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:38:57,240:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:39:02,676:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:39:08,696:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:39:12,222:INFO:Calculating mean and std
2025-10-19 13:39:12,222:INFO:Creating metrics dataframe
2025-10-19 13:39:12,223:INFO:Finalizing model
2025-10-19 13:39:15,215:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:39:19,109:INFO:Uploading results into container
2025-10-19 13:39:19,109:INFO:Uploading model into container now
2025-10-19 13:39:19,110:INFO:_master_model_container: 21
2025-10-19 13:39:19,110:INFO:_display_container: 6
2025-10-19 13:39:19,110:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462)
2025-10-19 13:39:19,110:INFO:create_model() successfully completed......................................
2025-10-19 13:39:19,291:INFO:SubProcess create_model() end ==================================
2025-10-19 13:39:19,292:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462) result for AUC is 0.93
2025-10-19 13:39:19,292:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.3,
                   n_estimators=300, random_state=5462) result for AUC is 0.9296
2025-10-19 13:39:19,292:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462) is best model
2025-10-19 13:39:19,292:INFO:choose_better completed
2025-10-19 13:39:19,293:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 13:39:19,302:INFO:_master_model_container: 21
2025-10-19 13:39:19,303:INFO:_display_container: 5
2025-10-19 13:39:19,303:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462)
2025-10-19 13:39:19,304:INFO:tune_model() successfully completed......................................
2025-10-19 13:39:19,543:INFO:Initializing blend_models()
2025-10-19 13:39:19,543:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5462, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=9.17, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5462)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-19 13:39:19,543:INFO:Checking exceptions
2025-10-19 13:39:19,543:INFO:Estimator RidgeClassifier(alpha=9.17, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=5462, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-19 13:39:19,649:INFO:Importing libraries
2025-10-19 13:39:19,649:INFO:Copying training dataset
2025-10-19 13:39:19,658:INFO:Getting model names
2025-10-19 13:39:19,664:INFO:SubProcess create_model() called ==================================
2025-10-19 13:39:19,672:INFO:Initializing create_model()
2025-10-19 13:39:19,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              RidgeClassifier(alpha=9.17, class_weight=None,
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5462, solver='auto',
                                              tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=5462))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
33366    U02541
3002     U10639
63711    U11345
34178    U00123
16227    U04201
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C4EE94250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:39:19,673:INFO:Checking exceptions
2025-10-19 13:39:19,673:INFO:Importing libraries
2025-10-19 13:39:19,673:INFO:Copying training dataset
2025-10-19 13:39:19,920:INFO:Defining folds
2025-10-19 13:39:19,921:INFO:Declaring metric variables
2025-10-19 13:39:19,924:INFO:Importing untrained model
2025-10-19 13:39:19,924:INFO:Declaring custom model
2025-10-19 13:39:19,929:INFO:Voting Classifier Imported successfully
2025-10-19 13:39:19,938:INFO:Starting cross validation
2025-10-19 13:39:19,944:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:39:32,327:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:39:35,906:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 13:39:48,273:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:39:52,299:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 13:40:05,456:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:40:09,360:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 13:40:21,267:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:40:24,389:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 13:40:34,394:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:40:37,342:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 13:40:37,362:INFO:Calculating mean and std
2025-10-19 13:40:37,363:INFO:Creating metrics dataframe
2025-10-19 13:40:37,367:INFO:Finalizing model
2025-10-19 13:40:49,903:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:40:53,237:INFO:Uploading results into container
2025-10-19 13:40:53,238:INFO:Uploading model into container now
2025-10-19 13:40:53,240:INFO:_master_model_container: 22
2025-10-19 13:40:53,240:INFO:_display_container: 6
2025-10-19 13:40:53,244:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              RidgeClassifier(alpha=9.17, class_weight=None,
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5462, solver='auto',
                                              tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=5462))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-19 13:40:53,244:INFO:create_model() successfully completed......................................
2025-10-19 13:40:53,408:INFO:SubProcess create_model() end ==================================
2025-10-19 13:40:53,416:INFO:_master_model_container: 22
2025-10-19 13:40:53,417:INFO:_display_container: 6
2025-10-19 13:40:53,420:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              RidgeClassifier(alpha=9.17, class_weight=None,
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5462, solver='auto',
                                              tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=5462))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-19 13:40:53,420:INFO:blend_models() successfully completed......................................
2025-10-19 13:40:53,581:INFO:Initializing finalize_model()
2025-10-19 13:40:53,581:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              RidgeClassifier(alpha=9.17, class_weight=None,
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5462, solver='auto',
                                              tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=5462))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-19 13:40:53,584:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              RidgeClassifier(alpha=9.17, class_weight=None,
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5462, solver='auto',
                                              tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=5462))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-19 13:40:53,720:INFO:Initializing create_model()
2025-10-19 13:40:53,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C503ABAD0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              RidgeClassifier(alpha=9.17, class_weight=None,
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=5462, solver='auto',
                                              tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=5462))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=62399    U09097
43913    U02291
48251    U04469
23056    U01803
48132    U11052
          ...  
53574    U03499
18239    U03372
13800    U01025
8190     U05995
54692    U08405
Name: id_usuario, Length: 63955, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:40:53,720:INFO:Checking exceptions
2025-10-19 13:40:53,721:INFO:Importing libraries
2025-10-19 13:40:53,721:INFO:Copying training dataset
2025-10-19 13:40:53,747:INFO:Defining folds
2025-10-19 13:40:53,747:INFO:Declaring metric variables
2025-10-19 13:40:53,747:INFO:Importing untrained model
2025-10-19 13:40:53,747:INFO:Declaring custom model
2025-10-19 13:40:53,748:INFO:Voting Classifier Imported successfully
2025-10-19 13:40:53,750:INFO:Cross validation set to False
2025-10-19 13:40:53,750:INFO:Fitting Model
2025-10-19 13:41:11,971:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 13:41:16,711:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                               RidgeClassifier(alpha=9.17,
                                                               class_weight=None,
                                                               copy_X=True,
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=5462,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Ada Boost Classifier',
                                               AdaBoostClassifier(algorithm='SAMME.R',
                                                                  estimator=None,
                                                                  learning_rate=1.0,
                                                                  n_estimators=50,
                                                                  random_state=5462))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-19 13:41:16,711:INFO:create_model() successfully completed......................................
2025-10-19 13:41:16,901:INFO:_master_model_container: 22
2025-10-19 13:41:16,902:INFO:_display_container: 6
2025-10-19 13:41:16,929:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                               RidgeClassifier(alpha=9.17,
                                                               class_weight=None,
                                                               copy_X=True,
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=5462,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Ada Boost Classifier',
                                               AdaBoostClassifier(algorithm='SAMME.R',
                                                                  estimator=None,
                                                                  learning_rate=1.0,
                                                                  n_estimators=50,
                                                                  random_state=5462))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-19 13:41:16,929:INFO:finalize_model() successfully completed......................................
2025-10-19 13:41:17,114:INFO:Initializing save_model()
2025-10-19 13:41:17,115:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                               RidgeClassifier(alpha=9.17,
                                                               class_weight=None,
                                                               copy_X=True,
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=5462,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Ada Boost Classifier',
                                               AdaBoostClassifier(algorithm='SAMME.R',
                                                                  estimator=None,
                                                                  learning_rate=1.0,
                                                                  n_estimators=50,
                                                                  random_state=5462))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), model_name=modelo_cls_like_v2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-19 13:41:17,115:INFO:Adding model into prep_pipe
2025-10-19 13:41:17,115:WARNING:Only Model saved as it was a pipeline.
2025-10-19 13:41:17,158:INFO:modelo_cls_like_v2.pkl saved in current working directory
2025-10-19 13:41:17,180:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                               RidgeClassifier(alpha=9.17,
                                                               class_weight=None,
                                                               copy_X=True,
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=5462,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Ada Boost Classifier',
                                               AdaBoostClassifier(algorithm='SAMME.R',
                                                                  estimator=None,
                                                                  learning_rate=1.0,
                                                                  n_estimators=50,
                                                                  random_state=5462))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-19 13:41:17,180:INFO:save_model() successfully completed......................................
2025-10-19 13:42:03,991:INFO:PyCaret RegressionExperiment
2025-10-19 13:42:03,991:INFO:Logging name: reg-default-name
2025-10-19 13:42:03,991:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-19 13:42:03,991:INFO:version 3.3.2
2025-10-19 13:42:03,991:INFO:Initializing setup()
2025-10-19 13:42:03,991:INFO:self.USI: 1bd7
2025-10-19 13:42:03,991:INFO:self._variable_keys: {'target_param', 'fold_groups_param', 'exp_name_log', 'X_train', 'USI', 'gpu_n_jobs_param', 'X_test', 'log_plots_param', 'fold_shuffle_param', 'transform_target_param', 'gpu_param', 'idx', 'y_train', 'exp_id', 'X', 'logging_param', 'data', 'pipeline', 'y_test', 'n_jobs_param', '_ml_usecase', 'y', 'seed', 'html_param', 'fold_generator', '_available_plots', 'memory'}
2025-10-19 13:42:03,992:INFO:Checking environment
2025-10-19 13:42:03,992:INFO:python_version: 3.11.13
2025-10-19 13:42:03,992:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 13:42:03,992:INFO:machine: AMD64
2025-10-19 13:42:03,992:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 13:42:04,002:INFO:Memory: svmem(total=16856211456, available=2799448064, percent=83.4, used=14056763392, free=2799448064)
2025-10-19 13:42:04,003:INFO:Physical Core: 4
2025-10-19 13:42:04,003:INFO:Logical Core: 8
2025-10-19 13:42:04,003:INFO:Checking libraries
2025-10-19 13:42:04,003:INFO:System:
2025-10-19 13:42:04,003:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 13:42:04,003:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 13:42:04,003:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 13:42:04,003:INFO:PyCaret required dependencies:
2025-10-19 13:42:04,003:INFO:                 pip: 25.2
2025-10-19 13:42:04,003:INFO:          setuptools: 80.9.0
2025-10-19 13:42:04,003:INFO:             pycaret: 3.3.2
2025-10-19 13:42:04,003:INFO:             IPython: 9.6.0
2025-10-19 13:42:04,003:INFO:          ipywidgets: 8.1.7
2025-10-19 13:42:04,003:INFO:                tqdm: 4.67.1
2025-10-19 13:42:04,003:INFO:               numpy: 1.26.4
2025-10-19 13:42:04,003:INFO:              pandas: 2.1.4
2025-10-19 13:42:04,003:INFO:              jinja2: 3.1.6
2025-10-19 13:42:04,003:INFO:               scipy: 1.11.4
2025-10-19 13:42:04,003:INFO:              joblib: 1.3.2
2025-10-19 13:42:04,003:INFO:             sklearn: 1.4.2
2025-10-19 13:42:04,003:INFO:                pyod: 2.0.5
2025-10-19 13:42:04,004:INFO:            imblearn: 0.14.0
2025-10-19 13:42:04,004:INFO:   category_encoders: 2.7.0
2025-10-19 13:42:04,004:INFO:            lightgbm: 4.6.0
2025-10-19 13:42:04,004:INFO:               numba: 0.61.0
2025-10-19 13:42:04,004:INFO:            requests: 2.32.5
2025-10-19 13:42:04,004:INFO:          matplotlib: 3.7.5
2025-10-19 13:42:04,004:INFO:          scikitplot: 0.3.7
2025-10-19 13:42:04,004:INFO:         yellowbrick: 1.5
2025-10-19 13:42:04,004:INFO:              plotly: 5.24.1
2025-10-19 13:42:04,004:INFO:    plotly-resampler: Not installed
2025-10-19 13:42:04,004:INFO:             kaleido: 1.1.0
2025-10-19 13:42:04,004:INFO:           schemdraw: 0.15
2025-10-19 13:42:04,004:INFO:         statsmodels: 0.14.5
2025-10-19 13:42:04,004:INFO:              sktime: 0.26.0
2025-10-19 13:42:04,004:INFO:               tbats: 1.1.3
2025-10-19 13:42:04,004:INFO:            pmdarima: 2.0.4
2025-10-19 13:42:04,004:INFO:              psutil: 7.1.0
2025-10-19 13:42:04,004:INFO:          markupsafe: 3.0.3
2025-10-19 13:42:04,004:INFO:             pickle5: Not installed
2025-10-19 13:42:04,004:INFO:         cloudpickle: 3.1.1
2025-10-19 13:42:04,004:INFO:         deprecation: 2.1.0
2025-10-19 13:42:04,004:INFO:              xxhash: 3.6.0
2025-10-19 13:42:04,004:INFO:           wurlitzer: Not installed
2025-10-19 13:42:04,004:INFO:PyCaret optional dependencies:
2025-10-19 13:42:04,004:INFO:                shap: 0.44.1
2025-10-19 13:42:04,004:INFO:           interpret: 0.7.3
2025-10-19 13:42:04,004:INFO:                umap: 0.5.7
2025-10-19 13:42:04,004:INFO:     ydata_profiling: 4.17.0
2025-10-19 13:42:04,004:INFO:  explainerdashboard: 0.5.1
2025-10-19 13:42:04,005:INFO:             autoviz: Not installed
2025-10-19 13:42:04,005:INFO:           fairlearn: 0.7.0
2025-10-19 13:42:04,005:INFO:          deepchecks: Not installed
2025-10-19 13:42:04,005:INFO:             xgboost: Not installed
2025-10-19 13:42:04,005:INFO:            catboost: 1.2.8
2025-10-19 13:42:04,005:INFO:              kmodes: 0.12.2
2025-10-19 13:42:04,005:INFO:             mlxtend: 0.23.4
2025-10-19 13:42:04,005:INFO:       statsforecast: 1.5.0
2025-10-19 13:42:04,005:INFO:        tune_sklearn: Not installed
2025-10-19 13:42:04,005:INFO:                 ray: Not installed
2025-10-19 13:42:04,005:INFO:            hyperopt: 0.2.7
2025-10-19 13:42:04,005:INFO:              optuna: 4.5.0
2025-10-19 13:42:04,005:INFO:               skopt: 0.10.2
2025-10-19 13:42:04,005:INFO:              mlflow: 3.5.0
2025-10-19 13:42:04,005:INFO:              gradio: 5.49.1
2025-10-19 13:42:04,005:INFO:             fastapi: 0.119.0
2025-10-19 13:42:04,005:INFO:             uvicorn: 0.38.0
2025-10-19 13:42:04,005:INFO:              m2cgen: 0.10.0
2025-10-19 13:42:04,005:INFO:           evidently: 0.4.40
2025-10-19 13:42:04,005:INFO:               fugue: 0.8.7
2025-10-19 13:42:04,005:INFO:           streamlit: Not installed
2025-10-19 13:42:04,005:INFO:             prophet: Not installed
2025-10-19 13:42:04,005:INFO:None
2025-10-19 13:42:04,005:INFO:Set up data.
2025-10-19 13:42:04,219:INFO:Set up folding strategy.
2025-10-19 13:42:04,416:INFO:Set up train/test split.
2025-10-19 13:42:04,704:INFO:Set up index.
2025-10-19 13:42:04,717:INFO:Assigning column types.
2025-10-19 13:42:04,927:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 13:42:04,927:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-19 13:42:04,933:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 13:42:04,939:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:05,233:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:05,234:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,237:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,241:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:05,465:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:05,465:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-19 13:42:05,469:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,472:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:05,678:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:05,682:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,685:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,881:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,916:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 13:42:05,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:05,916:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:05,917:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-19 13:42:05,923:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:06,129:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:06,138:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,317:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,350:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:06,351:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:06,352:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-19 13:42:06,522:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,555:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:06,556:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:06,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:06,788:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:06,788:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 13:42:06,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 13:42:06,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:06,998:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:07,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 13:42:07,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:07,256:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:07,257:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-19 13:42:07,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:07,495:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:07,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:07,751:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:07,752:INFO:Preparing preprocessing pipeline...
2025-10-19 13:42:07,752:INFO:Set up simple imputation.
2025-10-19 13:42:07,875:INFO:Set up encoding of ordinal features.
2025-10-19 13:42:07,936:INFO:Set up encoding of categorical features.
2025-10-19 13:42:07,939:INFO:Set up removing multicollinearity.
2025-10-19 13:42:07,974:INFO:Set up column name cleaning.
2025-10-19 13:42:09,268:INFO:Finished creating preprocessing pipeline.
2025-10-19 13:42:09,288:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 13:42:09,288:INFO:Creating final display dataframe.
2025-10-19 13:42:10,201:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target    rating_usuario
2                   Target type        Regression
3           Original data shape       (63955, 28)
4        Transformed data shape       (63955, 96)
5   Transformed train set shape       (44768, 96)
6    Transformed test set shape       (19187, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              1bd7
2025-10-19 13:42:10,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:10,433:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:10,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 13:42:10,641:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 13:42:10,642:INFO:setup() successfully completed in 6.74s...............
2025-10-19 13:42:10,642:INFO:Initializing compare_models()
2025-10-19 13:42:10,642:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-19 13:42:10,642:INFO:Checking exceptions
2025-10-19 13:42:10,702:INFO:Preparing display monitor
2025-10-19 13:42:10,723:INFO:Initializing Linear Regression
2025-10-19 13:42:10,723:INFO:Total runtime is 0.0 minutes
2025-10-19 13:42:10,729:INFO:SubProcess create_model() called ==================================
2025-10-19 13:42:10,730:INFO:Initializing create_model()
2025-10-19 13:42:10,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:42:10,731:INFO:Checking exceptions
2025-10-19 13:42:10,732:INFO:Importing libraries
2025-10-19 13:42:10,732:INFO:Copying training dataset
2025-10-19 13:42:10,933:INFO:Defining folds
2025-10-19 13:42:10,933:INFO:Declaring metric variables
2025-10-19 13:42:10,937:INFO:Importing untrained model
2025-10-19 13:42:10,939:INFO:Linear Regression Imported successfully
2025-10-19 13:42:10,946:INFO:Starting cross validation
2025-10-19 13:42:10,950:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:42:23,242:INFO:Calculating mean and std
2025-10-19 13:42:23,243:INFO:Creating metrics dataframe
2025-10-19 13:42:23,245:INFO:Uploading results into container
2025-10-19 13:42:23,247:INFO:Uploading model into container now
2025-10-19 13:42:23,248:INFO:_master_model_container: 1
2025-10-19 13:42:23,248:INFO:_display_container: 2
2025-10-19 13:42:23,248:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, positive=False)
2025-10-19 13:42:23,248:INFO:create_model() successfully completed......................................
2025-10-19 13:42:23,410:INFO:SubProcess create_model() end ==================================
2025-10-19 13:42:23,410:INFO:Creating metrics dataframe
2025-10-19 13:42:23,416:INFO:Initializing Lasso Regression
2025-10-19 13:42:23,416:INFO:Total runtime is 0.21154364744822185 minutes
2025-10-19 13:42:23,418:INFO:SubProcess create_model() called ==================================
2025-10-19 13:42:23,420:INFO:Initializing create_model()
2025-10-19 13:42:23,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=lasso, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:42:23,426:INFO:Checking exceptions
2025-10-19 13:42:23,426:INFO:Importing libraries
2025-10-19 13:42:23,426:INFO:Copying training dataset
2025-10-19 13:42:23,634:INFO:Defining folds
2025-10-19 13:42:23,634:INFO:Declaring metric variables
2025-10-19 13:42:23,638:INFO:Importing untrained model
2025-10-19 13:42:23,643:INFO:Lasso Regression Imported successfully
2025-10-19 13:42:23,652:INFO:Starting cross validation
2025-10-19 13:42:23,657:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:42:34,819:INFO:Calculating mean and std
2025-10-19 13:42:34,819:INFO:Creating metrics dataframe
2025-10-19 13:42:34,821:INFO:Uploading results into container
2025-10-19 13:42:34,822:INFO:Uploading model into container now
2025-10-19 13:42:34,823:INFO:_master_model_container: 2
2025-10-19 13:42:34,823:INFO:_display_container: 2
2025-10-19 13:42:34,824:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=42, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-10-19 13:42:34,824:INFO:create_model() successfully completed......................................
2025-10-19 13:42:34,981:INFO:SubProcess create_model() end ==================================
2025-10-19 13:42:34,982:INFO:Creating metrics dataframe
2025-10-19 13:42:34,988:INFO:Initializing Ridge Regression
2025-10-19 13:42:34,988:INFO:Total runtime is 0.4044145623842875 minutes
2025-10-19 13:42:34,992:INFO:SubProcess create_model() called ==================================
2025-10-19 13:42:34,993:INFO:Initializing create_model()
2025-10-19 13:42:34,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:42:34,993:INFO:Checking exceptions
2025-10-19 13:42:34,993:INFO:Importing libraries
2025-10-19 13:42:34,993:INFO:Copying training dataset
2025-10-19 13:42:35,175:INFO:Defining folds
2025-10-19 13:42:35,175:INFO:Declaring metric variables
2025-10-19 13:42:35,181:INFO:Importing untrained model
2025-10-19 13:42:35,185:INFO:Ridge Regression Imported successfully
2025-10-19 13:42:35,192:INFO:Starting cross validation
2025-10-19 13:42:35,197:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:42:46,156:INFO:Calculating mean and std
2025-10-19 13:42:46,157:INFO:Creating metrics dataframe
2025-10-19 13:42:46,158:INFO:Uploading results into container
2025-10-19 13:42:46,159:INFO:Uploading model into container now
2025-10-19 13:42:46,160:INFO:_master_model_container: 3
2025-10-19 13:42:46,160:INFO:_display_container: 2
2025-10-19 13:42:46,160:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001)
2025-10-19 13:42:46,160:INFO:create_model() successfully completed......................................
2025-10-19 13:42:46,316:INFO:SubProcess create_model() end ==================================
2025-10-19 13:42:46,316:INFO:Creating metrics dataframe
2025-10-19 13:42:46,324:INFO:Initializing Elastic Net
2025-10-19 13:42:46,324:INFO:Total runtime is 0.5933465282122294 minutes
2025-10-19 13:42:46,327:INFO:SubProcess create_model() called ==================================
2025-10-19 13:42:46,329:INFO:Initializing create_model()
2025-10-19 13:42:46,330:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=en, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:42:46,330:INFO:Checking exceptions
2025-10-19 13:42:46,330:INFO:Importing libraries
2025-10-19 13:42:46,330:INFO:Copying training dataset
2025-10-19 13:42:46,511:INFO:Defining folds
2025-10-19 13:42:46,511:INFO:Declaring metric variables
2025-10-19 13:42:46,517:INFO:Importing untrained model
2025-10-19 13:42:46,520:INFO:Elastic Net Imported successfully
2025-10-19 13:42:46,526:INFO:Starting cross validation
2025-10-19 13:42:46,532:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:42:57,542:INFO:Calculating mean and std
2025-10-19 13:42:57,543:INFO:Creating metrics dataframe
2025-10-19 13:42:57,545:INFO:Uploading results into container
2025-10-19 13:42:57,545:INFO:Uploading model into container now
2025-10-19 13:42:57,546:INFO:_master_model_container: 4
2025-10-19 13:42:57,546:INFO:_display_container: 2
2025-10-19 13:42:57,546:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=42,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-10-19 13:42:57,546:INFO:create_model() successfully completed......................................
2025-10-19 13:42:57,702:INFO:SubProcess create_model() end ==================================
2025-10-19 13:42:57,702:INFO:Creating metrics dataframe
2025-10-19 13:42:57,708:INFO:Initializing Least Angle Regression
2025-10-19 13:42:57,708:INFO:Total runtime is 0.783075499534607 minutes
2025-10-19 13:42:57,711:INFO:SubProcess create_model() called ==================================
2025-10-19 13:42:57,713:INFO:Initializing create_model()
2025-10-19 13:42:57,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=lar, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:42:57,714:INFO:Checking exceptions
2025-10-19 13:42:57,714:INFO:Importing libraries
2025-10-19 13:42:57,714:INFO:Copying training dataset
2025-10-19 13:42:57,944:INFO:Defining folds
2025-10-19 13:42:57,945:INFO:Declaring metric variables
2025-10-19 13:42:57,949:INFO:Importing untrained model
2025-10-19 13:42:57,953:INFO:Least Angle Regression Imported successfully
2025-10-19 13:42:57,960:INFO:Starting cross validation
2025-10-19 13:42:57,965:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:43:08,940:INFO:Calculating mean and std
2025-10-19 13:43:08,941:INFO:Creating metrics dataframe
2025-10-19 13:43:08,943:INFO:Uploading results into container
2025-10-19 13:43:08,943:INFO:Uploading model into container now
2025-10-19 13:43:08,943:INFO:_master_model_container: 5
2025-10-19 13:43:08,943:INFO:_display_container: 2
2025-10-19 13:43:08,944:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=42,
     verbose=False)
2025-10-19 13:43:08,944:INFO:create_model() successfully completed......................................
2025-10-19 13:43:09,098:INFO:SubProcess create_model() end ==================================
2025-10-19 13:43:09,098:INFO:Creating metrics dataframe
2025-10-19 13:43:09,104:INFO:Initializing Lasso Least Angle Regression
2025-10-19 13:43:09,104:INFO:Total runtime is 0.9730178674062093 minutes
2025-10-19 13:43:09,106:INFO:SubProcess create_model() called ==================================
2025-10-19 13:43:09,107:INFO:Initializing create_model()
2025-10-19 13:43:09,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=llar, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:43:09,108:INFO:Checking exceptions
2025-10-19 13:43:09,108:INFO:Importing libraries
2025-10-19 13:43:09,108:INFO:Copying training dataset
2025-10-19 13:43:09,287:INFO:Defining folds
2025-10-19 13:43:09,287:INFO:Declaring metric variables
2025-10-19 13:43:09,291:INFO:Importing untrained model
2025-10-19 13:43:09,295:INFO:Lasso Least Angle Regression Imported successfully
2025-10-19 13:43:09,302:INFO:Starting cross validation
2025-10-19 13:43:09,307:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:43:20,219:INFO:Calculating mean and std
2025-10-19 13:43:20,220:INFO:Creating metrics dataframe
2025-10-19 13:43:20,221:INFO:Uploading results into container
2025-10-19 13:43:20,221:INFO:Uploading model into container now
2025-10-19 13:43:20,222:INFO:_master_model_container: 6
2025-10-19 13:43:20,222:INFO:_display_container: 2
2025-10-19 13:43:20,222:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=42, verbose=False)
2025-10-19 13:43:20,222:INFO:create_model() successfully completed......................................
2025-10-19 13:43:20,387:INFO:SubProcess create_model() end ==================================
2025-10-19 13:43:20,387:INFO:Creating metrics dataframe
2025-10-19 13:43:20,399:INFO:Initializing Orthogonal Matching Pursuit
2025-10-19 13:43:20,399:INFO:Total runtime is 1.1612671216328938 minutes
2025-10-19 13:43:20,403:INFO:SubProcess create_model() called ==================================
2025-10-19 13:43:20,404:INFO:Initializing create_model()
2025-10-19 13:43:20,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=omp, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:43:20,405:INFO:Checking exceptions
2025-10-19 13:43:20,405:INFO:Importing libraries
2025-10-19 13:43:20,405:INFO:Copying training dataset
2025-10-19 13:43:20,594:INFO:Defining folds
2025-10-19 13:43:20,595:INFO:Declaring metric variables
2025-10-19 13:43:20,599:INFO:Importing untrained model
2025-10-19 13:43:20,603:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-19 13:43:20,610:INFO:Starting cross validation
2025-10-19 13:43:20,615:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:43:31,527:INFO:Calculating mean and std
2025-10-19 13:43:31,528:INFO:Creating metrics dataframe
2025-10-19 13:43:31,529:INFO:Uploading results into container
2025-10-19 13:43:31,529:INFO:Uploading model into container now
2025-10-19 13:43:31,529:INFO:_master_model_container: 7
2025-10-19 13:43:31,530:INFO:_display_container: 2
2025-10-19 13:43:31,530:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-10-19 13:43:31,530:INFO:create_model() successfully completed......................................
2025-10-19 13:43:31,684:INFO:SubProcess create_model() end ==================================
2025-10-19 13:43:31,684:INFO:Creating metrics dataframe
2025-10-19 13:43:31,690:INFO:Initializing Bayesian Ridge
2025-10-19 13:43:31,691:INFO:Total runtime is 1.349463923772176 minutes
2025-10-19 13:43:31,696:INFO:SubProcess create_model() called ==================================
2025-10-19 13:43:31,697:INFO:Initializing create_model()
2025-10-19 13:43:31,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=br, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:43:31,698:INFO:Checking exceptions
2025-10-19 13:43:31,698:INFO:Importing libraries
2025-10-19 13:43:31,698:INFO:Copying training dataset
2025-10-19 13:43:31,948:INFO:Defining folds
2025-10-19 13:43:31,949:INFO:Declaring metric variables
2025-10-19 13:43:31,953:INFO:Importing untrained model
2025-10-19 13:43:31,957:INFO:Bayesian Ridge Imported successfully
2025-10-19 13:43:31,963:INFO:Starting cross validation
2025-10-19 13:43:31,968:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:43:44,654:INFO:Calculating mean and std
2025-10-19 13:43:44,655:INFO:Creating metrics dataframe
2025-10-19 13:43:44,656:INFO:Uploading results into container
2025-10-19 13:43:44,657:INFO:Uploading model into container now
2025-10-19 13:43:44,657:INFO:_master_model_container: 8
2025-10-19 13:43:44,657:INFO:_display_container: 2
2025-10-19 13:43:44,657:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-10-19 13:43:44,657:INFO:create_model() successfully completed......................................
2025-10-19 13:43:44,814:INFO:SubProcess create_model() end ==================================
2025-10-19 13:43:44,814:INFO:Creating metrics dataframe
2025-10-19 13:43:44,824:INFO:Initializing Passive Aggressive Regressor
2025-10-19 13:43:44,824:INFO:Total runtime is 1.5683468222618102 minutes
2025-10-19 13:43:44,828:INFO:SubProcess create_model() called ==================================
2025-10-19 13:43:44,829:INFO:Initializing create_model()
2025-10-19 13:43:44,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=par, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:43:44,829:INFO:Checking exceptions
2025-10-19 13:43:44,829:INFO:Importing libraries
2025-10-19 13:43:44,829:INFO:Copying training dataset
2025-10-19 13:43:45,046:INFO:Defining folds
2025-10-19 13:43:45,047:INFO:Declaring metric variables
2025-10-19 13:43:45,051:INFO:Importing untrained model
2025-10-19 13:43:45,056:INFO:Passive Aggressive Regressor Imported successfully
2025-10-19 13:43:45,061:INFO:Starting cross validation
2025-10-19 13:43:45,066:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:44:01,831:INFO:Calculating mean and std
2025-10-19 13:44:01,831:INFO:Creating metrics dataframe
2025-10-19 13:44:01,833:INFO:Uploading results into container
2025-10-19 13:44:01,834:INFO:Uploading model into container now
2025-10-19 13:44:01,834:INFO:_master_model_container: 9
2025-10-19 13:44:01,834:INFO:_display_container: 2
2025-10-19 13:44:01,835:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=42, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 13:44:01,835:INFO:create_model() successfully completed......................................
2025-10-19 13:44:01,988:INFO:SubProcess create_model() end ==================================
2025-10-19 13:44:01,988:INFO:Creating metrics dataframe
2025-10-19 13:44:01,996:INFO:Initializing Huber Regressor
2025-10-19 13:44:01,996:INFO:Total runtime is 1.8545430819193522 minutes
2025-10-19 13:44:02,000:INFO:SubProcess create_model() called ==================================
2025-10-19 13:44:02,001:INFO:Initializing create_model()
2025-10-19 13:44:02,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=huber, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:44:02,002:INFO:Checking exceptions
2025-10-19 13:44:02,002:INFO:Importing libraries
2025-10-19 13:44:02,002:INFO:Copying training dataset
2025-10-19 13:44:02,183:INFO:Defining folds
2025-10-19 13:44:02,183:INFO:Declaring metric variables
2025-10-19 13:44:02,188:INFO:Importing untrained model
2025-10-19 13:44:02,192:INFO:Huber Regressor Imported successfully
2025-10-19 13:44:02,198:INFO:Starting cross validation
2025-10-19 13:44:02,201:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:44:22,995:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2025-10-19 13:44:23,195:INFO:Calculating mean and std
2025-10-19 13:44:23,196:INFO:Creating metrics dataframe
2025-10-19 13:44:23,198:INFO:Uploading results into container
2025-10-19 13:44:23,199:INFO:Uploading model into container now
2025-10-19 13:44:23,200:INFO:_master_model_container: 10
2025-10-19 13:44:23,200:INFO:_display_container: 2
2025-10-19 13:44:23,200:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-10-19 13:44:23,201:INFO:create_model() successfully completed......................................
2025-10-19 13:44:23,356:INFO:SubProcess create_model() end ==================================
2025-10-19 13:44:23,356:INFO:Creating metrics dataframe
2025-10-19 13:44:23,363:INFO:Initializing K Neighbors Regressor
2025-10-19 13:44:23,363:INFO:Total runtime is 2.210661788781484 minutes
2025-10-19 13:44:23,366:INFO:SubProcess create_model() called ==================================
2025-10-19 13:44:23,367:INFO:Initializing create_model()
2025-10-19 13:44:23,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:44:23,368:INFO:Checking exceptions
2025-10-19 13:44:23,368:INFO:Importing libraries
2025-10-19 13:44:23,368:INFO:Copying training dataset
2025-10-19 13:44:23,551:INFO:Defining folds
2025-10-19 13:44:23,551:INFO:Declaring metric variables
2025-10-19 13:44:23,556:INFO:Importing untrained model
2025-10-19 13:44:23,560:INFO:K Neighbors Regressor Imported successfully
2025-10-19 13:44:23,568:INFO:Starting cross validation
2025-10-19 13:44:23,572:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:44:38,183:INFO:Calculating mean and std
2025-10-19 13:44:38,185:INFO:Creating metrics dataframe
2025-10-19 13:44:38,188:INFO:Uploading results into container
2025-10-19 13:44:38,188:INFO:Uploading model into container now
2025-10-19 13:44:38,189:INFO:_master_model_container: 11
2025-10-19 13:44:38,189:INFO:_display_container: 2
2025-10-19 13:44:38,189:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                    weights='uniform')
2025-10-19 13:44:38,189:INFO:create_model() successfully completed......................................
2025-10-19 13:44:38,353:INFO:SubProcess create_model() end ==================================
2025-10-19 13:44:38,354:INFO:Creating metrics dataframe
2025-10-19 13:44:38,362:INFO:Initializing Decision Tree Regressor
2025-10-19 13:44:38,363:INFO:Total runtime is 2.4606683969497682 minutes
2025-10-19 13:44:38,368:INFO:SubProcess create_model() called ==================================
2025-10-19 13:44:38,369:INFO:Initializing create_model()
2025-10-19 13:44:38,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:44:38,369:INFO:Checking exceptions
2025-10-19 13:44:38,369:INFO:Importing libraries
2025-10-19 13:44:38,370:INFO:Copying training dataset
2025-10-19 13:44:38,558:INFO:Defining folds
2025-10-19 13:44:38,559:INFO:Declaring metric variables
2025-10-19 13:44:38,563:INFO:Importing untrained model
2025-10-19 13:44:38,567:INFO:Decision Tree Regressor Imported successfully
2025-10-19 13:44:38,574:INFO:Starting cross validation
2025-10-19 13:44:38,579:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:44:53,326:INFO:Calculating mean and std
2025-10-19 13:44:53,327:INFO:Creating metrics dataframe
2025-10-19 13:44:53,329:INFO:Uploading results into container
2025-10-19 13:44:53,329:INFO:Uploading model into container now
2025-10-19 13:44:53,329:INFO:_master_model_container: 12
2025-10-19 13:44:53,329:INFO:_display_container: 2
2025-10-19 13:44:53,330:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=42, splitter='best')
2025-10-19 13:44:53,330:INFO:create_model() successfully completed......................................
2025-10-19 13:44:53,482:INFO:SubProcess create_model() end ==================================
2025-10-19 13:44:53,483:INFO:Creating metrics dataframe
2025-10-19 13:44:53,492:INFO:Initializing Random Forest Regressor
2025-10-19 13:44:53,493:INFO:Total runtime is 2.7128288030624392 minutes
2025-10-19 13:44:53,496:INFO:SubProcess create_model() called ==================================
2025-10-19 13:44:53,497:INFO:Initializing create_model()
2025-10-19 13:44:53,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:44:53,497:INFO:Checking exceptions
2025-10-19 13:44:53,497:INFO:Importing libraries
2025-10-19 13:44:53,497:INFO:Copying training dataset
2025-10-19 13:44:53,676:INFO:Defining folds
2025-10-19 13:44:53,676:INFO:Declaring metric variables
2025-10-19 13:44:53,680:INFO:Importing untrained model
2025-10-19 13:44:53,685:INFO:Random Forest Regressor Imported successfully
2025-10-19 13:44:53,693:INFO:Starting cross validation
2025-10-19 13:44:53,696:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:49:03,858:INFO:Calculating mean and std
2025-10-19 13:49:03,859:INFO:Creating metrics dataframe
2025-10-19 13:49:03,861:INFO:Uploading results into container
2025-10-19 13:49:03,861:INFO:Uploading model into container now
2025-10-19 13:49:03,861:INFO:_master_model_container: 13
2025-10-19 13:49:03,861:INFO:_display_container: 2
2025-10-19 13:49:03,862:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=1, oob_score=False,
                      random_state=42, verbose=0, warm_start=False)
2025-10-19 13:49:03,862:INFO:create_model() successfully completed......................................
2025-10-19 13:49:04,030:INFO:SubProcess create_model() end ==================================
2025-10-19 13:49:04,030:INFO:Creating metrics dataframe
2025-10-19 13:49:04,041:INFO:Initializing Extra Trees Regressor
2025-10-19 13:49:04,041:INFO:Total runtime is 6.888633203506471 minutes
2025-10-19 13:49:04,043:INFO:SubProcess create_model() called ==================================
2025-10-19 13:49:04,045:INFO:Initializing create_model()
2025-10-19 13:49:04,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:49:04,045:INFO:Checking exceptions
2025-10-19 13:49:04,045:INFO:Importing libraries
2025-10-19 13:49:04,045:INFO:Copying training dataset
2025-10-19 13:49:04,222:INFO:Defining folds
2025-10-19 13:49:04,223:INFO:Declaring metric variables
2025-10-19 13:49:04,227:INFO:Importing untrained model
2025-10-19 13:49:04,230:INFO:Extra Trees Regressor Imported successfully
2025-10-19 13:49:04,239:INFO:Starting cross validation
2025-10-19 13:49:04,242:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:53:16,095:INFO:Calculating mean and std
2025-10-19 13:53:16,097:INFO:Creating metrics dataframe
2025-10-19 13:53:16,100:INFO:Uploading results into container
2025-10-19 13:53:16,101:INFO:Uploading model into container now
2025-10-19 13:53:16,107:INFO:_master_model_container: 14
2025-10-19 13:53:16,108:INFO:_display_container: 2
2025-10-19 13:53:16,108:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=1, oob_score=False,
                    random_state=42, verbose=0, warm_start=False)
2025-10-19 13:53:16,108:INFO:create_model() successfully completed......................................
2025-10-19 13:53:16,320:INFO:SubProcess create_model() end ==================================
2025-10-19 13:53:16,320:INFO:Creating metrics dataframe
2025-10-19 13:53:16,330:INFO:Initializing AdaBoost Regressor
2025-10-19 13:53:16,331:INFO:Total runtime is 11.093441474437714 minutes
2025-10-19 13:53:16,336:INFO:SubProcess create_model() called ==================================
2025-10-19 13:53:16,337:INFO:Initializing create_model()
2025-10-19 13:53:16,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:53:16,337:INFO:Checking exceptions
2025-10-19 13:53:16,337:INFO:Importing libraries
2025-10-19 13:53:16,337:INFO:Copying training dataset
2025-10-19 13:53:16,585:INFO:Defining folds
2025-10-19 13:53:16,585:INFO:Declaring metric variables
2025-10-19 13:53:16,590:INFO:Importing untrained model
2025-10-19 13:53:16,596:INFO:AdaBoost Regressor Imported successfully
2025-10-19 13:53:16,607:INFO:Starting cross validation
2025-10-19 13:53:16,613:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:53:51,388:INFO:Calculating mean and std
2025-10-19 13:53:51,389:INFO:Creating metrics dataframe
2025-10-19 13:53:51,390:INFO:Uploading results into container
2025-10-19 13:53:51,391:INFO:Uploading model into container now
2025-10-19 13:53:51,391:INFO:_master_model_container: 15
2025-10-19 13:53:51,391:INFO:_display_container: 2
2025-10-19 13:53:51,391:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=42)
2025-10-19 13:53:51,391:INFO:create_model() successfully completed......................................
2025-10-19 13:53:51,553:INFO:SubProcess create_model() end ==================================
2025-10-19 13:53:51,553:INFO:Creating metrics dataframe
2025-10-19 13:53:51,561:INFO:Initializing Gradient Boosting Regressor
2025-10-19 13:53:51,561:INFO:Total runtime is 11.68063721259435 minutes
2025-10-19 13:53:51,565:INFO:SubProcess create_model() called ==================================
2025-10-19 13:53:51,567:INFO:Initializing create_model()
2025-10-19 13:53:51,568:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=gbr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:53:51,568:INFO:Checking exceptions
2025-10-19 13:53:51,568:INFO:Importing libraries
2025-10-19 13:53:51,568:INFO:Copying training dataset
2025-10-19 13:53:51,753:INFO:Defining folds
2025-10-19 13:53:51,754:INFO:Declaring metric variables
2025-10-19 13:53:51,758:INFO:Importing untrained model
2025-10-19 13:53:51,762:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 13:53:51,770:INFO:Starting cross validation
2025-10-19 13:53:51,775:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:54:40,179:INFO:Calculating mean and std
2025-10-19 13:54:40,180:INFO:Creating metrics dataframe
2025-10-19 13:54:40,181:INFO:Uploading results into container
2025-10-19 13:54:40,181:INFO:Uploading model into container now
2025-10-19 13:54:40,182:INFO:_master_model_container: 16
2025-10-19 13:54:40,182:INFO:_display_container: 2
2025-10-19 13:54:40,182:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 13:54:40,183:INFO:create_model() successfully completed......................................
2025-10-19 13:54:40,351:INFO:SubProcess create_model() end ==================================
2025-10-19 13:54:40,352:INFO:Creating metrics dataframe
2025-10-19 13:54:40,363:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 13:54:40,364:INFO:Total runtime is 12.494007643063863 minutes
2025-10-19 13:54:40,369:INFO:SubProcess create_model() called ==================================
2025-10-19 13:54:40,371:INFO:Initializing create_model()
2025-10-19 13:54:40,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:54:40,371:INFO:Checking exceptions
2025-10-19 13:54:40,371:INFO:Importing libraries
2025-10-19 13:54:40,371:INFO:Copying training dataset
2025-10-19 13:54:40,564:INFO:Defining folds
2025-10-19 13:54:40,564:INFO:Declaring metric variables
2025-10-19 13:54:40,569:INFO:Importing untrained model
2025-10-19 13:54:40,574:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 13:54:40,582:INFO:Starting cross validation
2025-10-19 13:54:40,587:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:54:42,635:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:54:42,655:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006666 seconds.
2025-10-19 13:54:42,655:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:54:42,655:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:54:42,655:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 13:54:42,656:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 13:54:42,657:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 13:54:45,292:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:54:45,316:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009279 seconds.
2025-10-19 13:54:45,316:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:54:45,316:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:54:45,316:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 13:54:45,317:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 13:54:45,317:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 13:54:47,968:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:54:47,984:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004674 seconds.
2025-10-19 13:54:47,984:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:54:47,984:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:54:47,985:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 13:54:47,985:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 13:54:47,985:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 13:54:50,568:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:54:50,585:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006426 seconds.
2025-10-19 13:54:50,585:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:54:50,585:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:54:50,585:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 13:54:50,586:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 13:54:50,588:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 13:54:53,149:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:54:53,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007116 seconds.
2025-10-19 13:54:53,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:54:53,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:54:53,167:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 13:54:53,167:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 13:54:53,168:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 13:54:53,756:INFO:Calculating mean and std
2025-10-19 13:54:53,757:INFO:Creating metrics dataframe
2025-10-19 13:54:53,759:INFO:Uploading results into container
2025-10-19 13:54:53,759:INFO:Uploading model into container now
2025-10-19 13:54:53,759:INFO:_master_model_container: 17
2025-10-19 13:54:53,759:INFO:_display_container: 2
2025-10-19 13:54:53,760:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 13:54:53,760:INFO:create_model() successfully completed......................................
2025-10-19 13:54:53,914:INFO:SubProcess create_model() end ==================================
2025-10-19 13:54:53,914:INFO:Creating metrics dataframe
2025-10-19 13:54:53,926:INFO:Initializing CatBoost Regressor
2025-10-19 13:54:53,926:INFO:Total runtime is 12.720044938723246 minutes
2025-10-19 13:54:53,928:INFO:SubProcess create_model() called ==================================
2025-10-19 13:54:53,929:INFO:Initializing create_model()
2025-10-19 13:54:53,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:54:53,930:INFO:Checking exceptions
2025-10-19 13:54:53,930:INFO:Importing libraries
2025-10-19 13:54:53,930:INFO:Copying training dataset
2025-10-19 13:54:54,139:INFO:Defining folds
2025-10-19 13:54:54,139:INFO:Declaring metric variables
2025-10-19 13:54:54,143:INFO:Importing untrained model
2025-10-19 13:54:54,147:INFO:CatBoost Regressor Imported successfully
2025-10-19 13:54:54,155:INFO:Starting cross validation
2025-10-19 13:54:54,161:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:56:22,931:INFO:Calculating mean and std
2025-10-19 13:56:22,932:INFO:Creating metrics dataframe
2025-10-19 13:56:22,935:INFO:Uploading results into container
2025-10-19 13:56:22,936:INFO:Uploading model into container now
2025-10-19 13:56:22,937:INFO:_master_model_container: 18
2025-10-19 13:56:22,937:INFO:_display_container: 2
2025-10-19 13:56:22,937:INFO:<catboost.core.CatBoostRegressor object at 0x0000010C5E15F650>
2025-10-19 13:56:22,937:INFO:create_model() successfully completed......................................
2025-10-19 13:56:23,095:INFO:SubProcess create_model() end ==================================
2025-10-19 13:56:23,095:INFO:Creating metrics dataframe
2025-10-19 13:56:23,104:INFO:Initializing Dummy Regressor
2025-10-19 13:56:23,104:INFO:Total runtime is 14.206355257829031 minutes
2025-10-19 13:56:23,107:INFO:SubProcess create_model() called ==================================
2025-10-19 13:56:23,109:INFO:Initializing create_model()
2025-10-19 13:56:23,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E6638D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:56:23,109:INFO:Checking exceptions
2025-10-19 13:56:23,109:INFO:Importing libraries
2025-10-19 13:56:23,109:INFO:Copying training dataset
2025-10-19 13:56:23,279:INFO:Defining folds
2025-10-19 13:56:23,279:INFO:Declaring metric variables
2025-10-19 13:56:23,283:INFO:Importing untrained model
2025-10-19 13:56:23,287:INFO:Dummy Regressor Imported successfully
2025-10-19 13:56:23,295:INFO:Starting cross validation
2025-10-19 13:56:23,300:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 13:56:33,849:INFO:Calculating mean and std
2025-10-19 13:56:33,850:INFO:Creating metrics dataframe
2025-10-19 13:56:33,852:INFO:Uploading results into container
2025-10-19 13:56:33,852:INFO:Uploading model into container now
2025-10-19 13:56:33,853:INFO:_master_model_container: 19
2025-10-19 13:56:33,853:INFO:_display_container: 2
2025-10-19 13:56:33,853:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-10-19 13:56:33,853:INFO:create_model() successfully completed......................................
2025-10-19 13:56:34,021:INFO:SubProcess create_model() end ==================================
2025-10-19 13:56:34,021:INFO:Creating metrics dataframe
2025-10-19 13:56:34,031:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 13:56:34,043:INFO:Initializing create_model()
2025-10-19 13:56:34,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:56:34,043:INFO:Checking exceptions
2025-10-19 13:56:34,045:INFO:Importing libraries
2025-10-19 13:56:34,045:INFO:Copying training dataset
2025-10-19 13:56:34,263:INFO:Defining folds
2025-10-19 13:56:34,263:INFO:Declaring metric variables
2025-10-19 13:56:34,263:INFO:Importing untrained model
2025-10-19 13:56:34,263:INFO:Declaring custom model
2025-10-19 13:56:34,264:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 13:56:34,266:INFO:Cross validation set to False
2025-10-19 13:56:34,266:INFO:Fitting Model
2025-10-19 13:56:45,825:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 13:56:45,826:INFO:create_model() successfully completed......................................
2025-10-19 13:56:45,988:INFO:Initializing create_model()
2025-10-19 13:56:45,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:56:45,989:INFO:Checking exceptions
2025-10-19 13:56:45,990:INFO:Importing libraries
2025-10-19 13:56:45,990:INFO:Copying training dataset
2025-10-19 13:56:46,158:INFO:Defining folds
2025-10-19 13:56:46,158:INFO:Declaring metric variables
2025-10-19 13:56:46,158:INFO:Importing untrained model
2025-10-19 13:56:46,158:INFO:Declaring custom model
2025-10-19 13:56:46,159:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 13:56:46,162:INFO:Cross validation set to False
2025-10-19 13:56:46,162:INFO:Fitting Model
2025-10-19 13:56:48,593:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 13:56:48,615:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008948 seconds.
2025-10-19 13:56:48,615:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 13:56:48,615:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 13:56:48,616:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 13:56:48,616:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 13:56:48,617:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 13:56:49,054:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 13:56:49,054:INFO:create_model() successfully completed......................................
2025-10-19 13:56:49,217:INFO:Initializing create_model()
2025-10-19 13:56:49,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000010C5E15F650>, fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 13:56:49,218:INFO:Checking exceptions
2025-10-19 13:56:49,220:INFO:Importing libraries
2025-10-19 13:56:49,220:INFO:Copying training dataset
2025-10-19 13:56:49,414:INFO:Defining folds
2025-10-19 13:56:49,414:INFO:Declaring metric variables
2025-10-19 13:56:49,414:INFO:Importing untrained model
2025-10-19 13:56:49,414:INFO:Declaring custom model
2025-10-19 13:56:49,414:INFO:CatBoost Regressor Imported successfully
2025-10-19 13:56:49,417:INFO:Cross validation set to False
2025-10-19 13:56:49,417:INFO:Fitting Model
2025-10-19 13:57:10,055:INFO:<catboost.core.CatBoostRegressor object at 0x0000010C5E371850>
2025-10-19 13:57:10,055:INFO:create_model() successfully completed......................................
2025-10-19 13:57:10,237:INFO:_master_model_container: 19
2025-10-19 13:57:10,237:INFO:_display_container: 2
2025-10-19 13:57:10,238:INFO:[GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostRegressor object at 0x0000010C5E371850>]
2025-10-19 13:57:10,238:INFO:compare_models() successfully completed......................................
2025-10-19 13:57:10,252:INFO:Initializing tune_model()
2025-10-19 13:57:10,252:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 13:57:10,252:INFO:Checking exceptions
2025-10-19 13:57:10,389:INFO:Copying training dataset
2025-10-19 13:57:10,518:INFO:Checking base model
2025-10-19 13:57:10,519:INFO:Base model : Gradient Boosting Regressor
2025-10-19 13:57:10,522:INFO:Declaring metric variables
2025-10-19 13:57:10,525:INFO:Defining Hyperparameters
2025-10-19 13:57:10,675:INFO:Tuning with n_jobs=1
2025-10-19 13:57:10,675:INFO:Initializing RandomizedSearchCV
2025-10-19 14:01:23,349:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 270, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.05}
2025-10-19 14:01:23,350:INFO:Hyperparameter search completed
2025-10-19 14:01:23,351:INFO:SubProcess create_model() called ==================================
2025-10-19 14:01:23,353:INFO:Initializing create_model()
2025-10-19 14:01:23,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E67A890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 270, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 6, 'learning_rate': 0.05})
2025-10-19 14:01:23,353:INFO:Checking exceptions
2025-10-19 14:01:23,353:INFO:Importing libraries
2025-10-19 14:01:23,353:INFO:Copying training dataset
2025-10-19 14:01:23,533:INFO:Defining folds
2025-10-19 14:01:23,534:INFO:Declaring metric variables
2025-10-19 14:01:23,538:INFO:Importing untrained model
2025-10-19 14:01:23,538:INFO:Declaring custom model
2025-10-19 14:01:23,544:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 14:01:23,551:INFO:Starting cross validation
2025-10-19 14:01:23,553:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 14:01:53,475:INFO:Calculating mean and std
2025-10-19 14:01:53,477:INFO:Creating metrics dataframe
2025-10-19 14:01:53,482:INFO:Finalizing model
2025-10-19 14:02:00,520:INFO:Uploading results into container
2025-10-19 14:02:00,521:INFO:Uploading model into container now
2025-10-19 14:02:00,522:INFO:_master_model_container: 20
2025-10-19 14:02:00,522:INFO:_display_container: 3
2025-10-19 14:02:00,523:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.05, loss='squared_error',
                          max_depth=6, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.3, min_samples_leaf=4,
                          min_samples_split=10, min_weight_fraction_leaf=0.0,
                          n_estimators=270, n_iter_no_change=None,
                          random_state=42, subsample=0.7, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 14:02:00,523:INFO:create_model() successfully completed......................................
2025-10-19 14:02:00,695:INFO:SubProcess create_model() end ==================================
2025-10-19 14:02:00,695:INFO:choose_better activated
2025-10-19 14:02:00,698:INFO:SubProcess create_model() called ==================================
2025-10-19 14:02:00,699:INFO:Initializing create_model()
2025-10-19 14:02:00,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:02:00,699:INFO:Checking exceptions
2025-10-19 14:02:00,700:INFO:Importing libraries
2025-10-19 14:02:00,700:INFO:Copying training dataset
2025-10-19 14:02:00,873:INFO:Defining folds
2025-10-19 14:02:00,873:INFO:Declaring metric variables
2025-10-19 14:02:00,873:INFO:Importing untrained model
2025-10-19 14:02:00,873:INFO:Declaring custom model
2025-10-19 14:02:00,874:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 14:02:00,874:INFO:Starting cross validation
2025-10-19 14:02:00,877:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 14:02:48,624:INFO:Calculating mean and std
2025-10-19 14:02:48,625:INFO:Creating metrics dataframe
2025-10-19 14:02:48,626:INFO:Finalizing model
2025-10-19 14:03:00,215:INFO:Uploading results into container
2025-10-19 14:03:00,216:INFO:Uploading model into container now
2025-10-19 14:03:00,216:INFO:_master_model_container: 21
2025-10-19 14:03:00,216:INFO:_display_container: 4
2025-10-19 14:03:00,216:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 14:03:00,217:INFO:create_model() successfully completed......................................
2025-10-19 14:03:00,369:INFO:SubProcess create_model() end ==================================
2025-10-19 14:03:00,370:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for RMSE is 0.475
2025-10-19 14:03:00,370:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.05, loss='squared_error',
                          max_depth=6, max_features='sqrt', max_leaf_nodes=None,
                          min_impurity_decrease=0.3, min_samples_leaf=4,
                          min_samples_split=10, min_weight_fraction_leaf=0.0,
                          n_estimators=270, n_iter_no_change=None,
                          random_state=42, subsample=0.7, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for RMSE is 0.4755
2025-10-19 14:03:00,371:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) is best model
2025-10-19 14:03:00,371:INFO:choose_better completed
2025-10-19 14:03:00,371:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 14:03:00,380:INFO:_master_model_container: 21
2025-10-19 14:03:00,380:INFO:_display_container: 3
2025-10-19 14:03:00,381:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 14:03:00,381:INFO:tune_model() successfully completed......................................
2025-10-19 14:03:00,549:INFO:Initializing tune_model()
2025-10-19 14:03:00,549:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 14:03:00,549:INFO:Checking exceptions
2025-10-19 14:03:00,636:INFO:Copying training dataset
2025-10-19 14:03:00,780:INFO:Checking base model
2025-10-19 14:03:00,781:INFO:Base model : Light Gradient Boosting Machine
2025-10-19 14:03:00,786:INFO:Declaring metric variables
2025-10-19 14:03:00,788:INFO:Defining Hyperparameters
2025-10-19 14:03:00,954:INFO:Tuning with n_jobs=1
2025-10-19 14:03:00,955:INFO:Initializing RandomizedSearchCV
2025-10-19 14:05:27,056:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2025-10-19 14:05:27,057:INFO:Hyperparameter search completed
2025-10-19 14:05:27,057:INFO:SubProcess create_model() called ==================================
2025-10-19 14:05:27,058:INFO:Initializing create_model()
2025-10-19 14:05:27,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E07DD10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 5, 'reg_alpha': 0.001, 'num_leaves': 30, 'n_estimators': 100, 'min_split_gain': 0.6, 'min_child_samples': 6, 'learning_rate': 0.2, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2025-10-19 14:05:27,058:INFO:Checking exceptions
2025-10-19 14:05:27,059:INFO:Importing libraries
2025-10-19 14:05:27,059:INFO:Copying training dataset
2025-10-19 14:05:27,236:INFO:Defining folds
2025-10-19 14:05:27,237:INFO:Declaring metric variables
2025-10-19 14:05:27,241:INFO:Importing untrained model
2025-10-19 14:05:27,241:INFO:Declaring custom model
2025-10-19 14:05:27,248:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 14:05:27,255:INFO:Starting cross validation
2025-10-19 14:05:27,260:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 14:05:29,312:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:29,312:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:29,312:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:29,402:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:29,404:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:29,404:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:29,404:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:29,418:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004629 seconds.
2025-10-19 14:05:29,419:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:29,419:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:29,419:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 14:05:29,419:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 14:05:29,420:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 14:05:29,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,657:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,658:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,662:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,675:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,677:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,678:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,680:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,681:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,683:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,684:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,697:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,699:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,701:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,704:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,706:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,710:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,712:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,715:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,717:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,718:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,720:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:29,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:29,943:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:29,943:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:29,943:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:31,924:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:31,924:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:31,924:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:32,009:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:32,010:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:32,010:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:32,010:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:32,026:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006337 seconds.
2025-10-19 14:05:32,026:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:32,026:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:32,027:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 14:05:32,027:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 14:05:32,027:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 14:05:32,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,275:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,277:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,279:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,281:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,282:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,283:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,286:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,294:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,297:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,299:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,300:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,304:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,306:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,309:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,310:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,311:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,313:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,314:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,316:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,317:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:32,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:32,547:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:32,548:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:32,548:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:34,534:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:34,534:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:34,534:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:34,622:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:34,628:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:34,628:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:34,628:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:34,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006390 seconds.
2025-10-19 14:05:34,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:34,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:34,645:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 14:05:34,645:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 14:05:34,645:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 14:05:34,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,861:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,889:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,960:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,962:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,965:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,967:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,971:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,975:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,976:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,979:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,981:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,982:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,985:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:34,998:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:35,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:35,002:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:35,003:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:35,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:35,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:35,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:35,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:35,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:35,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:35,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:35,233:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:35,233:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:35,233:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:37,240:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:37,240:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:37,241:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:37,335:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:37,337:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:37,337:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:37,337:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:37,352:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006070 seconds.
2025-10-19 14:05:37,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:37,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:37,352:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 14:05:37,353:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 14:05:37,353:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 14:05:37,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,605:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,607:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,608:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,610:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,624:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,624:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,627:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,628:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,629:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,629:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,630:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,630:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,631:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,632:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,632:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,633:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,634:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,634:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,635:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,636:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,656:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,658:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,661:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,662:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:37,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:37,874:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:37,874:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:37,874:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:39,799:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:39,799:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:39,799:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:39,891:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:39,892:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:39,892:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:39,892:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:39,909:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006489 seconds.
2025-10-19 14:05:39,909:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:39,909:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:39,909:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 14:05:39,909:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 14:05:39,910:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 14:05:40,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,130:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,131:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,133:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,136:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,137:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,139:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,141:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,142:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,144:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,145:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,147:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,148:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,151:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,153:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,154:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,156:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,157:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,159:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,160:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,162:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,163:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,165:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,167:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,168:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,170:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,172:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,173:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,175:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,176:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,177:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,179:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,181:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,182:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,218:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,229:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:40,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:40,428:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:40,428:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:40,428:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:40,457:INFO:Calculating mean and std
2025-10-19 14:05:40,458:INFO:Creating metrics dataframe
2025-10-19 14:05:40,463:INFO:Finalizing model
2025-10-19 14:05:42,922:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:42,922:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:42,922:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:43,030:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:43,033:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-10-19 14:05:43,033:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-10-19 14:05:43,034:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-10-19 14:05:43,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010009 seconds.
2025-10-19 14:05:43,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:43,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:43,062:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 14:05:43,062:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 14:05:43,063:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 14:05:43,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,356:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,358:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,361:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,363:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,365:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,377:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,400:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,408:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,412:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,414:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,416:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,418:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,420:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,423:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,425:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,426:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,428:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,431:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,434:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,436:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,439:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,441:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,442:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,444:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,447:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,449:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,451:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,452:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,462:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,464:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,466:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,468:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,470:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,472:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-19 14:05:43,474:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-19 14:05:43,486:INFO:Uploading results into container
2025-10-19 14:05:43,487:INFO:Uploading model into container now
2025-10-19 14:05:43,489:INFO:_master_model_container: 22
2025-10-19 14:05:43,489:INFO:_display_container: 4
2025-10-19 14:05:43,490:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
              importance_type='split', learning_rate=0.2, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.6,
              n_estimators=100, n_jobs=1, num_leaves=30, objective=None,
              random_state=42, reg_alpha=0.001, reg_lambda=5, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 14:05:43,491:INFO:create_model() successfully completed......................................
2025-10-19 14:05:43,672:INFO:SubProcess create_model() end ==================================
2025-10-19 14:05:43,672:INFO:choose_better activated
2025-10-19 14:05:43,676:INFO:SubProcess create_model() called ==================================
2025-10-19 14:05:43,677:INFO:Initializing create_model()
2025-10-19 14:05:43,677:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:05:43,677:INFO:Checking exceptions
2025-10-19 14:05:43,678:INFO:Importing libraries
2025-10-19 14:05:43,678:INFO:Copying training dataset
2025-10-19 14:05:43,851:INFO:Defining folds
2025-10-19 14:05:43,851:INFO:Declaring metric variables
2025-10-19 14:05:43,852:INFO:Importing untrained model
2025-10-19 14:05:43,852:INFO:Declaring custom model
2025-10-19 14:05:43,853:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 14:05:43,853:INFO:Starting cross validation
2025-10-19 14:05:43,857:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 14:05:45,931:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:45,948:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006706 seconds.
2025-10-19 14:05:45,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:45,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:45,948:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 14:05:45,949:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 14:05:45,949:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 14:05:48,577:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:48,594:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006707 seconds.
2025-10-19 14:05:48,594:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:48,594:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:48,595:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 14:05:48,595:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 14:05:48,595:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 14:05:51,226:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:51,244:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006679 seconds.
2025-10-19 14:05:51,244:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:51,244:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:51,244:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 14:05:51,244:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 14:05:51,245:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 14:05:53,857:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:53,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006528 seconds.
2025-10-19 14:05:53,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:53,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:53,874:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 14:05:53,874:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 14:05:53,875:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 14:05:56,541:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:56,560:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007447 seconds.
2025-10-19 14:05:56,560:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:56,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:56,561:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 14:05:56,561:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 14:05:56,561:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 14:05:57,172:INFO:Calculating mean and std
2025-10-19 14:05:57,173:INFO:Creating metrics dataframe
2025-10-19 14:05:57,175:INFO:Finalizing model
2025-10-19 14:05:59,679:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:05:59,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008773 seconds.
2025-10-19 14:05:59,702:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:05:59,702:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:05:59,702:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 14:05:59,703:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 14:05:59,703:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 14:06:00,142:INFO:Uploading results into container
2025-10-19 14:06:00,142:INFO:Uploading model into container now
2025-10-19 14:06:00,143:INFO:_master_model_container: 23
2025-10-19 14:06:00,143:INFO:_display_container: 5
2025-10-19 14:06:00,143:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 14:06:00,143:INFO:create_model() successfully completed......................................
2025-10-19 14:06:00,293:INFO:SubProcess create_model() end ==================================
2025-10-19 14:06:00,294:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for RMSE is 0.4751
2025-10-19 14:06:00,295:INFO:LGBMRegressor(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
              importance_type='split', learning_rate=0.2, max_depth=-1,
              min_child_samples=6, min_child_weight=0.001, min_split_gain=0.6,
              n_estimators=100, n_jobs=1, num_leaves=30, objective=None,
              random_state=42, reg_alpha=0.001, reg_lambda=5, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for RMSE is 0.476
2025-10-19 14:06:00,295:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-19 14:06:00,295:INFO:choose_better completed
2025-10-19 14:06:00,295:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 14:06:00,303:INFO:_master_model_container: 23
2025-10-19 14:06:00,304:INFO:_display_container: 4
2025-10-19 14:06:00,305:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 14:06:00,305:INFO:tune_model() successfully completed......................................
2025-10-19 14:06:00,466:INFO:Initializing tune_model()
2025-10-19 14:06:00,466:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000010C5E371850>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 14:06:00,466:INFO:Checking exceptions
2025-10-19 14:06:00,547:INFO:Copying training dataset
2025-10-19 14:06:00,675:INFO:Checking base model
2025-10-19 14:06:00,675:INFO:Base model : CatBoost Regressor
2025-10-19 14:06:00,679:INFO:Declaring metric variables
2025-10-19 14:06:00,681:INFO:Defining Hyperparameters
2025-10-19 14:06:00,835:INFO:Tuning with n_jobs=1
2025-10-19 14:06:00,835:INFO:Initializing RandomizedSearchCV
2025-10-19 14:10:09,588:INFO:best_params: {'actual_estimator__random_strength': 0.5, 'actual_estimator__n_estimators': 280, 'actual_estimator__l2_leaf_reg': 200, 'actual_estimator__eta': 0.05, 'actual_estimator__depth': 5}
2025-10-19 14:10:09,589:INFO:Hyperparameter search completed
2025-10-19 14:10:09,590:INFO:SubProcess create_model() called ==================================
2025-10-19 14:10:09,590:INFO:Initializing create_model()
2025-10-19 14:10:09,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000010C5CB5EED0>, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E07DD10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.5, 'n_estimators': 280, 'l2_leaf_reg': 200, 'eta': 0.05, 'depth': 5})
2025-10-19 14:10:09,591:INFO:Checking exceptions
2025-10-19 14:10:09,591:INFO:Importing libraries
2025-10-19 14:10:09,591:INFO:Copying training dataset
2025-10-19 14:10:09,769:INFO:Defining folds
2025-10-19 14:10:09,769:INFO:Declaring metric variables
2025-10-19 14:10:09,772:INFO:Importing untrained model
2025-10-19 14:10:09,772:INFO:Declaring custom model
2025-10-19 14:10:09,779:INFO:CatBoost Regressor Imported successfully
2025-10-19 14:10:09,788:INFO:Starting cross validation
2025-10-19 14:10:09,793:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 14:10:39,563:INFO:Calculating mean and std
2025-10-19 14:10:39,564:INFO:Creating metrics dataframe
2025-10-19 14:10:39,568:INFO:Finalizing model
2025-10-19 14:10:46,867:INFO:Uploading results into container
2025-10-19 14:10:46,868:INFO:Uploading model into container now
2025-10-19 14:10:46,869:INFO:_master_model_container: 24
2025-10-19 14:10:46,869:INFO:_display_container: 5
2025-10-19 14:10:46,869:INFO:<catboost.core.CatBoostRegressor object at 0x0000010C5CC2A750>
2025-10-19 14:10:46,869:INFO:create_model() successfully completed......................................
2025-10-19 14:10:47,050:INFO:SubProcess create_model() end ==================================
2025-10-19 14:10:47,050:INFO:choose_better activated
2025-10-19 14:10:47,053:INFO:SubProcess create_model() called ==================================
2025-10-19 14:10:47,054:INFO:Initializing create_model()
2025-10-19 14:10:47,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=<catboost.core.CatBoostRegressor object at 0x0000010C5E371850>, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:10:47,055:INFO:Checking exceptions
2025-10-19 14:10:47,058:INFO:Importing libraries
2025-10-19 14:10:47,058:INFO:Copying training dataset
2025-10-19 14:10:47,260:INFO:Defining folds
2025-10-19 14:10:47,260:INFO:Declaring metric variables
2025-10-19 14:10:47,260:INFO:Importing untrained model
2025-10-19 14:10:47,260:INFO:Declaring custom model
2025-10-19 14:10:47,260:INFO:CatBoost Regressor Imported successfully
2025-10-19 14:10:47,260:INFO:Starting cross validation
2025-10-19 14:10:47,263:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 14:12:16,716:INFO:Calculating mean and std
2025-10-19 14:12:16,716:INFO:Creating metrics dataframe
2025-10-19 14:12:16,718:INFO:Finalizing model
2025-10-19 14:12:37,798:INFO:Uploading results into container
2025-10-19 14:12:37,798:INFO:Uploading model into container now
2025-10-19 14:12:37,799:INFO:_master_model_container: 25
2025-10-19 14:12:37,799:INFO:_display_container: 6
2025-10-19 14:12:37,799:INFO:<catboost.core.CatBoostRegressor object at 0x0000010C60D7E110>
2025-10-19 14:12:37,799:INFO:create_model() successfully completed......................................
2025-10-19 14:12:37,952:INFO:SubProcess create_model() end ==================================
2025-10-19 14:12:37,953:INFO:<catboost.core.CatBoostRegressor object at 0x0000010C60D7E110> result for RMSE is 0.4774
2025-10-19 14:12:37,953:INFO:<catboost.core.CatBoostRegressor object at 0x0000010C5CC2A750> result for RMSE is 0.4747
2025-10-19 14:12:37,953:INFO:<catboost.core.CatBoostRegressor object at 0x0000010C5CC2A750> is best model
2025-10-19 14:12:37,953:INFO:choose_better completed
2025-10-19 14:12:37,960:INFO:_master_model_container: 25
2025-10-19 14:12:37,961:INFO:_display_container: 5
2025-10-19 14:12:37,961:INFO:<catboost.core.CatBoostRegressor object at 0x0000010C5CC2A750>
2025-10-19 14:12:37,961:INFO:tune_model() successfully completed......................................
2025-10-19 14:12:38,121:INFO:Initializing blend_models()
2025-10-19 14:12:38,121:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator_list=[GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostRegressor object at 0x0000010C5CC2A750>], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-19 14:12:38,121:INFO:Checking exceptions
2025-10-19 14:12:38,204:INFO:Importing libraries
2025-10-19 14:12:38,205:INFO:Copying training dataset
2025-10-19 14:12:38,211:INFO:Getting model names
2025-10-19 14:12:38,218:INFO:SubProcess create_model() called ==================================
2025-10-19 14:12:38,226:INFO:Initializing create_model()
2025-10-19 14:12:38,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x0000010C5CC2A750>)],
                n_jobs=1, verbose=False, weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62570    U04033
38158    U11477
860      U08142
15795    U11535
56422    U02424
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5C7BC8D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:12:38,227:INFO:Checking exceptions
2025-10-19 14:12:38,227:INFO:Importing libraries
2025-10-19 14:12:38,227:INFO:Copying training dataset
2025-10-19 14:12:38,437:INFO:Defining folds
2025-10-19 14:12:38,437:INFO:Declaring metric variables
2025-10-19 14:12:38,441:INFO:Importing untrained model
2025-10-19 14:12:38,441:INFO:Declaring custom model
2025-10-19 14:12:38,447:INFO:Voting Regressor Imported successfully
2025-10-19 14:12:38,453:INFO:Starting cross validation
2025-10-19 14:12:38,457:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 14:12:48,024:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:12:48,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006669 seconds.
2025-10-19 14:12:48,041:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:12:48,041:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:12:48,041:INFO:[LightGBM] [Info] Total Bins 1413
2025-10-19 14:12:48,041:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 14:12:48,042:INFO:[LightGBM] [Info] Start training from score 3.317253
2025-10-19 14:13:01,581:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:13:01,599:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006954 seconds.
2025-10-19 14:13:01,599:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:13:01,599:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:13:01,600:INFO:[LightGBM] [Info] Total Bins 1411
2025-10-19 14:13:01,600:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 14:13:01,600:INFO:[LightGBM] [Info] Start training from score 3.317398
2025-10-19 14:13:15,334:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:13:15,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007145 seconds.
2025-10-19 14:13:15,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:13:15,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:13:15,352:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 14:13:15,352:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 14:13:15,352:INFO:[LightGBM] [Info] Start training from score 3.319844
2025-10-19 14:13:28,879:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:13:28,896:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006322 seconds.
2025-10-19 14:13:28,896:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:13:28,896:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:13:28,896:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 14:13:28,896:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 14:13:28,896:INFO:[LightGBM] [Info] Start training from score 3.319657
2025-10-19 14:13:42,514:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:13:42,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008055 seconds.
2025-10-19 14:13:42,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:13:42,537:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:13:42,537:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 14:13:42,538:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 14:13:42,538:INFO:[LightGBM] [Info] Start training from score 3.323071
2025-10-19 14:13:46,858:INFO:Calculating mean and std
2025-10-19 14:13:46,859:INFO:Creating metrics dataframe
2025-10-19 14:13:46,865:INFO:Finalizing model
2025-10-19 14:13:58,741:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:13:58,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008859 seconds.
2025-10-19 14:13:58,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:13:58,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:13:58,763:INFO:[LightGBM] [Info] Total Bins 1409
2025-10-19 14:13:58,763:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 14:13:58,763:INFO:[LightGBM] [Info] Start training from score 3.319445
2025-10-19 14:14:03,643:INFO:Uploading results into container
2025-10-19 14:14:03,644:INFO:Uploading model into container now
2025-10-19 14:14:03,645:INFO:_master_model_container: 26
2025-10-19 14:14:03,645:INFO:_display_container: 6
2025-10-19 14:14:03,648:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x0000010C5E1414D0>)],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 14:14:03,648:INFO:create_model() successfully completed......................................
2025-10-19 14:14:03,860:INFO:SubProcess create_model() end ==================================
2025-10-19 14:14:03,868:INFO:_master_model_container: 26
2025-10-19 14:14:03,869:INFO:_display_container: 6
2025-10-19 14:14:03,872:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x0000010C5E1414D0>)],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 14:14:03,873:INFO:blend_models() successfully completed......................................
2025-10-19 14:14:04,033:INFO:Initializing finalize_model()
2025-10-19 14:14:04,033:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x0000010C5E1414D0>)],
                n_jobs=1, verbose=False, weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-19 14:14:04,036:INFO:Finalizing VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x0000010C5E1414D0>)],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 14:14:04,163:INFO:Initializing create_model()
2025-10-19 14:14:04,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=1, num_leaves=31,
                                           objective=None, random_state=42,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0)),
                            ('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x0000010C5E1414D0>)],
                n_jobs=1, verbose=False, weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=48052    U07576
44572    U10574
724      U01064
37154    U00331
35243    U10138
          ...  
62296    U09331
28248    U08761
48600    U06118
8049     U04657
48533    U06931
Name: id_usuario, Length: 63955, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:14:04,163:INFO:Checking exceptions
2025-10-19 14:14:04,164:INFO:Importing libraries
2025-10-19 14:14:04,164:INFO:Copying training dataset
2025-10-19 14:14:04,188:INFO:Defining folds
2025-10-19 14:14:04,188:INFO:Declaring metric variables
2025-10-19 14:14:04,188:INFO:Importing untrained model
2025-10-19 14:14:04,188:INFO:Declaring custom model
2025-10-19 14:14:04,190:INFO:Voting Regressor Imported successfully
2025-10-19 14:14:04,192:INFO:Cross validation set to False
2025-10-19 14:14:04,192:INFO:Fitting Model
2025-10-19 14:14:21,118:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:14:21,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012802 seconds.
2025-10-19 14:14:21,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:14:21,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:14:21,148:INFO:[LightGBM] [Info] Total Bins 1410
2025-10-19 14:14:21,148:INFO:[LightGBM] [Info] Number of data points in the train set: 63955, number of used features: 95
2025-10-19 14:14:21,149:INFO:[LightGBM] [Info] Start training from score 3.320833
2025-10-19 14:14:27,841:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000010C617FA9D0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 14:14:27,841:INFO:create_model() successfully completed......................................
2025-10-19 14:14:28,009:INFO:_master_model_container: 26
2025-10-19 14:14:28,009:INFO:_display_container: 6
2025-10-19 14:14:28,032:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000010C617FA9D0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 14:14:28,032:INFO:finalize_model() successfully completed......................................
2025-10-19 14:14:28,236:INFO:Initializing save_model()
2025-10-19 14:14:28,236:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000010C617FA9D0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), model_name=modelo_reg_rating_v2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-10-19 14:14:28,236:INFO:Adding model into prep_pipe
2025-10-19 14:14:28,236:WARNING:Only Model saved as it was a pipeline.
2025-10-19 14:14:28,271:INFO:modelo_reg_rating_v2.pkl saved in current working directory
2025-10-19 14:14:28,296:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000010C617FA9D0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 14:14:28,296:INFO:save_model() successfully completed......................................
2025-10-19 14:14:28,504:INFO:Initializing predict_model()
2025-10-19 14:14:28,504:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000010C617FA9D0>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000010C6175A340>)
2025-10-19 14:14:28,504:INFO:Checking exceptions
2025-10-19 14:14:28,504:INFO:Preloading libraries
2025-10-19 14:14:28,506:INFO:Set up data.
2025-10-19 14:14:28,533:INFO:Set up index.
2025-10-19 14:16:00,420:INFO:Initializing load_model()
2025-10-19 14:16:00,420:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 14:16:00,488:INFO:Initializing load_model()
2025-10-19 14:16:00,488:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 14:16:00,821:INFO:Initializing predict_model()
2025-10-19 14:16:00,821:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000010C657B2990>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000010C5E0919E0>)
2025-10-19 14:16:00,821:INFO:Checking exceptions
2025-10-19 14:16:00,821:INFO:Preloading libraries
2025-10-19 14:16:00,825:INFO:Set up data.
2025-10-19 14:16:00,830:INFO:Set up index.
2025-10-19 14:16:04,937:INFO:Initializing load_model()
2025-10-19 14:16:04,938:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 14:16:04,985:INFO:Initializing load_model()
2025-10-19 14:16:04,985:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 14:16:05,116:INFO:Initializing predict_model()
2025-10-19 14:16:05,116:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000010C617E2590>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000010C5CBBCA40>)
2025-10-19 14:16:05,116:INFO:Checking exceptions
2025-10-19 14:16:05,117:INFO:Preloading libraries
2025-10-19 14:16:05,119:INFO:Set up data.
2025-10-19 14:16:05,126:INFO:Set up index.
2025-10-19 14:16:08,840:INFO:Initializing load_model()
2025-10-19 14:16:08,840:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 14:16:08,880:INFO:Initializing load_model()
2025-10-19 14:16:08,880:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 14:16:09,081:INFO:Initializing predict_model()
2025-10-19 14:16:09,081:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000010C619A4150>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000010C609E42C0>)
2025-10-19 14:16:09,081:INFO:Checking exceptions
2025-10-19 14:16:09,081:INFO:Preloading libraries
2025-10-19 14:16:09,083:INFO:Set up data.
2025-10-19 14:16:09,090:INFO:Set up index.
2025-10-19 14:16:20,759:INFO:Initializing load_model()
2025-10-19 14:16:20,759:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-19 14:16:20,798:INFO:Initializing load_model()
2025-10-19 14:16:20,798:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-19 14:16:21,119:INFO:Initializing predict_model()
2025-10-19 14:16:21,119:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000010C5E340C90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                            min_child_samples=20,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.0,
                                                            n_estimators=100,
                                                            n_jobs=1,
                                                            num_leaves=31,
                                                            objective=None,
                                                            random_state=42,
                                                            reg_alpha=0.0,
                                                            reg_lambda=0.0,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0)),
                                             ('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x0000010C65741590>)],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000010C236E6160>)
2025-10-19 14:16:21,119:INFO:Checking exceptions
2025-10-19 14:16:21,119:INFO:Preloading libraries
2025-10-19 14:16:21,120:INFO:Set up data.
2025-10-19 14:16:21,128:INFO:Set up index.
2025-10-19 14:18:20,960:INFO:PyCaret ClassificationExperiment
2025-10-19 14:18:20,960:INFO:Logging name: clf-default-name
2025-10-19 14:18:20,960:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 14:18:20,960:INFO:version 3.3.2
2025-10-19 14:18:20,960:INFO:Initializing setup()
2025-10-19 14:18:20,960:INFO:self.USI: d6d6
2025-10-19 14:18:20,961:INFO:self._variable_keys: {'target_param', 'fold_groups_param', 'exp_name_log', 'X_train', 'USI', 'gpu_n_jobs_param', 'X_test', 'log_plots_param', 'fold_shuffle_param', 'is_multiclass', 'gpu_param', 'idx', 'y_train', 'exp_id', 'X', 'logging_param', 'data', 'pipeline', 'y_test', 'n_jobs_param', '_ml_usecase', 'y', 'seed', 'html_param', 'fold_generator', '_available_plots', 'fix_imbalance', 'memory'}
2025-10-19 14:18:20,961:INFO:Checking environment
2025-10-19 14:18:20,961:INFO:python_version: 3.11.13
2025-10-19 14:18:20,961:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 14:18:20,961:INFO:machine: AMD64
2025-10-19 14:18:20,961:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 14:18:20,969:INFO:Memory: svmem(total=16856211456, available=3261112320, percent=80.7, used=13595099136, free=3261112320)
2025-10-19 14:18:20,969:INFO:Physical Core: 4
2025-10-19 14:18:20,969:INFO:Logical Core: 8
2025-10-19 14:18:20,969:INFO:Checking libraries
2025-10-19 14:18:20,969:INFO:System:
2025-10-19 14:18:20,969:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 14:18:20,969:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 14:18:20,969:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 14:18:20,969:INFO:PyCaret required dependencies:
2025-10-19 14:18:20,969:INFO:                 pip: 25.2
2025-10-19 14:18:20,969:INFO:          setuptools: 80.9.0
2025-10-19 14:18:20,969:INFO:             pycaret: 3.3.2
2025-10-19 14:18:20,969:INFO:             IPython: 9.6.0
2025-10-19 14:18:20,969:INFO:          ipywidgets: 8.1.7
2025-10-19 14:18:20,969:INFO:                tqdm: 4.67.1
2025-10-19 14:18:20,969:INFO:               numpy: 1.26.4
2025-10-19 14:18:20,969:INFO:              pandas: 2.1.4
2025-10-19 14:18:20,969:INFO:              jinja2: 3.1.6
2025-10-19 14:18:20,969:INFO:               scipy: 1.11.4
2025-10-19 14:18:20,969:INFO:              joblib: 1.3.2
2025-10-19 14:18:20,969:INFO:             sklearn: 1.4.2
2025-10-19 14:18:20,969:INFO:                pyod: 2.0.5
2025-10-19 14:18:20,970:INFO:            imblearn: 0.14.0
2025-10-19 14:18:20,970:INFO:   category_encoders: 2.7.0
2025-10-19 14:18:20,970:INFO:            lightgbm: 4.6.0
2025-10-19 14:18:20,970:INFO:               numba: 0.61.0
2025-10-19 14:18:20,970:INFO:            requests: 2.32.5
2025-10-19 14:18:20,970:INFO:          matplotlib: 3.7.5
2025-10-19 14:18:20,970:INFO:          scikitplot: 0.3.7
2025-10-19 14:18:20,970:INFO:         yellowbrick: 1.5
2025-10-19 14:18:20,970:INFO:              plotly: 5.24.1
2025-10-19 14:18:20,970:INFO:    plotly-resampler: Not installed
2025-10-19 14:18:20,970:INFO:             kaleido: 1.1.0
2025-10-19 14:18:20,970:INFO:           schemdraw: 0.15
2025-10-19 14:18:20,970:INFO:         statsmodels: 0.14.5
2025-10-19 14:18:20,970:INFO:              sktime: 0.26.0
2025-10-19 14:18:20,970:INFO:               tbats: 1.1.3
2025-10-19 14:18:20,970:INFO:            pmdarima: 2.0.4
2025-10-19 14:18:20,970:INFO:              psutil: 7.1.0
2025-10-19 14:18:20,970:INFO:          markupsafe: 3.0.3
2025-10-19 14:18:20,970:INFO:             pickle5: Not installed
2025-10-19 14:18:20,970:INFO:         cloudpickle: 3.1.1
2025-10-19 14:18:20,970:INFO:         deprecation: 2.1.0
2025-10-19 14:18:20,970:INFO:              xxhash: 3.6.0
2025-10-19 14:18:20,970:INFO:           wurlitzer: Not installed
2025-10-19 14:18:20,970:INFO:PyCaret optional dependencies:
2025-10-19 14:18:20,970:INFO:                shap: 0.44.1
2025-10-19 14:18:20,970:INFO:           interpret: 0.7.3
2025-10-19 14:18:20,970:INFO:                umap: 0.5.7
2025-10-19 14:18:20,970:INFO:     ydata_profiling: 4.17.0
2025-10-19 14:18:20,970:INFO:  explainerdashboard: 0.5.1
2025-10-19 14:18:20,970:INFO:             autoviz: Not installed
2025-10-19 14:18:20,970:INFO:           fairlearn: 0.7.0
2025-10-19 14:18:20,971:INFO:          deepchecks: Not installed
2025-10-19 14:18:20,971:INFO:             xgboost: Not installed
2025-10-19 14:18:20,971:INFO:            catboost: 1.2.8
2025-10-19 14:18:20,971:INFO:              kmodes: 0.12.2
2025-10-19 14:18:20,971:INFO:             mlxtend: 0.23.4
2025-10-19 14:18:20,971:INFO:       statsforecast: 1.5.0
2025-10-19 14:18:20,971:INFO:        tune_sklearn: Not installed
2025-10-19 14:18:20,971:INFO:                 ray: Not installed
2025-10-19 14:18:20,971:INFO:            hyperopt: 0.2.7
2025-10-19 14:18:20,971:INFO:              optuna: 4.5.0
2025-10-19 14:18:20,971:INFO:               skopt: 0.10.2
2025-10-19 14:18:20,971:INFO:              mlflow: 3.5.0
2025-10-19 14:18:20,971:INFO:              gradio: 5.49.1
2025-10-19 14:18:20,971:INFO:             fastapi: 0.119.0
2025-10-19 14:18:20,971:INFO:             uvicorn: 0.38.0
2025-10-19 14:18:20,971:INFO:              m2cgen: 0.10.0
2025-10-19 14:18:20,971:INFO:           evidently: 0.4.40
2025-10-19 14:18:20,971:INFO:               fugue: 0.8.7
2025-10-19 14:18:20,971:INFO:           streamlit: Not installed
2025-10-19 14:18:20,971:INFO:             prophet: Not installed
2025-10-19 14:18:20,971:INFO:None
2025-10-19 14:18:20,971:INFO:Set up data.
2025-10-19 14:18:21,137:INFO:Set up folding strategy.
2025-10-19 14:18:21,301:INFO:Set up train/test split.
2025-10-19 14:18:21,625:INFO:Set up index.
2025-10-19 14:18:21,639:INFO:Assigning column types.
2025-10-19 14:18:21,907:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 14:18:21,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 14:18:21,957:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 14:18:21,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 14:18:21,986:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 14:18:22,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 14:18:22,042:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 14:18:22,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 14:18:22,086:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 14:18:22,088:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 14:18:22,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 14:18:22,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 14:18:22,205:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 14:18:22,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 14:18:22,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 14:18:22,275:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 14:18:22,276:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 14:18:22,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 14:18:22,344:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 14:18:22,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 14:18:22,413:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 14:18:22,416:INFO:Preparing preprocessing pipeline...
2025-10-19 14:18:22,452:INFO:Set up simple imputation.
2025-10-19 14:18:22,605:INFO:Set up encoding of ordinal features.
2025-10-19 14:18:22,677:INFO:Set up encoding of categorical features.
2025-10-19 14:18:22,682:INFO:Set up removing multicollinearity.
2025-10-19 14:18:22,721:INFO:Set up column name cleaning.
2025-10-19 14:18:24,789:INFO:Finished creating preprocessing pipeline.
2025-10-19 14:18:24,808:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 14:18:24,808:INFO:Creating final display dataframe.
2025-10-19 14:18:27,048:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (63955, 28)
4        Transformed data shape       (63955, 96)
5   Transformed train set shape       (44768, 96)
6    Transformed test set shape       (19187, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              d6d6
2025-10-19 14:18:27,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 14:18:27,107:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 14:18:27,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 14:18:27,173:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 14:18:27,175:INFO:setup() successfully completed in 6.26s...............
2025-10-19 14:18:27,175:INFO:Initializing compare_models()
2025-10-19 14:18:27,175:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 14:18:27,175:INFO:Checking exceptions
2025-10-19 14:18:27,319:INFO:Preparing display monitor
2025-10-19 14:18:27,342:INFO:Initializing Logistic Regression
2025-10-19 14:18:27,342:INFO:Total runtime is 0.0 minutes
2025-10-19 14:18:27,347:INFO:SubProcess create_model() called ==================================
2025-10-19 14:18:27,350:INFO:Initializing create_model()
2025-10-19 14:18:27,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:18:27,350:INFO:Checking exceptions
2025-10-19 14:18:27,350:INFO:Importing libraries
2025-10-19 14:18:27,350:INFO:Copying training dataset
2025-10-19 14:18:27,575:INFO:Defining folds
2025-10-19 14:18:27,575:INFO:Declaring metric variables
2025-10-19 14:18:27,578:INFO:Importing untrained model
2025-10-19 14:18:27,583:INFO:Logistic Regression Imported successfully
2025-10-19 14:18:27,590:INFO:Starting cross validation
2025-10-19 14:18:27,594:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:18:55,026:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 14:18:55,302:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 14:18:55,563:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 14:18:55,604:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 14:18:55,703:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-19 14:18:56,069:INFO:Calculating mean and std
2025-10-19 14:18:56,071:INFO:Creating metrics dataframe
2025-10-19 14:18:56,074:INFO:Uploading results into container
2025-10-19 14:18:56,074:INFO:Uploading model into container now
2025-10-19 14:18:56,075:INFO:_master_model_container: 1
2025-10-19 14:18:56,075:INFO:_display_container: 2
2025-10-19 14:18:56,075:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 14:18:56,076:INFO:create_model() successfully completed......................................
2025-10-19 14:18:56,260:INFO:SubProcess create_model() end ==================================
2025-10-19 14:18:56,260:INFO:Creating metrics dataframe
2025-10-19 14:18:56,267:INFO:Initializing K Neighbors Classifier
2025-10-19 14:18:56,267:INFO:Total runtime is 0.4820869565010071 minutes
2025-10-19 14:18:56,270:INFO:SubProcess create_model() called ==================================
2025-10-19 14:18:56,271:INFO:Initializing create_model()
2025-10-19 14:18:56,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:18:56,272:INFO:Checking exceptions
2025-10-19 14:18:56,272:INFO:Importing libraries
2025-10-19 14:18:56,272:INFO:Copying training dataset
2025-10-19 14:18:56,453:INFO:Defining folds
2025-10-19 14:18:56,453:INFO:Declaring metric variables
2025-10-19 14:18:56,459:INFO:Importing untrained model
2025-10-19 14:18:56,463:INFO:K Neighbors Classifier Imported successfully
2025-10-19 14:18:56,471:INFO:Starting cross validation
2025-10-19 14:18:56,475:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:19:10,644:INFO:Calculating mean and std
2025-10-19 14:19:10,645:INFO:Creating metrics dataframe
2025-10-19 14:19:10,647:INFO:Uploading results into container
2025-10-19 14:19:10,648:INFO:Uploading model into container now
2025-10-19 14:19:10,648:INFO:_master_model_container: 2
2025-10-19 14:19:10,648:INFO:_display_container: 2
2025-10-19 14:19:10,648:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 14:19:10,648:INFO:create_model() successfully completed......................................
2025-10-19 14:19:10,825:INFO:SubProcess create_model() end ==================================
2025-10-19 14:19:10,826:INFO:Creating metrics dataframe
2025-10-19 14:19:10,854:INFO:Initializing Naive Bayes
2025-10-19 14:19:10,854:INFO:Total runtime is 0.725190015633901 minutes
2025-10-19 14:19:10,858:INFO:SubProcess create_model() called ==================================
2025-10-19 14:19:10,859:INFO:Initializing create_model()
2025-10-19 14:19:10,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:19:10,860:INFO:Checking exceptions
2025-10-19 14:19:10,860:INFO:Importing libraries
2025-10-19 14:19:10,860:INFO:Copying training dataset
2025-10-19 14:19:11,108:INFO:Defining folds
2025-10-19 14:19:11,108:INFO:Declaring metric variables
2025-10-19 14:19:11,113:INFO:Importing untrained model
2025-10-19 14:19:11,118:INFO:Naive Bayes Imported successfully
2025-10-19 14:19:11,124:INFO:Starting cross validation
2025-10-19 14:19:11,127:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:19:15,590:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:19:15,718:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:19:15,737:INFO:Calculating mean and std
2025-10-19 14:19:15,738:INFO:Creating metrics dataframe
2025-10-19 14:19:15,739:INFO:Uploading results into container
2025-10-19 14:19:15,739:INFO:Uploading model into container now
2025-10-19 14:19:15,740:INFO:_master_model_container: 3
2025-10-19 14:19:15,740:INFO:_display_container: 2
2025-10-19 14:19:15,740:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 14:19:15,740:INFO:create_model() successfully completed......................................
2025-10-19 14:19:15,899:INFO:SubProcess create_model() end ==================================
2025-10-19 14:19:15,899:INFO:Creating metrics dataframe
2025-10-19 14:19:15,909:INFO:Initializing Decision Tree Classifier
2025-10-19 14:19:15,909:INFO:Total runtime is 0.809438955783844 minutes
2025-10-19 14:19:15,911:INFO:SubProcess create_model() called ==================================
2025-10-19 14:19:15,913:INFO:Initializing create_model()
2025-10-19 14:19:15,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:19:15,913:INFO:Checking exceptions
2025-10-19 14:19:15,913:INFO:Importing libraries
2025-10-19 14:19:15,913:INFO:Copying training dataset
2025-10-19 14:19:16,094:INFO:Defining folds
2025-10-19 14:19:16,094:INFO:Declaring metric variables
2025-10-19 14:19:16,098:INFO:Importing untrained model
2025-10-19 14:19:16,103:INFO:Decision Tree Classifier Imported successfully
2025-10-19 14:19:16,111:INFO:Starting cross validation
2025-10-19 14:19:16,115:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:19:21,225:INFO:Calculating mean and std
2025-10-19 14:19:21,227:INFO:Creating metrics dataframe
2025-10-19 14:19:21,229:INFO:Uploading results into container
2025-10-19 14:19:21,229:INFO:Uploading model into container now
2025-10-19 14:19:21,230:INFO:_master_model_container: 4
2025-10-19 14:19:21,230:INFO:_display_container: 2
2025-10-19 14:19:21,230:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-19 14:19:21,230:INFO:create_model() successfully completed......................................
2025-10-19 14:19:21,425:INFO:SubProcess create_model() end ==================================
2025-10-19 14:19:21,425:INFO:Creating metrics dataframe
2025-10-19 14:19:21,436:INFO:Initializing SVM - Linear Kernel
2025-10-19 14:19:21,436:INFO:Total runtime is 0.9015604893366496 minutes
2025-10-19 14:19:21,441:INFO:SubProcess create_model() called ==================================
2025-10-19 14:19:21,442:INFO:Initializing create_model()
2025-10-19 14:19:21,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:19:21,442:INFO:Checking exceptions
2025-10-19 14:19:21,442:INFO:Importing libraries
2025-10-19 14:19:21,443:INFO:Copying training dataset
2025-10-19 14:19:21,643:INFO:Defining folds
2025-10-19 14:19:21,643:INFO:Declaring metric variables
2025-10-19 14:19:21,647:INFO:Importing untrained model
2025-10-19 14:19:21,652:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 14:19:21,659:INFO:Starting cross validation
2025-10-19 14:19:21,663:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:19:32,712:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:19:32,737:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:19:33,380:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:19:33,534:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:19:33,550:INFO:Calculating mean and std
2025-10-19 14:19:33,552:INFO:Creating metrics dataframe
2025-10-19 14:19:33,553:INFO:Uploading results into container
2025-10-19 14:19:33,553:INFO:Uploading model into container now
2025-10-19 14:19:33,553:INFO:_master_model_container: 5
2025-10-19 14:19:33,553:INFO:_display_container: 2
2025-10-19 14:19:33,554:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 14:19:33,554:INFO:create_model() successfully completed......................................
2025-10-19 14:19:33,715:INFO:SubProcess create_model() end ==================================
2025-10-19 14:19:33,715:INFO:Creating metrics dataframe
2025-10-19 14:19:33,725:INFO:Initializing Ridge Classifier
2025-10-19 14:19:33,725:INFO:Total runtime is 1.1063807606697083 minutes
2025-10-19 14:19:33,729:INFO:SubProcess create_model() called ==================================
2025-10-19 14:19:33,730:INFO:Initializing create_model()
2025-10-19 14:19:33,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:19:33,731:INFO:Checking exceptions
2025-10-19 14:19:33,731:INFO:Importing libraries
2025-10-19 14:19:33,731:INFO:Copying training dataset
2025-10-19 14:19:33,914:INFO:Defining folds
2025-10-19 14:19:33,914:INFO:Declaring metric variables
2025-10-19 14:19:33,919:INFO:Importing untrained model
2025-10-19 14:19:33,924:INFO:Ridge Classifier Imported successfully
2025-10-19 14:19:33,932:INFO:Starting cross validation
2025-10-19 14:19:33,936:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:19:38,586:INFO:Calculating mean and std
2025-10-19 14:19:38,587:INFO:Creating metrics dataframe
2025-10-19 14:19:38,588:INFO:Uploading results into container
2025-10-19 14:19:38,588:INFO:Uploading model into container now
2025-10-19 14:19:38,589:INFO:_master_model_container: 6
2025-10-19 14:19:38,589:INFO:_display_container: 2
2025-10-19 14:19:38,589:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 14:19:38,590:INFO:create_model() successfully completed......................................
2025-10-19 14:19:38,751:INFO:SubProcess create_model() end ==================================
2025-10-19 14:19:38,751:INFO:Creating metrics dataframe
2025-10-19 14:19:38,759:INFO:Initializing Random Forest Classifier
2025-10-19 14:19:38,759:INFO:Total runtime is 1.190272370974223 minutes
2025-10-19 14:19:38,762:INFO:SubProcess create_model() called ==================================
2025-10-19 14:19:38,763:INFO:Initializing create_model()
2025-10-19 14:19:38,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:19:38,763:INFO:Checking exceptions
2025-10-19 14:19:38,763:INFO:Importing libraries
2025-10-19 14:19:38,763:INFO:Copying training dataset
2025-10-19 14:19:38,945:INFO:Defining folds
2025-10-19 14:19:38,945:INFO:Declaring metric variables
2025-10-19 14:19:38,948:INFO:Importing untrained model
2025-10-19 14:19:38,953:INFO:Random Forest Classifier Imported successfully
2025-10-19 14:19:38,959:INFO:Starting cross validation
2025-10-19 14:19:38,964:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:19:50,025:INFO:Calculating mean and std
2025-10-19 14:19:50,027:INFO:Creating metrics dataframe
2025-10-19 14:19:50,028:INFO:Uploading results into container
2025-10-19 14:19:50,029:INFO:Uploading model into container now
2025-10-19 14:19:50,029:INFO:_master_model_container: 7
2025-10-19 14:19:50,029:INFO:_display_container: 2
2025-10-19 14:19:50,029:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-19 14:19:50,029:INFO:create_model() successfully completed......................................
2025-10-19 14:19:50,206:INFO:SubProcess create_model() end ==================================
2025-10-19 14:19:50,206:INFO:Creating metrics dataframe
2025-10-19 14:19:50,212:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 14:19:50,212:INFO:Total runtime is 1.3811576962471008 minutes
2025-10-19 14:19:50,215:INFO:SubProcess create_model() called ==================================
2025-10-19 14:19:50,216:INFO:Initializing create_model()
2025-10-19 14:19:50,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:19:50,216:INFO:Checking exceptions
2025-10-19 14:19:50,216:INFO:Importing libraries
2025-10-19 14:19:50,216:INFO:Copying training dataset
2025-10-19 14:19:50,411:INFO:Defining folds
2025-10-19 14:19:50,411:INFO:Declaring metric variables
2025-10-19 14:19:50,416:INFO:Importing untrained model
2025-10-19 14:19:50,421:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 14:19:50,428:INFO:Starting cross validation
2025-10-19 14:19:50,433:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:19:55,132:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 14:19:55,496:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 14:19:55,668:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 14:19:55,959:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 14:19:56,015:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-19 14:19:56,766:INFO:Calculating mean and std
2025-10-19 14:19:56,767:INFO:Creating metrics dataframe
2025-10-19 14:19:56,770:INFO:Uploading results into container
2025-10-19 14:19:56,770:INFO:Uploading model into container now
2025-10-19 14:19:56,771:INFO:_master_model_container: 8
2025-10-19 14:19:56,771:INFO:_display_container: 2
2025-10-19 14:19:56,771:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 14:19:56,771:INFO:create_model() successfully completed......................................
2025-10-19 14:19:56,936:INFO:SubProcess create_model() end ==================================
2025-10-19 14:19:56,936:INFO:Creating metrics dataframe
2025-10-19 14:19:56,943:INFO:Initializing Ada Boost Classifier
2025-10-19 14:19:56,944:INFO:Total runtime is 1.4933698336283365 minutes
2025-10-19 14:19:56,949:INFO:SubProcess create_model() called ==================================
2025-10-19 14:19:56,950:INFO:Initializing create_model()
2025-10-19 14:19:56,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:19:56,950:INFO:Checking exceptions
2025-10-19 14:19:56,950:INFO:Importing libraries
2025-10-19 14:19:56,950:INFO:Copying training dataset
2025-10-19 14:19:57,130:INFO:Defining folds
2025-10-19 14:19:57,131:INFO:Declaring metric variables
2025-10-19 14:19:57,134:INFO:Importing untrained model
2025-10-19 14:19:57,139:INFO:Ada Boost Classifier Imported successfully
2025-10-19 14:19:57,146:INFO:Starting cross validation
2025-10-19 14:19:57,149:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:20:00,683:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:20:00,785:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:20:00,896:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:20:01,083:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:20:01,132:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:20:05,843:INFO:Calculating mean and std
2025-10-19 14:20:05,844:INFO:Creating metrics dataframe
2025-10-19 14:20:05,845:INFO:Uploading results into container
2025-10-19 14:20:05,846:INFO:Uploading model into container now
2025-10-19 14:20:05,846:INFO:_master_model_container: 9
2025-10-19 14:20:05,846:INFO:_display_container: 2
2025-10-19 14:20:05,846:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 14:20:05,847:INFO:create_model() successfully completed......................................
2025-10-19 14:20:06,012:INFO:SubProcess create_model() end ==================================
2025-10-19 14:20:06,012:INFO:Creating metrics dataframe
2025-10-19 14:20:06,021:INFO:Initializing Gradient Boosting Classifier
2025-10-19 14:20:06,022:INFO:Total runtime is 1.6446656306584675 minutes
2025-10-19 14:20:06,025:INFO:SubProcess create_model() called ==================================
2025-10-19 14:20:06,027:INFO:Initializing create_model()
2025-10-19 14:20:06,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:20:06,027:INFO:Checking exceptions
2025-10-19 14:20:06,027:INFO:Importing libraries
2025-10-19 14:20:06,027:INFO:Copying training dataset
2025-10-19 14:20:06,207:INFO:Defining folds
2025-10-19 14:20:06,207:INFO:Declaring metric variables
2025-10-19 14:20:06,212:INFO:Importing untrained model
2025-10-19 14:20:06,216:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 14:20:06,225:INFO:Starting cross validation
2025-10-19 14:20:06,230:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:20:22,021:INFO:Calculating mean and std
2025-10-19 14:20:22,022:INFO:Creating metrics dataframe
2025-10-19 14:20:22,024:INFO:Uploading results into container
2025-10-19 14:20:22,024:INFO:Uploading model into container now
2025-10-19 14:20:22,025:INFO:_master_model_container: 10
2025-10-19 14:20:22,025:INFO:_display_container: 2
2025-10-19 14:20:22,026:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 14:20:22,026:INFO:create_model() successfully completed......................................
2025-10-19 14:20:22,199:INFO:SubProcess create_model() end ==================================
2025-10-19 14:20:22,199:INFO:Creating metrics dataframe
2025-10-19 14:20:22,206:INFO:Initializing Linear Discriminant Analysis
2025-10-19 14:20:22,207:INFO:Total runtime is 1.914421518643697 minutes
2025-10-19 14:20:22,211:INFO:SubProcess create_model() called ==================================
2025-10-19 14:20:22,212:INFO:Initializing create_model()
2025-10-19 14:20:22,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:20:22,212:INFO:Checking exceptions
2025-10-19 14:20:22,212:INFO:Importing libraries
2025-10-19 14:20:22,212:INFO:Copying training dataset
2025-10-19 14:20:22,424:INFO:Defining folds
2025-10-19 14:20:22,424:INFO:Declaring metric variables
2025-10-19 14:20:22,428:INFO:Importing untrained model
2025-10-19 14:20:22,432:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 14:20:22,441:INFO:Starting cross validation
2025-10-19 14:20:22,448:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:20:28,801:INFO:Calculating mean and std
2025-10-19 14:20:28,802:INFO:Creating metrics dataframe
2025-10-19 14:20:28,805:INFO:Uploading results into container
2025-10-19 14:20:28,805:INFO:Uploading model into container now
2025-10-19 14:20:28,806:INFO:_master_model_container: 11
2025-10-19 14:20:28,806:INFO:_display_container: 2
2025-10-19 14:20:28,806:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 14:20:28,807:INFO:create_model() successfully completed......................................
2025-10-19 14:20:28,972:INFO:SubProcess create_model() end ==================================
2025-10-19 14:20:28,973:INFO:Creating metrics dataframe
2025-10-19 14:20:28,982:INFO:Initializing Extra Trees Classifier
2025-10-19 14:20:28,982:INFO:Total runtime is 2.0273352742195128 minutes
2025-10-19 14:20:28,986:INFO:SubProcess create_model() called ==================================
2025-10-19 14:20:28,987:INFO:Initializing create_model()
2025-10-19 14:20:28,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:20:28,988:INFO:Checking exceptions
2025-10-19 14:20:28,988:INFO:Importing libraries
2025-10-19 14:20:28,988:INFO:Copying training dataset
2025-10-19 14:20:29,168:INFO:Defining folds
2025-10-19 14:20:29,168:INFO:Declaring metric variables
2025-10-19 14:20:29,172:INFO:Importing untrained model
2025-10-19 14:20:29,177:INFO:Extra Trees Classifier Imported successfully
2025-10-19 14:20:29,184:INFO:Starting cross validation
2025-10-19 14:20:29,190:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:20:42,742:INFO:Calculating mean and std
2025-10-19 14:20:42,744:INFO:Creating metrics dataframe
2025-10-19 14:20:42,747:INFO:Uploading results into container
2025-10-19 14:20:42,749:INFO:Uploading model into container now
2025-10-19 14:20:42,749:INFO:_master_model_container: 12
2025-10-19 14:20:42,749:INFO:_display_container: 2
2025-10-19 14:20:42,750:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-19 14:20:42,751:INFO:create_model() successfully completed......................................
2025-10-19 14:20:42,952:INFO:SubProcess create_model() end ==================================
2025-10-19 14:20:42,952:INFO:Creating metrics dataframe
2025-10-19 14:20:42,963:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 14:20:42,963:INFO:Total runtime is 2.260347163677215 minutes
2025-10-19 14:20:42,967:INFO:SubProcess create_model() called ==================================
2025-10-19 14:20:42,968:INFO:Initializing create_model()
2025-10-19 14:20:42,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:20:42,969:INFO:Checking exceptions
2025-10-19 14:20:42,969:INFO:Importing libraries
2025-10-19 14:20:42,969:INFO:Copying training dataset
2025-10-19 14:20:43,161:INFO:Defining folds
2025-10-19 14:20:43,161:INFO:Declaring metric variables
2025-10-19 14:20:43,166:INFO:Importing untrained model
2025-10-19 14:20:43,169:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 14:20:43,177:INFO:Starting cross validation
2025-10-19 14:20:43,182:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:20:48,616:INFO:Calculating mean and std
2025-10-19 14:20:48,617:INFO:Creating metrics dataframe
2025-10-19 14:20:48,621:INFO:Uploading results into container
2025-10-19 14:20:48,622:INFO:Uploading model into container now
2025-10-19 14:20:48,623:INFO:_master_model_container: 13
2025-10-19 14:20:48,623:INFO:_display_container: 2
2025-10-19 14:20:48,624:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 14:20:48,624:INFO:create_model() successfully completed......................................
2025-10-19 14:20:48,843:INFO:SubProcess create_model() end ==================================
2025-10-19 14:20:48,843:INFO:Creating metrics dataframe
2025-10-19 14:20:48,855:INFO:Initializing CatBoost Classifier
2025-10-19 14:20:48,855:INFO:Total runtime is 2.3585420608520504 minutes
2025-10-19 14:20:48,859:INFO:SubProcess create_model() called ==================================
2025-10-19 14:20:48,861:INFO:Initializing create_model()
2025-10-19 14:20:48,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:20:48,861:INFO:Checking exceptions
2025-10-19 14:20:48,861:INFO:Importing libraries
2025-10-19 14:20:48,861:INFO:Copying training dataset
2025-10-19 14:20:49,085:INFO:Defining folds
2025-10-19 14:20:49,085:INFO:Declaring metric variables
2025-10-19 14:20:49,089:INFO:Importing untrained model
2025-10-19 14:20:49,094:INFO:CatBoost Classifier Imported successfully
2025-10-19 14:20:49,100:INFO:Starting cross validation
2025-10-19 14:20:49,106:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:21:28,583:INFO:Calculating mean and std
2025-10-19 14:21:28,583:INFO:Creating metrics dataframe
2025-10-19 14:21:28,585:INFO:Uploading results into container
2025-10-19 14:21:28,585:INFO:Uploading model into container now
2025-10-19 14:21:28,586:INFO:_master_model_container: 14
2025-10-19 14:21:28,586:INFO:_display_container: 2
2025-10-19 14:21:28,586:INFO:<catboost.core.CatBoostClassifier object at 0x0000010C60CF5110>
2025-10-19 14:21:28,586:INFO:create_model() successfully completed......................................
2025-10-19 14:21:28,773:INFO:SubProcess create_model() end ==================================
2025-10-19 14:21:28,773:INFO:Creating metrics dataframe
2025-10-19 14:21:28,783:INFO:Initializing Dummy Classifier
2025-10-19 14:21:28,783:INFO:Total runtime is 3.0240112543106075 minutes
2025-10-19 14:21:28,786:INFO:SubProcess create_model() called ==================================
2025-10-19 14:21:28,787:INFO:Initializing create_model()
2025-10-19 14:21:28,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C61A13850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:21:28,787:INFO:Checking exceptions
2025-10-19 14:21:28,787:INFO:Importing libraries
2025-10-19 14:21:28,787:INFO:Copying training dataset
2025-10-19 14:21:28,970:INFO:Defining folds
2025-10-19 14:21:28,970:INFO:Declaring metric variables
2025-10-19 14:21:28,972:INFO:Importing untrained model
2025-10-19 14:21:28,978:INFO:Dummy Classifier Imported successfully
2025-10-19 14:21:28,984:INFO:Starting cross validation
2025-10-19 14:21:28,988:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:21:33,318:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:21:33,460:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:21:33,538:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:21:33,651:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:21:33,710:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-19 14:21:33,733:INFO:Calculating mean and std
2025-10-19 14:21:33,734:INFO:Creating metrics dataframe
2025-10-19 14:21:33,735:INFO:Uploading results into container
2025-10-19 14:21:33,736:INFO:Uploading model into container now
2025-10-19 14:21:33,736:INFO:_master_model_container: 15
2025-10-19 14:21:33,736:INFO:_display_container: 2
2025-10-19 14:21:33,736:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-19 14:21:33,737:INFO:create_model() successfully completed......................................
2025-10-19 14:21:33,896:INFO:SubProcess create_model() end ==================================
2025-10-19 14:21:33,896:INFO:Creating metrics dataframe
2025-10-19 14:21:33,906:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 14:21:33,916:INFO:Initializing create_model()
2025-10-19 14:21:33,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:21:33,917:INFO:Checking exceptions
2025-10-19 14:21:33,919:INFO:Importing libraries
2025-10-19 14:21:33,919:INFO:Copying training dataset
2025-10-19 14:21:34,088:INFO:Defining folds
2025-10-19 14:21:34,088:INFO:Declaring metric variables
2025-10-19 14:21:34,088:INFO:Importing untrained model
2025-10-19 14:21:34,088:INFO:Declaring custom model
2025-10-19 14:21:34,089:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 14:21:34,093:INFO:Cross validation set to False
2025-10-19 14:21:34,093:INFO:Fitting Model
2025-10-19 14:21:45,998:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 14:21:45,998:INFO:create_model() successfully completed......................................
2025-10-19 14:21:46,175:INFO:Initializing create_model()
2025-10-19 14:21:46,175:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:21:46,175:INFO:Checking exceptions
2025-10-19 14:21:46,177:INFO:Importing libraries
2025-10-19 14:21:46,177:INFO:Copying training dataset
2025-10-19 14:21:46,365:INFO:Defining folds
2025-10-19 14:21:46,365:INFO:Declaring metric variables
2025-10-19 14:21:46,365:INFO:Importing untrained model
2025-10-19 14:21:46,365:INFO:Declaring custom model
2025-10-19 14:21:46,366:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 14:21:46,368:INFO:Cross validation set to False
2025-10-19 14:21:46,369:INFO:Fitting Model
2025-10-19 14:21:48,781:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:21:48,783:INFO:[LightGBM] [Info] Number of positive: 9194, number of negative: 35574
2025-10-19 14:21:48,791:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006063 seconds.
2025-10-19 14:21:48,791:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-19 14:21:48,792:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 14:21:48,792:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 14:21:48,792:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205370 -> initscore=-1.353064
2025-10-19 14:21:48,792:INFO:[LightGBM] [Info] Start training from score -1.353064
2025-10-19 14:21:49,082:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 14:21:49,082:INFO:create_model() successfully completed......................................
2025-10-19 14:21:49,280:INFO:Initializing create_model()
2025-10-19 14:21:49,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:21:49,281:INFO:Checking exceptions
2025-10-19 14:21:49,284:INFO:Importing libraries
2025-10-19 14:21:49,284:INFO:Copying training dataset
2025-10-19 14:21:49,472:INFO:Defining folds
2025-10-19 14:21:49,472:INFO:Declaring metric variables
2025-10-19 14:21:49,473:INFO:Importing untrained model
2025-10-19 14:21:49,473:INFO:Declaring custom model
2025-10-19 14:21:49,473:INFO:Ridge Classifier Imported successfully
2025-10-19 14:21:49,478:INFO:Cross validation set to False
2025-10-19 14:21:49,478:INFO:Fitting Model
2025-10-19 14:21:51,903:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 14:21:51,904:INFO:create_model() successfully completed......................................
2025-10-19 14:21:52,072:INFO:Initializing create_model()
2025-10-19 14:21:52,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:21:52,072:INFO:Checking exceptions
2025-10-19 14:21:52,075:INFO:Importing libraries
2025-10-19 14:21:52,076:INFO:Copying training dataset
2025-10-19 14:21:52,247:INFO:Defining folds
2025-10-19 14:21:52,247:INFO:Declaring metric variables
2025-10-19 14:21:52,247:INFO:Importing untrained model
2025-10-19 14:21:52,247:INFO:Declaring custom model
2025-10-19 14:21:52,247:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 14:21:52,250:INFO:Cross validation set to False
2025-10-19 14:21:52,250:INFO:Fitting Model
2025-10-19 14:21:55,256:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 14:21:55,256:INFO:create_model() successfully completed......................................
2025-10-19 14:21:55,433:INFO:Initializing create_model()
2025-10-19 14:21:55,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:21:55,434:INFO:Checking exceptions
2025-10-19 14:21:55,436:INFO:Importing libraries
2025-10-19 14:21:55,436:INFO:Copying training dataset
2025-10-19 14:21:55,620:INFO:Defining folds
2025-10-19 14:21:55,620:INFO:Declaring metric variables
2025-10-19 14:21:55,620:INFO:Importing untrained model
2025-10-19 14:21:55,620:INFO:Declaring custom model
2025-10-19 14:21:55,621:INFO:Ada Boost Classifier Imported successfully
2025-10-19 14:21:55,623:INFO:Cross validation set to False
2025-10-19 14:21:55,624:INFO:Fitting Model
2025-10-19 14:21:58,014:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 14:22:01,149:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 14:22:01,149:INFO:create_model() successfully completed......................................
2025-10-19 14:22:01,338:INFO:_master_model_container: 15
2025-10-19 14:22:01,338:INFO:_display_container: 2
2025-10-19 14:22:01,340:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)]
2025-10-19 14:22:01,341:INFO:compare_models() successfully completed......................................
2025-10-19 14:22:01,343:INFO:Initializing tune_model()
2025-10-19 14:22:01,343:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 14:22:01,343:INFO:Checking exceptions
2025-10-19 14:22:01,439:INFO:Copying training dataset
2025-10-19 14:22:01,570:INFO:Checking base model
2025-10-19 14:22:01,570:INFO:Base model : Gradient Boosting Classifier
2025-10-19 14:22:01,573:INFO:Declaring metric variables
2025-10-19 14:22:01,578:INFO:Defining Hyperparameters
2025-10-19 14:22:01,755:INFO:Tuning with n_jobs=-1
2025-10-19 14:22:01,755:INFO:Initializing RandomizedSearchCV
2025-10-19 14:23:11,556:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.4}
2025-10-19 14:23:11,556:INFO:Hyperparameter search completed
2025-10-19 14:23:11,557:INFO:SubProcess create_model() called ==================================
2025-10-19 14:23:11,558:INFO:Initializing create_model()
2025-10-19 14:23:11,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E160C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 130, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 1, 'learning_rate': 0.4})
2025-10-19 14:23:11,558:INFO:Checking exceptions
2025-10-19 14:23:11,558:INFO:Importing libraries
2025-10-19 14:23:11,558:INFO:Copying training dataset
2025-10-19 14:23:11,739:INFO:Defining folds
2025-10-19 14:23:11,739:INFO:Declaring metric variables
2025-10-19 14:23:11,743:INFO:Importing untrained model
2025-10-19 14:23:11,743:INFO:Declaring custom model
2025-10-19 14:23:11,749:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 14:23:11,754:INFO:Starting cross validation
2025-10-19 14:23:11,759:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:23:19,611:INFO:Calculating mean and std
2025-10-19 14:23:19,613:INFO:Creating metrics dataframe
2025-10-19 14:23:19,620:INFO:Finalizing model
2025-10-19 14:23:25,140:INFO:Uploading results into container
2025-10-19 14:23:25,141:INFO:Uploading model into container now
2025-10-19 14:23:25,143:INFO:_master_model_container: 16
2025-10-19 14:23:25,143:INFO:_display_container: 3
2025-10-19 14:23:25,143:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 14:23:25,143:INFO:create_model() successfully completed......................................
2025-10-19 14:23:25,313:INFO:SubProcess create_model() end ==================================
2025-10-19 14:23:25,313:INFO:choose_better activated
2025-10-19 14:23:25,316:INFO:SubProcess create_model() called ==================================
2025-10-19 14:23:25,317:INFO:Initializing create_model()
2025-10-19 14:23:25,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:23:25,318:INFO:Checking exceptions
2025-10-19 14:23:25,319:INFO:Importing libraries
2025-10-19 14:23:25,319:INFO:Copying training dataset
2025-10-19 14:23:25,500:INFO:Defining folds
2025-10-19 14:23:25,500:INFO:Declaring metric variables
2025-10-19 14:23:25,500:INFO:Importing untrained model
2025-10-19 14:23:25,500:INFO:Declaring custom model
2025-10-19 14:23:25,501:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 14:23:25,501:INFO:Starting cross validation
2025-10-19 14:23:25,503:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:23:40,367:INFO:Calculating mean and std
2025-10-19 14:23:40,368:INFO:Creating metrics dataframe
2025-10-19 14:23:40,369:INFO:Finalizing model
2025-10-19 14:23:52,236:INFO:Uploading results into container
2025-10-19 14:23:52,236:INFO:Uploading model into container now
2025-10-19 14:23:52,236:INFO:_master_model_container: 17
2025-10-19 14:23:52,237:INFO:_display_container: 4
2025-10-19 14:23:52,237:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 14:23:52,237:INFO:create_model() successfully completed......................................
2025-10-19 14:23:52,395:INFO:SubProcess create_model() end ==================================
2025-10-19 14:23:52,396:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9343
2025-10-19 14:23:52,396:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9338
2025-10-19 14:23:52,396:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-19 14:23:52,397:INFO:choose_better completed
2025-10-19 14:23:52,397:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 14:23:52,406:INFO:_master_model_container: 17
2025-10-19 14:23:52,407:INFO:_display_container: 3
2025-10-19 14:23:52,407:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 14:23:52,408:INFO:tune_model() successfully completed......................................
2025-10-19 14:23:52,610:INFO:Initializing tune_model()
2025-10-19 14:23:52,610:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 14:23:52,611:INFO:Checking exceptions
2025-10-19 14:23:52,692:INFO:Copying training dataset
2025-10-19 14:23:52,827:INFO:Checking base model
2025-10-19 14:23:52,827:INFO:Base model : Light Gradient Boosting Machine
2025-10-19 14:23:52,830:INFO:Declaring metric variables
2025-10-19 14:23:52,834:INFO:Defining Hyperparameters
2025-10-19 14:23:52,997:INFO:Tuning with n_jobs=-1
2025-10-19 14:23:52,997:INFO:Initializing RandomizedSearchCV
2025-10-19 14:24:59,047:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 0.3, 'actual_estimator__num_leaves': 4, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 71, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.6}
2025-10-19 14:24:59,048:INFO:Hyperparameter search completed
2025-10-19 14:24:59,050:INFO:SubProcess create_model() called ==================================
2025-10-19 14:24:59,052:INFO:Initializing create_model()
2025-10-19 14:24:59,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C295CB690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 4, 'reg_alpha': 0.3, 'num_leaves': 4, 'n_estimators': 130, 'min_split_gain': 0.6, 'min_child_samples': 71, 'learning_rate': 0.1, 'feature_fraction': 1.0, 'bagging_freq': 5, 'bagging_fraction': 0.6})
2025-10-19 14:24:59,053:INFO:Checking exceptions
2025-10-19 14:24:59,054:INFO:Importing libraries
2025-10-19 14:24:59,054:INFO:Copying training dataset
2025-10-19 14:24:59,321:INFO:Defining folds
2025-10-19 14:24:59,321:INFO:Declaring metric variables
2025-10-19 14:24:59,327:INFO:Importing untrained model
2025-10-19 14:24:59,327:INFO:Declaring custom model
2025-10-19 14:24:59,334:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 14:24:59,345:INFO:Starting cross validation
2025-10-19 14:24:59,352:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:25:04,698:INFO:Calculating mean and std
2025-10-19 14:25:04,700:INFO:Creating metrics dataframe
2025-10-19 14:25:04,709:INFO:Finalizing model
2025-10-19 14:25:07,099:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-10-19 14:25:07,099:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-10-19 14:25:07,099:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-10-19 14:25:07,152:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:25:07,155:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-10-19 14:25:07,155:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-10-19 14:25:07,155:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-10-19 14:25:07,155:INFO:[LightGBM] [Info] Number of positive: 9194, number of negative: 35574
2025-10-19 14:25:07,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002439 seconds.
2025-10-19 14:25:07,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:25:07,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:25:07,163:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 14:25:07,163:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 14:25:07,164:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205370 -> initscore=-1.353064
2025-10-19 14:25:07,164:INFO:[LightGBM] [Info] Start training from score -1.353064
2025-10-19 14:25:07,314:INFO:Uploading results into container
2025-10-19 14:25:07,315:INFO:Uploading model into container now
2025-10-19 14:25:07,315:INFO:_master_model_container: 18
2025-10-19 14:25:07,316:INFO:_display_container: 4
2025-10-19 14:25:07,316:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 14:25:07,317:INFO:create_model() successfully completed......................................
2025-10-19 14:25:07,511:INFO:SubProcess create_model() end ==================================
2025-10-19 14:25:07,511:INFO:choose_better activated
2025-10-19 14:25:07,514:INFO:SubProcess create_model() called ==================================
2025-10-19 14:25:07,516:INFO:Initializing create_model()
2025-10-19 14:25:07,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:25:07,516:INFO:Checking exceptions
2025-10-19 14:25:07,517:INFO:Importing libraries
2025-10-19 14:25:07,518:INFO:Copying training dataset
2025-10-19 14:25:07,708:INFO:Defining folds
2025-10-19 14:25:07,709:INFO:Declaring metric variables
2025-10-19 14:25:07,709:INFO:Importing untrained model
2025-10-19 14:25:07,709:INFO:Declaring custom model
2025-10-19 14:25:07,710:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 14:25:07,710:INFO:Starting cross validation
2025-10-19 14:25:07,713:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:25:13,028:INFO:Calculating mean and std
2025-10-19 14:25:13,029:INFO:Creating metrics dataframe
2025-10-19 14:25:13,031:INFO:Finalizing model
2025-10-19 14:25:15,624:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:25:15,627:INFO:[LightGBM] [Info] Number of positive: 9194, number of negative: 35574
2025-10-19 14:25:15,636:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006750 seconds.
2025-10-19 14:25:15,636:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-19 14:25:15,636:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 14:25:15,636:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 14:25:15,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205370 -> initscore=-1.353064
2025-10-19 14:25:15,637:INFO:[LightGBM] [Info] Start training from score -1.353064
2025-10-19 14:25:15,885:INFO:Uploading results into container
2025-10-19 14:25:15,886:INFO:Uploading model into container now
2025-10-19 14:25:15,886:INFO:_master_model_container: 19
2025-10-19 14:25:15,886:INFO:_display_container: 5
2025-10-19 14:25:15,887:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 14:25:15,887:INFO:create_model() successfully completed......................................
2025-10-19 14:25:16,081:INFO:SubProcess create_model() end ==================================
2025-10-19 14:25:16,082:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9332
2025-10-19 14:25:16,083:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9337
2025-10-19 14:25:16,084:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-19 14:25:16,084:INFO:choose_better completed
2025-10-19 14:25:16,096:INFO:_master_model_container: 19
2025-10-19 14:25:16,097:INFO:_display_container: 4
2025-10-19 14:25:16,098:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 14:25:16,098:INFO:tune_model() successfully completed......................................
2025-10-19 14:25:16,264:INFO:Initializing tune_model()
2025-10-19 14:25:16,264:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 14:25:16,264:INFO:Checking exceptions
2025-10-19 14:25:16,344:INFO:Copying training dataset
2025-10-19 14:25:16,467:INFO:Checking base model
2025-10-19 14:25:16,467:INFO:Base model : Ridge Classifier
2025-10-19 14:25:16,471:INFO:Declaring metric variables
2025-10-19 14:25:16,474:INFO:Defining Hyperparameters
2025-10-19 14:25:16,637:INFO:Tuning with n_jobs=-1
2025-10-19 14:25:16,637:INFO:Initializing RandomizedSearchCV
2025-10-19 14:25:54,195:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.3}
2025-10-19 14:25:54,195:INFO:Hyperparameter search completed
2025-10-19 14:25:54,195:INFO:SubProcess create_model() called ==================================
2025-10-19 14:25:54,196:INFO:Initializing create_model()
2025-10-19 14:25:54,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C6577F810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 7.3})
2025-10-19 14:25:54,197:INFO:Checking exceptions
2025-10-19 14:25:54,197:INFO:Importing libraries
2025-10-19 14:25:54,197:INFO:Copying training dataset
2025-10-19 14:25:54,383:INFO:Defining folds
2025-10-19 14:25:54,383:INFO:Declaring metric variables
2025-10-19 14:25:54,386:INFO:Importing untrained model
2025-10-19 14:25:54,386:INFO:Declaring custom model
2025-10-19 14:25:54,392:INFO:Ridge Classifier Imported successfully
2025-10-19 14:25:54,399:INFO:Starting cross validation
2025-10-19 14:25:54,403:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:25:58,795:INFO:Calculating mean and std
2025-10-19 14:25:58,796:INFO:Creating metrics dataframe
2025-10-19 14:25:58,800:INFO:Finalizing model
2025-10-19 14:26:01,247:INFO:Uploading results into container
2025-10-19 14:26:01,248:INFO:Uploading model into container now
2025-10-19 14:26:01,249:INFO:_master_model_container: 20
2025-10-19 14:26:01,249:INFO:_display_container: 5
2025-10-19 14:26:01,250:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 14:26:01,250:INFO:create_model() successfully completed......................................
2025-10-19 14:26:01,436:INFO:SubProcess create_model() end ==================================
2025-10-19 14:26:01,436:INFO:choose_better activated
2025-10-19 14:26:01,439:INFO:SubProcess create_model() called ==================================
2025-10-19 14:26:01,440:INFO:Initializing create_model()
2025-10-19 14:26:01,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:26:01,441:INFO:Checking exceptions
2025-10-19 14:26:01,442:INFO:Importing libraries
2025-10-19 14:26:01,442:INFO:Copying training dataset
2025-10-19 14:26:01,620:INFO:Defining folds
2025-10-19 14:26:01,620:INFO:Declaring metric variables
2025-10-19 14:26:01,620:INFO:Importing untrained model
2025-10-19 14:26:01,620:INFO:Declaring custom model
2025-10-19 14:26:01,621:INFO:Ridge Classifier Imported successfully
2025-10-19 14:26:01,621:INFO:Starting cross validation
2025-10-19 14:26:01,625:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:26:06,018:INFO:Calculating mean and std
2025-10-19 14:26:06,018:INFO:Creating metrics dataframe
2025-10-19 14:26:06,020:INFO:Finalizing model
2025-10-19 14:26:08,364:INFO:Uploading results into container
2025-10-19 14:26:08,365:INFO:Uploading model into container now
2025-10-19 14:26:08,365:INFO:_master_model_container: 21
2025-10-19 14:26:08,365:INFO:_display_container: 6
2025-10-19 14:26:08,365:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 14:26:08,365:INFO:create_model() successfully completed......................................
2025-10-19 14:26:08,528:INFO:SubProcess create_model() end ==================================
2025-10-19 14:26:08,529:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9331
2025-10-19 14:26:08,529:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9333
2025-10-19 14:26:08,529:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) is best model
2025-10-19 14:26:08,529:INFO:choose_better completed
2025-10-19 14:26:08,537:INFO:_master_model_container: 21
2025-10-19 14:26:08,537:INFO:_display_container: 5
2025-10-19 14:26:08,538:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-19 14:26:08,538:INFO:tune_model() successfully completed......................................
2025-10-19 14:26:08,707:INFO:Initializing tune_model()
2025-10-19 14:26:08,707:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 14:26:08,708:INFO:Checking exceptions
2025-10-19 14:26:08,795:INFO:Copying training dataset
2025-10-19 14:26:08,970:INFO:Checking base model
2025-10-19 14:26:08,970:INFO:Base model : Linear Discriminant Analysis
2025-10-19 14:26:08,974:INFO:Declaring metric variables
2025-10-19 14:26:08,977:INFO:Defining Hyperparameters
2025-10-19 14:26:09,146:INFO:Tuning with n_jobs=-1
2025-10-19 14:26:09,147:INFO:Initializing RandomizedSearchCV
2025-10-19 14:26:47,027:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 'auto'}
2025-10-19 14:26:47,028:INFO:Hyperparameter search completed
2025-10-19 14:26:47,028:INFO:SubProcess create_model() called ==================================
2025-10-19 14:26:47,029:INFO:Initializing create_model()
2025-10-19 14:26:47,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E138250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 'auto'})
2025-10-19 14:26:47,031:INFO:Checking exceptions
2025-10-19 14:26:47,031:INFO:Importing libraries
2025-10-19 14:26:47,031:INFO:Copying training dataset
2025-10-19 14:26:47,209:INFO:Defining folds
2025-10-19 14:26:47,209:INFO:Declaring metric variables
2025-10-19 14:26:47,212:INFO:Importing untrained model
2025-10-19 14:26:47,213:INFO:Declaring custom model
2025-10-19 14:26:47,217:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 14:26:47,224:INFO:Starting cross validation
2025-10-19 14:26:47,229:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:26:51,726:INFO:Calculating mean and std
2025-10-19 14:26:51,728:INFO:Creating metrics dataframe
2025-10-19 14:26:51,733:INFO:Finalizing model
2025-10-19 14:26:54,260:INFO:Uploading results into container
2025-10-19 14:26:54,261:INFO:Uploading model into container now
2025-10-19 14:26:54,262:INFO:_master_model_container: 22
2025-10-19 14:26:54,262:INFO:_display_container: 6
2025-10-19 14:26:54,262:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-19 14:26:54,262:INFO:create_model() successfully completed......................................
2025-10-19 14:26:54,440:INFO:SubProcess create_model() end ==================================
2025-10-19 14:26:54,440:INFO:choose_better activated
2025-10-19 14:26:54,444:INFO:SubProcess create_model() called ==================================
2025-10-19 14:26:54,446:INFO:Initializing create_model()
2025-10-19 14:26:54,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:26:54,446:INFO:Checking exceptions
2025-10-19 14:26:54,447:INFO:Importing libraries
2025-10-19 14:26:54,447:INFO:Copying training dataset
2025-10-19 14:26:54,629:INFO:Defining folds
2025-10-19 14:26:54,629:INFO:Declaring metric variables
2025-10-19 14:26:54,629:INFO:Importing untrained model
2025-10-19 14:26:54,629:INFO:Declaring custom model
2025-10-19 14:26:54,629:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 14:26:54,630:INFO:Starting cross validation
2025-10-19 14:26:54,633:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:27:01,486:INFO:Calculating mean and std
2025-10-19 14:27:01,486:INFO:Creating metrics dataframe
2025-10-19 14:27:01,488:INFO:Finalizing model
2025-10-19 14:27:04,525:INFO:Uploading results into container
2025-10-19 14:27:04,527:INFO:Uploading model into container now
2025-10-19 14:27:04,527:INFO:_master_model_container: 23
2025-10-19 14:27:04,527:INFO:_display_container: 7
2025-10-19 14:27:04,527:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 14:27:04,527:INFO:create_model() successfully completed......................................
2025-10-19 14:27:04,690:INFO:SubProcess create_model() end ==================================
2025-10-19 14:27:04,691:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.933
2025-10-19 14:27:04,691:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9332
2025-10-19 14:27:04,692:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) is best model
2025-10-19 14:27:04,692:INFO:choose_better completed
2025-10-19 14:27:04,701:INFO:_master_model_container: 23
2025-10-19 14:27:04,701:INFO:_display_container: 6
2025-10-19 14:27:04,702:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-19 14:27:04,702:INFO:tune_model() successfully completed......................................
2025-10-19 14:27:04,875:INFO:Initializing tune_model()
2025-10-19 14:27:04,875:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 14:27:04,875:INFO:Checking exceptions
2025-10-19 14:27:04,957:INFO:Copying training dataset
2025-10-19 14:27:05,142:INFO:Checking base model
2025-10-19 14:27:05,142:INFO:Base model : Ada Boost Classifier
2025-10-19 14:27:05,146:INFO:Declaring metric variables
2025-10-19 14:27:05,149:INFO:Defining Hyperparameters
2025-10-19 14:27:05,311:INFO:Tuning with n_jobs=-1
2025-10-19 14:27:05,311:INFO:Initializing RandomizedSearchCV
2025-10-19 14:28:49,851:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__algorithm': 'SAMME'}
2025-10-19 14:28:49,852:INFO:Hyperparameter search completed
2025-10-19 14:28:49,852:INFO:SubProcess create_model() called ==================================
2025-10-19 14:28:49,853:INFO:Initializing create_model()
2025-10-19 14:28:49,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E138250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 190, 'learning_rate': 0.3, 'algorithm': 'SAMME'})
2025-10-19 14:28:49,853:INFO:Checking exceptions
2025-10-19 14:28:49,853:INFO:Importing libraries
2025-10-19 14:28:49,854:INFO:Copying training dataset
2025-10-19 14:28:50,038:INFO:Defining folds
2025-10-19 14:28:50,038:INFO:Declaring metric variables
2025-10-19 14:28:50,042:INFO:Importing untrained model
2025-10-19 14:28:50,043:INFO:Declaring custom model
2025-10-19 14:28:50,047:INFO:Ada Boost Classifier Imported successfully
2025-10-19 14:28:50,053:INFO:Starting cross validation
2025-10-19 14:28:50,058:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:29:09,651:INFO:Calculating mean and std
2025-10-19 14:29:09,652:INFO:Creating metrics dataframe
2025-10-19 14:29:09,657:INFO:Finalizing model
2025-10-19 14:29:23,229:INFO:Uploading results into container
2025-10-19 14:29:23,229:INFO:Uploading model into container now
2025-10-19 14:29:23,230:INFO:_master_model_container: 24
2025-10-19 14:29:23,230:INFO:_display_container: 7
2025-10-19 14:29:23,231:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.3,
                   n_estimators=190, random_state=42)
2025-10-19 14:29:23,231:INFO:create_model() successfully completed......................................
2025-10-19 14:29:23,410:INFO:SubProcess create_model() end ==================================
2025-10-19 14:29:23,410:INFO:choose_better activated
2025-10-19 14:29:23,413:INFO:SubProcess create_model() called ==================================
2025-10-19 14:29:23,414:INFO:Initializing create_model()
2025-10-19 14:29:23,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:29:23,414:INFO:Checking exceptions
2025-10-19 14:29:23,416:INFO:Importing libraries
2025-10-19 14:29:23,416:INFO:Copying training dataset
2025-10-19 14:29:23,592:INFO:Defining folds
2025-10-19 14:29:23,592:INFO:Declaring metric variables
2025-10-19 14:29:23,592:INFO:Importing untrained model
2025-10-19 14:29:23,592:INFO:Declaring custom model
2025-10-19 14:29:23,593:INFO:Ada Boost Classifier Imported successfully
2025-10-19 14:29:23,593:INFO:Starting cross validation
2025-10-19 14:29:23,595:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:29:27,047:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:29:27,157:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:29:27,268:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:29:27,345:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:29:27,460:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:29:32,154:INFO:Calculating mean and std
2025-10-19 14:29:32,154:INFO:Creating metrics dataframe
2025-10-19 14:29:32,155:INFO:Finalizing model
2025-10-19 14:29:34,519:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 14:29:37,697:INFO:Uploading results into container
2025-10-19 14:29:37,697:INFO:Uploading model into container now
2025-10-19 14:29:37,698:INFO:_master_model_container: 25
2025-10-19 14:29:37,698:INFO:_display_container: 8
2025-10-19 14:29:37,698:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 14:29:37,698:INFO:create_model() successfully completed......................................
2025-10-19 14:29:37,860:INFO:SubProcess create_model() end ==================================
2025-10-19 14:29:37,861:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for AUC is 0.9325
2025-10-19 14:29:37,861:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.3,
                   n_estimators=190, random_state=42) result for AUC is 0.932
2025-10-19 14:29:37,861:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) is best model
2025-10-19 14:29:37,861:INFO:choose_better completed
2025-10-19 14:29:37,861:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 14:29:37,871:INFO:_master_model_container: 25
2025-10-19 14:29:37,872:INFO:_display_container: 7
2025-10-19 14:29:37,872:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 14:29:37,872:INFO:tune_model() successfully completed......................................
2025-10-19 14:29:38,043:INFO:Initializing blend_models()
2025-10-19 14:29:38,043:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)], fold=None, round=4, choose_better=True, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-19 14:29:38,043:INFO:Checking exceptions
2025-10-19 14:29:38,122:INFO:Importing libraries
2025-10-19 14:29:38,122:INFO:Copying training dataset
2025-10-19 14:29:38,128:INFO:Getting model names
2025-10-19 14:29:38,137:INFO:SubProcess create_model() called ==================================
2025-10-19 14:29:38,143:INFO:Initializing create_model()
2025-10-19 14:29:38,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=42))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C5E347150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:29:38,143:INFO:Checking exceptions
2025-10-19 14:29:38,144:INFO:Importing libraries
2025-10-19 14:29:38,144:INFO:Copying training dataset
2025-10-19 14:29:38,338:INFO:Defining folds
2025-10-19 14:29:38,339:INFO:Declaring metric variables
2025-10-19 14:29:38,341:INFO:Importing untrained model
2025-10-19 14:29:38,342:INFO:Declaring custom model
2025-10-19 14:29:38,345:INFO:Voting Classifier Imported successfully
2025-10-19 14:29:38,354:INFO:Starting cross validation
2025-10-19 14:29:38,357:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:29:41,822:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:29:42,020:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:29:42,282:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:29:42,615:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:29:42,690:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:29:58,718:INFO:Calculating mean and std
2025-10-19 14:29:58,719:INFO:Creating metrics dataframe
2025-10-19 14:29:58,723:INFO:Finalizing model
2025-10-19 14:30:01,089:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:30:11,413:INFO:Uploading results into container
2025-10-19 14:30:11,414:INFO:Uploading model into container now
2025-10-19 14:30:11,415:INFO:_master_model_container: 26
2025-10-19 14:30:11,415:INFO:_display_container: 8
2025-10-19 14:30:11,420:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=42))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-10-19 14:30:11,421:INFO:create_model() successfully completed......................................
2025-10-19 14:30:11,596:INFO:SubProcess create_model() end ==================================
2025-10-19 14:30:11,597:INFO:choose_better activated
2025-10-19 14:30:11,605:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=42))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None) result for Accuracy is 0.9072
2025-10-19 14:30:11,605:INFO:SubProcess create_model() called ==================================
2025-10-19 14:30:11,607:INFO:Initializing create_model()
2025-10-19 14:30:11,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:30:11,607:INFO:Checking exceptions
2025-10-19 14:30:11,608:INFO:Importing libraries
2025-10-19 14:30:11,609:INFO:Copying training dataset
2025-10-19 14:30:11,790:INFO:Defining folds
2025-10-19 14:30:11,790:INFO:Declaring metric variables
2025-10-19 14:30:11,790:INFO:Importing untrained model
2025-10-19 14:30:11,790:INFO:Declaring custom model
2025-10-19 14:30:11,791:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 14:30:11,791:INFO:Starting cross validation
2025-10-19 14:30:11,794:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:30:26,580:INFO:Calculating mean and std
2025-10-19 14:30:26,580:INFO:Creating metrics dataframe
2025-10-19 14:30:26,583:INFO:Finalizing model
2025-10-19 14:30:38,761:INFO:Uploading results into container
2025-10-19 14:30:38,762:INFO:Uploading model into container now
2025-10-19 14:30:38,763:INFO:_master_model_container: 27
2025-10-19 14:30:38,763:INFO:_display_container: 9
2025-10-19 14:30:38,763:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 14:30:38,763:INFO:create_model() successfully completed......................................
2025-10-19 14:30:38,923:INFO:SubProcess create_model() end ==================================
2025-10-19 14:30:38,923:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9077
2025-10-19 14:30:38,923:INFO:SubProcess create_model() called ==================================
2025-10-19 14:30:38,925:INFO:Initializing create_model()
2025-10-19 14:30:38,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:30:38,925:INFO:Checking exceptions
2025-10-19 14:30:38,926:INFO:Importing libraries
2025-10-19 14:30:38,926:INFO:Copying training dataset
2025-10-19 14:30:39,110:INFO:Defining folds
2025-10-19 14:30:39,110:INFO:Declaring metric variables
2025-10-19 14:30:39,110:INFO:Importing untrained model
2025-10-19 14:30:39,110:INFO:Declaring custom model
2025-10-19 14:30:39,111:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 14:30:39,112:INFO:Starting cross validation
2025-10-19 14:30:39,114:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:30:43,903:INFO:Calculating mean and std
2025-10-19 14:30:43,904:INFO:Creating metrics dataframe
2025-10-19 14:30:43,907:INFO:Finalizing model
2025-10-19 14:30:46,286:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-10-19 14:30:46,286:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-10-19 14:30:46,286:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-10-19 14:30:46,334:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 14:30:46,337:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-10-19 14:30:46,337:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-10-19 14:30:46,337:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-10-19 14:30:46,337:INFO:[LightGBM] [Info] Number of positive: 9194, number of negative: 35574
2025-10-19 14:30:46,343:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002085 seconds.
2025-10-19 14:30:46,343:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 14:30:46,343:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 14:30:46,344:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 14:30:46,344:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 14:30:46,344:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205370 -> initscore=-1.353064
2025-10-19 14:30:46,344:INFO:[LightGBM] [Info] Start training from score -1.353064
2025-10-19 14:30:46,476:INFO:Uploading results into container
2025-10-19 14:30:46,476:INFO:Uploading model into container now
2025-10-19 14:30:46,477:INFO:_master_model_container: 28
2025-10-19 14:30:46,477:INFO:_display_container: 9
2025-10-19 14:30:46,478:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 14:30:46,478:INFO:create_model() successfully completed......................................
2025-10-19 14:30:46,676:INFO:SubProcess create_model() end ==================================
2025-10-19 14:30:46,676:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=71, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=130, n_jobs=-1, num_leaves=4, objective=None,
               random_state=42, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9072
2025-10-19 14:30:46,677:INFO:SubProcess create_model() called ==================================
2025-10-19 14:30:46,677:INFO:Initializing create_model()
2025-10-19 14:30:46,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:30:46,677:INFO:Checking exceptions
2025-10-19 14:30:46,679:INFO:Importing libraries
2025-10-19 14:30:46,679:INFO:Copying training dataset
2025-10-19 14:30:46,852:INFO:Defining folds
2025-10-19 14:30:46,852:INFO:Declaring metric variables
2025-10-19 14:30:46,852:INFO:Importing untrained model
2025-10-19 14:30:46,852:INFO:Declaring custom model
2025-10-19 14:30:46,853:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 14:30:46,853:INFO:Starting cross validation
2025-10-19 14:30:46,856:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:30:51,331:INFO:Calculating mean and std
2025-10-19 14:30:51,331:INFO:Creating metrics dataframe
2025-10-19 14:30:51,332:INFO:Finalizing model
2025-10-19 14:30:53,871:INFO:Uploading results into container
2025-10-19 14:30:53,872:INFO:Uploading model into container now
2025-10-19 14:30:53,872:INFO:_master_model_container: 29
2025-10-19 14:30:53,872:INFO:_display_container: 9
2025-10-19 14:30:53,872:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-19 14:30:53,872:INFO:create_model() successfully completed......................................
2025-10-19 14:30:54,030:INFO:SubProcess create_model() end ==================================
2025-10-19 14:30:54,030:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for Accuracy is 0.9065
2025-10-19 14:30:54,031:INFO:SubProcess create_model() called ==================================
2025-10-19 14:30:54,031:INFO:Initializing create_model()
2025-10-19 14:30:54,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:30:54,032:INFO:Checking exceptions
2025-10-19 14:30:54,033:INFO:Importing libraries
2025-10-19 14:30:54,033:INFO:Copying training dataset
2025-10-19 14:30:54,209:INFO:Defining folds
2025-10-19 14:30:54,209:INFO:Declaring metric variables
2025-10-19 14:30:54,209:INFO:Importing untrained model
2025-10-19 14:30:54,209:INFO:Declaring custom model
2025-10-19 14:30:54,210:INFO:Ada Boost Classifier Imported successfully
2025-10-19 14:30:54,210:INFO:Starting cross validation
2025-10-19 14:30:54,213:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:30:57,605:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:30:57,682:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:30:57,772:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:30:57,870:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:30:57,935:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-19 14:31:02,595:INFO:Calculating mean and std
2025-10-19 14:31:02,595:INFO:Creating metrics dataframe
2025-10-19 14:31:02,596:INFO:Finalizing model
2025-10-19 14:31:04,939:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 14:31:08,376:INFO:Uploading results into container
2025-10-19 14:31:08,376:INFO:Uploading model into container now
2025-10-19 14:31:08,377:INFO:_master_model_container: 30
2025-10-19 14:31:08,377:INFO:_display_container: 9
2025-10-19 14:31:08,377:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-19 14:31:08,377:INFO:create_model() successfully completed......................................
2025-10-19 14:31:08,553:INFO:SubProcess create_model() end ==================================
2025-10-19 14:31:08,553:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for Accuracy is 0.9052
2025-10-19 14:31:08,553:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-19 14:31:08,553:INFO:choose_better completed
2025-10-19 14:31:08,553:INFO:Original model was better than the blended model, hence it will be returned. NOTE: The display metrics are for the blended model (not the original one).
2025-10-19 14:31:08,563:INFO:_master_model_container: 30
2025-10-19 14:31:08,563:INFO:_display_container: 8
2025-10-19 14:31:08,564:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 14:31:08,564:INFO:blend_models() successfully completed......................................
2025-10-19 14:31:08,772:INFO:Initializing calibrate_model()
2025-10-19 14:31:08,772:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), method=isotonic, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2025-10-19 14:31:08,772:INFO:Checking exceptions
2025-10-19 14:31:08,857:INFO:Preloading libraries
2025-10-19 14:31:08,857:INFO:Preparing display monitor
2025-10-19 14:31:08,871:INFO:Getting model name
2025-10-19 14:31:08,871:INFO:Base model : Gradient Boosting Classifier
2025-10-19 14:31:08,880:INFO:Importing untrained CalibratedClassifierCV
2025-10-19 14:31:08,881:INFO:SubProcess create_model() called ==================================
2025-10-19 14:31:08,885:INFO:Initializing create_model()
2025-10-19 14:31:08,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
60459    U10895
49198    U02564
60926    U04662
60197    U07513
58950    U00466
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000010C633A0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:31:08,885:INFO:Checking exceptions
2025-10-19 14:31:08,885:INFO:Importing libraries
2025-10-19 14:31:08,885:INFO:Copying training dataset
2025-10-19 14:31:09,076:INFO:Defining folds
2025-10-19 14:31:09,076:INFO:Declaring metric variables
2025-10-19 14:31:09,078:INFO:Importing untrained model
2025-10-19 14:31:09,078:INFO:Declaring custom model
2025-10-19 14:31:09,081:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 14:31:09,087:INFO:Starting cross validation
2025-10-19 14:31:09,093:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-19 14:31:56,279:INFO:Calculating mean and std
2025-10-19 14:31:56,280:INFO:Creating metrics dataframe
2025-10-19 14:31:56,284:INFO:Finalizing model
2025-10-19 14:32:37,405:INFO:Uploading results into container
2025-10-19 14:32:37,406:INFO:Uploading model into container now
2025-10-19 14:32:37,407:INFO:_master_model_container: 31
2025-10-19 14:32:37,407:INFO:_display_container: 9
2025-10-19 14:32:37,408:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None)
2025-10-19 14:32:37,408:INFO:create_model() successfully completed......................................
2025-10-19 14:32:37,576:INFO:SubProcess create_model() end ==================================
2025-10-19 14:32:37,593:INFO:_master_model_container: 31
2025-10-19 14:32:37,593:INFO:_display_container: 9
2025-10-19 14:32:37,595:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None)
2025-10-19 14:32:37,595:INFO:calibrate_model() successfully completed......................................
2025-10-19 14:32:37,769:INFO:Initializing finalize_model()
2025-10-19 14:32:37,769:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-19 14:32:37,770:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None)
2025-10-19 14:32:37,903:INFO:Initializing create_model()
2025-10-19 14:32:37,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000010C699C02D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                            criterion='friedman_mse',
                                                            init=None,
                                                            learning_rate=0.1,
                                                            loss='log_loss',
                                                            max_depth=3,
                                                            max_features=None,
                                                            max_leaf_nodes=None,
                                                            min_impurity_decrease=0.0,
                                                            min_samples_leaf=1,
                                                            min_samples_split=2,
                                                            min_weight_fraction_leaf=0.0,
                                                            n_estimators=100,
                                                            n_iter_no_change=None,
                                                            random_state=42,
                                                            subsample=1.0,
                                                            tol=0.0001,
                                                            validation_fraction=0.1,
                                                            verbose=0,
                                                            warm_start=False),
                       method='isotonic', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=36850    U09461
17107    U02940
32389    U06506
47842    U10752
14249    U09102
          ...  
52938    U00197
20841    U06433
39708    U10051
60356    U09962
61665    U06888
Name: id_usuario, Length: 63955, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 14:32:37,904:INFO:Checking exceptions
2025-10-19 14:32:37,905:INFO:Importing libraries
2025-10-19 14:32:37,905:INFO:Copying training dataset
2025-10-19 14:32:37,932:INFO:Defining folds
2025-10-19 14:32:37,932:INFO:Declaring metric variables
2025-10-19 14:32:37,932:INFO:Importing untrained model
2025-10-19 14:32:37,933:INFO:Declaring custom model
2025-10-19 14:32:37,933:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 14:32:37,937:INFO:Cross validation set to False
2025-10-19 14:32:37,937:INFO:Fitting Model
2025-10-19 14:33:36,939:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                             learning_rate=0.1,
                                                                             loss='log_loss',
                                                                             max_depth=3,
                                                                             max_features=None,
                                                                             max_leaf_nodes=None,
                                                                             min_impurity_decrease=0.0,
                                                                             min_samples_leaf=1,
                                                                             min_samples_split=2,
                                                                             min_weight_fraction_leaf=0.0,
                                                                             n_estimators=100,
                                                                             n_iter_no_change=None,
                                                                             random_state=42,
                                                                             subsample=1.0,
                                                                             tol=0.0001,
                                                                             validation_fraction=0.1,
                                                                             verbose=0,
                                                                             warm_start=False),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-10-19 14:33:36,939:INFO:create_model() successfully completed......................................
2025-10-19 14:33:37,106:INFO:_master_model_container: 31
2025-10-19 14:33:37,106:INFO:_display_container: 9
2025-10-19 14:33:37,124:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                             learning_rate=0.1,
                                                                             loss='log_loss',
                                                                             max_depth=3,
                                                                             max_features=None,
                                                                             max_leaf_nodes=None,
                                                                             min_impurity_decrease=0.0,
                                                                             min_samples_leaf=1,
                                                                             min_samples_split=2,
                                                                             min_weight_fraction_leaf=0.0,
                                                                             n_estimators=100,
                                                                             n_iter_no_change=None,
                                                                             random_state=42,
                                                                             subsample=1.0,
                                                                             tol=0.0001,
                                                                             validation_fraction=0.1,
                                                                             verbose=0,
                                                                             warm_start=False),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-10-19 14:33:37,124:INFO:finalize_model() successfully completed......................................
2025-10-19 14:33:37,330:INFO:Initializing save_model()
2025-10-19 14:33:37,331:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                             learning_rate=0.1,
                                                                             loss='log_loss',
                                                                             max_depth=3,
                                                                             max_features=None,
                                                                             max_leaf_nodes=None,
                                                                             min_impurity_decrease=0.0,
                                                                             min_samples_leaf=1,
                                                                             min_samples_split=2,
                                                                             min_weight_fraction_leaf=0.0,
                                                                             n_estimators=100,
                                                                             n_iter_no_change=None,
                                                                             random_state=42,
                                                                             subsample=1.0,
                                                                             tol=0.0001,
                                                                             validation_fraction=0.1,
                                                                             verbose=0,
                                                                             warm_start=False),
                                        method='isotonic', n_jobs=None))],
         verbose=False), model_name=modelo_cls_like_soft_v1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-19 14:33:37,331:INFO:Adding model into prep_pipe
2025-10-19 14:33:37,331:WARNING:Only Model saved as it was a pipeline.
2025-10-19 14:33:37,369:INFO:modelo_cls_like_soft_v1.pkl saved in current working directory
2025-10-19 14:33:37,387:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                             learning_rate=0.1,
                                                                             loss='log_loss',
                                                                             max_depth=3,
                                                                             max_features=None,
                                                                             max_leaf_nodes=None,
                                                                             min_impurity_decrease=0.0,
                                                                             min_samples_leaf=1,
                                                                             min_samples_split=2,
                                                                             min_weight_fraction_leaf=0.0,
                                                                             n_estimators=100,
                                                                             n_iter_no_change=None,
                                                                             random_state=42,
                                                                             subsample=1.0,
                                                                             tol=0.0001,
                                                                             validation_fraction=0.1,
                                                                             verbose=0,
                                                                             warm_start=False),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-10-19 14:33:37,387:INFO:save_model() successfully completed......................................
2025-10-19 17:48:27,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:48:27,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:48:27,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:48:27,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 17:48:35,687:INFO:PyCaret ClassificationExperiment
2025-10-19 17:48:35,687:INFO:Logging name: clf-default-name
2025-10-19 17:48:35,687:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 17:48:35,688:INFO:version 3.3.2
2025-10-19 17:48:35,688:INFO:Initializing setup()
2025-10-19 17:48:35,688:INFO:self.USI: 5a93
2025-10-19 17:48:35,688:INFO:self._variable_keys: {'pipeline', 'y_train', 'html_param', 'exp_name_log', 'idx', 'logging_param', 'y_test', 'fold_groups_param', 'USI', 'target_param', 'is_multiclass', 'memory', 'exp_id', 'y', 'X_test', 'X', 'log_plots_param', 'fold_shuffle_param', 'gpu_param', 'seed', '_available_plots', 'n_jobs_param', '_ml_usecase', 'X_train', 'fold_generator', 'fix_imbalance', 'data', 'gpu_n_jobs_param'}
2025-10-19 17:48:35,688:INFO:Checking environment
2025-10-19 17:48:35,688:INFO:python_version: 3.11.13
2025-10-19 17:48:35,688:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 17:48:35,688:INFO:machine: AMD64
2025-10-19 17:48:35,688:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 17:48:35,697:INFO:Memory: svmem(total=16856211456, available=3129536512, percent=81.4, used=13726674944, free=3129536512)
2025-10-19 17:48:35,697:INFO:Physical Core: 4
2025-10-19 17:48:35,698:INFO:Logical Core: 8
2025-10-19 17:48:35,698:INFO:Checking libraries
2025-10-19 17:48:35,698:INFO:System:
2025-10-19 17:48:35,698:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 17:48:35,698:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 17:48:35,698:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 17:48:35,698:INFO:PyCaret required dependencies:
2025-10-19 17:48:37,773:INFO:                 pip: 25.2
2025-10-19 17:48:37,774:INFO:          setuptools: 80.9.0
2025-10-19 17:48:37,774:INFO:             pycaret: 3.3.2
2025-10-19 17:48:37,774:INFO:             IPython: 9.6.0
2025-10-19 17:48:37,774:INFO:          ipywidgets: 8.1.7
2025-10-19 17:48:37,774:INFO:                tqdm: 4.67.1
2025-10-19 17:48:37,774:INFO:               numpy: 1.26.4
2025-10-19 17:48:37,774:INFO:              pandas: 2.1.4
2025-10-19 17:48:37,774:INFO:              jinja2: 3.1.6
2025-10-19 17:48:37,774:INFO:               scipy: 1.11.4
2025-10-19 17:48:37,774:INFO:              joblib: 1.3.2
2025-10-19 17:48:37,774:INFO:             sklearn: 1.4.2
2025-10-19 17:48:37,774:INFO:                pyod: 2.0.5
2025-10-19 17:48:37,774:INFO:            imblearn: 0.14.0
2025-10-19 17:48:37,774:INFO:   category_encoders: 2.7.0
2025-10-19 17:48:37,774:INFO:            lightgbm: 4.6.0
2025-10-19 17:48:37,774:INFO:               numba: 0.61.0
2025-10-19 17:48:37,774:INFO:            requests: 2.32.5
2025-10-19 17:48:37,774:INFO:          matplotlib: 3.7.5
2025-10-19 17:48:37,774:INFO:          scikitplot: 0.3.7
2025-10-19 17:48:37,774:INFO:         yellowbrick: 1.5
2025-10-19 17:48:37,774:INFO:              plotly: 5.24.1
2025-10-19 17:48:37,774:INFO:    plotly-resampler: Not installed
2025-10-19 17:48:37,774:INFO:             kaleido: 1.1.0
2025-10-19 17:48:37,774:INFO:           schemdraw: 0.15
2025-10-19 17:48:37,774:INFO:         statsmodels: 0.14.5
2025-10-19 17:48:37,775:INFO:              sktime: 0.26.0
2025-10-19 17:48:37,775:INFO:               tbats: 1.1.3
2025-10-19 17:48:37,775:INFO:            pmdarima: 2.0.4
2025-10-19 17:48:37,775:INFO:              psutil: 7.1.0
2025-10-19 17:48:37,775:INFO:          markupsafe: 3.0.3
2025-10-19 17:48:37,775:INFO:             pickle5: Not installed
2025-10-19 17:48:37,775:INFO:         cloudpickle: 3.1.1
2025-10-19 17:48:37,775:INFO:         deprecation: 2.1.0
2025-10-19 17:48:37,775:INFO:              xxhash: 3.6.0
2025-10-19 17:48:37,775:INFO:           wurlitzer: Not installed
2025-10-19 17:48:37,775:INFO:PyCaret optional dependencies:
2025-10-19 17:48:54,466:INFO:                shap: 0.44.1
2025-10-19 17:48:54,466:INFO:           interpret: 0.7.3
2025-10-19 17:48:54,467:INFO:                umap: 0.5.7
2025-10-19 17:48:54,467:INFO:     ydata_profiling: 4.17.0
2025-10-19 17:48:54,467:INFO:  explainerdashboard: 0.5.1
2025-10-19 17:48:54,467:INFO:             autoviz: Not installed
2025-10-19 17:48:54,467:INFO:           fairlearn: 0.7.0
2025-10-19 17:48:54,467:INFO:          deepchecks: Not installed
2025-10-19 17:48:54,467:INFO:             xgboost: Not installed
2025-10-19 17:48:54,467:INFO:            catboost: 1.2.8
2025-10-19 17:48:54,467:INFO:              kmodes: 0.12.2
2025-10-19 17:48:54,467:INFO:             mlxtend: 0.23.4
2025-10-19 17:48:54,467:INFO:       statsforecast: 1.5.0
2025-10-19 17:48:54,467:INFO:        tune_sklearn: Not installed
2025-10-19 17:48:54,467:INFO:                 ray: Not installed
2025-10-19 17:48:54,467:INFO:            hyperopt: 0.2.7
2025-10-19 17:48:54,467:INFO:              optuna: 4.5.0
2025-10-19 17:48:54,467:INFO:               skopt: 0.10.2
2025-10-19 17:48:54,467:INFO:              mlflow: 3.5.0
2025-10-19 17:48:54,467:INFO:              gradio: 5.49.1
2025-10-19 17:48:54,467:INFO:             fastapi: 0.119.0
2025-10-19 17:48:54,467:INFO:             uvicorn: 0.38.0
2025-10-19 17:48:54,467:INFO:              m2cgen: 0.10.0
2025-10-19 17:48:54,467:INFO:           evidently: 0.4.40
2025-10-19 17:48:54,467:INFO:               fugue: 0.8.7
2025-10-19 17:48:54,467:INFO:           streamlit: Not installed
2025-10-19 17:48:54,467:INFO:             prophet: Not installed
2025-10-19 17:48:54,467:INFO:None
2025-10-19 17:48:54,467:INFO:Set up data.
2025-10-19 17:48:54,690:INFO:Set up folding strategy.
2025-10-19 17:48:54,925:INFO:Set up train/test split.
2025-10-19 17:48:55,193:INFO:Set up index.
2025-10-19 17:48:55,213:INFO:Assigning column types.
2025-10-19 17:48:55,520:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 17:48:55,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 17:48:55,567:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 17:48:55,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 17:48:55,618:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 17:48:55,698:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 17:48:55,699:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 17:48:55,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 17:48:55,720:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 17:48:55,721:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 17:48:55,755:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 17:48:55,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 17:48:55,780:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 17:48:55,821:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 17:48:55,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 17:48:55,843:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 17:48:55,843:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 17:48:55,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 17:48:55,914:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 17:48:55,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 17:48:55,987:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 17:48:55,991:INFO:Preparing preprocessing pipeline...
2025-10-19 17:48:56,038:INFO:Set up simple imputation.
2025-10-19 17:48:56,232:INFO:Set up encoding of ordinal features.
2025-10-19 17:48:56,383:INFO:Set up encoding of categorical features.
2025-10-19 17:48:56,389:INFO:Set up removing multicollinearity.
2025-10-19 17:48:56,429:INFO:Set up column name cleaning.
2025-10-19 17:49:01,179:INFO:Finished creating preprocessing pipeline.
2025-10-19 17:49:01,205:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 17:49:01,205:INFO:Creating final display dataframe.
2025-10-19 17:49:05,251:INFO:Setup _display_container:                     Description             Value
0                    Session id              5467
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (79874, 28)
4        Transformed data shape       (79874, 86)
5   Transformed train set shape       (55911, 86)
6    Transformed test set shape       (23963, 86)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              5a93
2025-10-19 17:49:05,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 17:49:05,314:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 17:49:05,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 17:49:05,377:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 17:49:05,379:INFO:setup() successfully completed in 29.9s...............
2025-10-19 17:49:05,379:INFO:Initializing compare_models()
2025-10-19 17:49:05,379:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D232F05990>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D232F05990>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 17:49:05,379:INFO:Checking exceptions
2025-10-19 17:49:05,565:INFO:Preparing display monitor
2025-10-19 17:49:05,601:INFO:Initializing Logistic Regression
2025-10-19 17:49:05,601:INFO:Total runtime is 0.0 minutes
2025-10-19 17:49:05,605:INFO:SubProcess create_model() called ==================================
2025-10-19 17:49:05,606:INFO:Initializing create_model()
2025-10-19 17:49:05,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D232F05990>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43686    U10652
50591    U07099
52644    U14185
77968    U04713
58236    U11381
          ...  
22756    U06192
54805    U06006
74878    U09019
70466    U03686
73796    U09130
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D23E463890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 17:49:05,606:INFO:Checking exceptions
2025-10-19 17:49:05,606:INFO:Importing libraries
2025-10-19 17:49:05,606:INFO:Copying training dataset
2025-10-19 17:49:05,968:INFO:Defining folds
2025-10-19 17:49:05,968:INFO:Declaring metric variables
2025-10-19 17:49:05,971:INFO:Importing untrained model
2025-10-19 17:49:05,974:INFO:Logistic Regression Imported successfully
2025-10-19 17:49:05,983:INFO:Starting cross validation
2025-10-19 17:49:05,987:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 17:49:17,308:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 17:49:17,602:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:49:28,400:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 17:49:28,641:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:49:38,486:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 17:49:38,727:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:49:48,862:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 17:49:49,217:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:50:00,076:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 17:50:00,323:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:50:00,337:INFO:Calculating mean and std
2025-10-19 17:50:00,338:INFO:Creating metrics dataframe
2025-10-19 17:50:00,339:INFO:Uploading results into container
2025-10-19 17:50:00,340:INFO:Uploading model into container now
2025-10-19 17:50:00,340:INFO:_master_model_container: 1
2025-10-19 17:50:00,340:INFO:_display_container: 2
2025-10-19 17:50:00,340:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5467, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 17:50:00,340:INFO:create_model() successfully completed......................................
2025-10-19 17:50:00,496:INFO:SubProcess create_model() end ==================================
2025-10-19 17:50:00,497:INFO:Creating metrics dataframe
2025-10-19 17:50:00,502:INFO:Initializing K Neighbors Classifier
2025-10-19 17:50:00,502:INFO:Total runtime is 0.9150278568267822 minutes
2025-10-19 17:50:00,505:INFO:SubProcess create_model() called ==================================
2025-10-19 17:50:00,506:INFO:Initializing create_model()
2025-10-19 17:50:00,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D232F05990>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43686    U10652
50591    U07099
52644    U14185
77968    U04713
58236    U11381
          ...  
22756    U06192
54805    U06006
74878    U09019
70466    U03686
73796    U09130
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D23E463890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 17:50:00,507:INFO:Checking exceptions
2025-10-19 17:50:00,507:INFO:Importing libraries
2025-10-19 17:50:00,507:INFO:Copying training dataset
2025-10-19 17:50:00,800:INFO:Defining folds
2025-10-19 17:50:00,801:INFO:Declaring metric variables
2025-10-19 17:50:00,805:INFO:Importing untrained model
2025-10-19 17:50:00,810:INFO:K Neighbors Classifier Imported successfully
2025-10-19 17:50:00,819:INFO:Starting cross validation
2025-10-19 17:50:00,823:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 17:50:26,317:INFO:Calculating mean and std
2025-10-19 17:50:26,320:INFO:Creating metrics dataframe
2025-10-19 17:50:26,324:INFO:Uploading results into container
2025-10-19 17:50:26,325:INFO:Uploading model into container now
2025-10-19 17:50:26,325:INFO:_master_model_container: 2
2025-10-19 17:50:26,325:INFO:_display_container: 2
2025-10-19 17:50:26,326:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 17:50:26,326:INFO:create_model() successfully completed......................................
2025-10-19 17:50:26,476:INFO:SubProcess create_model() end ==================================
2025-10-19 17:50:26,476:INFO:Creating metrics dataframe
2025-10-19 17:50:26,482:INFO:Initializing Naive Bayes
2025-10-19 17:50:26,482:INFO:Total runtime is 1.348015828927358 minutes
2025-10-19 17:50:26,484:INFO:SubProcess create_model() called ==================================
2025-10-19 17:50:26,486:INFO:Initializing create_model()
2025-10-19 17:50:26,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D232F05990>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43686    U10652
50591    U07099
52644    U14185
77968    U04713
58236    U11381
          ...  
22756    U06192
54805    U06006
74878    U09019
70466    U03686
73796    U09130
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D23E463890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 17:50:26,486:INFO:Checking exceptions
2025-10-19 17:50:26,486:INFO:Importing libraries
2025-10-19 17:50:26,486:INFO:Copying training dataset
2025-10-19 17:50:26,741:INFO:Defining folds
2025-10-19 17:50:26,741:INFO:Declaring metric variables
2025-10-19 17:50:26,743:INFO:Importing untrained model
2025-10-19 17:50:26,749:INFO:Naive Bayes Imported successfully
2025-10-19 17:50:26,756:INFO:Starting cross validation
2025-10-19 17:50:26,761:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 17:50:29,413:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:50:31,958:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:50:34,557:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:50:37,031:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:50:39,496:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:50:39,510:INFO:Calculating mean and std
2025-10-19 17:50:39,511:INFO:Creating metrics dataframe
2025-10-19 17:50:39,513:INFO:Uploading results into container
2025-10-19 17:50:39,513:INFO:Uploading model into container now
2025-10-19 17:50:39,513:INFO:_master_model_container: 3
2025-10-19 17:50:39,514:INFO:_display_container: 2
2025-10-19 17:50:39,514:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 17:50:39,514:INFO:create_model() successfully completed......................................
2025-10-19 17:50:39,689:INFO:SubProcess create_model() end ==================================
2025-10-19 17:50:39,689:INFO:Creating metrics dataframe
2025-10-19 17:50:39,696:INFO:Initializing Decision Tree Classifier
2025-10-19 17:50:39,697:INFO:Total runtime is 1.5682723164558412 minutes
2025-10-19 17:50:39,702:INFO:SubProcess create_model() called ==================================
2025-10-19 17:50:39,703:INFO:Initializing create_model()
2025-10-19 17:50:39,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D232F05990>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43686    U10652
50591    U07099
52644    U14185
77968    U04713
58236    U11381
          ...  
22756    U06192
54805    U06006
74878    U09019
70466    U03686
73796    U09130
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D23E463890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 17:50:39,703:INFO:Checking exceptions
2025-10-19 17:50:39,703:INFO:Importing libraries
2025-10-19 17:50:39,704:INFO:Copying training dataset
2025-10-19 17:50:40,007:INFO:Defining folds
2025-10-19 17:50:40,007:INFO:Declaring metric variables
2025-10-19 17:50:40,012:INFO:Importing untrained model
2025-10-19 17:50:40,016:INFO:Decision Tree Classifier Imported successfully
2025-10-19 17:50:40,025:INFO:Starting cross validation
2025-10-19 17:50:40,030:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 17:50:56,366:INFO:Calculating mean and std
2025-10-19 17:50:56,367:INFO:Creating metrics dataframe
2025-10-19 17:50:56,370:INFO:Uploading results into container
2025-10-19 17:50:56,371:INFO:Uploading model into container now
2025-10-19 17:50:56,372:INFO:_master_model_container: 4
2025-10-19 17:50:56,372:INFO:_display_container: 2
2025-10-19 17:50:56,373:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5467, splitter='best')
2025-10-19 17:50:56,373:INFO:create_model() successfully completed......................................
2025-10-19 17:50:56,553:INFO:SubProcess create_model() end ==================================
2025-10-19 17:50:56,554:INFO:Creating metrics dataframe
2025-10-19 17:50:56,560:INFO:Initializing SVM - Linear Kernel
2025-10-19 17:50:56,560:INFO:Total runtime is 1.8493268291155498 minutes
2025-10-19 17:50:56,563:INFO:SubProcess create_model() called ==================================
2025-10-19 17:50:56,564:INFO:Initializing create_model()
2025-10-19 17:50:56,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D232F05990>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43686    U10652
50591    U07099
52644    U14185
77968    U04713
58236    U11381
          ...  
22756    U06192
54805    U06006
74878    U09019
70466    U03686
73796    U09130
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D23E463890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 17:50:56,565:INFO:Checking exceptions
2025-10-19 17:50:56,565:INFO:Importing libraries
2025-10-19 17:50:56,565:INFO:Copying training dataset
2025-10-19 17:50:56,832:INFO:Defining folds
2025-10-19 17:50:56,832:INFO:Declaring metric variables
2025-10-19 17:50:56,838:INFO:Importing untrained model
2025-10-19 17:50:56,844:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 17:50:56,858:INFO:Starting cross validation
2025-10-19 17:50:56,863:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 17:51:02,538:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:51:07,987:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:51:12,725:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:51:18,499:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:51:23,783:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:51:23,797:INFO:Calculating mean and std
2025-10-19 17:51:23,798:INFO:Creating metrics dataframe
2025-10-19 17:51:23,800:INFO:Uploading results into container
2025-10-19 17:51:23,800:INFO:Uploading model into container now
2025-10-19 17:51:23,801:INFO:_master_model_container: 5
2025-10-19 17:51:23,801:INFO:_display_container: 2
2025-10-19 17:51:23,801:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=5467, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 17:51:23,801:INFO:create_model() successfully completed......................................
2025-10-19 17:51:23,956:INFO:SubProcess create_model() end ==================================
2025-10-19 17:51:23,956:INFO:Creating metrics dataframe
2025-10-19 17:51:23,965:INFO:Initializing Ridge Classifier
2025-10-19 17:51:23,965:INFO:Total runtime is 2.3060706059137983 minutes
2025-10-19 17:51:23,968:INFO:SubProcess create_model() called ==================================
2025-10-19 17:51:23,970:INFO:Initializing create_model()
2025-10-19 17:51:23,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D232F05990>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43686    U10652
50591    U07099
52644    U14185
77968    U04713
58236    U11381
          ...  
22756    U06192
54805    U06006
74878    U09019
70466    U03686
73796    U09130
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D23E463890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 17:51:23,970:INFO:Checking exceptions
2025-10-19 17:51:23,970:INFO:Importing libraries
2025-10-19 17:51:23,971:INFO:Copying training dataset
2025-10-19 17:51:24,206:INFO:Defining folds
2025-10-19 17:51:24,207:INFO:Declaring metric variables
2025-10-19 17:51:24,210:INFO:Importing untrained model
2025-10-19 17:51:24,214:INFO:Ridge Classifier Imported successfully
2025-10-19 17:51:24,220:INFO:Starting cross validation
2025-10-19 17:51:24,225:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 17:51:26,735:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:51:29,573:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:51:32,215:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:51:34,698:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:51:37,286:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 17:51:37,298:INFO:Calculating mean and std
2025-10-19 17:51:37,299:INFO:Creating metrics dataframe
2025-10-19 17:51:37,300:INFO:Uploading results into container
2025-10-19 17:51:37,300:INFO:Uploading model into container now
2025-10-19 17:51:37,300:INFO:_master_model_container: 6
2025-10-19 17:51:37,301:INFO:_display_container: 2
2025-10-19 17:51:37,301:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5467, solver='auto',
                tol=0.0001)
2025-10-19 17:51:37,301:INFO:create_model() successfully completed......................................
2025-10-19 17:51:37,454:INFO:SubProcess create_model() end ==================================
2025-10-19 17:51:37,454:INFO:Creating metrics dataframe
2025-10-19 17:51:37,462:INFO:Initializing Random Forest Classifier
2025-10-19 17:51:37,462:INFO:Total runtime is 2.531020474433899 minutes
2025-10-19 17:51:37,466:INFO:SubProcess create_model() called ==================================
2025-10-19 17:51:37,468:INFO:Initializing create_model()
2025-10-19 17:51:37,468:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D232F05990>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43686    U10652
50591    U07099
52644    U14185
77968    U04713
58236    U11381
          ...  
22756    U06192
54805    U06006
74878    U09019
70466    U03686
73796    U09130
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D23E463890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 17:51:37,468:INFO:Checking exceptions
2025-10-19 17:51:37,468:INFO:Importing libraries
2025-10-19 17:51:37,468:INFO:Copying training dataset
2025-10-19 17:51:37,699:INFO:Defining folds
2025-10-19 17:51:37,700:INFO:Declaring metric variables
2025-10-19 17:51:37,703:INFO:Importing untrained model
2025-10-19 17:51:37,709:INFO:Random Forest Classifier Imported successfully
2025-10-19 17:51:37,715:INFO:Starting cross validation
2025-10-19 17:51:37,718:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 17:52:17,764:INFO:Calculating mean and std
2025-10-19 17:52:17,766:INFO:Creating metrics dataframe
2025-10-19 17:52:17,767:INFO:Uploading results into container
2025-10-19 17:52:17,768:INFO:Uploading model into container now
2025-10-19 17:52:17,768:INFO:_master_model_container: 7
2025-10-19 17:52:17,768:INFO:_display_container: 2
2025-10-19 17:52:17,768:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=5467, verbose=0,
                       warm_start=False)
2025-10-19 17:52:17,768:INFO:create_model() successfully completed......................................
2025-10-19 17:52:17,931:INFO:SubProcess create_model() end ==================================
2025-10-19 17:52:17,931:INFO:Creating metrics dataframe
2025-10-19 17:52:17,938:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 17:52:17,939:INFO:Total runtime is 3.205644818147024 minutes
2025-10-19 17:52:17,946:INFO:SubProcess create_model() called ==================================
2025-10-19 17:52:17,947:INFO:Initializing create_model()
2025-10-19 17:52:17,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D232F05990>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43686    U10652
50591    U07099
52644    U14185
77968    U04713
58236    U11381
          ...  
22756    U06192
54805    U06006
74878    U09019
70466    U03686
73796    U09130
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D23E463890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 17:52:17,947:INFO:Checking exceptions
2025-10-19 17:52:17,947:INFO:Importing libraries
2025-10-19 17:52:17,947:INFO:Copying training dataset
2025-10-19 17:52:18,233:INFO:Defining folds
2025-10-19 17:52:18,234:INFO:Declaring metric variables
2025-10-19 17:52:18,239:INFO:Importing untrained model
2025-10-19 17:52:18,245:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 17:52:18,253:INFO:Starting cross validation
2025-10-19 17:52:18,259:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:24:30,719:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:24:30,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:24:30,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:24:30,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:31:29,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:31:29,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:31:29,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:31:29,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:31:32,742:INFO:PyCaret ClassificationExperiment
2025-10-19 18:31:32,742:INFO:Logging name: clf-default-name
2025-10-19 18:31:32,742:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 18:31:32,742:INFO:version 3.3.2
2025-10-19 18:31:32,742:INFO:Initializing setup()
2025-10-19 18:31:32,742:INFO:self.USI: 140b
2025-10-19 18:31:32,742:INFO:self._variable_keys: {'data', 'logging_param', 'fold_groups_param', 'is_multiclass', 'log_plots_param', 'seed', 'y', 'exp_id', '_ml_usecase', 'memory', 'X_train', 'fold_generator', 'X_test', 'gpu_n_jobs_param', '_available_plots', 'X', 'fix_imbalance', 'pipeline', 'exp_name_log', 'html_param', 'y_train', 'gpu_param', 'n_jobs_param', 'USI', 'target_param', 'fold_shuffle_param', 'idx', 'y_test'}
2025-10-19 18:31:32,742:INFO:Checking environment
2025-10-19 18:31:32,742:INFO:python_version: 3.11.13
2025-10-19 18:31:32,742:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 18:31:32,742:INFO:machine: AMD64
2025-10-19 18:31:32,743:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 18:31:32,750:INFO:Memory: svmem(total=16856211456, available=1401221120, percent=91.7, used=15454990336, free=1401221120)
2025-10-19 18:31:32,750:INFO:Physical Core: 4
2025-10-19 18:31:32,750:INFO:Logical Core: 8
2025-10-19 18:31:32,750:INFO:Checking libraries
2025-10-19 18:31:32,750:INFO:System:
2025-10-19 18:31:32,750:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 18:31:32,750:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 18:31:32,750:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 18:31:32,750:INFO:PyCaret required dependencies:
2025-10-19 18:31:34,237:INFO:                 pip: 25.2
2025-10-19 18:31:34,237:INFO:          setuptools: 80.9.0
2025-10-19 18:31:34,237:INFO:             pycaret: 3.3.2
2025-10-19 18:31:34,238:INFO:             IPython: 9.6.0
2025-10-19 18:31:34,238:INFO:          ipywidgets: 8.1.7
2025-10-19 18:31:34,238:INFO:                tqdm: 4.67.1
2025-10-19 18:31:34,238:INFO:               numpy: 1.26.4
2025-10-19 18:31:34,238:INFO:              pandas: 2.1.4
2025-10-19 18:31:34,238:INFO:              jinja2: 3.1.6
2025-10-19 18:31:34,238:INFO:               scipy: 1.11.4
2025-10-19 18:31:34,238:INFO:              joblib: 1.3.2
2025-10-19 18:31:34,238:INFO:             sklearn: 1.4.2
2025-10-19 18:31:34,238:INFO:                pyod: 2.0.5
2025-10-19 18:31:34,238:INFO:            imblearn: 0.14.0
2025-10-19 18:31:34,238:INFO:   category_encoders: 2.7.0
2025-10-19 18:31:34,238:INFO:            lightgbm: 4.6.0
2025-10-19 18:31:34,238:INFO:               numba: 0.61.0
2025-10-19 18:31:34,238:INFO:            requests: 2.32.5
2025-10-19 18:31:34,238:INFO:          matplotlib: 3.7.5
2025-10-19 18:31:34,238:INFO:          scikitplot: 0.3.7
2025-10-19 18:31:34,238:INFO:         yellowbrick: 1.5
2025-10-19 18:31:34,238:INFO:              plotly: 5.24.1
2025-10-19 18:31:34,238:INFO:    plotly-resampler: Not installed
2025-10-19 18:31:34,238:INFO:             kaleido: 1.1.0
2025-10-19 18:31:34,238:INFO:           schemdraw: 0.15
2025-10-19 18:31:34,238:INFO:         statsmodels: 0.14.5
2025-10-19 18:31:34,238:INFO:              sktime: 0.26.0
2025-10-19 18:31:34,238:INFO:               tbats: 1.1.3
2025-10-19 18:31:34,238:INFO:            pmdarima: 2.0.4
2025-10-19 18:31:34,238:INFO:              psutil: 7.1.0
2025-10-19 18:31:34,238:INFO:          markupsafe: 3.0.3
2025-10-19 18:31:34,238:INFO:             pickle5: Not installed
2025-10-19 18:31:34,238:INFO:         cloudpickle: 3.1.1
2025-10-19 18:31:34,238:INFO:         deprecation: 2.1.0
2025-10-19 18:31:34,238:INFO:              xxhash: 3.6.0
2025-10-19 18:31:34,238:INFO:           wurlitzer: Not installed
2025-10-19 18:31:34,238:INFO:PyCaret optional dependencies:
2025-10-19 18:31:40,507:INFO:                shap: 0.44.1
2025-10-19 18:31:40,507:INFO:           interpret: 0.7.3
2025-10-19 18:31:40,507:INFO:                umap: 0.5.7
2025-10-19 18:31:40,507:INFO:     ydata_profiling: 4.17.0
2025-10-19 18:31:40,507:INFO:  explainerdashboard: 0.5.1
2025-10-19 18:31:40,507:INFO:             autoviz: Not installed
2025-10-19 18:31:40,507:INFO:           fairlearn: 0.7.0
2025-10-19 18:31:40,507:INFO:          deepchecks: Not installed
2025-10-19 18:31:40,507:INFO:             xgboost: Not installed
2025-10-19 18:31:40,507:INFO:            catboost: 1.2.8
2025-10-19 18:31:40,507:INFO:              kmodes: 0.12.2
2025-10-19 18:31:40,508:INFO:             mlxtend: 0.23.4
2025-10-19 18:31:40,508:INFO:       statsforecast: 1.5.0
2025-10-19 18:31:40,508:INFO:        tune_sklearn: Not installed
2025-10-19 18:31:40,508:INFO:                 ray: Not installed
2025-10-19 18:31:40,508:INFO:            hyperopt: 0.2.7
2025-10-19 18:31:40,508:INFO:              optuna: 4.5.0
2025-10-19 18:31:40,508:INFO:               skopt: 0.10.2
2025-10-19 18:31:40,508:INFO:              mlflow: 3.5.0
2025-10-19 18:31:40,508:INFO:              gradio: 5.49.1
2025-10-19 18:31:40,508:INFO:             fastapi: 0.119.0
2025-10-19 18:31:40,508:INFO:             uvicorn: 0.38.0
2025-10-19 18:31:40,508:INFO:              m2cgen: 0.10.0
2025-10-19 18:31:40,508:INFO:           evidently: 0.4.40
2025-10-19 18:31:40,508:INFO:               fugue: 0.8.7
2025-10-19 18:31:40,508:INFO:           streamlit: Not installed
2025-10-19 18:31:40,508:INFO:             prophet: Not installed
2025-10-19 18:31:40,508:INFO:None
2025-10-19 18:31:40,508:INFO:Set up data.
2025-10-19 18:31:40,825:INFO:Set up folding strategy.
2025-10-19 18:31:41,244:INFO:Set up train/test split.
2025-10-19 18:31:41,640:INFO:Set up index.
2025-10-19 18:31:41,670:INFO:Assigning column types.
2025-10-19 18:31:42,042:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 18:31:42,129:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 18:31:42,139:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 18:31:42,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:31:42,212:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:31:42,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 18:31:42,687:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 18:31:42,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:31:42,737:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:31:42,737:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 18:31:42,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 18:31:42,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:31:42,856:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:31:42,933:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 18:31:42,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:31:42,985:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:31:42,985:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 18:31:43,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:31:43,121:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:31:43,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:31:43,249:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:31:43,256:INFO:Preparing preprocessing pipeline...
2025-10-19 18:31:43,326:INFO:Set up simple imputation.
2025-10-19 18:31:43,628:INFO:Set up encoding of ordinal features.
2025-10-19 18:31:43,992:INFO:Set up encoding of categorical features.
2025-10-19 18:31:43,999:INFO:Set up removing multicollinearity.
2025-10-19 18:31:44,092:INFO:Set up column name cleaning.
2025-10-19 18:31:53,124:INFO:Finished creating preprocessing pipeline.
2025-10-19 18:31:53,181:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 18:31:53,182:INFO:Creating final display dataframe.
2025-10-19 18:31:59,400:INFO:Setup _display_container:                     Description             Value
0                    Session id              1041
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (79874, 28)
4        Transformed data shape       (79874, 86)
5   Transformed train set shape       (55911, 86)
6    Transformed test set shape       (23963, 86)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              140b
2025-10-19 18:31:59,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:31:59,546:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:31:59,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:31:59,731:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:31:59,736:INFO:setup() successfully completed in 27.17s...............
2025-10-19 18:31:59,736:INFO:Initializing compare_models()
2025-10-19 18:31:59,737:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 18:31:59,737:INFO:Checking exceptions
2025-10-19 18:32:00,092:INFO:Preparing display monitor
2025-10-19 18:32:00,137:INFO:Initializing Logistic Regression
2025-10-19 18:32:00,138:INFO:Total runtime is 9.008248647054036e-06 minutes
2025-10-19 18:32:00,145:INFO:SubProcess create_model() called ==================================
2025-10-19 18:32:00,148:INFO:Initializing create_model()
2025-10-19 18:32:00,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:32:00,148:INFO:Checking exceptions
2025-10-19 18:32:00,148:INFO:Importing libraries
2025-10-19 18:32:00,148:INFO:Copying training dataset
2025-10-19 18:32:00,653:INFO:Defining folds
2025-10-19 18:32:00,653:INFO:Declaring metric variables
2025-10-19 18:32:00,657:INFO:Importing untrained model
2025-10-19 18:32:00,664:INFO:Logistic Regression Imported successfully
2025-10-19 18:32:00,672:INFO:Starting cross validation
2025-10-19 18:32:00,678:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:32:16,863:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 18:32:17,506:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:32:32,467:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 18:32:33,048:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:32:47,039:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 18:32:47,712:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:33:03,019:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 18:33:03,518:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:33:17,630:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 18:33:18,255:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:33:18,284:INFO:Calculating mean and std
2025-10-19 18:33:18,286:INFO:Creating metrics dataframe
2025-10-19 18:33:18,291:INFO:Uploading results into container
2025-10-19 18:33:18,291:INFO:Uploading model into container now
2025-10-19 18:33:18,292:INFO:_master_model_container: 1
2025-10-19 18:33:18,292:INFO:_display_container: 2
2025-10-19 18:33:18,292:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1041, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 18:33:18,292:INFO:create_model() successfully completed......................................
2025-10-19 18:33:18,599:INFO:SubProcess create_model() end ==================================
2025-10-19 18:33:18,599:INFO:Creating metrics dataframe
2025-10-19 18:33:18,613:INFO:Initializing K Neighbors Classifier
2025-10-19 18:33:18,614:INFO:Total runtime is 1.3079295516014098 minutes
2025-10-19 18:33:18,622:INFO:SubProcess create_model() called ==================================
2025-10-19 18:33:18,625:INFO:Initializing create_model()
2025-10-19 18:33:18,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:33:18,626:INFO:Checking exceptions
2025-10-19 18:33:18,626:INFO:Importing libraries
2025-10-19 18:33:18,626:INFO:Copying training dataset
2025-10-19 18:33:19,194:INFO:Defining folds
2025-10-19 18:33:19,194:INFO:Declaring metric variables
2025-10-19 18:33:19,200:INFO:Importing untrained model
2025-10-19 18:33:19,207:INFO:K Neighbors Classifier Imported successfully
2025-10-19 18:33:19,222:INFO:Starting cross validation
2025-10-19 18:33:19,228:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:34:01,757:INFO:Calculating mean and std
2025-10-19 18:34:01,760:INFO:Creating metrics dataframe
2025-10-19 18:34:01,764:INFO:Uploading results into container
2025-10-19 18:34:01,765:INFO:Uploading model into container now
2025-10-19 18:34:01,766:INFO:_master_model_container: 2
2025-10-19 18:34:01,766:INFO:_display_container: 2
2025-10-19 18:34:01,768:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 18:34:01,768:INFO:create_model() successfully completed......................................
2025-10-19 18:34:02,018:INFO:SubProcess create_model() end ==================================
2025-10-19 18:34:02,018:INFO:Creating metrics dataframe
2025-10-19 18:34:02,037:INFO:Initializing Naive Bayes
2025-10-19 18:34:02,037:INFO:Total runtime is 2.0316738645235697 minutes
2025-10-19 18:34:02,042:INFO:SubProcess create_model() called ==================================
2025-10-19 18:34:02,043:INFO:Initializing create_model()
2025-10-19 18:34:02,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:34:02,043:INFO:Checking exceptions
2025-10-19 18:34:02,043:INFO:Importing libraries
2025-10-19 18:34:02,043:INFO:Copying training dataset
2025-10-19 18:34:02,494:INFO:Defining folds
2025-10-19 18:34:02,494:INFO:Declaring metric variables
2025-10-19 18:34:02,500:INFO:Importing untrained model
2025-10-19 18:34:02,506:INFO:Naive Bayes Imported successfully
2025-10-19 18:34:02,515:INFO:Starting cross validation
2025-10-19 18:34:02,523:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:34:07,357:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:34:12,048:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:34:17,209:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:34:22,339:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:34:27,401:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:34:27,423:INFO:Calculating mean and std
2025-10-19 18:34:27,428:INFO:Creating metrics dataframe
2025-10-19 18:34:27,435:INFO:Uploading results into container
2025-10-19 18:34:27,437:INFO:Uploading model into container now
2025-10-19 18:34:27,437:INFO:_master_model_container: 3
2025-10-19 18:34:27,437:INFO:_display_container: 2
2025-10-19 18:34:27,438:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 18:34:27,438:INFO:create_model() successfully completed......................................
2025-10-19 18:34:27,694:INFO:SubProcess create_model() end ==================================
2025-10-19 18:34:27,695:INFO:Creating metrics dataframe
2025-10-19 18:34:27,719:INFO:Initializing Decision Tree Classifier
2025-10-19 18:34:27,720:INFO:Total runtime is 2.4597092231114703 minutes
2025-10-19 18:34:27,727:INFO:SubProcess create_model() called ==================================
2025-10-19 18:34:27,729:INFO:Initializing create_model()
2025-10-19 18:34:27,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:34:27,730:INFO:Checking exceptions
2025-10-19 18:34:27,730:INFO:Importing libraries
2025-10-19 18:34:27,730:INFO:Copying training dataset
2025-10-19 18:34:28,189:INFO:Defining folds
2025-10-19 18:34:28,190:INFO:Declaring metric variables
2025-10-19 18:34:28,198:INFO:Importing untrained model
2025-10-19 18:34:28,206:INFO:Decision Tree Classifier Imported successfully
2025-10-19 18:34:28,218:INFO:Starting cross validation
2025-10-19 18:34:28,224:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:34:56,585:INFO:Calculating mean and std
2025-10-19 18:34:56,588:INFO:Creating metrics dataframe
2025-10-19 18:34:56,592:INFO:Uploading results into container
2025-10-19 18:34:56,595:INFO:Uploading model into container now
2025-10-19 18:34:56,596:INFO:_master_model_container: 4
2025-10-19 18:34:56,596:INFO:_display_container: 2
2025-10-19 18:34:56,597:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1041, splitter='best')
2025-10-19 18:34:56,598:INFO:create_model() successfully completed......................................
2025-10-19 18:34:56,862:INFO:SubProcess create_model() end ==================================
2025-10-19 18:34:56,862:INFO:Creating metrics dataframe
2025-10-19 18:34:56,882:INFO:Initializing SVM - Linear Kernel
2025-10-19 18:34:56,882:INFO:Total runtime is 2.9457461595535275 minutes
2025-10-19 18:34:56,891:INFO:SubProcess create_model() called ==================================
2025-10-19 18:34:56,894:INFO:Initializing create_model()
2025-10-19 18:34:56,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:34:56,894:INFO:Checking exceptions
2025-10-19 18:34:56,894:INFO:Importing libraries
2025-10-19 18:34:56,894:INFO:Copying training dataset
2025-10-19 18:34:57,397:INFO:Defining folds
2025-10-19 18:34:57,397:INFO:Declaring metric variables
2025-10-19 18:34:57,407:INFO:Importing untrained model
2025-10-19 18:34:57,413:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 18:34:57,431:INFO:Starting cross validation
2025-10-19 18:34:57,439:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:35:06,284:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:35:16,493:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:35:24,651:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:35:35,119:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:35:43,681:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:35:43,704:INFO:Calculating mean and std
2025-10-19 18:35:43,707:INFO:Creating metrics dataframe
2025-10-19 18:35:43,710:INFO:Uploading results into container
2025-10-19 18:35:43,711:INFO:Uploading model into container now
2025-10-19 18:35:43,712:INFO:_master_model_container: 5
2025-10-19 18:35:43,712:INFO:_display_container: 2
2025-10-19 18:35:43,714:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=1041, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 18:35:43,715:INFO:create_model() successfully completed......................................
2025-10-19 18:35:44,049:INFO:SubProcess create_model() end ==================================
2025-10-19 18:35:44,050:INFO:Creating metrics dataframe
2025-10-19 18:35:44,068:INFO:Initializing Ridge Classifier
2025-10-19 18:35:44,068:INFO:Total runtime is 3.732184346516927 minutes
2025-10-19 18:35:44,078:INFO:SubProcess create_model() called ==================================
2025-10-19 18:35:44,081:INFO:Initializing create_model()
2025-10-19 18:35:44,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:35:44,081:INFO:Checking exceptions
2025-10-19 18:35:44,082:INFO:Importing libraries
2025-10-19 18:35:44,082:INFO:Copying training dataset
2025-10-19 18:35:44,576:INFO:Defining folds
2025-10-19 18:35:44,576:INFO:Declaring metric variables
2025-10-19 18:35:44,584:INFO:Importing untrained model
2025-10-19 18:35:44,593:INFO:Ridge Classifier Imported successfully
2025-10-19 18:35:44,606:INFO:Starting cross validation
2025-10-19 18:35:44,614:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:35:49,804:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:35:55,107:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:36:00,641:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:36:06,155:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:36:10,751:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:36:10,780:INFO:Calculating mean and std
2025-10-19 18:36:10,782:INFO:Creating metrics dataframe
2025-10-19 18:36:10,786:INFO:Uploading results into container
2025-10-19 18:36:10,787:INFO:Uploading model into container now
2025-10-19 18:36:10,788:INFO:_master_model_container: 6
2025-10-19 18:36:10,788:INFO:_display_container: 2
2025-10-19 18:36:10,789:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1041, solver='auto',
                tol=0.0001)
2025-10-19 18:36:10,790:INFO:create_model() successfully completed......................................
2025-10-19 18:36:11,078:INFO:SubProcess create_model() end ==================================
2025-10-19 18:36:11,079:INFO:Creating metrics dataframe
2025-10-19 18:36:11,091:INFO:Initializing Random Forest Classifier
2025-10-19 18:36:11,093:INFO:Total runtime is 4.182573719819387 minutes
2025-10-19 18:36:11,097:INFO:SubProcess create_model() called ==================================
2025-10-19 18:36:11,101:INFO:Initializing create_model()
2025-10-19 18:36:11,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:36:11,101:INFO:Checking exceptions
2025-10-19 18:36:11,101:INFO:Importing libraries
2025-10-19 18:36:11,101:INFO:Copying training dataset
2025-10-19 18:36:11,581:INFO:Defining folds
2025-10-19 18:36:11,581:INFO:Declaring metric variables
2025-10-19 18:36:11,592:INFO:Importing untrained model
2025-10-19 18:36:11,601:INFO:Random Forest Classifier Imported successfully
2025-10-19 18:36:11,616:INFO:Starting cross validation
2025-10-19 18:36:11,622:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:37:26,833:INFO:Calculating mean and std
2025-10-19 18:37:26,835:INFO:Creating metrics dataframe
2025-10-19 18:37:26,839:INFO:Uploading results into container
2025-10-19 18:37:26,840:INFO:Uploading model into container now
2025-10-19 18:37:26,840:INFO:_master_model_container: 7
2025-10-19 18:37:26,840:INFO:_display_container: 2
2025-10-19 18:37:26,842:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=1041, verbose=0,
                       warm_start=False)
2025-10-19 18:37:26,842:INFO:create_model() successfully completed......................................
2025-10-19 18:37:27,138:INFO:SubProcess create_model() end ==================================
2025-10-19 18:37:27,138:INFO:Creating metrics dataframe
2025-10-19 18:37:27,156:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 18:37:27,156:INFO:Total runtime is 5.4503090937932335 minutes
2025-10-19 18:37:27,160:INFO:SubProcess create_model() called ==================================
2025-10-19 18:37:27,164:INFO:Initializing create_model()
2025-10-19 18:37:27,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:37:27,165:INFO:Checking exceptions
2025-10-19 18:37:27,165:INFO:Importing libraries
2025-10-19 18:37:27,165:INFO:Copying training dataset
2025-10-19 18:37:27,623:INFO:Defining folds
2025-10-19 18:37:27,624:INFO:Declaring metric variables
2025-10-19 18:37:27,633:INFO:Importing untrained model
2025-10-19 18:37:27,639:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 18:37:27,654:INFO:Starting cross validation
2025-10-19 18:37:27,660:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:37:32,448:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 18:37:38,151:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 18:37:44,276:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 18:37:49,375:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 18:37:55,104:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 18:37:55,749:INFO:Calculating mean and std
2025-10-19 18:37:55,751:INFO:Creating metrics dataframe
2025-10-19 18:37:55,756:INFO:Uploading results into container
2025-10-19 18:37:55,758:INFO:Uploading model into container now
2025-10-19 18:37:55,759:INFO:_master_model_container: 8
2025-10-19 18:37:55,759:INFO:_display_container: 2
2025-10-19 18:37:55,760:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 18:37:55,760:INFO:create_model() successfully completed......................................
2025-10-19 18:37:56,045:INFO:SubProcess create_model() end ==================================
2025-10-19 18:37:56,045:INFO:Creating metrics dataframe
2025-10-19 18:37:56,068:INFO:Initializing Ada Boost Classifier
2025-10-19 18:37:56,069:INFO:Total runtime is 5.932194932301839 minutes
2025-10-19 18:37:56,073:INFO:SubProcess create_model() called ==================================
2025-10-19 18:37:56,075:INFO:Initializing create_model()
2025-10-19 18:37:56,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:37:56,075:INFO:Checking exceptions
2025-10-19 18:37:56,075:INFO:Importing libraries
2025-10-19 18:37:56,075:INFO:Copying training dataset
2025-10-19 18:37:56,512:INFO:Defining folds
2025-10-19 18:37:56,512:INFO:Declaring metric variables
2025-10-19 18:37:56,520:INFO:Importing untrained model
2025-10-19 18:37:56,525:INFO:Ada Boost Classifier Imported successfully
2025-10-19 18:37:56,537:INFO:Starting cross validation
2025-10-19 18:37:56,546:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:38:00,859:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 18:38:08,139:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:38:11,996:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 18:38:19,794:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:38:24,072:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 18:38:35,742:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 18:38:43,704:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:38:48,044:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 18:38:56,367:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:38:56,397:INFO:Calculating mean and std
2025-10-19 18:38:56,402:INFO:Creating metrics dataframe
2025-10-19 18:38:56,405:INFO:Uploading results into container
2025-10-19 18:38:56,407:INFO:Uploading model into container now
2025-10-19 18:38:56,408:INFO:_master_model_container: 9
2025-10-19 18:38:56,408:INFO:_display_container: 2
2025-10-19 18:38:56,409:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1041)
2025-10-19 18:38:56,409:INFO:create_model() successfully completed......................................
2025-10-19 18:38:56,651:INFO:SubProcess create_model() end ==================================
2025-10-19 18:38:56,652:INFO:Creating metrics dataframe
2025-10-19 18:38:56,675:INFO:Initializing Gradient Boosting Classifier
2025-10-19 18:38:56,676:INFO:Total runtime is 6.942318149407704 minutes
2025-10-19 18:38:56,684:INFO:SubProcess create_model() called ==================================
2025-10-19 18:38:56,686:INFO:Initializing create_model()
2025-10-19 18:38:56,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:38:56,686:INFO:Checking exceptions
2025-10-19 18:38:56,686:INFO:Importing libraries
2025-10-19 18:38:56,686:INFO:Copying training dataset
2025-10-19 18:38:57,191:INFO:Defining folds
2025-10-19 18:38:57,191:INFO:Declaring metric variables
2025-10-19 18:38:57,201:INFO:Importing untrained model
2025-10-19 18:38:57,212:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 18:38:57,230:INFO:Starting cross validation
2025-10-19 18:38:57,239:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:39:27,134:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:41:20,575:INFO:Calculating mean and std
2025-10-19 18:41:20,577:INFO:Creating metrics dataframe
2025-10-19 18:41:20,579:INFO:Uploading results into container
2025-10-19 18:41:20,580:INFO:Uploading model into container now
2025-10-19 18:41:20,580:INFO:_master_model_container: 10
2025-10-19 18:41:20,580:INFO:_display_container: 2
2025-10-19 18:41:20,581:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1041, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 18:41:20,581:INFO:create_model() successfully completed......................................
2025-10-19 18:41:20,888:INFO:SubProcess create_model() end ==================================
2025-10-19 18:41:20,889:INFO:Creating metrics dataframe
2025-10-19 18:41:20,912:INFO:Initializing Linear Discriminant Analysis
2025-10-19 18:41:20,913:INFO:Total runtime is 9.346245956420898 minutes
2025-10-19 18:41:20,923:INFO:SubProcess create_model() called ==================================
2025-10-19 18:41:20,927:INFO:Initializing create_model()
2025-10-19 18:41:20,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:41:20,927:INFO:Checking exceptions
2025-10-19 18:41:20,927:INFO:Importing libraries
2025-10-19 18:41:20,927:INFO:Copying training dataset
2025-10-19 18:41:21,355:INFO:Defining folds
2025-10-19 18:41:21,355:INFO:Declaring metric variables
2025-10-19 18:41:21,364:INFO:Importing untrained model
2025-10-19 18:41:21,373:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 18:41:21,392:INFO:Starting cross validation
2025-10-19 18:41:21,404:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:41:49,450:INFO:Calculating mean and std
2025-10-19 18:41:49,452:INFO:Creating metrics dataframe
2025-10-19 18:41:49,456:INFO:Uploading results into container
2025-10-19 18:41:49,457:INFO:Uploading model into container now
2025-10-19 18:41:49,457:INFO:_master_model_container: 11
2025-10-19 18:41:49,458:INFO:_display_container: 2
2025-10-19 18:41:49,459:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 18:41:49,459:INFO:create_model() successfully completed......................................
2025-10-19 18:41:49,711:INFO:SubProcess create_model() end ==================================
2025-10-19 18:41:49,711:INFO:Creating metrics dataframe
2025-10-19 18:41:49,732:INFO:Initializing Extra Trees Classifier
2025-10-19 18:41:49,732:INFO:Total runtime is 9.826578402519225 minutes
2025-10-19 18:41:49,739:INFO:SubProcess create_model() called ==================================
2025-10-19 18:41:49,742:INFO:Initializing create_model()
2025-10-19 18:41:49,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:41:49,742:INFO:Checking exceptions
2025-10-19 18:41:49,742:INFO:Importing libraries
2025-10-19 18:41:49,742:INFO:Copying training dataset
2025-10-19 18:41:50,162:INFO:Defining folds
2025-10-19 18:41:50,163:INFO:Declaring metric variables
2025-10-19 18:41:50,169:INFO:Importing untrained model
2025-10-19 18:41:50,177:INFO:Extra Trees Classifier Imported successfully
2025-10-19 18:41:50,201:INFO:Starting cross validation
2025-10-19 18:41:50,212:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:43:10,518:INFO:Calculating mean and std
2025-10-19 18:43:10,522:INFO:Creating metrics dataframe
2025-10-19 18:43:10,526:INFO:Uploading results into container
2025-10-19 18:43:10,528:INFO:Uploading model into container now
2025-10-19 18:43:10,528:INFO:_master_model_container: 12
2025-10-19 18:43:10,528:INFO:_display_container: 2
2025-10-19 18:43:10,529:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=1041, verbose=0,
                     warm_start=False)
2025-10-19 18:43:10,529:INFO:create_model() successfully completed......................................
2025-10-19 18:43:10,792:INFO:SubProcess create_model() end ==================================
2025-10-19 18:43:10,792:INFO:Creating metrics dataframe
2025-10-19 18:43:10,806:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 18:43:10,806:INFO:Total runtime is 11.1778138478597 minutes
2025-10-19 18:43:10,814:INFO:SubProcess create_model() called ==================================
2025-10-19 18:43:10,816:INFO:Initializing create_model()
2025-10-19 18:43:10,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:43:10,816:INFO:Checking exceptions
2025-10-19 18:43:10,816:INFO:Importing libraries
2025-10-19 18:43:10,816:INFO:Copying training dataset
2025-10-19 18:43:11,235:INFO:Defining folds
2025-10-19 18:43:11,235:INFO:Declaring metric variables
2025-10-19 18:43:11,243:INFO:Importing untrained model
2025-10-19 18:43:11,249:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 18:43:11,262:INFO:Starting cross validation
2025-10-19 18:43:11,269:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:43:15,999:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:43:16,005:INFO:[LightGBM] [Info] Number of positive: 1811, number of negative: 42917
2025-10-19 18:43:16,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015954 seconds.
2025-10-19 18:43:16,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 18:43:16,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 18:43:16,049:INFO:[LightGBM] [Info] Total Bins 1472
2025-10-19 18:43:16,050:INFO:[LightGBM] [Info] Number of data points in the train set: 44728, number of used features: 85
2025-10-19 18:43:16,052:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040489 -> initscore=-3.165389
2025-10-19 18:43:16,053:INFO:[LightGBM] [Info] Start training from score -3.165389
2025-10-19 18:43:22,612:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:43:22,615:INFO:[LightGBM] [Info] Number of positive: 1731, number of negative: 42998
2025-10-19 18:43:22,662:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015262 seconds.
2025-10-19 18:43:22,662:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 18:43:22,662:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 18:43:22,662:INFO:[LightGBM] [Info] Total Bins 1474
2025-10-19 18:43:22,663:INFO:[LightGBM] [Info] Number of data points in the train set: 44729, number of used features: 85
2025-10-19 18:43:22,664:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038700 -> initscore=-3.212454
2025-10-19 18:43:22,664:INFO:[LightGBM] [Info] Start training from score -3.212454
2025-10-19 18:43:28,786:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:43:28,791:INFO:[LightGBM] [Info] Number of positive: 1733, number of negative: 42996
2025-10-19 18:43:28,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015293 seconds.
2025-10-19 18:43:28,839:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 18:43:28,839:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 18:43:28,839:INFO:[LightGBM] [Info] Total Bins 1473
2025-10-19 18:43:28,840:INFO:[LightGBM] [Info] Number of data points in the train set: 44729, number of used features: 85
2025-10-19 18:43:28,841:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038744 -> initscore=-3.211253
2025-10-19 18:43:28,842:INFO:[LightGBM] [Info] Start training from score -3.211253
2025-10-19 18:43:35,285:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:43:35,290:INFO:[LightGBM] [Info] Number of positive: 1746, number of negative: 42983
2025-10-19 18:43:35,363:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027022 seconds.
2025-10-19 18:43:35,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 18:43:35,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 18:43:35,363:INFO:[LightGBM] [Info] Total Bins 1471
2025-10-19 18:43:35,364:INFO:[LightGBM] [Info] Number of data points in the train set: 44729, number of used features: 85
2025-10-19 18:43:35,366:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039035 -> initscore=-3.203477
2025-10-19 18:43:35,366:INFO:[LightGBM] [Info] Start training from score -3.203477
2025-10-19 18:43:41,335:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:43:41,338:INFO:[LightGBM] [Info] Number of positive: 1767, number of negative: 42962
2025-10-19 18:43:41,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034510 seconds.
2025-10-19 18:43:41,380:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-19 18:43:41,381:INFO:[LightGBM] [Info] Total Bins 1468
2025-10-19 18:43:41,382:INFO:[LightGBM] [Info] Number of data points in the train set: 44729, number of used features: 85
2025-10-19 18:43:41,384:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039505 -> initscore=-3.191033
2025-10-19 18:43:41,384:INFO:[LightGBM] [Info] Start training from score -3.191033
2025-10-19 18:43:43,301:INFO:Calculating mean and std
2025-10-19 18:43:43,303:INFO:Creating metrics dataframe
2025-10-19 18:43:43,308:INFO:Uploading results into container
2025-10-19 18:43:43,310:INFO:Uploading model into container now
2025-10-19 18:43:43,310:INFO:_master_model_container: 13
2025-10-19 18:43:43,311:INFO:_display_container: 2
2025-10-19 18:43:43,312:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=1041, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 18:43:43,312:INFO:create_model() successfully completed......................................
2025-10-19 18:43:43,554:INFO:SubProcess create_model() end ==================================
2025-10-19 18:43:43,554:INFO:Creating metrics dataframe
2025-10-19 18:43:43,573:INFO:Initializing CatBoost Classifier
2025-10-19 18:43:43,574:INFO:Total runtime is 11.723943404356637 minutes
2025-10-19 18:43:43,583:INFO:SubProcess create_model() called ==================================
2025-10-19 18:43:43,584:INFO:Initializing create_model()
2025-10-19 18:43:43,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BD2E5D6F90>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=2428     U03777
72514    U08803
52662    U14603
11174    U00575
40940    U03629
          ...  
59281    U11155
75252    U06709
11746    U05818
53518    U12726
5776     U13408
Name: id_usuario, Length: 55911, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BD399A78D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:43:43,585:INFO:Checking exceptions
2025-10-19 18:43:43,585:INFO:Importing libraries
2025-10-19 18:43:43,585:INFO:Copying training dataset
2025-10-19 18:43:44,007:INFO:Defining folds
2025-10-19 18:43:44,007:INFO:Declaring metric variables
2025-10-19 18:43:44,019:INFO:Importing untrained model
2025-10-19 18:43:44,028:INFO:CatBoost Classifier Imported successfully
2025-10-19 18:43:44,045:INFO:Starting cross validation
2025-10-19 18:43:44,056:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:47:37,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:47:37,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:47:37,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:47:37,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 18:47:40,376:INFO:PyCaret ClassificationExperiment
2025-10-19 18:47:40,376:INFO:Logging name: clf-default-name
2025-10-19 18:47:40,376:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 18:47:40,376:INFO:version 3.3.2
2025-10-19 18:47:40,376:INFO:Initializing setup()
2025-10-19 18:47:40,376:INFO:self.USI: e022
2025-10-19 18:47:40,376:INFO:self._variable_keys: {'y_train', 'fold_groups_param', 'seed', 'target_param', 'memory', 'idx', 'logging_param', 'X', 'fold_generator', 'y_test', 'gpu_param', 'data', 'y', 'fold_shuffle_param', '_ml_usecase', 'X_test', 'n_jobs_param', '_available_plots', 'is_multiclass', 'pipeline', 'X_train', 'exp_id', 'fix_imbalance', 'exp_name_log', 'html_param', 'log_plots_param', 'gpu_n_jobs_param', 'USI'}
2025-10-19 18:47:40,376:INFO:Checking environment
2025-10-19 18:47:40,376:INFO:python_version: 3.11.13
2025-10-19 18:47:40,376:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 18:47:40,376:INFO:machine: AMD64
2025-10-19 18:47:40,376:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 18:47:40,384:INFO:Memory: svmem(total=16856211456, available=3206684672, percent=81.0, used=13649526784, free=3206684672)
2025-10-19 18:47:40,384:INFO:Physical Core: 4
2025-10-19 18:47:40,384:INFO:Logical Core: 8
2025-10-19 18:47:40,384:INFO:Checking libraries
2025-10-19 18:47:40,384:INFO:System:
2025-10-19 18:47:40,384:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 18:47:40,384:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 18:47:40,384:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 18:47:40,384:INFO:PyCaret required dependencies:
2025-10-19 18:47:41,672:INFO:                 pip: 25.2
2025-10-19 18:47:41,672:INFO:          setuptools: 80.9.0
2025-10-19 18:47:41,672:INFO:             pycaret: 3.3.2
2025-10-19 18:47:41,673:INFO:             IPython: 9.6.0
2025-10-19 18:47:41,673:INFO:          ipywidgets: 8.1.7
2025-10-19 18:47:41,673:INFO:                tqdm: 4.67.1
2025-10-19 18:47:41,673:INFO:               numpy: 1.26.4
2025-10-19 18:47:41,673:INFO:              pandas: 2.1.4
2025-10-19 18:47:41,673:INFO:              jinja2: 3.1.6
2025-10-19 18:47:41,673:INFO:               scipy: 1.11.4
2025-10-19 18:47:41,673:INFO:              joblib: 1.3.2
2025-10-19 18:47:41,673:INFO:             sklearn: 1.4.2
2025-10-19 18:47:41,673:INFO:                pyod: 2.0.5
2025-10-19 18:47:41,673:INFO:            imblearn: 0.14.0
2025-10-19 18:47:41,673:INFO:   category_encoders: 2.7.0
2025-10-19 18:47:41,673:INFO:            lightgbm: 4.6.0
2025-10-19 18:47:41,673:INFO:               numba: 0.61.0
2025-10-19 18:47:41,673:INFO:            requests: 2.32.5
2025-10-19 18:47:41,673:INFO:          matplotlib: 3.7.5
2025-10-19 18:47:41,673:INFO:          scikitplot: 0.3.7
2025-10-19 18:47:41,673:INFO:         yellowbrick: 1.5
2025-10-19 18:47:41,673:INFO:              plotly: 5.24.1
2025-10-19 18:47:41,673:INFO:    plotly-resampler: Not installed
2025-10-19 18:47:41,673:INFO:             kaleido: 1.1.0
2025-10-19 18:47:41,673:INFO:           schemdraw: 0.15
2025-10-19 18:47:41,673:INFO:         statsmodels: 0.14.5
2025-10-19 18:47:41,673:INFO:              sktime: 0.26.0
2025-10-19 18:47:41,673:INFO:               tbats: 1.1.3
2025-10-19 18:47:41,673:INFO:            pmdarima: 2.0.4
2025-10-19 18:47:41,674:INFO:              psutil: 7.1.0
2025-10-19 18:47:41,674:INFO:          markupsafe: 3.0.3
2025-10-19 18:47:41,674:INFO:             pickle5: Not installed
2025-10-19 18:47:41,674:INFO:         cloudpickle: 3.1.1
2025-10-19 18:47:41,674:INFO:         deprecation: 2.1.0
2025-10-19 18:47:41,674:INFO:              xxhash: 3.6.0
2025-10-19 18:47:41,674:INFO:           wurlitzer: Not installed
2025-10-19 18:47:41,674:INFO:PyCaret optional dependencies:
2025-10-19 18:47:46,899:INFO:                shap: 0.44.1
2025-10-19 18:47:46,899:INFO:           interpret: 0.7.3
2025-10-19 18:47:46,899:INFO:                umap: 0.5.7
2025-10-19 18:47:46,899:INFO:     ydata_profiling: 4.17.0
2025-10-19 18:47:46,899:INFO:  explainerdashboard: 0.5.1
2025-10-19 18:47:46,900:INFO:             autoviz: Not installed
2025-10-19 18:47:46,900:INFO:           fairlearn: 0.7.0
2025-10-19 18:47:46,900:INFO:          deepchecks: Not installed
2025-10-19 18:47:46,900:INFO:             xgboost: Not installed
2025-10-19 18:47:46,900:INFO:            catboost: 1.2.8
2025-10-19 18:47:46,900:INFO:              kmodes: 0.12.2
2025-10-19 18:47:46,900:INFO:             mlxtend: 0.23.4
2025-10-19 18:47:46,900:INFO:       statsforecast: 1.5.0
2025-10-19 18:47:46,900:INFO:        tune_sklearn: Not installed
2025-10-19 18:47:46,900:INFO:                 ray: Not installed
2025-10-19 18:47:46,900:INFO:            hyperopt: 0.2.7
2025-10-19 18:47:46,900:INFO:              optuna: 4.5.0
2025-10-19 18:47:46,900:INFO:               skopt: 0.10.2
2025-10-19 18:47:46,900:INFO:              mlflow: 3.5.0
2025-10-19 18:47:46,900:INFO:              gradio: 5.49.1
2025-10-19 18:47:46,900:INFO:             fastapi: 0.119.0
2025-10-19 18:47:46,900:INFO:             uvicorn: 0.38.0
2025-10-19 18:47:46,900:INFO:              m2cgen: 0.10.0
2025-10-19 18:47:46,900:INFO:           evidently: 0.4.40
2025-10-19 18:47:46,900:INFO:               fugue: 0.8.7
2025-10-19 18:47:46,900:INFO:           streamlit: Not installed
2025-10-19 18:47:46,900:INFO:             prophet: Not installed
2025-10-19 18:47:46,900:INFO:None
2025-10-19 18:47:46,900:INFO:Set up data.
2025-10-19 18:47:47,043:INFO:Set up folding strategy.
2025-10-19 18:47:47,189:INFO:Set up train/test split.
2025-10-19 18:47:47,345:INFO:Set up index.
2025-10-19 18:47:47,353:INFO:Assigning column types.
2025-10-19 18:47:47,522:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 18:47:47,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 18:47:47,560:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 18:47:47,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:47:47,592:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:47:47,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 18:47:47,666:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 18:47:47,688:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:47:47,688:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:47:47,688:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 18:47:47,735:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 18:47:47,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:47:47,759:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:47:47,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 18:47:47,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:47:47,826:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:47:47,827:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 18:47:47,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:47:47,885:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:47:47,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:47:47,941:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:47:47,943:INFO:Preparing preprocessing pipeline...
2025-10-19 18:47:47,970:INFO:Set up simple imputation.
2025-10-19 18:47:48,093:INFO:Set up encoding of ordinal features.
2025-10-19 18:47:48,149:INFO:Set up encoding of categorical features.
2025-10-19 18:47:48,153:INFO:Set up removing multicollinearity.
2025-10-19 18:47:48,180:INFO:Set up column name cleaning.
2025-10-19 18:47:52,300:INFO:Finished creating preprocessing pipeline.
2025-10-19 18:47:52,316:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 18:47:52,316:INFO:Creating final display dataframe.
2025-10-19 18:47:54,782:INFO:Setup _display_container:                     Description             Value
0                    Session id              6904
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (63955, 28)
4        Transformed data shape       (63955, 96)
5   Transformed train set shape       (44768, 96)
6    Transformed test set shape       (19187, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              e022
2025-10-19 18:47:54,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:47:54,835:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:47:54,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 18:47:54,893:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 18:47:54,895:INFO:setup() successfully completed in 14.59s...............
2025-10-19 18:47:54,895:INFO:Initializing compare_models()
2025-10-19 18:47:54,895:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 18:47:54,895:INFO:Checking exceptions
2025-10-19 18:47:55,018:INFO:Preparing display monitor
2025-10-19 18:47:55,046:INFO:Initializing Logistic Regression
2025-10-19 18:47:55,047:INFO:Total runtime is 1.6621748606363933e-05 minutes
2025-10-19 18:47:55,051:INFO:SubProcess create_model() called ==================================
2025-10-19 18:47:55,053:INFO:Initializing create_model()
2025-10-19 18:47:55,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:47:55,054:INFO:Checking exceptions
2025-10-19 18:47:55,054:INFO:Importing libraries
2025-10-19 18:47:55,054:INFO:Copying training dataset
2025-10-19 18:47:55,268:INFO:Defining folds
2025-10-19 18:47:55,269:INFO:Declaring metric variables
2025-10-19 18:47:55,271:INFO:Importing untrained model
2025-10-19 18:47:55,275:INFO:Logistic Regression Imported successfully
2025-10-19 18:47:55,282:INFO:Starting cross validation
2025-10-19 18:47:55,286:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:48:03,217:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 18:48:10,557:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 18:48:17,845:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 18:48:25,381:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 18:48:32,714:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 18:48:32,955:INFO:Calculating mean and std
2025-10-19 18:48:32,957:INFO:Creating metrics dataframe
2025-10-19 18:48:32,959:INFO:Uploading results into container
2025-10-19 18:48:32,959:INFO:Uploading model into container now
2025-10-19 18:48:32,960:INFO:_master_model_container: 1
2025-10-19 18:48:32,960:INFO:_display_container: 2
2025-10-19 18:48:32,960:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6904, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 18:48:32,961:INFO:create_model() successfully completed......................................
2025-10-19 18:48:33,118:INFO:SubProcess create_model() end ==================================
2025-10-19 18:48:33,118:INFO:Creating metrics dataframe
2025-10-19 18:48:33,122:INFO:Initializing K Neighbors Classifier
2025-10-19 18:48:33,123:INFO:Total runtime is 0.63462895154953 minutes
2025-10-19 18:48:33,128:INFO:SubProcess create_model() called ==================================
2025-10-19 18:48:33,130:INFO:Initializing create_model()
2025-10-19 18:48:33,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:48:33,130:INFO:Checking exceptions
2025-10-19 18:48:33,130:INFO:Importing libraries
2025-10-19 18:48:33,130:INFO:Copying training dataset
2025-10-19 18:48:33,316:INFO:Defining folds
2025-10-19 18:48:33,316:INFO:Declaring metric variables
2025-10-19 18:48:33,319:INFO:Importing untrained model
2025-10-19 18:48:33,323:INFO:K Neighbors Classifier Imported successfully
2025-10-19 18:48:33,331:INFO:Starting cross validation
2025-10-19 18:48:33,335:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:48:52,589:INFO:Calculating mean and std
2025-10-19 18:48:52,590:INFO:Creating metrics dataframe
2025-10-19 18:48:52,592:INFO:Uploading results into container
2025-10-19 18:48:52,592:INFO:Uploading model into container now
2025-10-19 18:48:52,593:INFO:_master_model_container: 2
2025-10-19 18:48:52,593:INFO:_display_container: 2
2025-10-19 18:48:52,594:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 18:48:52,594:INFO:create_model() successfully completed......................................
2025-10-19 18:48:52,776:INFO:SubProcess create_model() end ==================================
2025-10-19 18:48:52,776:INFO:Creating metrics dataframe
2025-10-19 18:48:52,783:INFO:Initializing Naive Bayes
2025-10-19 18:48:52,783:INFO:Total runtime is 0.9622835000356038 minutes
2025-10-19 18:48:52,787:INFO:SubProcess create_model() called ==================================
2025-10-19 18:48:52,788:INFO:Initializing create_model()
2025-10-19 18:48:52,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:48:52,789:INFO:Checking exceptions
2025-10-19 18:48:52,789:INFO:Importing libraries
2025-10-19 18:48:52,789:INFO:Copying training dataset
2025-10-19 18:48:53,000:INFO:Defining folds
2025-10-19 18:48:53,000:INFO:Declaring metric variables
2025-10-19 18:48:53,004:INFO:Importing untrained model
2025-10-19 18:48:53,010:INFO:Naive Bayes Imported successfully
2025-10-19 18:48:53,018:INFO:Starting cross validation
2025-10-19 18:48:53,022:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:48:55,282:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:48:59,830:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:49:02,080:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:49:04,216:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:49:04,227:INFO:Calculating mean and std
2025-10-19 18:49:04,228:INFO:Creating metrics dataframe
2025-10-19 18:49:04,230:INFO:Uploading results into container
2025-10-19 18:49:04,231:INFO:Uploading model into container now
2025-10-19 18:49:04,231:INFO:_master_model_container: 3
2025-10-19 18:49:04,231:INFO:_display_container: 2
2025-10-19 18:49:04,231:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 18:49:04,231:INFO:create_model() successfully completed......................................
2025-10-19 18:49:04,381:INFO:SubProcess create_model() end ==================================
2025-10-19 18:49:04,381:INFO:Creating metrics dataframe
2025-10-19 18:49:04,387:INFO:Initializing Decision Tree Classifier
2025-10-19 18:49:04,387:INFO:Total runtime is 1.1556955377260842 minutes
2025-10-19 18:49:04,392:INFO:SubProcess create_model() called ==================================
2025-10-19 18:49:04,394:INFO:Initializing create_model()
2025-10-19 18:49:04,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:49:04,394:INFO:Checking exceptions
2025-10-19 18:49:04,394:INFO:Importing libraries
2025-10-19 18:49:04,394:INFO:Copying training dataset
2025-10-19 18:49:04,581:INFO:Defining folds
2025-10-19 18:49:04,582:INFO:Declaring metric variables
2025-10-19 18:49:04,586:INFO:Importing untrained model
2025-10-19 18:49:04,591:INFO:Decision Tree Classifier Imported successfully
2025-10-19 18:49:04,599:INFO:Starting cross validation
2025-10-19 18:49:04,604:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:49:17,828:INFO:Calculating mean and std
2025-10-19 18:49:17,829:INFO:Creating metrics dataframe
2025-10-19 18:49:17,831:INFO:Uploading results into container
2025-10-19 18:49:17,831:INFO:Uploading model into container now
2025-10-19 18:49:17,832:INFO:_master_model_container: 4
2025-10-19 18:49:17,832:INFO:_display_container: 2
2025-10-19 18:49:17,832:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6904, splitter='best')
2025-10-19 18:49:17,832:INFO:create_model() successfully completed......................................
2025-10-19 18:49:17,978:INFO:SubProcess create_model() end ==================================
2025-10-19 18:49:17,979:INFO:Creating metrics dataframe
2025-10-19 18:49:17,988:INFO:Initializing SVM - Linear Kernel
2025-10-19 18:49:17,988:INFO:Total runtime is 1.3823707660039264 minutes
2025-10-19 18:49:17,992:INFO:SubProcess create_model() called ==================================
2025-10-19 18:49:17,993:INFO:Initializing create_model()
2025-10-19 18:49:17,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:49:17,993:INFO:Checking exceptions
2025-10-19 18:49:17,993:INFO:Importing libraries
2025-10-19 18:49:17,993:INFO:Copying training dataset
2025-10-19 18:49:18,173:INFO:Defining folds
2025-10-19 18:49:18,173:INFO:Declaring metric variables
2025-10-19 18:49:18,178:INFO:Importing untrained model
2025-10-19 18:49:18,183:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 18:49:18,190:INFO:Starting cross validation
2025-10-19 18:49:18,195:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:49:27,927:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:49:40,038:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:49:46,888:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:49:46,900:INFO:Calculating mean and std
2025-10-19 18:49:46,901:INFO:Creating metrics dataframe
2025-10-19 18:49:46,903:INFO:Uploading results into container
2025-10-19 18:49:46,903:INFO:Uploading model into container now
2025-10-19 18:49:46,904:INFO:_master_model_container: 5
2025-10-19 18:49:46,904:INFO:_display_container: 2
2025-10-19 18:49:46,904:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=6904, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 18:49:46,904:INFO:create_model() successfully completed......................................
2025-10-19 18:49:47,056:INFO:SubProcess create_model() end ==================================
2025-10-19 18:49:47,056:INFO:Creating metrics dataframe
2025-10-19 18:49:47,063:INFO:Initializing Ridge Classifier
2025-10-19 18:49:47,063:INFO:Total runtime is 1.866956583658854 minutes
2025-10-19 18:49:47,068:INFO:SubProcess create_model() called ==================================
2025-10-19 18:49:47,069:INFO:Initializing create_model()
2025-10-19 18:49:47,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:49:47,069:INFO:Checking exceptions
2025-10-19 18:49:47,069:INFO:Importing libraries
2025-10-19 18:49:47,069:INFO:Copying training dataset
2025-10-19 18:49:47,255:INFO:Defining folds
2025-10-19 18:49:47,255:INFO:Declaring metric variables
2025-10-19 18:49:47,259:INFO:Importing untrained model
2025-10-19 18:49:47,264:INFO:Ridge Classifier Imported successfully
2025-10-19 18:49:47,270:INFO:Starting cross validation
2025-10-19 18:49:47,275:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:49:58,918:INFO:Calculating mean and std
2025-10-19 18:49:58,919:INFO:Creating metrics dataframe
2025-10-19 18:49:58,920:INFO:Uploading results into container
2025-10-19 18:49:58,921:INFO:Uploading model into container now
2025-10-19 18:49:58,922:INFO:_master_model_container: 6
2025-10-19 18:49:58,922:INFO:_display_container: 2
2025-10-19 18:49:58,922:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6904, solver='auto',
                tol=0.0001)
2025-10-19 18:49:58,922:INFO:create_model() successfully completed......................................
2025-10-19 18:49:59,090:INFO:SubProcess create_model() end ==================================
2025-10-19 18:49:59,090:INFO:Creating metrics dataframe
2025-10-19 18:49:59,100:INFO:Initializing Random Forest Classifier
2025-10-19 18:49:59,100:INFO:Total runtime is 2.0675638556480407 minutes
2025-10-19 18:49:59,104:INFO:SubProcess create_model() called ==================================
2025-10-19 18:49:59,105:INFO:Initializing create_model()
2025-10-19 18:49:59,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:49:59,106:INFO:Checking exceptions
2025-10-19 18:49:59,106:INFO:Importing libraries
2025-10-19 18:49:59,106:INFO:Copying training dataset
2025-10-19 18:49:59,292:INFO:Defining folds
2025-10-19 18:49:59,292:INFO:Declaring metric variables
2025-10-19 18:49:59,297:INFO:Importing untrained model
2025-10-19 18:49:59,303:INFO:Random Forest Classifier Imported successfully
2025-10-19 18:49:59,309:INFO:Starting cross validation
2025-10-19 18:49:59,313:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:50:37,052:INFO:Calculating mean and std
2025-10-19 18:50:37,053:INFO:Creating metrics dataframe
2025-10-19 18:50:37,055:INFO:Uploading results into container
2025-10-19 18:50:37,057:INFO:Uploading model into container now
2025-10-19 18:50:37,058:INFO:_master_model_container: 7
2025-10-19 18:50:37,058:INFO:_display_container: 2
2025-10-19 18:50:37,058:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=6904, verbose=0,
                       warm_start=False)
2025-10-19 18:50:37,058:INFO:create_model() successfully completed......................................
2025-10-19 18:50:37,218:INFO:SubProcess create_model() end ==================================
2025-10-19 18:50:37,218:INFO:Creating metrics dataframe
2025-10-19 18:50:37,225:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 18:50:37,225:INFO:Total runtime is 2.702992848555247 minutes
2025-10-19 18:50:37,229:INFO:SubProcess create_model() called ==================================
2025-10-19 18:50:37,229:INFO:Initializing create_model()
2025-10-19 18:50:37,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:50:37,230:INFO:Checking exceptions
2025-10-19 18:50:37,230:INFO:Importing libraries
2025-10-19 18:50:37,230:INFO:Copying training dataset
2025-10-19 18:50:37,410:INFO:Defining folds
2025-10-19 18:50:37,411:INFO:Declaring metric variables
2025-10-19 18:50:37,415:INFO:Importing untrained model
2025-10-19 18:50:37,419:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 18:50:37,427:INFO:Starting cross validation
2025-10-19 18:50:37,432:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:50:39,699:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 18:50:42,136:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 18:50:44,677:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 18:50:47,107:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 18:50:49,557:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 18:50:49,873:INFO:Calculating mean and std
2025-10-19 18:50:49,874:INFO:Creating metrics dataframe
2025-10-19 18:50:49,875:INFO:Uploading results into container
2025-10-19 18:50:49,875:INFO:Uploading model into container now
2025-10-19 18:50:49,876:INFO:_master_model_container: 8
2025-10-19 18:50:49,876:INFO:_display_container: 2
2025-10-19 18:50:49,876:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 18:50:49,876:INFO:create_model() successfully completed......................................
2025-10-19 18:50:50,062:INFO:SubProcess create_model() end ==================================
2025-10-19 18:50:50,062:INFO:Creating metrics dataframe
2025-10-19 18:50:50,074:INFO:Initializing Ada Boost Classifier
2025-10-19 18:50:50,074:INFO:Total runtime is 2.9171353300412495 minutes
2025-10-19 18:50:50,079:INFO:SubProcess create_model() called ==================================
2025-10-19 18:50:50,080:INFO:Initializing create_model()
2025-10-19 18:50:50,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:50:50,081:INFO:Checking exceptions
2025-10-19 18:50:50,081:INFO:Importing libraries
2025-10-19 18:50:50,081:INFO:Copying training dataset
2025-10-19 18:50:50,293:INFO:Defining folds
2025-10-19 18:50:50,293:INFO:Declaring metric variables
2025-10-19 18:50:50,297:INFO:Importing untrained model
2025-10-19 18:50:50,303:INFO:Ada Boost Classifier Imported successfully
2025-10-19 18:50:50,310:INFO:Starting cross validation
2025-10-19 18:50:50,314:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:50:52,295:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 18:50:56,978:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 18:51:01,828:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 18:51:06,872:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 18:51:11,686:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 18:51:14,665:INFO:Calculating mean and std
2025-10-19 18:51:14,666:INFO:Creating metrics dataframe
2025-10-19 18:51:14,668:INFO:Uploading results into container
2025-10-19 18:51:14,668:INFO:Uploading model into container now
2025-10-19 18:51:14,669:INFO:_master_model_container: 9
2025-10-19 18:51:14,669:INFO:_display_container: 2
2025-10-19 18:51:14,670:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6904)
2025-10-19 18:51:14,670:INFO:create_model() successfully completed......................................
2025-10-19 18:51:14,823:INFO:SubProcess create_model() end ==================================
2025-10-19 18:51:14,823:INFO:Creating metrics dataframe
2025-10-19 18:51:14,830:INFO:Initializing Gradient Boosting Classifier
2025-10-19 18:51:14,830:INFO:Total runtime is 3.3297449390093483 minutes
2025-10-19 18:51:14,833:INFO:SubProcess create_model() called ==================================
2025-10-19 18:51:14,834:INFO:Initializing create_model()
2025-10-19 18:51:14,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:51:14,835:INFO:Checking exceptions
2025-10-19 18:51:14,835:INFO:Importing libraries
2025-10-19 18:51:14,835:INFO:Copying training dataset
2025-10-19 18:51:15,016:INFO:Defining folds
2025-10-19 18:51:15,017:INFO:Declaring metric variables
2025-10-19 18:51:15,021:INFO:Importing untrained model
2025-10-19 18:51:15,026:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 18:51:15,032:INFO:Starting cross validation
2025-10-19 18:51:15,036:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:52:04,215:INFO:Calculating mean and std
2025-10-19 18:52:04,216:INFO:Creating metrics dataframe
2025-10-19 18:52:04,218:INFO:Uploading results into container
2025-10-19 18:52:04,219:INFO:Uploading model into container now
2025-10-19 18:52:04,219:INFO:_master_model_container: 10
2025-10-19 18:52:04,219:INFO:_display_container: 2
2025-10-19 18:52:04,220:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6904, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 18:52:04,220:INFO:create_model() successfully completed......................................
2025-10-19 18:52:04,391:INFO:SubProcess create_model() end ==================================
2025-10-19 18:52:04,392:INFO:Creating metrics dataframe
2025-10-19 18:52:04,402:INFO:Initializing Linear Discriminant Analysis
2025-10-19 18:52:04,402:INFO:Total runtime is 4.155929748217265 minutes
2025-10-19 18:52:04,406:INFO:SubProcess create_model() called ==================================
2025-10-19 18:52:04,408:INFO:Initializing create_model()
2025-10-19 18:52:04,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:52:04,408:INFO:Checking exceptions
2025-10-19 18:52:04,408:INFO:Importing libraries
2025-10-19 18:52:04,408:INFO:Copying training dataset
2025-10-19 18:52:04,610:INFO:Defining folds
2025-10-19 18:52:04,611:INFO:Declaring metric variables
2025-10-19 18:52:04,614:INFO:Importing untrained model
2025-10-19 18:52:04,621:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 18:52:04,630:INFO:Starting cross validation
2025-10-19 18:52:04,634:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:52:19,044:INFO:Calculating mean and std
2025-10-19 18:52:19,045:INFO:Creating metrics dataframe
2025-10-19 18:52:19,047:INFO:Uploading results into container
2025-10-19 18:52:19,048:INFO:Uploading model into container now
2025-10-19 18:52:19,048:INFO:_master_model_container: 11
2025-10-19 18:52:19,048:INFO:_display_container: 2
2025-10-19 18:52:19,049:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 18:52:19,049:INFO:create_model() successfully completed......................................
2025-10-19 18:52:19,207:INFO:SubProcess create_model() end ==================================
2025-10-19 18:52:19,207:INFO:Creating metrics dataframe
2025-10-19 18:52:19,214:INFO:Initializing Extra Trees Classifier
2025-10-19 18:52:19,214:INFO:Total runtime is 4.402798386414846 minutes
2025-10-19 18:52:19,218:INFO:SubProcess create_model() called ==================================
2025-10-19 18:52:19,219:INFO:Initializing create_model()
2025-10-19 18:52:19,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:52:19,219:INFO:Checking exceptions
2025-10-19 18:52:19,219:INFO:Importing libraries
2025-10-19 18:52:19,219:INFO:Copying training dataset
2025-10-19 18:52:19,406:INFO:Defining folds
2025-10-19 18:52:19,406:INFO:Declaring metric variables
2025-10-19 18:52:19,409:INFO:Importing untrained model
2025-10-19 18:52:19,414:INFO:Extra Trees Classifier Imported successfully
2025-10-19 18:52:19,420:INFO:Starting cross validation
2025-10-19 18:52:19,426:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:53:02,268:INFO:Calculating mean and std
2025-10-19 18:53:02,270:INFO:Creating metrics dataframe
2025-10-19 18:53:02,272:INFO:Uploading results into container
2025-10-19 18:53:02,273:INFO:Uploading model into container now
2025-10-19 18:53:02,273:INFO:_master_model_container: 12
2025-10-19 18:53:02,274:INFO:_display_container: 2
2025-10-19 18:53:02,275:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=6904, verbose=0,
                     warm_start=False)
2025-10-19 18:53:02,275:INFO:create_model() successfully completed......................................
2025-10-19 18:53:02,437:INFO:SubProcess create_model() end ==================================
2025-10-19 18:53:02,438:INFO:Creating metrics dataframe
2025-10-19 18:53:02,447:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 18:53:02,447:INFO:Total runtime is 5.123346797625223 minutes
2025-10-19 18:53:02,451:INFO:SubProcess create_model() called ==================================
2025-10-19 18:53:02,452:INFO:Initializing create_model()
2025-10-19 18:53:02,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:53:02,452:INFO:Checking exceptions
2025-10-19 18:53:02,452:INFO:Importing libraries
2025-10-19 18:53:02,452:INFO:Copying training dataset
2025-10-19 18:53:02,634:INFO:Defining folds
2025-10-19 18:53:02,635:INFO:Declaring metric variables
2025-10-19 18:53:02,639:INFO:Importing untrained model
2025-10-19 18:53:02,645:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 18:53:02,650:INFO:Starting cross validation
2025-10-19 18:53:02,655:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:53:04,797:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:53:04,799:INFO:[LightGBM] [Info] Number of positive: 7399, number of negative: 28415
2025-10-19 18:53:04,818:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007699 seconds.
2025-10-19 18:53:04,818:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 18:53:04,818:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 18:53:04,818:INFO:[LightGBM] [Info] Total Bins 1405
2025-10-19 18:53:04,818:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 18:53:04,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206595 -> initscore=-1.345572
2025-10-19 18:53:04,819:INFO:[LightGBM] [Info] Start training from score -1.345572
2025-10-19 18:53:07,625:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:53:07,628:INFO:[LightGBM] [Info] Number of positive: 7369, number of negative: 28445
2025-10-19 18:53:07,646:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007805 seconds.
2025-10-19 18:53:07,646:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 18:53:07,646:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 18:53:07,646:INFO:[LightGBM] [Info] Total Bins 1407
2025-10-19 18:53:07,647:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 18:53:07,647:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205758 -> initscore=-1.350690
2025-10-19 18:53:07,647:INFO:[LightGBM] [Info] Start training from score -1.350690
2025-10-19 18:53:10,363:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:53:10,365:INFO:[LightGBM] [Info] Number of positive: 7348, number of negative: 28466
2025-10-19 18:53:10,385:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007318 seconds.
2025-10-19 18:53:10,385:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 18:53:10,385:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 18:53:10,385:INFO:[LightGBM] [Info] Total Bins 1405
2025-10-19 18:53:10,385:INFO:[LightGBM] [Info] Number of data points in the train set: 35814, number of used features: 95
2025-10-19 18:53:10,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205171 -> initscore=-1.354282
2025-10-19 18:53:10,386:INFO:[LightGBM] [Info] Start training from score -1.354282
2025-10-19 18:53:13,154:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:53:13,156:INFO:[LightGBM] [Info] Number of positive: 7308, number of negative: 28507
2025-10-19 18:53:13,172:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006956 seconds.
2025-10-19 18:53:13,172:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 18:53:13,173:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 18:53:13,173:INFO:[LightGBM] [Info] Total Bins 1406
2025-10-19 18:53:13,173:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 18:53:13,173:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204049 -> initscore=-1.361180
2025-10-19 18:53:13,173:INFO:[LightGBM] [Info] Start training from score -1.361180
2025-10-19 18:53:15,955:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:53:15,957:INFO:[LightGBM] [Info] Number of positive: 7352, number of negative: 28463
2025-10-19 18:53:15,974:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007282 seconds.
2025-10-19 18:53:15,974:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 18:53:15,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 18:53:15,974:INFO:[LightGBM] [Info] Total Bins 1406
2025-10-19 18:53:15,974:INFO:[LightGBM] [Info] Number of data points in the train set: 35815, number of used features: 95
2025-10-19 18:53:15,975:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205277 -> initscore=-1.353633
2025-10-19 18:53:15,975:INFO:[LightGBM] [Info] Start training from score -1.353633
2025-10-19 18:53:16,700:INFO:Calculating mean and std
2025-10-19 18:53:16,702:INFO:Creating metrics dataframe
2025-10-19 18:53:16,703:INFO:Uploading results into container
2025-10-19 18:53:16,704:INFO:Uploading model into container now
2025-10-19 18:53:16,704:INFO:_master_model_container: 13
2025-10-19 18:53:16,704:INFO:_display_container: 2
2025-10-19 18:53:16,705:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=6904, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 18:53:16,705:INFO:create_model() successfully completed......................................
2025-10-19 18:53:16,905:INFO:SubProcess create_model() end ==================================
2025-10-19 18:53:16,906:INFO:Creating metrics dataframe
2025-10-19 18:53:16,915:INFO:Initializing CatBoost Classifier
2025-10-19 18:53:16,915:INFO:Total runtime is 5.36449507077535 minutes
2025-10-19 18:53:16,919:INFO:SubProcess create_model() called ==================================
2025-10-19 18:53:16,920:INFO:Initializing create_model()
2025-10-19 18:53:16,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:53:16,921:INFO:Checking exceptions
2025-10-19 18:53:16,921:INFO:Importing libraries
2025-10-19 18:53:16,921:INFO:Copying training dataset
2025-10-19 18:53:17,127:INFO:Defining folds
2025-10-19 18:53:17,127:INFO:Declaring metric variables
2025-10-19 18:53:17,131:INFO:Importing untrained model
2025-10-19 18:53:17,135:INFO:CatBoost Classifier Imported successfully
2025-10-19 18:53:17,140:INFO:Starting cross validation
2025-10-19 18:53:17,145:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:55:12,305:INFO:Calculating mean and std
2025-10-19 18:55:12,306:INFO:Creating metrics dataframe
2025-10-19 18:55:12,308:INFO:Uploading results into container
2025-10-19 18:55:12,308:INFO:Uploading model into container now
2025-10-19 18:55:12,309:INFO:_master_model_container: 14
2025-10-19 18:55:12,309:INFO:_display_container: 2
2025-10-19 18:55:12,309:INFO:<catboost.core.CatBoostClassifier object at 0x000001DE3C33C690>
2025-10-19 18:55:12,309:INFO:create_model() successfully completed......................................
2025-10-19 18:55:12,490:INFO:SubProcess create_model() end ==================================
2025-10-19 18:55:12,490:INFO:Creating metrics dataframe
2025-10-19 18:55:12,504:INFO:Initializing Dummy Classifier
2025-10-19 18:55:12,504:INFO:Total runtime is 7.290964277585347 minutes
2025-10-19 18:55:12,509:INFO:SubProcess create_model() called ==================================
2025-10-19 18:55:12,509:INFO:Initializing create_model()
2025-10-19 18:55:12,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DE3DCBD310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:55:12,510:INFO:Checking exceptions
2025-10-19 18:55:12,510:INFO:Importing libraries
2025-10-19 18:55:12,510:INFO:Copying training dataset
2025-10-19 18:55:12,711:INFO:Defining folds
2025-10-19 18:55:12,711:INFO:Declaring metric variables
2025-10-19 18:55:12,718:INFO:Importing untrained model
2025-10-19 18:55:12,722:INFO:Dummy Classifier Imported successfully
2025-10-19 18:55:12,730:INFO:Starting cross validation
2025-10-19 18:55:12,736:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 18:55:14,949:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:55:17,220:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:55:19,326:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:55:21,401:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:55:23,512:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 18:55:23,524:INFO:Calculating mean and std
2025-10-19 18:55:23,526:INFO:Creating metrics dataframe
2025-10-19 18:55:23,527:INFO:Uploading results into container
2025-10-19 18:55:23,528:INFO:Uploading model into container now
2025-10-19 18:55:23,528:INFO:_master_model_container: 15
2025-10-19 18:55:23,528:INFO:_display_container: 2
2025-10-19 18:55:23,528:INFO:DummyClassifier(constant=None, random_state=6904, strategy='prior')
2025-10-19 18:55:23,529:INFO:create_model() successfully completed......................................
2025-10-19 18:55:23,702:INFO:SubProcess create_model() end ==================================
2025-10-19 18:55:23,702:INFO:Creating metrics dataframe
2025-10-19 18:55:23,715:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 18:55:23,727:INFO:Initializing create_model()
2025-10-19 18:55:23,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6904, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:55:23,729:INFO:Checking exceptions
2025-10-19 18:55:23,730:INFO:Importing libraries
2025-10-19 18:55:23,731:INFO:Copying training dataset
2025-10-19 18:55:23,953:INFO:Defining folds
2025-10-19 18:55:23,953:INFO:Declaring metric variables
2025-10-19 18:55:23,953:INFO:Importing untrained model
2025-10-19 18:55:23,954:INFO:Declaring custom model
2025-10-19 18:55:23,954:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 18:55:23,957:INFO:Cross validation set to False
2025-10-19 18:55:23,957:INFO:Fitting Model
2025-10-19 18:55:36,256:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6904, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 18:55:36,256:INFO:create_model() successfully completed......................................
2025-10-19 18:55:36,428:INFO:Initializing create_model()
2025-10-19 18:55:36,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=6904, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:55:36,429:INFO:Checking exceptions
2025-10-19 18:55:36,431:INFO:Importing libraries
2025-10-19 18:55:36,432:INFO:Copying training dataset
2025-10-19 18:55:36,653:INFO:Defining folds
2025-10-19 18:55:36,654:INFO:Declaring metric variables
2025-10-19 18:55:36,654:INFO:Importing untrained model
2025-10-19 18:55:36,654:INFO:Declaring custom model
2025-10-19 18:55:36,656:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 18:55:36,660:INFO:Cross validation set to False
2025-10-19 18:55:36,660:INFO:Fitting Model
2025-10-19 18:55:39,169:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 18:55:39,171:INFO:[LightGBM] [Info] Number of positive: 9194, number of negative: 35574
2025-10-19 18:55:39,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010955 seconds.
2025-10-19 18:55:39,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 18:55:39,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 18:55:39,196:INFO:[LightGBM] [Info] Total Bins 1404
2025-10-19 18:55:39,196:INFO:[LightGBM] [Info] Number of data points in the train set: 44768, number of used features: 95
2025-10-19 18:55:39,197:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.205370 -> initscore=-1.353064
2025-10-19 18:55:39,197:INFO:[LightGBM] [Info] Start training from score -1.353064
2025-10-19 18:55:39,741:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=6904, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 18:55:39,742:INFO:create_model() successfully completed......................................
2025-10-19 18:55:39,917:INFO:Initializing create_model()
2025-10-19 18:55:39,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6904, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=43309    U02994
44348    U02485
56405    U02731
12767    U01130
36931    U11629
          ...  
42553    U06845
36990    U06735
38095    U09606
54478    U10284
27569    U11715
Name: id_usuario, Length: 44768, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 18:55:39,917:INFO:Checking exceptions
2025-10-19 18:55:39,920:INFO:Importing libraries
2025-10-19 18:55:39,920:INFO:Copying training dataset
2025-10-19 18:55:40,114:INFO:Defining folds
2025-10-19 18:55:40,114:INFO:Declaring metric variables
2025-10-19 18:55:40,115:INFO:Importing untrained model
2025-10-19 18:55:40,115:INFO:Declaring custom model
2025-10-19 18:55:40,115:INFO:Ridge Classifier Imported successfully
2025-10-19 18:55:40,118:INFO:Cross validation set to False
2025-10-19 18:55:40,119:INFO:Fitting Model
2025-10-19 18:55:42,792:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6904, solver='auto',
                tol=0.0001)
2025-10-19 18:55:42,793:INFO:create_model() successfully completed......................................
2025-10-19 18:55:42,988:INFO:_master_model_container: 15
2025-10-19 18:55:42,988:INFO:_display_container: 2
2025-10-19 18:55:42,988:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6904, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=6904, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6904, solver='auto',
                tol=0.0001)]
2025-10-19 18:55:42,990:INFO:compare_models() successfully completed......................................
2025-10-19 18:55:42,991:INFO:Initializing tune_model()
2025-10-19 18:55:42,991:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DE31DE54D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6904, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 18:55:42,992:INFO:Checking exceptions
2025-10-19 18:55:43,084:INFO:Copying training dataset
2025-10-19 18:55:43,233:INFO:Checking base model
2025-10-19 18:55:43,233:INFO:Base model : Gradient Boosting Classifier
2025-10-19 18:55:43,238:INFO:Declaring metric variables
2025-10-19 18:55:43,242:INFO:Defining Hyperparameters
2025-10-19 18:55:43,413:INFO:Tuning with n_jobs=1
2025-10-19 18:55:43,413:INFO:Initializing RandomizedSearchCV
2025-10-19 19:03:34,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 19:03:34,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 19:03:34,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 19:03:34,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-19 19:03:41,656:INFO:PyCaret ClassificationExperiment
2025-10-19 19:03:41,656:INFO:Logging name: clf-default-name
2025-10-19 19:03:41,656:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-19 19:03:41,656:INFO:version 3.3.2
2025-10-19 19:03:41,656:INFO:Initializing setup()
2025-10-19 19:03:41,656:INFO:self.USI: 3c5b
2025-10-19 19:03:41,656:INFO:self._variable_keys: {'seed', 'fold_generator', 'USI', 'exp_name_log', 'n_jobs_param', 'data', 'exp_id', 'fold_shuffle_param', 'gpu_param', 'X_test', 'is_multiclass', 'fix_imbalance', 'gpu_n_jobs_param', 'y_test', 'html_param', 'memory', 'idx', 'X', 'y_train', 'X_train', 'target_param', 'log_plots_param', 'logging_param', '_available_plots', 'y', 'fold_groups_param', '_ml_usecase', 'pipeline'}
2025-10-19 19:03:41,656:INFO:Checking environment
2025-10-19 19:03:41,656:INFO:python_version: 3.11.13
2025-10-19 19:03:41,656:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 19:03:41,656:INFO:machine: AMD64
2025-10-19 19:03:41,656:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 19:03:41,665:INFO:Memory: svmem(total=16856211456, available=3138727936, percent=81.4, used=13717483520, free=3138727936)
2025-10-19 19:03:41,665:INFO:Physical Core: 4
2025-10-19 19:03:41,665:INFO:Logical Core: 8
2025-10-19 19:03:41,665:INFO:Checking libraries
2025-10-19 19:03:41,665:INFO:System:
2025-10-19 19:03:41,665:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 19:03:41,665:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 19:03:41,665:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 19:03:41,665:INFO:PyCaret required dependencies:
2025-10-19 19:03:43,392:INFO:                 pip: 25.2
2025-10-19 19:03:43,392:INFO:          setuptools: 80.9.0
2025-10-19 19:03:43,392:INFO:             pycaret: 3.3.2
2025-10-19 19:03:43,392:INFO:             IPython: 9.6.0
2025-10-19 19:03:43,392:INFO:          ipywidgets: 8.1.7
2025-10-19 19:03:43,392:INFO:                tqdm: 4.67.1
2025-10-19 19:03:43,392:INFO:               numpy: 1.26.4
2025-10-19 19:03:43,392:INFO:              pandas: 2.1.4
2025-10-19 19:03:43,392:INFO:              jinja2: 3.1.6
2025-10-19 19:03:43,392:INFO:               scipy: 1.11.4
2025-10-19 19:03:43,392:INFO:              joblib: 1.3.2
2025-10-19 19:03:43,392:INFO:             sklearn: 1.4.2
2025-10-19 19:03:43,392:INFO:                pyod: 2.0.5
2025-10-19 19:03:43,393:INFO:            imblearn: 0.14.0
2025-10-19 19:03:43,393:INFO:   category_encoders: 2.7.0
2025-10-19 19:03:43,393:INFO:            lightgbm: 4.6.0
2025-10-19 19:03:43,393:INFO:               numba: 0.61.0
2025-10-19 19:03:43,393:INFO:            requests: 2.32.5
2025-10-19 19:03:43,393:INFO:          matplotlib: 3.7.5
2025-10-19 19:03:43,393:INFO:          scikitplot: 0.3.7
2025-10-19 19:03:43,393:INFO:         yellowbrick: 1.5
2025-10-19 19:03:43,393:INFO:              plotly: 5.24.1
2025-10-19 19:03:43,393:INFO:    plotly-resampler: Not installed
2025-10-19 19:03:43,393:INFO:             kaleido: 1.1.0
2025-10-19 19:03:43,393:INFO:           schemdraw: 0.15
2025-10-19 19:03:43,393:INFO:         statsmodels: 0.14.5
2025-10-19 19:03:43,393:INFO:              sktime: 0.26.0
2025-10-19 19:03:43,393:INFO:               tbats: 1.1.3
2025-10-19 19:03:43,393:INFO:            pmdarima: 2.0.4
2025-10-19 19:03:43,393:INFO:              psutil: 7.1.0
2025-10-19 19:03:43,393:INFO:          markupsafe: 3.0.3
2025-10-19 19:03:43,393:INFO:             pickle5: Not installed
2025-10-19 19:03:43,393:INFO:         cloudpickle: 3.1.1
2025-10-19 19:03:43,393:INFO:         deprecation: 2.1.0
2025-10-19 19:03:43,393:INFO:              xxhash: 3.6.0
2025-10-19 19:03:43,393:INFO:           wurlitzer: Not installed
2025-10-19 19:03:43,393:INFO:PyCaret optional dependencies:
2025-10-19 19:03:57,724:INFO:                shap: 0.44.1
2025-10-19 19:03:57,724:INFO:           interpret: 0.7.3
2025-10-19 19:03:57,724:INFO:                umap: 0.5.7
2025-10-19 19:03:57,724:INFO:     ydata_profiling: 4.17.0
2025-10-19 19:03:57,725:INFO:  explainerdashboard: 0.5.1
2025-10-19 19:03:57,725:INFO:             autoviz: Not installed
2025-10-19 19:03:57,725:INFO:           fairlearn: 0.7.0
2025-10-19 19:03:57,725:INFO:          deepchecks: Not installed
2025-10-19 19:03:57,725:INFO:             xgboost: Not installed
2025-10-19 19:03:57,725:INFO:            catboost: 1.2.8
2025-10-19 19:03:57,725:INFO:              kmodes: 0.12.2
2025-10-19 19:03:57,725:INFO:             mlxtend: 0.23.4
2025-10-19 19:03:57,725:INFO:       statsforecast: 1.5.0
2025-10-19 19:03:57,725:INFO:        tune_sklearn: Not installed
2025-10-19 19:03:57,725:INFO:                 ray: Not installed
2025-10-19 19:03:57,725:INFO:            hyperopt: 0.2.7
2025-10-19 19:03:57,725:INFO:              optuna: 4.5.0
2025-10-19 19:03:57,725:INFO:               skopt: 0.10.2
2025-10-19 19:03:57,725:INFO:              mlflow: 3.5.0
2025-10-19 19:03:57,725:INFO:              gradio: 5.49.1
2025-10-19 19:03:57,725:INFO:             fastapi: 0.119.0
2025-10-19 19:03:57,725:INFO:             uvicorn: 0.38.0
2025-10-19 19:03:57,725:INFO:              m2cgen: 0.10.0
2025-10-19 19:03:57,725:INFO:           evidently: 0.4.40
2025-10-19 19:03:57,725:INFO:               fugue: 0.8.7
2025-10-19 19:03:57,725:INFO:           streamlit: Not installed
2025-10-19 19:03:57,725:INFO:             prophet: Not installed
2025-10-19 19:03:57,725:INFO:None
2025-10-19 19:03:57,725:INFO:Set up data.
2025-10-19 19:03:57,926:INFO:Set up folding strategy.
2025-10-19 19:03:58,116:INFO:Set up train/test split.
2025-10-19 19:03:58,319:INFO:Set up index.
2025-10-19 19:03:58,333:INFO:Assigning column types.
2025-10-19 19:03:58,549:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 19:03:58,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 19:03:58,590:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 19:03:58,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:03:58,634:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:03:58,707:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 19:03:58,708:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 19:03:58,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:03:58,732:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:03:58,732:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 19:03:58,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 19:03:58,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:03:58,787:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:03:58,822:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-19 19:03:58,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:03:58,846:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:03:58,848:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-19 19:03:58,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:03:58,902:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:03:58,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:03:58,958:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:03:58,960:INFO:Preparing preprocessing pipeline...
2025-10-19 19:03:58,994:INFO:Set up simple imputation.
2025-10-19 19:03:59,150:INFO:Set up encoding of ordinal features.
2025-10-19 19:03:59,222:INFO:Set up encoding of categorical features.
2025-10-19 19:03:59,226:INFO:Set up removing multicollinearity.
2025-10-19 19:03:59,261:INFO:Set up column name cleaning.
2025-10-19 19:04:04,606:INFO:Finished creating preprocessing pipeline.
2025-10-19 19:04:04,628:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 19:04:04,628:INFO:Creating final display dataframe.
2025-10-19 19:04:07,842:INFO:Setup _display_container:                     Description             Value
0                    Session id               289
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 28)
4        Transformed data shape       (80004, 97)
5   Transformed train set shape       (56002, 97)
6    Transformed test set shape       (24002, 97)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              3c5b
2025-10-19 19:04:07,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:04:07,900:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:04:07,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:04:07,957:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:04:07,958:INFO:setup() successfully completed in 26.44s...............
2025-10-19 19:04:07,958:INFO:Initializing compare_models()
2025-10-19 19:04:07,958:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-19 19:04:07,959:INFO:Checking exceptions
2025-10-19 19:04:08,134:INFO:Preparing display monitor
2025-10-19 19:04:08,173:INFO:Initializing Logistic Regression
2025-10-19 19:04:08,173:INFO:Total runtime is 1.6947587331136067e-05 minutes
2025-10-19 19:04:08,179:INFO:SubProcess create_model() called ==================================
2025-10-19 19:04:08,181:INFO:Initializing create_model()
2025-10-19 19:04:08,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:04:08,181:INFO:Checking exceptions
2025-10-19 19:04:08,181:INFO:Importing libraries
2025-10-19 19:04:08,181:INFO:Copying training dataset
2025-10-19 19:04:08,460:INFO:Defining folds
2025-10-19 19:04:08,460:INFO:Declaring metric variables
2025-10-19 19:04:08,465:INFO:Importing untrained model
2025-10-19 19:04:08,470:INFO:Logistic Regression Imported successfully
2025-10-19 19:04:08,480:INFO:Starting cross validation
2025-10-19 19:04:08,487:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:04:17,371:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 19:04:26,408:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 19:04:35,181:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 19:04:44,336:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 19:04:53,514:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-19 19:04:53,822:INFO:Calculating mean and std
2025-10-19 19:04:53,823:INFO:Creating metrics dataframe
2025-10-19 19:04:53,826:INFO:Uploading results into container
2025-10-19 19:04:53,826:INFO:Uploading model into container now
2025-10-19 19:04:53,827:INFO:_master_model_container: 1
2025-10-19 19:04:53,828:INFO:_display_container: 2
2025-10-19 19:04:53,828:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=289, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-19 19:04:53,828:INFO:create_model() successfully completed......................................
2025-10-19 19:04:54,004:INFO:SubProcess create_model() end ==================================
2025-10-19 19:04:54,004:INFO:Creating metrics dataframe
2025-10-19 19:04:54,010:INFO:Initializing K Neighbors Classifier
2025-10-19 19:04:54,010:INFO:Total runtime is 0.7639624238014222 minutes
2025-10-19 19:04:54,013:INFO:SubProcess create_model() called ==================================
2025-10-19 19:04:54,016:INFO:Initializing create_model()
2025-10-19 19:04:54,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:04:54,016:INFO:Checking exceptions
2025-10-19 19:04:54,017:INFO:Importing libraries
2025-10-19 19:04:54,017:INFO:Copying training dataset
2025-10-19 19:04:54,291:INFO:Defining folds
2025-10-19 19:04:54,291:INFO:Declaring metric variables
2025-10-19 19:04:54,295:INFO:Importing untrained model
2025-10-19 19:04:54,302:INFO:K Neighbors Classifier Imported successfully
2025-10-19 19:04:54,309:INFO:Starting cross validation
2025-10-19 19:04:54,312:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:05:21,938:INFO:Calculating mean and std
2025-10-19 19:05:21,940:INFO:Creating metrics dataframe
2025-10-19 19:05:21,945:INFO:Uploading results into container
2025-10-19 19:05:21,947:INFO:Uploading model into container now
2025-10-19 19:05:21,947:INFO:_master_model_container: 2
2025-10-19 19:05:21,947:INFO:_display_container: 2
2025-10-19 19:05:21,948:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-19 19:05:21,948:INFO:create_model() successfully completed......................................
2025-10-19 19:05:22,120:INFO:SubProcess create_model() end ==================================
2025-10-19 19:05:22,120:INFO:Creating metrics dataframe
2025-10-19 19:05:22,129:INFO:Initializing Naive Bayes
2025-10-19 19:05:22,129:INFO:Total runtime is 1.2326175053914388 minutes
2025-10-19 19:05:22,136:INFO:SubProcess create_model() called ==================================
2025-10-19 19:05:22,138:INFO:Initializing create_model()
2025-10-19 19:05:22,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:05:22,138:INFO:Checking exceptions
2025-10-19 19:05:22,138:INFO:Importing libraries
2025-10-19 19:05:22,138:INFO:Copying training dataset
2025-10-19 19:05:22,408:INFO:Defining folds
2025-10-19 19:05:22,408:INFO:Declaring metric variables
2025-10-19 19:05:22,414:INFO:Importing untrained model
2025-10-19 19:05:22,419:INFO:Naive Bayes Imported successfully
2025-10-19 19:05:22,426:INFO:Starting cross validation
2025-10-19 19:05:22,430:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:05:25,482:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:05:28,628:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:05:31,617:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:05:38,621:INFO:Calculating mean and std
2025-10-19 19:05:38,623:INFO:Creating metrics dataframe
2025-10-19 19:05:38,626:INFO:Uploading results into container
2025-10-19 19:05:38,626:INFO:Uploading model into container now
2025-10-19 19:05:38,627:INFO:_master_model_container: 3
2025-10-19 19:05:38,627:INFO:_display_container: 2
2025-10-19 19:05:38,628:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-19 19:05:38,628:INFO:create_model() successfully completed......................................
2025-10-19 19:05:38,816:INFO:SubProcess create_model() end ==================================
2025-10-19 19:05:38,816:INFO:Creating metrics dataframe
2025-10-19 19:05:38,824:INFO:Initializing Decision Tree Classifier
2025-10-19 19:05:38,824:INFO:Total runtime is 1.5108626723289489 minutes
2025-10-19 19:05:38,827:INFO:SubProcess create_model() called ==================================
2025-10-19 19:05:38,828:INFO:Initializing create_model()
2025-10-19 19:05:38,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:05:38,828:INFO:Checking exceptions
2025-10-19 19:05:38,828:INFO:Importing libraries
2025-10-19 19:05:38,828:INFO:Copying training dataset
2025-10-19 19:05:39,110:INFO:Defining folds
2025-10-19 19:05:39,110:INFO:Declaring metric variables
2025-10-19 19:05:39,114:INFO:Importing untrained model
2025-10-19 19:05:39,121:INFO:Decision Tree Classifier Imported successfully
2025-10-19 19:05:39,129:INFO:Starting cross validation
2025-10-19 19:05:39,135:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:05:57,050:INFO:Calculating mean and std
2025-10-19 19:05:57,051:INFO:Creating metrics dataframe
2025-10-19 19:05:57,053:INFO:Uploading results into container
2025-10-19 19:05:57,053:INFO:Uploading model into container now
2025-10-19 19:05:57,053:INFO:_master_model_container: 4
2025-10-19 19:05:57,053:INFO:_display_container: 2
2025-10-19 19:05:57,054:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=289, splitter='best')
2025-10-19 19:05:57,054:INFO:create_model() successfully completed......................................
2025-10-19 19:05:57,196:INFO:SubProcess create_model() end ==================================
2025-10-19 19:05:57,197:INFO:Creating metrics dataframe
2025-10-19 19:05:57,204:INFO:Initializing SVM - Linear Kernel
2025-10-19 19:05:57,204:INFO:Total runtime is 1.8171937704086303 minutes
2025-10-19 19:05:57,206:INFO:SubProcess create_model() called ==================================
2025-10-19 19:05:57,207:INFO:Initializing create_model()
2025-10-19 19:05:57,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:05:57,208:INFO:Checking exceptions
2025-10-19 19:05:57,208:INFO:Importing libraries
2025-10-19 19:05:57,208:INFO:Copying training dataset
2025-10-19 19:05:57,476:INFO:Defining folds
2025-10-19 19:05:57,477:INFO:Declaring metric variables
2025-10-19 19:05:57,480:INFO:Importing untrained model
2025-10-19 19:05:57,484:INFO:SVM - Linear Kernel Imported successfully
2025-10-19 19:05:57,490:INFO:Starting cross validation
2025-10-19 19:05:57,495:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:06:07,051:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:06:38,463:INFO:Calculating mean and std
2025-10-19 19:06:38,465:INFO:Creating metrics dataframe
2025-10-19 19:06:38,466:INFO:Uploading results into container
2025-10-19 19:06:38,467:INFO:Uploading model into container now
2025-10-19 19:06:38,467:INFO:_master_model_container: 5
2025-10-19 19:06:38,467:INFO:_display_container: 2
2025-10-19 19:06:38,467:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=289, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 19:06:38,467:INFO:create_model() successfully completed......................................
2025-10-19 19:06:38,638:INFO:SubProcess create_model() end ==================================
2025-10-19 19:06:38,638:INFO:Creating metrics dataframe
2025-10-19 19:06:38,648:INFO:Initializing Ridge Classifier
2025-10-19 19:06:38,648:INFO:Total runtime is 2.5079285780588787 minutes
2025-10-19 19:06:38,650:INFO:SubProcess create_model() called ==================================
2025-10-19 19:06:38,652:INFO:Initializing create_model()
2025-10-19 19:06:38,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:06:38,652:INFO:Checking exceptions
2025-10-19 19:06:38,652:INFO:Importing libraries
2025-10-19 19:06:38,652:INFO:Copying training dataset
2025-10-19 19:06:38,911:INFO:Defining folds
2025-10-19 19:06:38,911:INFO:Declaring metric variables
2025-10-19 19:06:38,914:INFO:Importing untrained model
2025-10-19 19:06:38,920:INFO:Ridge Classifier Imported successfully
2025-10-19 19:06:38,928:INFO:Starting cross validation
2025-10-19 19:06:38,932:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:06:55,685:INFO:Calculating mean and std
2025-10-19 19:06:55,686:INFO:Creating metrics dataframe
2025-10-19 19:06:55,689:INFO:Uploading results into container
2025-10-19 19:06:55,690:INFO:Uploading model into container now
2025-10-19 19:06:55,690:INFO:_master_model_container: 6
2025-10-19 19:06:55,690:INFO:_display_container: 2
2025-10-19 19:06:55,691:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001)
2025-10-19 19:06:55,691:INFO:create_model() successfully completed......................................
2025-10-19 19:06:55,858:INFO:SubProcess create_model() end ==================================
2025-10-19 19:06:55,859:INFO:Creating metrics dataframe
2025-10-19 19:06:55,866:INFO:Initializing Random Forest Classifier
2025-10-19 19:06:55,866:INFO:Total runtime is 2.7949051499366764 minutes
2025-10-19 19:06:55,872:INFO:SubProcess create_model() called ==================================
2025-10-19 19:06:55,877:INFO:Initializing create_model()
2025-10-19 19:06:55,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:06:55,877:INFO:Checking exceptions
2025-10-19 19:06:55,877:INFO:Importing libraries
2025-10-19 19:06:55,878:INFO:Copying training dataset
2025-10-19 19:06:56,226:INFO:Defining folds
2025-10-19 19:06:56,227:INFO:Declaring metric variables
2025-10-19 19:06:56,231:INFO:Importing untrained model
2025-10-19 19:06:56,236:INFO:Random Forest Classifier Imported successfully
2025-10-19 19:06:56,246:INFO:Starting cross validation
2025-10-19 19:06:56,250:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:08:06,370:INFO:Calculating mean and std
2025-10-19 19:08:06,371:INFO:Creating metrics dataframe
2025-10-19 19:08:06,373:INFO:Uploading results into container
2025-10-19 19:08:06,373:INFO:Uploading model into container now
2025-10-19 19:08:06,373:INFO:_master_model_container: 7
2025-10-19 19:08:06,373:INFO:_display_container: 2
2025-10-19 19:08:06,374:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=289, verbose=0,
                       warm_start=False)
2025-10-19 19:08:06,374:INFO:create_model() successfully completed......................................
2025-10-19 19:08:06,534:INFO:SubProcess create_model() end ==================================
2025-10-19 19:08:06,535:INFO:Creating metrics dataframe
2025-10-19 19:08:06,541:INFO:Initializing Quadratic Discriminant Analysis
2025-10-19 19:08:06,541:INFO:Total runtime is 3.972814710934957 minutes
2025-10-19 19:08:06,545:INFO:SubProcess create_model() called ==================================
2025-10-19 19:08:06,546:INFO:Initializing create_model()
2025-10-19 19:08:06,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:08:06,546:INFO:Checking exceptions
2025-10-19 19:08:06,547:INFO:Importing libraries
2025-10-19 19:08:06,547:INFO:Copying training dataset
2025-10-19 19:08:06,807:INFO:Defining folds
2025-10-19 19:08:06,808:INFO:Declaring metric variables
2025-10-19 19:08:06,814:INFO:Importing untrained model
2025-10-19 19:08:06,817:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-19 19:08:06,824:INFO:Starting cross validation
2025-10-19 19:08:06,830:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:08:10,190:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 19:08:13,663:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 19:08:17,158:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 19:08:20,567:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 19:08:23,938:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-19 19:08:24,405:INFO:Calculating mean and std
2025-10-19 19:08:24,406:INFO:Creating metrics dataframe
2025-10-19 19:08:24,407:INFO:Uploading results into container
2025-10-19 19:08:24,407:INFO:Uploading model into container now
2025-10-19 19:08:24,408:INFO:_master_model_container: 8
2025-10-19 19:08:24,408:INFO:_display_container: 2
2025-10-19 19:08:24,408:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-19 19:08:24,409:INFO:create_model() successfully completed......................................
2025-10-19 19:08:24,566:INFO:SubProcess create_model() end ==================================
2025-10-19 19:08:24,566:INFO:Creating metrics dataframe
2025-10-19 19:08:24,574:INFO:Initializing Ada Boost Classifier
2025-10-19 19:08:24,574:INFO:Total runtime is 4.273364388942719 minutes
2025-10-19 19:08:24,577:INFO:SubProcess create_model() called ==================================
2025-10-19 19:08:24,579:INFO:Initializing create_model()
2025-10-19 19:08:24,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:08:24,580:INFO:Checking exceptions
2025-10-19 19:08:24,580:INFO:Importing libraries
2025-10-19 19:08:24,580:INFO:Copying training dataset
2025-10-19 19:08:24,858:INFO:Defining folds
2025-10-19 19:08:24,858:INFO:Declaring metric variables
2025-10-19 19:08:24,861:INFO:Importing untrained model
2025-10-19 19:08:24,865:INFO:Ada Boost Classifier Imported successfully
2025-10-19 19:08:24,874:INFO:Starting cross validation
2025-10-19 19:08:24,880:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:08:27,545:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 19:08:34,059:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 19:08:40,572:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 19:08:47,158:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 19:08:53,646:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-19 19:08:57,600:INFO:Calculating mean and std
2025-10-19 19:08:57,601:INFO:Creating metrics dataframe
2025-10-19 19:08:57,603:INFO:Uploading results into container
2025-10-19 19:08:57,603:INFO:Uploading model into container now
2025-10-19 19:08:57,603:INFO:_master_model_container: 9
2025-10-19 19:08:57,603:INFO:_display_container: 2
2025-10-19 19:08:57,604:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=289)
2025-10-19 19:08:57,604:INFO:create_model() successfully completed......................................
2025-10-19 19:08:57,755:INFO:SubProcess create_model() end ==================================
2025-10-19 19:08:57,755:INFO:Creating metrics dataframe
2025-10-19 19:08:57,762:INFO:Initializing Gradient Boosting Classifier
2025-10-19 19:08:57,762:INFO:Total runtime is 4.826501838366191 minutes
2025-10-19 19:08:57,767:INFO:SubProcess create_model() called ==================================
2025-10-19 19:08:57,768:INFO:Initializing create_model()
2025-10-19 19:08:57,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:08:57,768:INFO:Checking exceptions
2025-10-19 19:08:57,768:INFO:Importing libraries
2025-10-19 19:08:57,768:INFO:Copying training dataset
2025-10-19 19:08:58,006:INFO:Defining folds
2025-10-19 19:08:58,007:INFO:Declaring metric variables
2025-10-19 19:08:58,009:INFO:Importing untrained model
2025-10-19 19:08:58,016:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 19:08:58,024:INFO:Starting cross validation
2025-10-19 19:08:58,029:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:10:07,438:INFO:Calculating mean and std
2025-10-19 19:10:07,438:INFO:Creating metrics dataframe
2025-10-19 19:10:07,441:INFO:Uploading results into container
2025-10-19 19:10:07,442:INFO:Uploading model into container now
2025-10-19 19:10:07,443:INFO:_master_model_container: 10
2025-10-19 19:10:07,443:INFO:_display_container: 2
2025-10-19 19:10:07,444:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=289, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 19:10:07,444:INFO:create_model() successfully completed......................................
2025-10-19 19:10:07,610:INFO:SubProcess create_model() end ==================================
2025-10-19 19:10:07,610:INFO:Creating metrics dataframe
2025-10-19 19:10:07,617:INFO:Initializing Linear Discriminant Analysis
2025-10-19 19:10:07,617:INFO:Total runtime is 5.990756718317668 minutes
2025-10-19 19:10:07,621:INFO:SubProcess create_model() called ==================================
2025-10-19 19:10:07,622:INFO:Initializing create_model()
2025-10-19 19:10:07,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:10:07,622:INFO:Checking exceptions
2025-10-19 19:10:07,622:INFO:Importing libraries
2025-10-19 19:10:07,622:INFO:Copying training dataset
2025-10-19 19:10:07,858:INFO:Defining folds
2025-10-19 19:10:07,859:INFO:Declaring metric variables
2025-10-19 19:10:07,863:INFO:Importing untrained model
2025-10-19 19:10:07,869:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 19:10:07,877:INFO:Starting cross validation
2025-10-19 19:10:07,882:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:10:25,609:INFO:Calculating mean and std
2025-10-19 19:10:25,610:INFO:Creating metrics dataframe
2025-10-19 19:10:25,613:INFO:Uploading results into container
2025-10-19 19:10:25,614:INFO:Uploading model into container now
2025-10-19 19:10:25,615:INFO:_master_model_container: 11
2025-10-19 19:10:25,615:INFO:_display_container: 2
2025-10-19 19:10:25,615:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 19:10:25,615:INFO:create_model() successfully completed......................................
2025-10-19 19:10:25,792:INFO:SubProcess create_model() end ==================================
2025-10-19 19:10:25,793:INFO:Creating metrics dataframe
2025-10-19 19:10:25,803:INFO:Initializing Extra Trees Classifier
2025-10-19 19:10:25,803:INFO:Total runtime is 6.293856986363729 minutes
2025-10-19 19:10:25,808:INFO:SubProcess create_model() called ==================================
2025-10-19 19:10:25,809:INFO:Initializing create_model()
2025-10-19 19:10:25,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:10:25,810:INFO:Checking exceptions
2025-10-19 19:10:25,810:INFO:Importing libraries
2025-10-19 19:10:25,810:INFO:Copying training dataset
2025-10-19 19:10:26,073:INFO:Defining folds
2025-10-19 19:10:26,073:INFO:Declaring metric variables
2025-10-19 19:10:26,076:INFO:Importing untrained model
2025-10-19 19:10:26,081:INFO:Extra Trees Classifier Imported successfully
2025-10-19 19:10:26,091:INFO:Starting cross validation
2025-10-19 19:10:26,096:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:11:39,614:INFO:Calculating mean and std
2025-10-19 19:11:39,615:INFO:Creating metrics dataframe
2025-10-19 19:11:39,617:INFO:Uploading results into container
2025-10-19 19:11:39,617:INFO:Uploading model into container now
2025-10-19 19:11:39,617:INFO:_master_model_container: 12
2025-10-19 19:11:39,617:INFO:_display_container: 2
2025-10-19 19:11:39,618:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=289, verbose=0,
                     warm_start=False)
2025-10-19 19:11:39,618:INFO:create_model() successfully completed......................................
2025-10-19 19:11:39,784:INFO:SubProcess create_model() end ==================================
2025-10-19 19:11:39,784:INFO:Creating metrics dataframe
2025-10-19 19:11:39,793:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 19:11:39,794:INFO:Total runtime is 7.527007226149242 minutes
2025-10-19 19:11:39,798:INFO:SubProcess create_model() called ==================================
2025-10-19 19:11:39,799:INFO:Initializing create_model()
2025-10-19 19:11:39,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:11:39,800:INFO:Checking exceptions
2025-10-19 19:11:39,800:INFO:Importing libraries
2025-10-19 19:11:39,800:INFO:Copying training dataset
2025-10-19 19:11:40,076:INFO:Defining folds
2025-10-19 19:11:40,076:INFO:Declaring metric variables
2025-10-19 19:11:40,079:INFO:Importing untrained model
2025-10-19 19:11:40,084:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 19:11:40,092:INFO:Starting cross validation
2025-10-19 19:11:40,096:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:11:42,948:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 19:11:42,950:INFO:[LightGBM] [Info] Number of positive: 14846, number of negative: 29955
2025-10-19 19:11:42,974:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009482 seconds.
2025-10-19 19:11:42,974:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 19:11:42,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 19:11:42,974:INFO:[LightGBM] [Info] Total Bins 1453
2025-10-19 19:11:42,975:INFO:[LightGBM] [Info] Number of data points in the train set: 44801, number of used features: 96
2025-10-19 19:11:42,975:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.331377 -> initscore=-0.701966
2025-10-19 19:11:42,975:INFO:[LightGBM] [Info] Start training from score -0.701966
2025-10-19 19:11:46,602:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 19:11:46,604:INFO:[LightGBM] [Info] Number of positive: 14880, number of negative: 29921
2025-10-19 19:11:46,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009535 seconds.
2025-10-19 19:11:46,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 19:11:46,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 19:11:46,627:INFO:[LightGBM] [Info] Total Bins 1451
2025-10-19 19:11:46,628:INFO:[LightGBM] [Info] Number of data points in the train set: 44801, number of used features: 96
2025-10-19 19:11:46,628:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332135 -> initscore=-0.698543
2025-10-19 19:11:46,628:INFO:[LightGBM] [Info] Start training from score -0.698543
2025-10-19 19:11:50,208:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 19:11:50,210:INFO:[LightGBM] [Info] Number of positive: 15019, number of negative: 29783
2025-10-19 19:11:50,234:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010202 seconds.
2025-10-19 19:11:50,234:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 19:11:50,234:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 19:11:50,234:INFO:[LightGBM] [Info] Total Bins 1452
2025-10-19 19:11:50,235:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-19 19:11:50,235:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.335231 -> initscore=-0.684622
2025-10-19 19:11:50,235:INFO:[LightGBM] [Info] Start training from score -0.684622
2025-10-19 19:11:53,728:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 19:11:53,730:INFO:[LightGBM] [Info] Number of positive: 14879, number of negative: 29923
2025-10-19 19:11:53,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008866 seconds.
2025-10-19 19:11:53,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 19:11:53,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 19:11:53,754:INFO:[LightGBM] [Info] Total Bins 1449
2025-10-19 19:11:53,755:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-19 19:11:53,755:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332106 -> initscore=-0.698677
2025-10-19 19:11:53,755:INFO:[LightGBM] [Info] Start training from score -0.698677
2025-10-19 19:11:57,313:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 19:11:57,315:INFO:[LightGBM] [Info] Number of positive: 14892, number of negative: 29910
2025-10-19 19:11:57,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009032 seconds.
2025-10-19 19:11:57,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 19:11:57,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 19:11:57,338:INFO:[LightGBM] [Info] Total Bins 1452
2025-10-19 19:11:57,339:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-19 19:11:57,339:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332396 -> initscore=-0.697369
2025-10-19 19:11:57,339:INFO:[LightGBM] [Info] Start training from score -0.697369
2025-10-19 19:11:58,231:INFO:Calculating mean and std
2025-10-19 19:11:58,232:INFO:Creating metrics dataframe
2025-10-19 19:11:58,233:INFO:Uploading results into container
2025-10-19 19:11:58,234:INFO:Uploading model into container now
2025-10-19 19:11:58,234:INFO:_master_model_container: 13
2025-10-19 19:11:58,234:INFO:_display_container: 2
2025-10-19 19:11:58,235:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=289, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-19 19:11:58,235:INFO:create_model() successfully completed......................................
2025-10-19 19:11:58,384:INFO:SubProcess create_model() end ==================================
2025-10-19 19:11:58,384:INFO:Creating metrics dataframe
2025-10-19 19:11:58,396:INFO:Initializing CatBoost Classifier
2025-10-19 19:11:58,396:INFO:Total runtime is 7.837063225110373 minutes
2025-10-19 19:11:58,400:INFO:SubProcess create_model() called ==================================
2025-10-19 19:11:58,401:INFO:Initializing create_model()
2025-10-19 19:11:58,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:11:58,401:INFO:Checking exceptions
2025-10-19 19:11:58,401:INFO:Importing libraries
2025-10-19 19:11:58,401:INFO:Copying training dataset
2025-10-19 19:11:58,639:INFO:Defining folds
2025-10-19 19:11:58,640:INFO:Declaring metric variables
2025-10-19 19:11:58,644:INFO:Importing untrained model
2025-10-19 19:11:58,649:INFO:CatBoost Classifier Imported successfully
2025-10-19 19:11:58,654:INFO:Starting cross validation
2025-10-19 19:11:58,658:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:14:54,873:INFO:Calculating mean and std
2025-10-19 19:14:54,875:INFO:Creating metrics dataframe
2025-10-19 19:14:54,876:INFO:Uploading results into container
2025-10-19 19:14:54,876:INFO:Uploading model into container now
2025-10-19 19:14:54,877:INFO:_master_model_container: 14
2025-10-19 19:14:54,877:INFO:_display_container: 2
2025-10-19 19:14:54,877:INFO:<catboost.core.CatBoostClassifier object at 0x00000128CD6D9C50>
2025-10-19 19:14:54,877:INFO:create_model() successfully completed......................................
2025-10-19 19:14:55,048:INFO:SubProcess create_model() end ==================================
2025-10-19 19:14:55,048:INFO:Creating metrics dataframe
2025-10-19 19:14:55,058:INFO:Initializing Dummy Classifier
2025-10-19 19:14:55,058:INFO:Total runtime is 10.781429235140482 minutes
2025-10-19 19:14:55,062:INFO:SubProcess create_model() called ==================================
2025-10-19 19:14:55,062:INFO:Initializing create_model()
2025-10-19 19:14:55,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CF005790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:14:55,063:INFO:Checking exceptions
2025-10-19 19:14:55,063:INFO:Importing libraries
2025-10-19 19:14:55,063:INFO:Copying training dataset
2025-10-19 19:14:55,309:INFO:Defining folds
2025-10-19 19:14:55,309:INFO:Declaring metric variables
2025-10-19 19:14:55,312:INFO:Importing untrained model
2025-10-19 19:14:55,317:INFO:Dummy Classifier Imported successfully
2025-10-19 19:14:55,325:INFO:Starting cross validation
2025-10-19 19:14:55,330:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:14:58,986:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:15:02,530:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:15:05,719:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:15:09,102:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:15:14,838:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:15:14,866:INFO:Calculating mean and std
2025-10-19 19:15:14,870:INFO:Creating metrics dataframe
2025-10-19 19:15:14,874:INFO:Uploading results into container
2025-10-19 19:15:14,876:INFO:Uploading model into container now
2025-10-19 19:15:14,876:INFO:_master_model_container: 15
2025-10-19 19:15:14,877:INFO:_display_container: 2
2025-10-19 19:15:14,877:INFO:DummyClassifier(constant=None, random_state=289, strategy='prior')
2025-10-19 19:15:14,877:INFO:create_model() successfully completed......................................
2025-10-19 19:15:15,148:INFO:SubProcess create_model() end ==================================
2025-10-19 19:15:15,148:INFO:Creating metrics dataframe
2025-10-19 19:15:15,166:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 19:15:15,184:INFO:Initializing create_model()
2025-10-19 19:15:15,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=289, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:15:15,185:INFO:Checking exceptions
2025-10-19 19:15:15,190:INFO:Importing libraries
2025-10-19 19:15:15,190:INFO:Copying training dataset
2025-10-19 19:15:15,693:INFO:Defining folds
2025-10-19 19:15:15,693:INFO:Declaring metric variables
2025-10-19 19:15:15,693:INFO:Importing untrained model
2025-10-19 19:15:15,693:INFO:Declaring custom model
2025-10-19 19:15:15,695:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 19:15:15,701:INFO:Cross validation set to False
2025-10-19 19:15:15,701:INFO:Fitting Model
2025-10-19 19:15:49,170:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=289, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 19:15:49,171:INFO:create_model() successfully completed......................................
2025-10-19 19:15:49,422:INFO:Initializing create_model()
2025-10-19 19:15:49,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:15:49,423:INFO:Checking exceptions
2025-10-19 19:15:49,426:INFO:Importing libraries
2025-10-19 19:15:49,427:INFO:Copying training dataset
2025-10-19 19:15:49,860:INFO:Defining folds
2025-10-19 19:15:49,860:INFO:Declaring metric variables
2025-10-19 19:15:49,860:INFO:Importing untrained model
2025-10-19 19:15:49,861:INFO:Declaring custom model
2025-10-19 19:15:49,861:INFO:Ridge Classifier Imported successfully
2025-10-19 19:15:49,870:INFO:Cross validation set to False
2025-10-19 19:15:49,870:INFO:Fitting Model
2025-10-19 19:15:56,307:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001)
2025-10-19 19:15:56,308:INFO:create_model() successfully completed......................................
2025-10-19 19:15:56,577:INFO:Initializing create_model()
2025-10-19 19:15:56,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:15:56,577:INFO:Checking exceptions
2025-10-19 19:15:56,579:INFO:Importing libraries
2025-10-19 19:15:56,580:INFO:Copying training dataset
2025-10-19 19:15:57,040:INFO:Defining folds
2025-10-19 19:15:57,040:INFO:Declaring metric variables
2025-10-19 19:15:57,041:INFO:Importing untrained model
2025-10-19 19:15:57,041:INFO:Declaring custom model
2025-10-19 19:15:57,042:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 19:15:57,050:INFO:Cross validation set to False
2025-10-19 19:15:57,050:INFO:Fitting Model
2025-10-19 19:16:04,134:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 19:16:04,134:INFO:create_model() successfully completed......................................
2025-10-19 19:16:04,444:INFO:_master_model_container: 15
2025-10-19 19:16:04,445:INFO:_display_container: 2
2025-10-19 19:16:04,446:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=289, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2025-10-19 19:16:04,447:INFO:compare_models() successfully completed......................................
2025-10-19 19:16:04,449:INFO:Initializing tune_model()
2025-10-19 19:16:04,450:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=289, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 19:16:04,450:INFO:Checking exceptions
2025-10-19 19:16:04,633:INFO:Copying training dataset
2025-10-19 19:16:04,892:INFO:Checking base model
2025-10-19 19:16:04,892:INFO:Base model : Gradient Boosting Classifier
2025-10-19 19:16:04,898:INFO:Declaring metric variables
2025-10-19 19:16:04,904:INFO:Defining Hyperparameters
2025-10-19 19:16:05,142:INFO:Tuning with n_jobs=1
2025-10-19 19:16:05,142:INFO:Initializing RandomizedSearchCV
2025-10-19 19:35:20,945:INFO:best_params: {'actual_estimator__subsample': 0.3, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 5, 'actual_estimator__learning_rate': 0.0001}
2025-10-19 19:35:20,946:INFO:Hyperparameter search completed
2025-10-19 19:35:20,946:INFO:SubProcess create_model() called ==================================
2025-10-19 19:35:20,947:INFO:Initializing create_model()
2025-10-19 19:35:20,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=289, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128BF6BF0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.3, 'n_estimators': 30, 'min_samples_split': 9, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.005, 'max_features': 1.0, 'max_depth': 5, 'learning_rate': 0.0001})
2025-10-19 19:35:20,947:INFO:Checking exceptions
2025-10-19 19:35:20,948:INFO:Importing libraries
2025-10-19 19:35:20,948:INFO:Copying training dataset
2025-10-19 19:35:21,199:INFO:Defining folds
2025-10-19 19:35:21,200:INFO:Declaring metric variables
2025-10-19 19:35:21,206:INFO:Importing untrained model
2025-10-19 19:35:21,206:INFO:Declaring custom model
2025-10-19 19:35:21,210:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 19:35:21,216:INFO:Starting cross validation
2025-10-19 19:35:21,223:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:35:27,043:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:35:34,982:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:35:41,324:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:35:47,641:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:35:53,449:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-19 19:35:53,463:INFO:Calculating mean and std
2025-10-19 19:35:53,464:INFO:Creating metrics dataframe
2025-10-19 19:35:53,468:INFO:Finalizing model
2025-10-19 19:36:00,053:INFO:Uploading results into container
2025-10-19 19:36:00,054:INFO:Uploading model into container now
2025-10-19 19:36:00,055:INFO:_master_model_container: 16
2025-10-19 19:36:00,055:INFO:_display_container: 3
2025-10-19 19:36:00,055:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=5,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.005, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=289, subsample=0.3, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 19:36:00,055:INFO:create_model() successfully completed......................................
2025-10-19 19:36:00,233:INFO:SubProcess create_model() end ==================================
2025-10-19 19:36:00,233:INFO:choose_better activated
2025-10-19 19:36:00,237:INFO:SubProcess create_model() called ==================================
2025-10-19 19:36:00,239:INFO:Initializing create_model()
2025-10-19 19:36:00,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=289, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:36:00,239:INFO:Checking exceptions
2025-10-19 19:36:00,240:INFO:Importing libraries
2025-10-19 19:36:00,241:INFO:Copying training dataset
2025-10-19 19:36:00,465:INFO:Defining folds
2025-10-19 19:36:00,466:INFO:Declaring metric variables
2025-10-19 19:36:00,466:INFO:Importing untrained model
2025-10-19 19:36:00,466:INFO:Declaring custom model
2025-10-19 19:36:00,466:INFO:Gradient Boosting Classifier Imported successfully
2025-10-19 19:36:00,467:INFO:Starting cross validation
2025-10-19 19:36:00,469:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:37:18,158:INFO:Calculating mean and std
2025-10-19 19:37:18,158:INFO:Creating metrics dataframe
2025-10-19 19:37:18,160:INFO:Finalizing model
2025-10-19 19:37:34,809:INFO:Uploading results into container
2025-10-19 19:37:34,810:INFO:Uploading model into container now
2025-10-19 19:37:34,810:INFO:_master_model_container: 17
2025-10-19 19:37:34,810:INFO:_display_container: 4
2025-10-19 19:37:34,811:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=289, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 19:37:34,811:INFO:create_model() successfully completed......................................
2025-10-19 19:37:34,958:INFO:SubProcess create_model() end ==================================
2025-10-19 19:37:34,958:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=289, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9215
2025-10-19 19:37:34,959:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=5,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.005, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=289, subsample=0.3, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9216
2025-10-19 19:37:34,959:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=5,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.005, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=289, subsample=0.3, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-19 19:37:34,959:INFO:choose_better completed
2025-10-19 19:37:34,967:INFO:_master_model_container: 17
2025-10-19 19:37:34,968:INFO:_display_container: 3
2025-10-19 19:37:34,968:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=5,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.005, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=289, subsample=0.3, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 19:37:34,969:INFO:tune_model() successfully completed......................................
2025-10-19 19:37:35,113:INFO:Initializing tune_model()
2025-10-19 19:37:35,113:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 19:37:35,113:INFO:Checking exceptions
2025-10-19 19:37:35,210:INFO:Copying training dataset
2025-10-19 19:37:35,365:INFO:Checking base model
2025-10-19 19:37:35,365:INFO:Base model : Ridge Classifier
2025-10-19 19:37:35,368:INFO:Declaring metric variables
2025-10-19 19:37:35,371:INFO:Defining Hyperparameters
2025-10-19 19:37:35,508:INFO:Tuning with n_jobs=1
2025-10-19 19:37:35,508:INFO:Initializing RandomizedSearchCV
2025-10-19 19:39:50,860:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.27711e-17): result may not be accurate.

2025-10-19 19:39:55,975:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.27933e-17): result may not be accurate.

2025-10-19 19:39:59,463:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.27446e-17): result may not be accurate.

2025-10-19 19:40:04,485:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.22857e-17): result may not be accurate.

2025-10-19 19:40:08,423:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.26031e-17): result may not be accurate.

2025-10-19 19:40:26,639:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.85}
2025-10-19 19:40:26,640:INFO:Hyperparameter search completed
2025-10-19 19:40:26,641:INFO:SubProcess create_model() called ==================================
2025-10-19 19:40:26,642:INFO:Initializing create_model()
2025-10-19 19:40:26,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CD3741D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 7.85})
2025-10-19 19:40:26,642:INFO:Checking exceptions
2025-10-19 19:40:26,642:INFO:Importing libraries
2025-10-19 19:40:26,642:INFO:Copying training dataset
2025-10-19 19:40:26,916:INFO:Defining folds
2025-10-19 19:40:26,917:INFO:Declaring metric variables
2025-10-19 19:40:26,922:INFO:Importing untrained model
2025-10-19 19:40:26,922:INFO:Declaring custom model
2025-10-19 19:40:26,927:INFO:Ridge Classifier Imported successfully
2025-10-19 19:40:26,934:INFO:Starting cross validation
2025-10-19 19:40:26,941:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:40:46,212:INFO:Calculating mean and std
2025-10-19 19:40:46,214:INFO:Creating metrics dataframe
2025-10-19 19:40:46,222:INFO:Finalizing model
2025-10-19 19:40:49,974:INFO:Uploading results into container
2025-10-19 19:40:49,975:INFO:Uploading model into container now
2025-10-19 19:40:49,976:INFO:_master_model_container: 18
2025-10-19 19:40:49,976:INFO:_display_container: 4
2025-10-19 19:40:49,977:INFO:RidgeClassifier(alpha=7.85, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001)
2025-10-19 19:40:49,977:INFO:create_model() successfully completed......................................
2025-10-19 19:40:50,230:INFO:SubProcess create_model() end ==================================
2025-10-19 19:40:50,230:INFO:choose_better activated
2025-10-19 19:40:50,234:INFO:SubProcess create_model() called ==================================
2025-10-19 19:40:50,237:INFO:Initializing create_model()
2025-10-19 19:40:50,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:40:50,238:INFO:Checking exceptions
2025-10-19 19:40:50,241:INFO:Importing libraries
2025-10-19 19:40:50,241:INFO:Copying training dataset
2025-10-19 19:40:50,514:INFO:Defining folds
2025-10-19 19:40:50,514:INFO:Declaring metric variables
2025-10-19 19:40:50,514:INFO:Importing untrained model
2025-10-19 19:40:50,514:INFO:Declaring custom model
2025-10-19 19:40:50,514:INFO:Ridge Classifier Imported successfully
2025-10-19 19:40:50,515:INFO:Starting cross validation
2025-10-19 19:40:50,518:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:41:08,824:INFO:Calculating mean and std
2025-10-19 19:41:08,825:INFO:Creating metrics dataframe
2025-10-19 19:41:08,826:INFO:Finalizing model
2025-10-19 19:41:12,547:INFO:Uploading results into container
2025-10-19 19:41:12,548:INFO:Uploading model into container now
2025-10-19 19:41:12,548:INFO:_master_model_container: 19
2025-10-19 19:41:12,548:INFO:_display_container: 5
2025-10-19 19:41:12,549:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001)
2025-10-19 19:41:12,549:INFO:create_model() successfully completed......................................
2025-10-19 19:41:12,763:INFO:SubProcess create_model() end ==================================
2025-10-19 19:41:12,764:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001) result for AUC is 0.9213
2025-10-19 19:41:12,765:INFO:RidgeClassifier(alpha=7.85, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001) result for AUC is 0.9217
2025-10-19 19:41:12,765:INFO:RidgeClassifier(alpha=7.85, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001) is best model
2025-10-19 19:41:12,765:INFO:choose_better completed
2025-10-19 19:41:12,775:INFO:_master_model_container: 19
2025-10-19 19:41:12,776:INFO:_display_container: 4
2025-10-19 19:41:12,776:INFO:RidgeClassifier(alpha=7.85, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001)
2025-10-19 19:41:12,776:INFO:tune_model() successfully completed......................................
2025-10-19 19:41:13,049:INFO:Initializing tune_model()
2025-10-19 19:41:13,049:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 19:41:13,049:INFO:Checking exceptions
2025-10-19 19:41:13,185:INFO:Copying training dataset
2025-10-19 19:41:13,456:INFO:Checking base model
2025-10-19 19:41:13,456:INFO:Base model : Linear Discriminant Analysis
2025-10-19 19:41:13,463:INFO:Declaring metric variables
2025-10-19 19:41:13,468:INFO:Defining Hyperparameters
2025-10-19 19:41:13,685:INFO:Tuning with n_jobs=1
2025-10-19 19:41:13,686:INFO:Initializing RandomizedSearchCV
2025-10-19 19:44:07,375:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\base.py", line 1467, in wrapper
    estimator._validate_params()
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'shrinkage' parameter of LinearDiscriminantAnalysis must be a str among {'auto'}, a float in the range [0.0, 1.0] or None. Got 'empirical' instead.


2025-10-19 19:44:07,378:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.92118768 0.50487812 0.50410918 0.92118821 0.50415051
 0.50528614 0.50519449 0.50517265 0.50494376]

2025-10-19 19:44:07,378:INFO:best_params: {'actual_estimator__solver': 'eigen', 'actual_estimator__shrinkage': 'auto'}
2025-10-19 19:44:07,380:INFO:Hyperparameter search completed
2025-10-19 19:44:07,380:INFO:SubProcess create_model() called ==================================
2025-10-19 19:44:07,383:INFO:Initializing create_model()
2025-10-19 19:44:07,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CD600050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'eigen', 'shrinkage': 'auto'})
2025-10-19 19:44:07,384:INFO:Checking exceptions
2025-10-19 19:44:07,384:INFO:Importing libraries
2025-10-19 19:44:07,384:INFO:Copying training dataset
2025-10-19 19:44:07,672:INFO:Defining folds
2025-10-19 19:44:07,672:INFO:Declaring metric variables
2025-10-19 19:44:07,676:INFO:Importing untrained model
2025-10-19 19:44:07,677:INFO:Declaring custom model
2025-10-19 19:44:07,683:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 19:44:07,692:INFO:Starting cross validation
2025-10-19 19:44:07,695:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:44:26,123:INFO:Calculating mean and std
2025-10-19 19:44:26,124:INFO:Creating metrics dataframe
2025-10-19 19:44:26,130:INFO:Finalizing model
2025-10-19 19:44:30,293:INFO:Uploading results into container
2025-10-19 19:44:30,293:INFO:Uploading model into container now
2025-10-19 19:44:30,294:INFO:_master_model_container: 20
2025-10-19 19:44:30,294:INFO:_display_container: 5
2025-10-19 19:44:30,294:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001)
2025-10-19 19:44:30,294:INFO:create_model() successfully completed......................................
2025-10-19 19:44:30,522:INFO:SubProcess create_model() end ==================================
2025-10-19 19:44:30,522:INFO:choose_better activated
2025-10-19 19:44:30,526:INFO:SubProcess create_model() called ==================================
2025-10-19 19:44:30,527:INFO:Initializing create_model()
2025-10-19 19:44:30,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:44:30,528:INFO:Checking exceptions
2025-10-19 19:44:30,529:INFO:Importing libraries
2025-10-19 19:44:30,529:INFO:Copying training dataset
2025-10-19 19:44:30,794:INFO:Defining folds
2025-10-19 19:44:30,794:INFO:Declaring metric variables
2025-10-19 19:44:30,794:INFO:Importing untrained model
2025-10-19 19:44:30,794:INFO:Declaring custom model
2025-10-19 19:44:30,795:INFO:Linear Discriminant Analysis Imported successfully
2025-10-19 19:44:30,795:INFO:Starting cross validation
2025-10-19 19:44:30,798:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:44:50,443:INFO:Calculating mean and std
2025-10-19 19:44:50,443:INFO:Creating metrics dataframe
2025-10-19 19:44:50,446:INFO:Finalizing model
2025-10-19 19:44:54,676:INFO:Uploading results into container
2025-10-19 19:44:54,677:INFO:Uploading model into container now
2025-10-19 19:44:54,678:INFO:_master_model_container: 21
2025-10-19 19:44:54,678:INFO:_display_container: 6
2025-10-19 19:44:54,678:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 19:44:54,678:INFO:create_model() successfully completed......................................
2025-10-19 19:44:54,855:INFO:SubProcess create_model() end ==================================
2025-10-19 19:44:54,856:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9212
2025-10-19 19:44:54,856:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9212
2025-10-19 19:44:54,856:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2025-10-19 19:44:54,856:INFO:choose_better completed
2025-10-19 19:44:54,857:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 19:44:54,865:INFO:_master_model_container: 21
2025-10-19 19:44:54,866:INFO:_display_container: 5
2025-10-19 19:44:54,866:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-19 19:44:54,866:INFO:tune_model() successfully completed......................................
2025-10-19 19:44:55,043:INFO:Initializing blend_models()
2025-10-19 19:44:55,043:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.0001, loss='log_loss', max_depth=5,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.005, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=289, subsample=0.3, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=7.85, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-19 19:44:55,043:INFO:Checking exceptions
2025-10-19 19:44:55,043:INFO:Estimator RidgeClassifier(alpha=7.85, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=289, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-19 19:44:55,177:INFO:Importing libraries
2025-10-19 19:44:55,178:INFO:Copying training dataset
2025-10-19 19:44:55,183:INFO:Getting model names
2025-10-19 19:44:55,189:INFO:SubProcess create_model() called ==================================
2025-10-19 19:44:55,197:INFO:Initializing create_model()
2025-10-19 19:44:55,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.0001,
                                                         loss='log_loss',
                                                         max_depth=5,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.005,
                                                         min_samples_leaf=1,
                                                         min_samples_split=9,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=30,
                                                         n_iter_no_change=...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=289, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
839      U12087
41643    U03148
35947    U03379
66080    U06996
38679    U13273
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CD600190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:44:55,197:INFO:Checking exceptions
2025-10-19 19:44:55,197:INFO:Importing libraries
2025-10-19 19:44:55,198:INFO:Copying training dataset
2025-10-19 19:44:55,512:INFO:Defining folds
2025-10-19 19:44:55,512:INFO:Declaring metric variables
2025-10-19 19:44:55,515:INFO:Importing untrained model
2025-10-19 19:44:55,515:INFO:Declaring custom model
2025-10-19 19:44:55,522:INFO:Voting Classifier Imported successfully
2025-10-19 19:44:55,528:INFO:Starting cross validation
2025-10-19 19:44:55,534:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:45:02,446:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 19:45:09,106:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 19:45:15,866:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 19:45:22,573:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 19:45:29,033:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-19 19:45:29,060:INFO:Calculating mean and std
2025-10-19 19:45:29,062:INFO:Creating metrics dataframe
2025-10-19 19:45:29,067:INFO:Finalizing model
2025-10-19 19:45:37,030:INFO:Uploading results into container
2025-10-19 19:45:37,031:INFO:Uploading model into container now
2025-10-19 19:45:37,031:INFO:_master_model_container: 22
2025-10-19 19:45:37,031:INFO:_display_container: 6
2025-10-19 19:45:37,034:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.0001,
                                                         loss='log_loss',
                                                         max_depth=5,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.005,
                                                         min_samples_leaf=1,
                                                         min_samples_split=9,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=30,
                                                         n_iter_no_change=...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=289, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-19 19:45:37,034:INFO:create_model() successfully completed......................................
2025-10-19 19:45:37,225:INFO:SubProcess create_model() end ==================================
2025-10-19 19:45:37,236:INFO:_master_model_container: 22
2025-10-19 19:45:37,236:INFO:_display_container: 6
2025-10-19 19:45:37,241:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.0001,
                                                         loss='log_loss',
                                                         max_depth=5,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.005,
                                                         min_samples_leaf=1,
                                                         min_samples_split=9,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=30,
                                                         n_iter_no_change=...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=289, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-19 19:45:37,242:INFO:blend_models() successfully completed......................................
2025-10-19 19:45:37,433:INFO:Initializing finalize_model()
2025-10-19 19:45:37,433:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.0001,
                                                         loss='log_loss',
                                                         max_depth=5,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.005,
                                                         min_samples_leaf=1,
                                                         min_samples_split=9,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=30,
                                                         n_iter_no_change=...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=289, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-19 19:45:37,436:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.0001,
                                                         loss='log_loss',
                                                         max_depth=5,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.005,
                                                         min_samples_leaf=1,
                                                         min_samples_split=9,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=30,
                                                         n_iter_no_change=...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=289, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-19 19:45:37,620:INFO:Initializing create_model()
2025-10-19 19:45:37,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000128C1C054D0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.0001,
                                                         loss='log_loss',
                                                         max_depth=5,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.005,
                                                         min_samples_leaf=1,
                                                         min_samples_split=9,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=30,
                                                         n_iter_no_change=...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=289, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=5446     U01263
56878    U13332
21665    U17113
53964    U15788
75729    U00774
          ...  
65107    U02236
1605     U18276
52231    U11648
73027    U10146
56862    U16978
Name: id_usuario, Length: 80004, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:45:37,621:INFO:Checking exceptions
2025-10-19 19:45:37,622:INFO:Importing libraries
2025-10-19 19:45:37,622:INFO:Copying training dataset
2025-10-19 19:45:37,655:INFO:Defining folds
2025-10-19 19:45:37,656:INFO:Declaring metric variables
2025-10-19 19:45:37,656:INFO:Importing untrained model
2025-10-19 19:45:37,656:INFO:Declaring custom model
2025-10-19 19:45:37,657:INFO:Voting Classifier Imported successfully
2025-10-19 19:45:37,660:INFO:Cross validation set to False
2025-10-19 19:45:37,660:INFO:Fitting Model
2025-10-19 19:45:49,385:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=289,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-19 19:45:49,385:INFO:create_model() successfully completed......................................
2025-10-19 19:45:49,604:INFO:_master_model_container: 22
2025-10-19 19:45:49,604:INFO:_display_container: 6
2025-10-19 19:45:49,629:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=289,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-19 19:45:49,629:INFO:finalize_model() successfully completed......................................
2025-10-19 19:45:49,837:INFO:Initializing save_model()
2025-10-19 19:45:49,837:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=289,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), model_name=modelo_cls_like_v2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-19 19:45:49,837:INFO:Adding model into prep_pipe
2025-10-19 19:45:49,837:WARNING:Only Model saved as it was a pipeline.
2025-10-19 19:45:49,871:INFO:modelo_cls_like_v2.pkl saved in current working directory
2025-10-19 19:45:49,906:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=289,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-19 19:45:49,906:INFO:save_model() successfully completed......................................
2025-10-19 19:48:31,583:INFO:PyCaret RegressionExperiment
2025-10-19 19:48:31,583:INFO:Logging name: reg-default-name
2025-10-19 19:48:31,583:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-19 19:48:31,583:INFO:version 3.3.2
2025-10-19 19:48:31,583:INFO:Initializing setup()
2025-10-19 19:48:31,584:INFO:self.USI: 1d4c
2025-10-19 19:48:31,584:INFO:self._variable_keys: {'seed', 'transform_target_param', 'fold_generator', 'USI', 'exp_name_log', 'n_jobs_param', 'data', 'exp_id', 'fold_shuffle_param', 'gpu_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'html_param', 'memory', 'idx', 'X', 'y_train', 'X_train', 'target_param', 'log_plots_param', 'logging_param', '_available_plots', 'y', 'fold_groups_param', '_ml_usecase', 'pipeline'}
2025-10-19 19:48:31,584:INFO:Checking environment
2025-10-19 19:48:31,584:INFO:python_version: 3.11.13
2025-10-19 19:48:31,584:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-19 19:48:31,584:INFO:machine: AMD64
2025-10-19 19:48:31,584:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-19 19:48:31,591:INFO:Memory: svmem(total=16856211456, available=2779471872, percent=83.5, used=14076739584, free=2779471872)
2025-10-19 19:48:31,591:INFO:Physical Core: 4
2025-10-19 19:48:31,591:INFO:Logical Core: 8
2025-10-19 19:48:31,591:INFO:Checking libraries
2025-10-19 19:48:31,591:INFO:System:
2025-10-19 19:48:31,591:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-19 19:48:31,591:INFO:executable: c:\Users\Usuario\anaconda3\envs\nuevo_env\python.exe
2025-10-19 19:48:31,591:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-19 19:48:31,591:INFO:PyCaret required dependencies:
2025-10-19 19:48:31,592:INFO:                 pip: 25.2
2025-10-19 19:48:31,592:INFO:          setuptools: 80.9.0
2025-10-19 19:48:31,592:INFO:             pycaret: 3.3.2
2025-10-19 19:48:31,592:INFO:             IPython: 9.6.0
2025-10-19 19:48:31,592:INFO:          ipywidgets: 8.1.7
2025-10-19 19:48:31,592:INFO:                tqdm: 4.67.1
2025-10-19 19:48:31,592:INFO:               numpy: 1.26.4
2025-10-19 19:48:31,592:INFO:              pandas: 2.1.4
2025-10-19 19:48:31,592:INFO:              jinja2: 3.1.6
2025-10-19 19:48:31,592:INFO:               scipy: 1.11.4
2025-10-19 19:48:31,592:INFO:              joblib: 1.3.2
2025-10-19 19:48:31,592:INFO:             sklearn: 1.4.2
2025-10-19 19:48:31,592:INFO:                pyod: 2.0.5
2025-10-19 19:48:31,592:INFO:            imblearn: 0.14.0
2025-10-19 19:48:31,592:INFO:   category_encoders: 2.7.0
2025-10-19 19:48:31,592:INFO:            lightgbm: 4.6.0
2025-10-19 19:48:31,592:INFO:               numba: 0.61.0
2025-10-19 19:48:31,592:INFO:            requests: 2.32.5
2025-10-19 19:48:31,592:INFO:          matplotlib: 3.7.5
2025-10-19 19:48:31,592:INFO:          scikitplot: 0.3.7
2025-10-19 19:48:31,592:INFO:         yellowbrick: 1.5
2025-10-19 19:48:31,592:INFO:              plotly: 5.24.1
2025-10-19 19:48:31,592:INFO:    plotly-resampler: Not installed
2025-10-19 19:48:31,592:INFO:             kaleido: 1.1.0
2025-10-19 19:48:31,592:INFO:           schemdraw: 0.15
2025-10-19 19:48:31,592:INFO:         statsmodels: 0.14.5
2025-10-19 19:48:31,592:INFO:              sktime: 0.26.0
2025-10-19 19:48:31,592:INFO:               tbats: 1.1.3
2025-10-19 19:48:31,592:INFO:            pmdarima: 2.0.4
2025-10-19 19:48:31,592:INFO:              psutil: 7.1.0
2025-10-19 19:48:31,592:INFO:          markupsafe: 3.0.3
2025-10-19 19:48:31,592:INFO:             pickle5: Not installed
2025-10-19 19:48:31,592:INFO:         cloudpickle: 3.1.1
2025-10-19 19:48:31,592:INFO:         deprecation: 2.1.0
2025-10-19 19:48:31,592:INFO:              xxhash: 3.6.0
2025-10-19 19:48:31,593:INFO:           wurlitzer: Not installed
2025-10-19 19:48:31,593:INFO:PyCaret optional dependencies:
2025-10-19 19:48:31,593:INFO:                shap: 0.44.1
2025-10-19 19:48:31,593:INFO:           interpret: 0.7.3
2025-10-19 19:48:31,593:INFO:                umap: 0.5.7
2025-10-19 19:48:31,593:INFO:     ydata_profiling: 4.17.0
2025-10-19 19:48:31,593:INFO:  explainerdashboard: 0.5.1
2025-10-19 19:48:31,593:INFO:             autoviz: Not installed
2025-10-19 19:48:31,593:INFO:           fairlearn: 0.7.0
2025-10-19 19:48:31,593:INFO:          deepchecks: Not installed
2025-10-19 19:48:31,593:INFO:             xgboost: Not installed
2025-10-19 19:48:31,593:INFO:            catboost: 1.2.8
2025-10-19 19:48:31,593:INFO:              kmodes: 0.12.2
2025-10-19 19:48:31,593:INFO:             mlxtend: 0.23.4
2025-10-19 19:48:31,593:INFO:       statsforecast: 1.5.0
2025-10-19 19:48:31,593:INFO:        tune_sklearn: Not installed
2025-10-19 19:48:31,593:INFO:                 ray: Not installed
2025-10-19 19:48:31,593:INFO:            hyperopt: 0.2.7
2025-10-19 19:48:31,593:INFO:              optuna: 4.5.0
2025-10-19 19:48:31,593:INFO:               skopt: 0.10.2
2025-10-19 19:48:31,593:INFO:              mlflow: 3.5.0
2025-10-19 19:48:31,593:INFO:              gradio: 5.49.1
2025-10-19 19:48:31,593:INFO:             fastapi: 0.119.0
2025-10-19 19:48:31,593:INFO:             uvicorn: 0.38.0
2025-10-19 19:48:31,593:INFO:              m2cgen: 0.10.0
2025-10-19 19:48:31,593:INFO:           evidently: 0.4.40
2025-10-19 19:48:31,593:INFO:               fugue: 0.8.7
2025-10-19 19:48:31,593:INFO:           streamlit: Not installed
2025-10-19 19:48:31,593:INFO:             prophet: Not installed
2025-10-19 19:48:31,593:INFO:None
2025-10-19 19:48:31,594:INFO:Set up data.
2025-10-19 19:48:31,776:INFO:Set up folding strategy.
2025-10-19 19:48:32,018:INFO:Set up train/test split.
2025-10-19 19:48:32,350:INFO:Set up index.
2025-10-19 19:48:32,365:INFO:Assigning column types.
2025-10-19 19:48:32,637:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-19 19:48:32,637:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-19 19:48:32,641:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 19:48:32,644:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 19:48:32,935:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 19:48:32,985:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 19:48:32,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:32,986:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:32,987:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-19 19:48:32,992:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 19:48:32,998:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 19:48:33,326:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 19:48:33,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 19:48:33,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:33,382:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:33,382:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-19 19:48:33,389:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 19:48:33,393:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 19:48:33,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 19:48:33,751:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 19:48:33,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:33,752:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:33,757:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-19 19:48:33,765:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 19:48:34,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 19:48:34,153:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 19:48:34,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:34,154:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:34,154:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-19 19:48:34,162:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 19:48:34,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 19:48:34,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 19:48:34,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:34,574:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:34,586:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-19 19:48:34,912:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 19:48:34,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 19:48:34,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:34,954:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:34,955:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-19 19:48:35,253:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 19:48:35,304:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 19:48:35,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:35,305:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:35,665:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 19:48:35,708:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-19 19:48:35,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:35,709:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:35,710:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-19 19:48:36,019:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 19:48:36,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:36,067:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:36,392:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-19 19:48:36,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:36,441:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:36,442:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-19 19:48:36,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:36,882:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:37,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:37,233:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:37,236:INFO:Preparing preprocessing pipeline...
2025-10-19 19:48:37,236:INFO:Set up simple imputation.
2025-10-19 19:48:37,430:INFO:Set up encoding of ordinal features.
2025-10-19 19:48:37,512:INFO:Set up encoding of categorical features.
2025-10-19 19:48:37,518:INFO:Set up removing multicollinearity.
2025-10-19 19:48:37,553:INFO:Set up column name cleaning.
2025-10-19 19:48:44,425:INFO:Finished creating preprocessing pipeline.
2025-10-19 19:48:44,450:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-19 19:48:44,450:INFO:Creating final display dataframe.
2025-10-19 19:48:47,877:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target    rating_usuario
2                   Target type        Regression
3           Original data shape       (80004, 28)
4        Transformed data shape       (80004, 97)
5   Transformed train set shape       (56002, 97)
6    Transformed test set shape       (24002, 97)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              1d4c
2025-10-19 19:48:48,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:48,195:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:48,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-19 19:48:48,520:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-19 19:48:48,521:INFO:setup() successfully completed in 17.02s...............
2025-10-19 19:48:48,521:INFO:Initializing compare_models()
2025-10-19 19:48:48,521:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-19 19:48:48,522:INFO:Checking exceptions
2025-10-19 19:48:48,624:INFO:Preparing display monitor
2025-10-19 19:48:48,651:INFO:Initializing Linear Regression
2025-10-19 19:48:48,651:INFO:Total runtime is 0.0 minutes
2025-10-19 19:48:48,656:INFO:SubProcess create_model() called ==================================
2025-10-19 19:48:48,657:INFO:Initializing create_model()
2025-10-19 19:48:48,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:48:48,657:INFO:Checking exceptions
2025-10-19 19:48:48,658:INFO:Importing libraries
2025-10-19 19:48:48,658:INFO:Copying training dataset
2025-10-19 19:48:48,986:INFO:Defining folds
2025-10-19 19:48:48,987:INFO:Declaring metric variables
2025-10-19 19:48:48,991:INFO:Importing untrained model
2025-10-19 19:48:48,995:INFO:Linear Regression Imported successfully
2025-10-19 19:48:49,003:INFO:Starting cross validation
2025-10-19 19:48:49,008:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:49:07,341:INFO:Calculating mean and std
2025-10-19 19:49:07,343:INFO:Creating metrics dataframe
2025-10-19 19:49:07,344:INFO:Uploading results into container
2025-10-19 19:49:07,345:INFO:Uploading model into container now
2025-10-19 19:49:07,345:INFO:_master_model_container: 1
2025-10-19 19:49:07,345:INFO:_display_container: 2
2025-10-19 19:49:07,345:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, positive=False)
2025-10-19 19:49:07,345:INFO:create_model() successfully completed......................................
2025-10-19 19:49:07,533:INFO:SubProcess create_model() end ==================================
2025-10-19 19:49:07,533:INFO:Creating metrics dataframe
2025-10-19 19:49:07,539:INFO:Initializing Lasso Regression
2025-10-19 19:49:07,539:INFO:Total runtime is 0.3148073196411133 minutes
2025-10-19 19:49:07,545:INFO:SubProcess create_model() called ==================================
2025-10-19 19:49:07,546:INFO:Initializing create_model()
2025-10-19 19:49:07,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=lasso, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:49:07,546:INFO:Checking exceptions
2025-10-19 19:49:07,546:INFO:Importing libraries
2025-10-19 19:49:07,547:INFO:Copying training dataset
2025-10-19 19:49:07,813:INFO:Defining folds
2025-10-19 19:49:07,814:INFO:Declaring metric variables
2025-10-19 19:49:07,821:INFO:Importing untrained model
2025-10-19 19:49:07,826:INFO:Lasso Regression Imported successfully
2025-10-19 19:49:07,835:INFO:Starting cross validation
2025-10-19 19:49:07,840:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:49:24,525:INFO:Calculating mean and std
2025-10-19 19:49:24,527:INFO:Creating metrics dataframe
2025-10-19 19:49:24,528:INFO:Uploading results into container
2025-10-19 19:49:24,530:INFO:Uploading model into container now
2025-10-19 19:49:24,531:INFO:_master_model_container: 2
2025-10-19 19:49:24,531:INFO:_display_container: 2
2025-10-19 19:49:24,531:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=42, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-10-19 19:49:24,531:INFO:create_model() successfully completed......................................
2025-10-19 19:49:24,715:INFO:SubProcess create_model() end ==================================
2025-10-19 19:49:24,715:INFO:Creating metrics dataframe
2025-10-19 19:49:24,724:INFO:Initializing Ridge Regression
2025-10-19 19:49:24,724:INFO:Total runtime is 0.6012178540229798 minutes
2025-10-19 19:49:24,727:INFO:SubProcess create_model() called ==================================
2025-10-19 19:49:24,729:INFO:Initializing create_model()
2025-10-19 19:49:24,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:49:24,729:INFO:Checking exceptions
2025-10-19 19:49:24,729:INFO:Importing libraries
2025-10-19 19:49:24,730:INFO:Copying training dataset
2025-10-19 19:49:25,071:INFO:Defining folds
2025-10-19 19:49:25,072:INFO:Declaring metric variables
2025-10-19 19:49:25,077:INFO:Importing untrained model
2025-10-19 19:49:25,080:INFO:Ridge Regression Imported successfully
2025-10-19 19:49:25,090:INFO:Starting cross validation
2025-10-19 19:49:25,094:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:49:41,680:INFO:Calculating mean and std
2025-10-19 19:49:41,681:INFO:Creating metrics dataframe
2025-10-19 19:49:41,683:INFO:Uploading results into container
2025-10-19 19:49:41,685:INFO:Uploading model into container now
2025-10-19 19:49:41,686:INFO:_master_model_container: 3
2025-10-19 19:49:41,686:INFO:_display_container: 2
2025-10-19 19:49:41,686:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001)
2025-10-19 19:49:41,687:INFO:create_model() successfully completed......................................
2025-10-19 19:49:41,853:INFO:SubProcess create_model() end ==================================
2025-10-19 19:49:41,853:INFO:Creating metrics dataframe
2025-10-19 19:49:41,860:INFO:Initializing Elastic Net
2025-10-19 19:49:41,860:INFO:Total runtime is 0.886822537581126 minutes
2025-10-19 19:49:41,863:INFO:SubProcess create_model() called ==================================
2025-10-19 19:49:41,864:INFO:Initializing create_model()
2025-10-19 19:49:41,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=en, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:49:41,865:INFO:Checking exceptions
2025-10-19 19:49:41,865:INFO:Importing libraries
2025-10-19 19:49:41,865:INFO:Copying training dataset
2025-10-19 19:49:42,145:INFO:Defining folds
2025-10-19 19:49:42,145:INFO:Declaring metric variables
2025-10-19 19:49:42,150:INFO:Importing untrained model
2025-10-19 19:49:42,155:INFO:Elastic Net Imported successfully
2025-10-19 19:49:42,163:INFO:Starting cross validation
2025-10-19 19:49:42,169:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:49:58,375:INFO:Calculating mean and std
2025-10-19 19:49:58,377:INFO:Creating metrics dataframe
2025-10-19 19:49:58,378:INFO:Uploading results into container
2025-10-19 19:49:58,379:INFO:Uploading model into container now
2025-10-19 19:49:58,379:INFO:_master_model_container: 4
2025-10-19 19:49:58,379:INFO:_display_container: 2
2025-10-19 19:49:58,380:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=42,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-10-19 19:49:58,380:INFO:create_model() successfully completed......................................
2025-10-19 19:49:58,562:INFO:SubProcess create_model() end ==================================
2025-10-19 19:49:58,563:INFO:Creating metrics dataframe
2025-10-19 19:49:58,570:INFO:Initializing Least Angle Regression
2025-10-19 19:49:58,570:INFO:Total runtime is 1.1653268337249756 minutes
2025-10-19 19:49:58,575:INFO:SubProcess create_model() called ==================================
2025-10-19 19:49:58,577:INFO:Initializing create_model()
2025-10-19 19:49:58,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=lar, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:49:58,577:INFO:Checking exceptions
2025-10-19 19:49:58,577:INFO:Importing libraries
2025-10-19 19:49:58,577:INFO:Copying training dataset
2025-10-19 19:49:58,859:INFO:Defining folds
2025-10-19 19:49:58,859:INFO:Declaring metric variables
2025-10-19 19:49:58,862:INFO:Importing untrained model
2025-10-19 19:49:58,867:INFO:Least Angle Regression Imported successfully
2025-10-19 19:49:58,875:INFO:Starting cross validation
2025-10-19 19:49:58,879:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:50:02,140:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square

2025-10-19 19:50:02,141:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square

2025-10-19 19:50:02,142:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\metrics\_regression.py:1196: RuntimeWarning: overflow encountered in square

2025-10-19 19:50:05,081:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=2.681e-03, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.

2025-10-19 19:50:08,189:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.194e-04, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.

2025-10-19 19:50:14,729:INFO:Calculating mean and std
2025-10-19 19:50:14,730:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply

2025-10-19 19:50:14,730:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\numpy\core\_methods.py:173: RuntimeWarning: invalid value encountered in subtract

2025-10-19 19:50:14,731:INFO:Creating metrics dataframe
2025-10-19 19:50:14,733:INFO:Uploading results into container
2025-10-19 19:50:14,733:INFO:Uploading model into container now
2025-10-19 19:50:14,733:INFO:_master_model_container: 5
2025-10-19 19:50:14,733:INFO:_display_container: 2
2025-10-19 19:50:14,734:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=42,
     verbose=False)
2025-10-19 19:50:14,734:INFO:create_model() successfully completed......................................
2025-10-19 19:50:14,896:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\numpy\core\_methods.py:49: RuntimeWarning: invalid value encountered in reduce

2025-10-19 19:50:14,896:INFO:SubProcess create_model() end ==================================
2025-10-19 19:50:14,897:INFO:Creating metrics dataframe
2025-10-19 19:50:14,905:INFO:Initializing Lasso Least Angle Regression
2025-10-19 19:50:14,905:INFO:Total runtime is 1.4375647981961568 minutes
2025-10-19 19:50:14,907:INFO:SubProcess create_model() called ==================================
2025-10-19 19:50:14,909:INFO:Initializing create_model()
2025-10-19 19:50:14,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=llar, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:50:14,909:INFO:Checking exceptions
2025-10-19 19:50:14,909:INFO:Importing libraries
2025-10-19 19:50:14,909:INFO:Copying training dataset
2025-10-19 19:50:15,165:INFO:Defining folds
2025-10-19 19:50:15,165:INFO:Declaring metric variables
2025-10-19 19:50:15,171:INFO:Importing untrained model
2025-10-19 19:50:15,175:INFO:Lasso Least Angle Regression Imported successfully
2025-10-19 19:50:15,181:INFO:Starting cross validation
2025-10-19 19:50:15,185:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:50:31,893:INFO:Calculating mean and std
2025-10-19 19:50:31,895:INFO:Creating metrics dataframe
2025-10-19 19:50:31,896:INFO:Uploading results into container
2025-10-19 19:50:31,897:INFO:Uploading model into container now
2025-10-19 19:50:31,897:INFO:_master_model_container: 6
2025-10-19 19:50:31,897:INFO:_display_container: 2
2025-10-19 19:50:31,897:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=42, verbose=False)
2025-10-19 19:50:31,897:INFO:create_model() successfully completed......................................
2025-10-19 19:50:32,098:INFO:SubProcess create_model() end ==================================
2025-10-19 19:50:32,098:INFO:Creating metrics dataframe
2025-10-19 19:50:32,107:INFO:Initializing Orthogonal Matching Pursuit
2025-10-19 19:50:32,108:INFO:Total runtime is 1.7242663383483887 minutes
2025-10-19 19:50:32,113:INFO:SubProcess create_model() called ==================================
2025-10-19 19:50:32,113:INFO:Initializing create_model()
2025-10-19 19:50:32,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=omp, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:50:32,114:INFO:Checking exceptions
2025-10-19 19:50:32,114:INFO:Importing libraries
2025-10-19 19:50:32,114:INFO:Copying training dataset
2025-10-19 19:50:32,377:INFO:Defining folds
2025-10-19 19:50:32,378:INFO:Declaring metric variables
2025-10-19 19:50:32,381:INFO:Importing untrained model
2025-10-19 19:50:32,385:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-19 19:50:32,393:INFO:Starting cross validation
2025-10-19 19:50:32,397:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:50:48,983:INFO:Calculating mean and std
2025-10-19 19:50:48,984:INFO:Creating metrics dataframe
2025-10-19 19:50:48,987:INFO:Uploading results into container
2025-10-19 19:50:48,988:INFO:Uploading model into container now
2025-10-19 19:50:48,989:INFO:_master_model_container: 7
2025-10-19 19:50:48,989:INFO:_display_container: 2
2025-10-19 19:50:48,990:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-10-19 19:50:48,990:INFO:create_model() successfully completed......................................
2025-10-19 19:50:49,195:INFO:SubProcess create_model() end ==================================
2025-10-19 19:50:49,195:INFO:Creating metrics dataframe
2025-10-19 19:50:49,205:INFO:Initializing Bayesian Ridge
2025-10-19 19:50:49,206:INFO:Total runtime is 2.0092457930246987 minutes
2025-10-19 19:50:49,210:INFO:SubProcess create_model() called ==================================
2025-10-19 19:50:49,212:INFO:Initializing create_model()
2025-10-19 19:50:49,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=br, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:50:49,212:INFO:Checking exceptions
2025-10-19 19:50:49,212:INFO:Importing libraries
2025-10-19 19:50:49,212:INFO:Copying training dataset
2025-10-19 19:50:49,467:INFO:Defining folds
2025-10-19 19:50:49,468:INFO:Declaring metric variables
2025-10-19 19:50:49,474:INFO:Importing untrained model
2025-10-19 19:50:49,479:INFO:Bayesian Ridge Imported successfully
2025-10-19 19:50:49,489:INFO:Starting cross validation
2025-10-19 19:50:49,496:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:51:09,097:INFO:Calculating mean and std
2025-10-19 19:51:09,098:INFO:Creating metrics dataframe
2025-10-19 19:51:09,100:INFO:Uploading results into container
2025-10-19 19:51:09,101:INFO:Uploading model into container now
2025-10-19 19:51:09,101:INFO:_master_model_container: 8
2025-10-19 19:51:09,102:INFO:_display_container: 2
2025-10-19 19:51:09,102:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-10-19 19:51:09,102:INFO:create_model() successfully completed......................................
2025-10-19 19:51:09,284:INFO:SubProcess create_model() end ==================================
2025-10-19 19:51:09,285:INFO:Creating metrics dataframe
2025-10-19 19:51:09,293:INFO:Initializing Passive Aggressive Regressor
2025-10-19 19:51:09,293:INFO:Total runtime is 2.344032204151153 minutes
2025-10-19 19:51:09,297:INFO:SubProcess create_model() called ==================================
2025-10-19 19:51:09,299:INFO:Initializing create_model()
2025-10-19 19:51:09,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=par, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:51:09,300:INFO:Checking exceptions
2025-10-19 19:51:09,300:INFO:Importing libraries
2025-10-19 19:51:09,300:INFO:Copying training dataset
2025-10-19 19:51:09,669:INFO:Defining folds
2025-10-19 19:51:09,669:INFO:Declaring metric variables
2025-10-19 19:51:09,674:INFO:Importing untrained model
2025-10-19 19:51:09,679:INFO:Passive Aggressive Regressor Imported successfully
2025-10-19 19:51:09,686:INFO:Starting cross validation
2025-10-19 19:51:09,692:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:51:30,045:INFO:Calculating mean and std
2025-10-19 19:51:30,046:INFO:Creating metrics dataframe
2025-10-19 19:51:30,049:INFO:Uploading results into container
2025-10-19 19:51:30,049:INFO:Uploading model into container now
2025-10-19 19:51:30,049:INFO:_master_model_container: 9
2025-10-19 19:51:30,049:INFO:_display_container: 2
2025-10-19 19:51:30,051:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=42, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-19 19:51:30,051:INFO:create_model() successfully completed......................................
2025-10-19 19:51:30,229:INFO:SubProcess create_model() end ==================================
2025-10-19 19:51:30,229:INFO:Creating metrics dataframe
2025-10-19 19:51:30,237:INFO:Initializing Huber Regressor
2025-10-19 19:51:30,237:INFO:Total runtime is 2.693101930618286 minutes
2025-10-19 19:51:30,243:INFO:SubProcess create_model() called ==================================
2025-10-19 19:51:30,245:INFO:Initializing create_model()
2025-10-19 19:51:30,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=huber, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:51:30,245:INFO:Checking exceptions
2025-10-19 19:51:30,245:INFO:Importing libraries
2025-10-19 19:51:30,245:INFO:Copying training dataset
2025-10-19 19:51:30,553:INFO:Defining folds
2025-10-19 19:51:30,553:INFO:Declaring metric variables
2025-10-19 19:51:30,559:INFO:Importing untrained model
2025-10-19 19:51:30,563:INFO:Huber Regressor Imported successfully
2025-10-19 19:51:30,569:INFO:Starting cross validation
2025-10-19 19:51:30,575:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:51:56,167:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2025-10-19 19:52:03,238:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2025-10-19 19:52:03,629:INFO:Calculating mean and std
2025-10-19 19:52:03,631:INFO:Creating metrics dataframe
2025-10-19 19:52:03,634:INFO:Uploading results into container
2025-10-19 19:52:03,635:INFO:Uploading model into container now
2025-10-19 19:52:03,636:INFO:_master_model_container: 10
2025-10-19 19:52:03,636:INFO:_display_container: 2
2025-10-19 19:52:03,637:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-10-19 19:52:03,637:INFO:create_model() successfully completed......................................
2025-10-19 19:52:03,865:INFO:SubProcess create_model() end ==================================
2025-10-19 19:52:03,865:INFO:Creating metrics dataframe
2025-10-19 19:52:03,874:INFO:Initializing K Neighbors Regressor
2025-10-19 19:52:03,874:INFO:Total runtime is 3.253722588221232 minutes
2025-10-19 19:52:03,878:INFO:SubProcess create_model() called ==================================
2025-10-19 19:52:03,879:INFO:Initializing create_model()
2025-10-19 19:52:03,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:52:03,880:INFO:Checking exceptions
2025-10-19 19:52:03,880:INFO:Importing libraries
2025-10-19 19:52:03,880:INFO:Copying training dataset
2025-10-19 19:52:04,204:INFO:Defining folds
2025-10-19 19:52:04,204:INFO:Declaring metric variables
2025-10-19 19:52:04,209:INFO:Importing untrained model
2025-10-19 19:52:04,214:INFO:K Neighbors Regressor Imported successfully
2025-10-19 19:52:04,222:INFO:Starting cross validation
2025-10-19 19:52:04,230:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:52:26,740:INFO:Calculating mean and std
2025-10-19 19:52:26,743:INFO:Creating metrics dataframe
2025-10-19 19:52:26,748:INFO:Uploading results into container
2025-10-19 19:52:26,749:INFO:Uploading model into container now
2025-10-19 19:52:26,749:INFO:_master_model_container: 11
2025-10-19 19:52:26,749:INFO:_display_container: 2
2025-10-19 19:52:26,750:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                    weights='uniform')
2025-10-19 19:52:26,750:INFO:create_model() successfully completed......................................
2025-10-19 19:52:26,925:INFO:SubProcess create_model() end ==================================
2025-10-19 19:52:26,925:INFO:Creating metrics dataframe
2025-10-19 19:52:26,935:INFO:Initializing Decision Tree Regressor
2025-10-19 19:52:26,935:INFO:Total runtime is 3.6380733927090962 minutes
2025-10-19 19:52:26,940:INFO:SubProcess create_model() called ==================================
2025-10-19 19:52:26,941:INFO:Initializing create_model()
2025-10-19 19:52:26,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:52:26,941:INFO:Checking exceptions
2025-10-19 19:52:26,942:INFO:Importing libraries
2025-10-19 19:52:26,942:INFO:Copying training dataset
2025-10-19 19:52:27,206:INFO:Defining folds
2025-10-19 19:52:27,206:INFO:Declaring metric variables
2025-10-19 19:52:27,211:INFO:Importing untrained model
2025-10-19 19:52:27,217:INFO:Decision Tree Regressor Imported successfully
2025-10-19 19:52:27,223:INFO:Starting cross validation
2025-10-19 19:52:27,229:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:52:49,757:INFO:Calculating mean and std
2025-10-19 19:52:49,758:INFO:Creating metrics dataframe
2025-10-19 19:52:49,762:INFO:Uploading results into container
2025-10-19 19:52:49,763:INFO:Uploading model into container now
2025-10-19 19:52:49,763:INFO:_master_model_container: 12
2025-10-19 19:52:49,764:INFO:_display_container: 2
2025-10-19 19:52:49,764:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=42, splitter='best')
2025-10-19 19:52:49,764:INFO:create_model() successfully completed......................................
2025-10-19 19:52:49,929:INFO:SubProcess create_model() end ==================================
2025-10-19 19:52:49,930:INFO:Creating metrics dataframe
2025-10-19 19:52:49,938:INFO:Initializing Random Forest Regressor
2025-10-19 19:52:49,938:INFO:Total runtime is 4.021452490488688 minutes
2025-10-19 19:52:49,941:INFO:SubProcess create_model() called ==================================
2025-10-19 19:52:49,942:INFO:Initializing create_model()
2025-10-19 19:52:49,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:52:49,942:INFO:Checking exceptions
2025-10-19 19:52:49,943:INFO:Importing libraries
2025-10-19 19:52:49,943:INFO:Copying training dataset
2025-10-19 19:52:50,255:INFO:Defining folds
2025-10-19 19:52:50,256:INFO:Declaring metric variables
2025-10-19 19:52:50,261:INFO:Importing untrained model
2025-10-19 19:52:50,266:INFO:Random Forest Regressor Imported successfully
2025-10-19 19:52:50,274:INFO:Starting cross validation
2025-10-19 19:52:50,279:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 19:59:35,303:INFO:Calculating mean and std
2025-10-19 19:59:35,305:INFO:Creating metrics dataframe
2025-10-19 19:59:35,308:INFO:Uploading results into container
2025-10-19 19:59:35,309:INFO:Uploading model into container now
2025-10-19 19:59:35,310:INFO:_master_model_container: 13
2025-10-19 19:59:35,310:INFO:_display_container: 2
2025-10-19 19:59:35,310:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=1, oob_score=False,
                      random_state=42, verbose=0, warm_start=False)
2025-10-19 19:59:35,310:INFO:create_model() successfully completed......................................
2025-10-19 19:59:35,494:INFO:SubProcess create_model() end ==================================
2025-10-19 19:59:35,495:INFO:Creating metrics dataframe
2025-10-19 19:59:35,502:INFO:Initializing Extra Trees Regressor
2025-10-19 19:59:35,502:INFO:Total runtime is 10.780845673878988 minutes
2025-10-19 19:59:35,507:INFO:SubProcess create_model() called ==================================
2025-10-19 19:59:35,509:INFO:Initializing create_model()
2025-10-19 19:59:35,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 19:59:35,509:INFO:Checking exceptions
2025-10-19 19:59:35,509:INFO:Importing libraries
2025-10-19 19:59:35,509:INFO:Copying training dataset
2025-10-19 19:59:35,816:INFO:Defining folds
2025-10-19 19:59:35,817:INFO:Declaring metric variables
2025-10-19 19:59:35,821:INFO:Importing untrained model
2025-10-19 19:59:35,827:INFO:Extra Trees Regressor Imported successfully
2025-10-19 19:59:35,835:INFO:Starting cross validation
2025-10-19 19:59:35,842:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:07:04,506:INFO:Calculating mean and std
2025-10-19 20:07:04,508:INFO:Creating metrics dataframe
2025-10-19 20:07:04,511:INFO:Uploading results into container
2025-10-19 20:07:04,512:INFO:Uploading model into container now
2025-10-19 20:07:04,512:INFO:_master_model_container: 14
2025-10-19 20:07:04,513:INFO:_display_container: 2
2025-10-19 20:07:04,514:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=1, oob_score=False,
                    random_state=42, verbose=0, warm_start=False)
2025-10-19 20:07:04,514:INFO:create_model() successfully completed......................................
2025-10-19 20:07:04,702:INFO:SubProcess create_model() end ==================================
2025-10-19 20:07:04,702:INFO:Creating metrics dataframe
2025-10-19 20:07:04,713:INFO:Initializing AdaBoost Regressor
2025-10-19 20:07:04,713:INFO:Total runtime is 18.267701625823975 minutes
2025-10-19 20:07:04,717:INFO:SubProcess create_model() called ==================================
2025-10-19 20:07:04,718:INFO:Initializing create_model()
2025-10-19 20:07:04,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:07:04,718:INFO:Checking exceptions
2025-10-19 20:07:04,718:INFO:Importing libraries
2025-10-19 20:07:04,719:INFO:Copying training dataset
2025-10-19 20:07:04,997:INFO:Defining folds
2025-10-19 20:07:04,997:INFO:Declaring metric variables
2025-10-19 20:07:05,003:INFO:Importing untrained model
2025-10-19 20:07:05,007:INFO:AdaBoost Regressor Imported successfully
2025-10-19 20:07:05,019:INFO:Starting cross validation
2025-10-19 20:07:05,025:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:08:00,041:INFO:Calculating mean and std
2025-10-19 20:08:00,043:INFO:Creating metrics dataframe
2025-10-19 20:08:00,046:INFO:Uploading results into container
2025-10-19 20:08:00,046:INFO:Uploading model into container now
2025-10-19 20:08:00,047:INFO:_master_model_container: 15
2025-10-19 20:08:00,047:INFO:_display_container: 2
2025-10-19 20:08:00,048:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=42)
2025-10-19 20:08:00,048:INFO:create_model() successfully completed......................................
2025-10-19 20:08:00,244:INFO:SubProcess create_model() end ==================================
2025-10-19 20:08:00,244:INFO:Creating metrics dataframe
2025-10-19 20:08:00,254:INFO:Initializing Gradient Boosting Regressor
2025-10-19 20:08:00,254:INFO:Total runtime is 19.193382501602173 minutes
2025-10-19 20:08:00,256:INFO:SubProcess create_model() called ==================================
2025-10-19 20:08:00,258:INFO:Initializing create_model()
2025-10-19 20:08:00,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=gbr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:08:00,259:INFO:Checking exceptions
2025-10-19 20:08:00,259:INFO:Importing libraries
2025-10-19 20:08:00,259:INFO:Copying training dataset
2025-10-19 20:08:00,531:INFO:Defining folds
2025-10-19 20:08:00,531:INFO:Declaring metric variables
2025-10-19 20:08:00,535:INFO:Importing untrained model
2025-10-19 20:08:00,539:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 20:08:00,546:INFO:Starting cross validation
2025-10-19 20:08:00,553:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:09:17,262:INFO:Calculating mean and std
2025-10-19 20:09:17,263:INFO:Creating metrics dataframe
2025-10-19 20:09:17,264:INFO:Uploading results into container
2025-10-19 20:09:17,265:INFO:Uploading model into container now
2025-10-19 20:09:17,265:INFO:_master_model_container: 16
2025-10-19 20:09:17,265:INFO:_display_container: 2
2025-10-19 20:09:17,265:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 20:09:17,266:INFO:create_model() successfully completed......................................
2025-10-19 20:09:17,434:INFO:SubProcess create_model() end ==================================
2025-10-19 20:09:17,434:INFO:Creating metrics dataframe
2025-10-19 20:09:17,445:INFO:Initializing Light Gradient Boosting Machine
2025-10-19 20:09:17,445:INFO:Total runtime is 20.479904353618622 minutes
2025-10-19 20:09:17,450:INFO:SubProcess create_model() called ==================================
2025-10-19 20:09:17,451:INFO:Initializing create_model()
2025-10-19 20:09:17,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:09:17,451:INFO:Checking exceptions
2025-10-19 20:09:17,451:INFO:Importing libraries
2025-10-19 20:09:17,451:INFO:Copying training dataset
2025-10-19 20:09:17,713:INFO:Defining folds
2025-10-19 20:09:17,714:INFO:Declaring metric variables
2025-10-19 20:09:17,718:INFO:Importing untrained model
2025-10-19 20:09:17,721:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-19 20:09:17,732:INFO:Starting cross validation
2025-10-19 20:09:17,737:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:09:20,737:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 20:09:20,762:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010538 seconds.
2025-10-19 20:09:20,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 20:09:20,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 20:09:20,763:INFO:[LightGBM] [Info] Total Bins 1452
2025-10-19 20:09:20,763:INFO:[LightGBM] [Info] Number of data points in the train set: 44801, number of used features: 96
2025-10-19 20:09:20,764:INFO:[LightGBM] [Info] Start training from score 3.640073
2025-10-19 20:09:24,673:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 20:09:24,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014883 seconds.
2025-10-19 20:09:24,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 20:09:24,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 20:09:24,708:INFO:[LightGBM] [Info] Total Bins 1452
2025-10-19 20:09:24,708:INFO:[LightGBM] [Info] Number of data points in the train set: 44801, number of used features: 96
2025-10-19 20:09:24,709:INFO:[LightGBM] [Info] Start training from score 3.633687
2025-10-19 20:09:28,647:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 20:09:28,675:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010920 seconds.
2025-10-19 20:09:28,675:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 20:09:28,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 20:09:28,676:INFO:[LightGBM] [Info] Total Bins 1450
2025-10-19 20:09:28,676:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-19 20:09:28,676:INFO:[LightGBM] [Info] Start training from score 3.637945
2025-10-19 20:09:32,802:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 20:09:32,829:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011015 seconds.
2025-10-19 20:09:32,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 20:09:32,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 20:09:32,830:INFO:[LightGBM] [Info] Total Bins 1452
2025-10-19 20:09:32,830:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-19 20:09:32,831:INFO:[LightGBM] [Info] Start training from score 3.643299
2025-10-19 20:09:36,537:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-19 20:09:36,566:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011749 seconds.
2025-10-19 20:09:36,567:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-19 20:09:36,567:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-19 20:09:36,567:INFO:[LightGBM] [Info] Total Bins 1452
2025-10-19 20:09:36,567:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-19 20:09:36,568:INFO:[LightGBM] [Info] Start training from score 3.646926
2025-10-19 20:09:37,474:INFO:Calculating mean and std
2025-10-19 20:09:37,475:INFO:Creating metrics dataframe
2025-10-19 20:09:37,478:INFO:Uploading results into container
2025-10-19 20:09:37,479:INFO:Uploading model into container now
2025-10-19 20:09:37,479:INFO:_master_model_container: 17
2025-10-19 20:09:37,479:INFO:_display_container: 2
2025-10-19 20:09:37,480:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
              random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-10-19 20:09:37,480:INFO:create_model() successfully completed......................................
2025-10-19 20:09:37,656:INFO:SubProcess create_model() end ==================================
2025-10-19 20:09:37,656:INFO:Creating metrics dataframe
2025-10-19 20:09:37,671:INFO:Initializing CatBoost Regressor
2025-10-19 20:09:37,671:INFO:Total runtime is 20.816995561122894 minutes
2025-10-19 20:09:37,675:INFO:SubProcess create_model() called ==================================
2025-10-19 20:09:37,676:INFO:Initializing create_model()
2025-10-19 20:09:37,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:09:37,677:INFO:Checking exceptions
2025-10-19 20:09:37,677:INFO:Importing libraries
2025-10-19 20:09:37,677:INFO:Copying training dataset
2025-10-19 20:09:37,950:INFO:Defining folds
2025-10-19 20:09:37,950:INFO:Declaring metric variables
2025-10-19 20:09:37,954:INFO:Importing untrained model
2025-10-19 20:09:37,958:INFO:CatBoost Regressor Imported successfully
2025-10-19 20:09:37,967:INFO:Starting cross validation
2025-10-19 20:09:37,970:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:13:25,712:INFO:Calculating mean and std
2025-10-19 20:13:25,716:INFO:Creating metrics dataframe
2025-10-19 20:13:25,721:INFO:Uploading results into container
2025-10-19 20:13:25,723:INFO:Uploading model into container now
2025-10-19 20:13:25,724:INFO:_master_model_container: 18
2025-10-19 20:13:25,724:INFO:_display_container: 2
2025-10-19 20:13:25,725:INFO:<catboost.core.CatBoostRegressor object at 0x00000128CD16F150>
2025-10-19 20:13:25,725:INFO:create_model() successfully completed......................................
2025-10-19 20:13:25,984:INFO:SubProcess create_model() end ==================================
2025-10-19 20:13:25,984:INFO:Creating metrics dataframe
2025-10-19 20:13:26,013:INFO:Initializing Dummy Regressor
2025-10-19 20:13:26,013:INFO:Total runtime is 24.622694579760235 minutes
2025-10-19 20:13:26,018:INFO:SubProcess create_model() called ==================================
2025-10-19 20:13:26,022:INFO:Initializing create_model()
2025-10-19 20:13:26,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001288033F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:13:26,023:INFO:Checking exceptions
2025-10-19 20:13:26,023:INFO:Importing libraries
2025-10-19 20:13:26,023:INFO:Copying training dataset
2025-10-19 20:13:26,524:INFO:Defining folds
2025-10-19 20:13:26,525:INFO:Declaring metric variables
2025-10-19 20:13:26,534:INFO:Importing untrained model
2025-10-19 20:13:26,543:INFO:Dummy Regressor Imported successfully
2025-10-19 20:13:26,561:INFO:Starting cross validation
2025-10-19 20:13:26,567:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:13:58,282:INFO:Calculating mean and std
2025-10-19 20:13:58,283:INFO:Creating metrics dataframe
2025-10-19 20:13:58,286:INFO:Uploading results into container
2025-10-19 20:13:58,288:INFO:Uploading model into container now
2025-10-19 20:13:58,290:INFO:_master_model_container: 19
2025-10-19 20:13:58,290:INFO:_display_container: 2
2025-10-19 20:13:58,290:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-10-19 20:13:58,290:INFO:create_model() successfully completed......................................
2025-10-19 20:13:58,596:INFO:SubProcess create_model() end ==================================
2025-10-19 20:13:58,596:INFO:Creating metrics dataframe
2025-10-19 20:13:58,643:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-19 20:13:58,673:INFO:Initializing create_model()
2025-10-19 20:13:58,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:13:58,674:INFO:Checking exceptions
2025-10-19 20:13:58,676:INFO:Importing libraries
2025-10-19 20:13:58,676:INFO:Copying training dataset
2025-10-19 20:13:59,293:INFO:Defining folds
2025-10-19 20:13:59,294:INFO:Declaring metric variables
2025-10-19 20:13:59,294:INFO:Importing untrained model
2025-10-19 20:13:59,294:INFO:Declaring custom model
2025-10-19 20:13:59,297:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 20:13:59,307:INFO:Cross validation set to False
2025-10-19 20:13:59,307:INFO:Fitting Model
2025-10-19 20:14:38,540:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 20:14:38,540:INFO:create_model() successfully completed......................................
2025-10-19 20:14:38,830:INFO:Initializing create_model()
2025-10-19 20:14:38,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:14:38,831:INFO:Checking exceptions
2025-10-19 20:14:38,833:INFO:Importing libraries
2025-10-19 20:14:38,833:INFO:Copying training dataset
2025-10-19 20:14:39,258:INFO:Defining folds
2025-10-19 20:14:39,258:INFO:Declaring metric variables
2025-10-19 20:14:39,259:INFO:Importing untrained model
2025-10-19 20:14:39,259:INFO:Declaring custom model
2025-10-19 20:14:39,259:INFO:Ridge Regression Imported successfully
2025-10-19 20:14:39,265:INFO:Cross validation set to False
2025-10-19 20:14:39,266:INFO:Fitting Model
2025-10-19 20:14:45,348:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001)
2025-10-19 20:14:45,348:INFO:create_model() successfully completed......................................
2025-10-19 20:14:45,663:INFO:Initializing create_model()
2025-10-19 20:14:45,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:14:45,663:INFO:Checking exceptions
2025-10-19 20:14:45,665:INFO:Importing libraries
2025-10-19 20:14:45,666:INFO:Copying training dataset
2025-10-19 20:14:46,183:INFO:Defining folds
2025-10-19 20:14:46,183:INFO:Declaring metric variables
2025-10-19 20:14:46,184:INFO:Importing untrained model
2025-10-19 20:14:46,184:INFO:Declaring custom model
2025-10-19 20:14:46,184:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-19 20:14:46,190:INFO:Cross validation set to False
2025-10-19 20:14:46,190:INFO:Fitting Model
2025-10-19 20:14:53,270:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-10-19 20:14:53,270:INFO:create_model() successfully completed......................................
2025-10-19 20:14:53,647:INFO:_master_model_container: 19
2025-10-19 20:14:53,648:INFO:_display_container: 2
2025-10-19 20:14:53,649:INFO:[GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001), OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)]
2025-10-19 20:14:53,650:INFO:compare_models() successfully completed......................................
2025-10-19 20:14:53,669:INFO:Initializing tune_model()
2025-10-19 20:14:53,669:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 20:14:53,669:INFO:Checking exceptions
2025-10-19 20:14:53,875:INFO:Copying training dataset
2025-10-19 20:14:54,188:INFO:Checking base model
2025-10-19 20:14:54,189:INFO:Base model : Gradient Boosting Regressor
2025-10-19 20:14:54,195:INFO:Declaring metric variables
2025-10-19 20:14:54,201:INFO:Defining Hyperparameters
2025-10-19 20:14:54,465:INFO:Tuning with n_jobs=1
2025-10-19 20:14:54,465:INFO:Initializing RandomizedSearchCV
2025-10-19 20:24:59,135:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.4}
2025-10-19 20:24:59,137:INFO:Hyperparameter search completed
2025-10-19 20:24:59,137:INFO:SubProcess create_model() called ==================================
2025-10-19 20:24:59,140:INFO:Initializing create_model()
2025-10-19 20:24:59,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CD35F890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 130, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 1, 'learning_rate': 0.4})
2025-10-19 20:24:59,140:INFO:Checking exceptions
2025-10-19 20:24:59,140:INFO:Importing libraries
2025-10-19 20:24:59,140:INFO:Copying training dataset
2025-10-19 20:24:59,640:INFO:Defining folds
2025-10-19 20:24:59,640:INFO:Declaring metric variables
2025-10-19 20:24:59,647:INFO:Importing untrained model
2025-10-19 20:24:59,647:INFO:Declaring custom model
2025-10-19 20:24:59,657:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 20:24:59,669:INFO:Starting cross validation
2025-10-19 20:24:59,674:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:26:04,062:INFO:Calculating mean and std
2025-10-19 20:26:04,064:INFO:Creating metrics dataframe
2025-10-19 20:26:04,072:INFO:Finalizing model
2025-10-19 20:26:19,498:INFO:Uploading results into container
2025-10-19 20:26:19,501:INFO:Uploading model into container now
2025-10-19 20:26:19,503:INFO:_master_model_container: 20
2025-10-19 20:26:19,503:INFO:_display_container: 3
2025-10-19 20:26:19,504:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.4, loss='squared_error',
                          max_depth=1, max_features=1.0, max_leaf_nodes=None,
                          min_impurity_decrease=0.4, min_samples_leaf=4,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=130, n_iter_no_change=None,
                          random_state=42, subsample=0.6, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 20:26:19,505:INFO:create_model() successfully completed......................................
2025-10-19 20:26:19,907:INFO:SubProcess create_model() end ==================================
2025-10-19 20:26:19,908:INFO:choose_better activated
2025-10-19 20:26:19,929:INFO:SubProcess create_model() called ==================================
2025-10-19 20:26:19,942:INFO:Initializing create_model()
2025-10-19 20:26:19,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:26:19,945:INFO:Checking exceptions
2025-10-19 20:26:19,960:INFO:Importing libraries
2025-10-19 20:26:19,961:INFO:Copying training dataset
2025-10-19 20:26:20,733:INFO:Defining folds
2025-10-19 20:26:20,733:INFO:Declaring metric variables
2025-10-19 20:26:20,734:INFO:Importing untrained model
2025-10-19 20:26:20,734:INFO:Declaring custom model
2025-10-19 20:26:20,736:INFO:Gradient Boosting Regressor Imported successfully
2025-10-19 20:26:20,737:INFO:Starting cross validation
2025-10-19 20:26:20,750:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:28:49,199:INFO:Calculating mean and std
2025-10-19 20:28:49,200:INFO:Creating metrics dataframe
2025-10-19 20:28:49,204:INFO:Finalizing model
2025-10-19 20:29:25,720:INFO:Uploading results into container
2025-10-19 20:29:25,721:INFO:Uploading model into container now
2025-10-19 20:29:25,721:INFO:_master_model_container: 21
2025-10-19 20:29:25,721:INFO:_display_container: 4
2025-10-19 20:29:25,723:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 20:29:25,723:INFO:create_model() successfully completed......................................
2025-10-19 20:29:25,972:INFO:SubProcess create_model() end ==================================
2025-10-19 20:29:25,973:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for RMSE is 0.3444
2025-10-19 20:29:25,974:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.4, loss='squared_error',
                          max_depth=1, max_features=1.0, max_leaf_nodes=None,
                          min_impurity_decrease=0.4, min_samples_leaf=4,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=130, n_iter_no_change=None,
                          random_state=42, subsample=0.6, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) result for RMSE is 0.347
2025-10-19 20:29:25,974:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) is best model
2025-10-19 20:29:25,974:INFO:choose_better completed
2025-10-19 20:29:25,975:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-19 20:29:25,992:INFO:_master_model_container: 21
2025-10-19 20:29:25,993:INFO:_display_container: 3
2025-10-19 20:29:25,993:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-19 20:29:25,994:INFO:tune_model() successfully completed......................................
2025-10-19 20:29:26,278:INFO:Initializing tune_model()
2025-10-19 20:29:26,278:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 20:29:26,278:INFO:Checking exceptions
2025-10-19 20:29:26,543:INFO:Copying training dataset
2025-10-19 20:29:26,827:INFO:Checking base model
2025-10-19 20:29:26,828:INFO:Base model : Ridge Regression
2025-10-19 20:29:26,837:INFO:Declaring metric variables
2025-10-19 20:29:26,848:INFO:Defining Hyperparameters
2025-10-19 20:29:27,096:INFO:Tuning with n_jobs=1
2025-10-19 20:29:27,096:INFO:Initializing RandomizedSearchCV
2025-10-19 20:32:01,309:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.0841e-17): result may not be accurate.

2025-10-19 20:32:04,483:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.92961e-17): result may not be accurate.

2025-10-19 20:32:08,223:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.00098e-17): result may not be accurate.

2025-10-19 20:32:11,566:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.88153e-17): result may not be accurate.

2025-10-19 20:32:14,649:WARNING:c:\Users\Usuario\anaconda3\envs\nuevo_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.04753e-17): result may not be accurate.

2025-10-19 20:32:32,770:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 5.48}
2025-10-19 20:32:32,773:INFO:Hyperparameter search completed
2025-10-19 20:32:32,774:INFO:SubProcess create_model() called ==================================
2025-10-19 20:32:32,775:INFO:Initializing create_model()
2025-10-19 20:32:32,776:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128A6E69C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 5.48})
2025-10-19 20:32:32,776:INFO:Checking exceptions
2025-10-19 20:32:32,776:INFO:Importing libraries
2025-10-19 20:32:32,776:INFO:Copying training dataset
2025-10-19 20:32:33,072:INFO:Defining folds
2025-10-19 20:32:33,074:INFO:Declaring metric variables
2025-10-19 20:32:33,076:INFO:Importing untrained model
2025-10-19 20:32:33,076:INFO:Declaring custom model
2025-10-19 20:32:33,080:INFO:Ridge Regression Imported successfully
2025-10-19 20:32:33,088:INFO:Starting cross validation
2025-10-19 20:32:33,094:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:32:51,924:INFO:Calculating mean and std
2025-10-19 20:32:51,925:INFO:Creating metrics dataframe
2025-10-19 20:32:51,930:INFO:Finalizing model
2025-10-19 20:32:55,577:INFO:Uploading results into container
2025-10-19 20:32:55,577:INFO:Uploading model into container now
2025-10-19 20:32:55,578:INFO:_master_model_container: 22
2025-10-19 20:32:55,578:INFO:_display_container: 4
2025-10-19 20:32:55,579:INFO:Ridge(alpha=5.48, copy_X=True, fit_intercept=False, max_iter=None,
      positive=False, random_state=42, solver='auto', tol=0.0001)
2025-10-19 20:32:55,579:INFO:create_model() successfully completed......................................
2025-10-19 20:32:55,798:INFO:SubProcess create_model() end ==================================
2025-10-19 20:32:55,798:INFO:choose_better activated
2025-10-19 20:32:55,804:INFO:SubProcess create_model() called ==================================
2025-10-19 20:32:55,806:INFO:Initializing create_model()
2025-10-19 20:32:55,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:32:55,806:INFO:Checking exceptions
2025-10-19 20:32:55,808:INFO:Importing libraries
2025-10-19 20:32:55,808:INFO:Copying training dataset
2025-10-19 20:32:56,097:INFO:Defining folds
2025-10-19 20:32:56,097:INFO:Declaring metric variables
2025-10-19 20:32:56,097:INFO:Importing untrained model
2025-10-19 20:32:56,097:INFO:Declaring custom model
2025-10-19 20:32:56,098:INFO:Ridge Regression Imported successfully
2025-10-19 20:32:56,098:INFO:Starting cross validation
2025-10-19 20:32:56,104:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:33:12,608:INFO:Calculating mean and std
2025-10-19 20:33:12,608:INFO:Creating metrics dataframe
2025-10-19 20:33:12,610:INFO:Finalizing model
2025-10-19 20:33:16,890:INFO:Uploading results into container
2025-10-19 20:33:16,891:INFO:Uploading model into container now
2025-10-19 20:33:16,891:INFO:_master_model_container: 23
2025-10-19 20:33:16,891:INFO:_display_container: 5
2025-10-19 20:33:16,891:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001)
2025-10-19 20:33:16,892:INFO:create_model() successfully completed......................................
2025-10-19 20:33:17,074:INFO:SubProcess create_model() end ==================================
2025-10-19 20:33:17,075:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=42, solver='auto', tol=0.0001) result for RMSE is 0.3447
2025-10-19 20:33:17,075:INFO:Ridge(alpha=5.48, copy_X=True, fit_intercept=False, max_iter=None,
      positive=False, random_state=42, solver='auto', tol=0.0001) result for RMSE is 0.3445
2025-10-19 20:33:17,076:INFO:Ridge(alpha=5.48, copy_X=True, fit_intercept=False, max_iter=None,
      positive=False, random_state=42, solver='auto', tol=0.0001) is best model
2025-10-19 20:33:17,076:INFO:choose_better completed
2025-10-19 20:33:17,084:INFO:_master_model_container: 23
2025-10-19 20:33:17,085:INFO:_display_container: 4
2025-10-19 20:33:17,085:INFO:Ridge(alpha=5.48, copy_X=True, fit_intercept=False, max_iter=None,
      positive=False, random_state=42, solver='auto', tol=0.0001)
2025-10-19 20:33:17,085:INFO:tune_model() successfully completed......................................
2025-10-19 20:33:17,274:INFO:Initializing tune_model()
2025-10-19 20:33:17,275:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None), fold=None, round=4, n_iter=10, custom_grid=None, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-19 20:33:17,275:INFO:Checking exceptions
2025-10-19 20:33:17,400:INFO:Copying training dataset
2025-10-19 20:33:17,586:INFO:Checking base model
2025-10-19 20:33:17,586:INFO:Base model : Orthogonal Matching Pursuit
2025-10-19 20:33:17,591:INFO:Declaring metric variables
2025-10-19 20:33:17,594:INFO:Defining Hyperparameters
2025-10-19 20:33:17,795:INFO:Tuning with n_jobs=1
2025-10-19 20:33:17,795:INFO:Initializing RandomizedSearchCV
2025-10-19 20:35:48,401:INFO:best_params: {'actual_estimator__n_nonzero_coefs': 17, 'actual_estimator__fit_intercept': False}
2025-10-19 20:35:48,402:INFO:Hyperparameter search completed
2025-10-19 20:35:48,403:INFO:SubProcess create_model() called ==================================
2025-10-19 20:35:48,405:INFO:Initializing create_model()
2025-10-19 20:35:48,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128A8431ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_nonzero_coefs': 17, 'fit_intercept': False})
2025-10-19 20:35:48,405:INFO:Checking exceptions
2025-10-19 20:35:48,406:INFO:Importing libraries
2025-10-19 20:35:48,406:INFO:Copying training dataset
2025-10-19 20:35:48,764:INFO:Defining folds
2025-10-19 20:35:48,764:INFO:Declaring metric variables
2025-10-19 20:35:48,769:INFO:Importing untrained model
2025-10-19 20:35:48,770:INFO:Declaring custom model
2025-10-19 20:35:48,777:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-19 20:35:48,790:INFO:Starting cross validation
2025-10-19 20:35:48,796:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:36:06,144:INFO:Calculating mean and std
2025-10-19 20:36:06,145:INFO:Creating metrics dataframe
2025-10-19 20:36:06,149:INFO:Finalizing model
2025-10-19 20:36:09,889:INFO:Uploading results into container
2025-10-19 20:36:09,890:INFO:Uploading model into container now
2025-10-19 20:36:09,891:INFO:_master_model_container: 24
2025-10-19 20:36:09,891:INFO:_display_container: 5
2025-10-19 20:36:09,891:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=17,
                          precompute='auto', tol=None)
2025-10-19 20:36:09,892:INFO:create_model() successfully completed......................................
2025-10-19 20:36:10,094:INFO:SubProcess create_model() end ==================================
2025-10-19 20:36:10,094:INFO:choose_better activated
2025-10-19 20:36:10,098:INFO:SubProcess create_model() called ==================================
2025-10-19 20:36:10,100:INFO:Initializing create_model()
2025-10-19 20:36:10,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:36:10,101:INFO:Checking exceptions
2025-10-19 20:36:10,102:INFO:Importing libraries
2025-10-19 20:36:10,102:INFO:Copying training dataset
2025-10-19 20:36:10,326:INFO:Defining folds
2025-10-19 20:36:10,326:INFO:Declaring metric variables
2025-10-19 20:36:10,327:INFO:Importing untrained model
2025-10-19 20:36:10,327:INFO:Declaring custom model
2025-10-19 20:36:10,327:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-19 20:36:10,327:INFO:Starting cross validation
2025-10-19 20:36:10,330:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:36:25,554:INFO:Calculating mean and std
2025-10-19 20:36:25,554:INFO:Creating metrics dataframe
2025-10-19 20:36:25,557:INFO:Finalizing model
2025-10-19 20:36:28,854:INFO:Uploading results into container
2025-10-19 20:36:28,854:INFO:Uploading model into container now
2025-10-19 20:36:28,855:INFO:_master_model_container: 25
2025-10-19 20:36:28,855:INFO:_display_container: 6
2025-10-19 20:36:28,855:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-10-19 20:36:28,855:INFO:create_model() successfully completed......................................
2025-10-19 20:36:29,000:INFO:SubProcess create_model() end ==================================
2025-10-19 20:36:29,001:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None) result for RMSE is 0.3447
2025-10-19 20:36:29,001:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=17,
                          precompute='auto', tol=None) result for RMSE is 0.3446
2025-10-19 20:36:29,001:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=17,
                          precompute='auto', tol=None) is best model
2025-10-19 20:36:29,001:INFO:choose_better completed
2025-10-19 20:36:29,009:INFO:_master_model_container: 25
2025-10-19 20:36:29,009:INFO:_display_container: 5
2025-10-19 20:36:29,010:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=17,
                          precompute='auto', tol=None)
2025-10-19 20:36:29,010:INFO:tune_model() successfully completed......................................
2025-10-19 20:36:29,153:INFO:Initializing blend_models()
2025-10-19 20:36:29,153:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator_list=[GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=42, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False), Ridge(alpha=5.48, copy_X=True, fit_intercept=False, max_iter=None,
      positive=False, random_state=42, solver='auto', tol=0.0001), OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=17,
                          precompute='auto', tol=None)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-19 20:36:29,153:INFO:Checking exceptions
2025-10-19 20:36:29,259:INFO:Importing libraries
2025-10-19 20:36:29,259:INFO:Copying training dataset
2025-10-19 20:36:29,264:INFO:Getting model names
2025-10-19 20:36:29,268:INFO:SubProcess create_model() called ==================================
2025-10-19 20:36:29,271:INFO:Initializing create_model()
2025-10-19 20:36:29,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False)),
                            ('Ridge Regression',
                             Ridge(alpha=5.48, copy_X=True, fit_intercept=False,
                                   max_iter=None, positive=False,
                                   random_state=42, solver='auto',
                                   tol=0.0001)),
                            ('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=17,
                                                       precompute='auto',
                                                       tol=None))],
                n_jobs=1, verbose=False, weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
6265     U18895
54886    U04403
76820    U08748
860      U15770
15795    U02930
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000128CD39A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:36:29,271:INFO:Checking exceptions
2025-10-19 20:36:29,271:INFO:Importing libraries
2025-10-19 20:36:29,271:INFO:Copying training dataset
2025-10-19 20:36:29,514:INFO:Defining folds
2025-10-19 20:36:29,515:INFO:Declaring metric variables
2025-10-19 20:36:29,517:INFO:Importing untrained model
2025-10-19 20:36:29,517:INFO:Declaring custom model
2025-10-19 20:36:29,522:INFO:Voting Regressor Imported successfully
2025-10-19 20:36:29,528:INFO:Starting cross validation
2025-10-19 20:36:29,532:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-19 20:37:42,203:INFO:Calculating mean and std
2025-10-19 20:37:42,204:INFO:Creating metrics dataframe
2025-10-19 20:37:42,211:INFO:Finalizing model
2025-10-19 20:37:58,970:INFO:Uploading results into container
2025-10-19 20:37:58,971:INFO:Uploading model into container now
2025-10-19 20:37:58,971:INFO:_master_model_container: 26
2025-10-19 20:37:58,972:INFO:_display_container: 6
2025-10-19 20:37:58,974:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False)),
                            ('Ridge Regression',
                             Ridge(alpha=5.48, copy_X=True, fit_intercept=False,
                                   max_iter=None, positive=False,
                                   random_state=42, solver='auto',
                                   tol=0.0001)),
                            ('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=17,
                                                       precompute='auto',
                                                       tol=None))],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 20:37:58,974:INFO:create_model() successfully completed......................................
2025-10-19 20:37:59,147:INFO:SubProcess create_model() end ==================================
2025-10-19 20:37:59,155:INFO:_master_model_container: 26
2025-10-19 20:37:59,155:INFO:_display_container: 6
2025-10-19 20:37:59,159:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False)),
                            ('Ridge Regression',
                             Ridge(alpha=5.48, copy_X=True, fit_intercept=False,
                                   max_iter=None, positive=False,
                                   random_state=42, solver='auto',
                                   tol=0.0001)),
                            ('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=17,
                                                       precompute='auto',
                                                       tol=None))],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 20:37:59,159:INFO:blend_models() successfully completed......................................
2025-10-19 20:37:59,303:INFO:Initializing finalize_model()
2025-10-19 20:37:59,304:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False)),
                            ('Ridge Regression',
                             Ridge(alpha=5.48, copy_X=True, fit_intercept=False,
                                   max_iter=None, positive=False,
                                   random_state=42, solver='auto',
                                   tol=0.0001)),
                            ('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=17,
                                                       precompute='auto',
                                                       tol=None))],
                n_jobs=1, verbose=False, weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-19 20:37:59,306:INFO:Finalizing VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False)),
                            ('Ridge Regression',
                             Ridge(alpha=5.48, copy_X=True, fit_intercept=False,
                                   max_iter=None, positive=False,
                                   random_state=42, solver='auto',
                                   tol=0.0001)),
                            ('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=17,
                                                       precompute='auto',
                                                       tol=None))],
                n_jobs=1, verbose=False, weights=None)
2025-10-19 20:37:59,489:INFO:Initializing create_model()
2025-10-19 20:37:59,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='squared_error',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_n...
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False)),
                            ('Ridge Regression',
                             Ridge(alpha=5.48, copy_X=True, fit_intercept=False,
                                   max_iter=None, positive=False,
                                   random_state=42, solver='auto',
                                   tol=0.0001)),
                            ('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=17,
                                                       precompute='auto',
                                                       tol=None))],
                n_jobs=1, verbose=False, weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=11092    U10893
53797    U09324
16599    U05364
53820    U11389
60363    U18131
          ...  
32204    U18073
64876    U11693
31646    U11605
8477     U00822
40193    U18945
Name: id_usuario, Length: 80004, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-19 20:37:59,489:INFO:Checking exceptions
2025-10-19 20:37:59,490:INFO:Importing libraries
2025-10-19 20:37:59,491:INFO:Copying training dataset
2025-10-19 20:37:59,520:INFO:Defining folds
2025-10-19 20:37:59,520:INFO:Declaring metric variables
2025-10-19 20:37:59,521:INFO:Importing untrained model
2025-10-19 20:37:59,521:INFO:Declaring custom model
2025-10-19 20:37:59,522:INFO:Voting Regressor Imported successfully
2025-10-19 20:37:59,524:INFO:Cross validation set to False
2025-10-19 20:37:59,525:INFO:Fitting Model
2025-10-19 20:38:25,492:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                        validation_fraction=0.1,
                                                                        verbose=0,
                                                                        warm_start=False)),
                                             ('Ridge Regression',
                                              Ridge(alpha=5.48, copy_X=True,
                                                    fit_intercept=False,
                                                    max_iter=None,
                                                    positive=False,
                                                    random_state=42,
                                                    solver='auto',
                                                    tol=0.0001)),
                                             ('Orthogonal Matching Pursuit',
                                              OrthogonalMatchingPursuit(fit_intercept=False,
                                                                        n_nonzero_coefs=17,
                                                                        precompute='auto',
                                                                        tol=None))],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 20:38:25,493:INFO:create_model() successfully completed......................................
2025-10-19 20:38:25,649:INFO:_master_model_container: 26
2025-10-19 20:38:25,649:INFO:_display_container: 6
2025-10-19 20:38:25,670:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                        validation_fraction=0.1,
                                                                        verbose=0,
                                                                        warm_start=False)),
                                             ('Ridge Regression',
                                              Ridge(alpha=5.48, copy_X=True,
                                                    fit_intercept=False,
                                                    max_iter=None,
                                                    positive=False,
                                                    random_state=42,
                                                    solver='auto',
                                                    tol=0.0001)),
                                             ('Orthogonal Matching Pursuit',
                                              OrthogonalMatchingPursuit(fit_intercept=False,
                                                                        n_nonzero_coefs=17,
                                                                        precompute='auto',
                                                                        tol=None))],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 20:38:25,670:INFO:finalize_model() successfully completed......................................
2025-10-19 20:38:25,846:INFO:Initializing save_model()
2025-10-19 20:38:25,846:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                        validation_fraction=0.1,
                                                                        verbose=0,
                                                                        warm_start=False)),
                                             ('Ridge Regression',
                                              Ridge(alpha=5.48, copy_X=True,
                                                    fit_intercept=False,
                                                    max_iter=None,
                                                    positive=False,
                                                    random_state=42,
                                                    solver='auto',
                                                    tol=0.0001)),
                                             ('Orthogonal Matching Pursuit',
                                              OrthogonalMatchingPursuit(fit_intercept=False,
                                                                        n_nonzero_coefs=17,
                                                                        precompute='auto',
                                                                        tol=None))],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), model_name=modelo_reg_rating_v2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-10-19 20:38:25,847:INFO:Adding model into prep_pipe
2025-10-19 20:38:25,847:WARNING:Only Model saved as it was a pipeline.
2025-10-19 20:38:25,880:INFO:modelo_reg_rating_v2.pkl saved in current working directory
2025-10-19 20:38:25,900:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                        validation_fraction=0.1,
                                                                        verbose=0,
                                                                        warm_start=False)),
                                             ('Ridge Regression',
                                              Ridge(alpha=5.48, copy_X=True,
                                                    fit_intercept=False,
                                                    max_iter=None,
                                                    positive=False,
                                                    random_state=42,
                                                    solver='auto',
                                                    tol=0.0001)),
                                             ('Orthogonal Matching Pursuit',
                                              OrthogonalMatchingPursuit(fit_intercept=False,
                                                                        n_nonzero_coefs=17,
                                                                        precompute='auto',
                                                                        tol=None))],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False)
2025-10-19 20:38:25,900:INFO:save_model() successfully completed......................................
2025-10-19 20:38:26,261:INFO:Initializing predict_model()
2025-10-19 20:38:26,261:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000128CEFAD190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                                        validation_fraction=0.1,
                                                                        verbose=0,
                                                                        warm_start=False)),
                                             ('Ridge Regression',
                                              Ridge(alpha=5.48, copy_X=True,
                                                    fit_intercept=False,
                                                    max_iter=None,
                                                    positive=False,
                                                    random_state=42,
                                                    solver='auto',
                                                    tol=0.0001)),
                                             ('Orthogonal Matching Pursuit',
                                              OrthogonalMatchingPursuit(fit_intercept=False,
                                                                        n_nonzero_coefs=17,
                                                                        precompute='auto',
                                                                        tol=None))],
                                 n_jobs=1, verbose=False, weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000128A8405300>)
2025-10-19 20:38:26,261:INFO:Checking exceptions
2025-10-19 20:38:26,261:INFO:Preloading libraries
2025-10-19 20:38:26,263:INFO:Set up data.
2025-10-19 20:38:26,292:INFO:Set up index.
2025-10-21 08:48:29,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 08:48:29,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 08:48:29,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 08:48:29,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 08:48:33,074:INFO:PyCaret ClassificationExperiment
2025-10-21 08:48:33,074:INFO:Logging name: clf-default-name
2025-10-21 08:48:33,074:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-21 08:48:33,074:INFO:version 3.3.2
2025-10-21 08:48:33,074:INFO:Initializing setup()
2025-10-21 08:48:33,074:INFO:self.USI: 2117
2025-10-21 08:48:33,074:INFO:self._variable_keys: {'memory', 'gpu_n_jobs_param', 'exp_id', 'exp_name_log', 'X', 'y_train', 'log_plots_param', 'fold_shuffle_param', '_available_plots', 'fix_imbalance', 'gpu_param', 'y_test', 'n_jobs_param', 'fold_groups_param', 'seed', 'fold_generator', 'is_multiclass', '_ml_usecase', 'X_test', 'target_param', 'X_train', 'idx', 'logging_param', 'y', 'USI', 'html_param', 'pipeline', 'data'}
2025-10-21 08:48:33,074:INFO:Checking environment
2025-10-21 08:48:33,074:INFO:python_version: 3.11.13
2025-10-21 08:48:33,074:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-21 08:48:33,074:INFO:machine: AMD64
2025-10-21 08:48:33,074:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-21 08:48:33,080:INFO:Memory: svmem(total=16856211456, available=1866780672, percent=88.9, used=14989430784, free=1866780672)
2025-10-21 08:48:33,080:INFO:Physical Core: 4
2025-10-21 08:48:33,080:INFO:Logical Core: 8
2025-10-21 08:48:33,080:INFO:Checking libraries
2025-10-21 08:48:33,080:INFO:System:
2025-10-21 08:48:33,080:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-21 08:48:33,080:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-21 08:48:33,080:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-21 08:48:33,080:INFO:PyCaret required dependencies:
2025-10-21 08:48:34,360:INFO:                 pip: 25.2
2025-10-21 08:48:34,361:INFO:          setuptools: 80.9.0
2025-10-21 08:48:34,361:INFO:             pycaret: 3.3.2
2025-10-21 08:48:34,361:INFO:             IPython: 9.6.0
2025-10-21 08:48:34,361:INFO:          ipywidgets: 8.1.7
2025-10-21 08:48:34,361:INFO:                tqdm: 4.67.1
2025-10-21 08:48:34,361:INFO:               numpy: 1.26.4
2025-10-21 08:48:34,361:INFO:              pandas: 2.1.4
2025-10-21 08:48:34,361:INFO:              jinja2: 3.1.6
2025-10-21 08:48:34,361:INFO:               scipy: 1.11.4
2025-10-21 08:48:34,361:INFO:              joblib: 1.3.2
2025-10-21 08:48:34,361:INFO:             sklearn: 1.4.2
2025-10-21 08:48:34,361:INFO:                pyod: 2.0.5
2025-10-21 08:48:34,361:INFO:            imblearn: 0.14.0
2025-10-21 08:48:34,361:INFO:   category_encoders: 2.7.0
2025-10-21 08:48:34,361:INFO:            lightgbm: 4.6.0
2025-10-21 08:48:34,361:INFO:               numba: 0.61.0
2025-10-21 08:48:34,361:INFO:            requests: 2.32.5
2025-10-21 08:48:34,361:INFO:          matplotlib: 3.7.5
2025-10-21 08:48:34,361:INFO:          scikitplot: 0.3.7
2025-10-21 08:48:34,361:INFO:         yellowbrick: 1.5
2025-10-21 08:48:34,361:INFO:              plotly: 5.24.1
2025-10-21 08:48:34,361:INFO:    plotly-resampler: Not installed
2025-10-21 08:48:34,361:INFO:             kaleido: 1.1.0
2025-10-21 08:48:34,361:INFO:           schemdraw: 0.15
2025-10-21 08:48:34,361:INFO:         statsmodels: 0.14.5
2025-10-21 08:48:34,361:INFO:              sktime: 0.26.0
2025-10-21 08:48:34,361:INFO:               tbats: 1.1.3
2025-10-21 08:48:34,361:INFO:            pmdarima: 2.0.4
2025-10-21 08:48:34,361:INFO:              psutil: 7.1.1
2025-10-21 08:48:34,361:INFO:          markupsafe: 3.0.3
2025-10-21 08:48:34,362:INFO:             pickle5: Not installed
2025-10-21 08:48:34,362:INFO:         cloudpickle: 3.1.1
2025-10-21 08:48:34,362:INFO:         deprecation: 2.1.0
2025-10-21 08:48:34,362:INFO:              xxhash: 3.6.0
2025-10-21 08:48:34,362:INFO:           wurlitzer: Not installed
2025-10-21 08:48:34,362:INFO:PyCaret optional dependencies:
2025-10-21 08:48:39,356:INFO:                shap: 0.44.1
2025-10-21 08:48:39,356:INFO:           interpret: 0.7.3
2025-10-21 08:48:39,357:INFO:                umap: 0.5.7
2025-10-21 08:48:39,357:INFO:     ydata_profiling: 4.17.0
2025-10-21 08:48:39,357:INFO:  explainerdashboard: 0.5.1
2025-10-21 08:48:39,357:INFO:             autoviz: Not installed
2025-10-21 08:48:39,357:INFO:           fairlearn: 0.7.0
2025-10-21 08:48:39,357:INFO:          deepchecks: Not installed
2025-10-21 08:48:39,357:INFO:             xgboost: 3.1.0
2025-10-21 08:48:39,357:INFO:            catboost: 1.2.8
2025-10-21 08:48:39,357:INFO:              kmodes: 0.12.2
2025-10-21 08:48:39,357:INFO:             mlxtend: 0.23.4
2025-10-21 08:48:39,357:INFO:       statsforecast: 1.5.0
2025-10-21 08:48:39,357:INFO:        tune_sklearn: Not installed
2025-10-21 08:48:39,357:INFO:                 ray: Not installed
2025-10-21 08:48:39,357:INFO:            hyperopt: 0.2.7
2025-10-21 08:48:39,357:INFO:              optuna: 4.5.0
2025-10-21 08:48:39,357:INFO:               skopt: 0.10.2
2025-10-21 08:48:39,357:INFO:              mlflow: 3.5.0
2025-10-21 08:48:39,357:INFO:              gradio: 5.49.1
2025-10-21 08:48:39,357:INFO:             fastapi: 0.119.1
2025-10-21 08:48:39,357:INFO:             uvicorn: 0.38.0
2025-10-21 08:48:39,357:INFO:              m2cgen: 0.10.0
2025-10-21 08:48:39,358:INFO:           evidently: 0.4.40
2025-10-21 08:48:39,358:INFO:               fugue: 0.8.7
2025-10-21 08:48:39,358:INFO:           streamlit: Not installed
2025-10-21 08:48:39,358:INFO:             prophet: Not installed
2025-10-21 08:48:39,358:INFO:None
2025-10-21 08:48:39,358:INFO:Set up data.
2025-10-21 08:48:39,560:INFO:Set up folding strategy.
2025-10-21 08:48:39,787:INFO:Set up train/test split.
2025-10-21 08:48:40,012:INFO:Set up index.
2025-10-21 08:48:40,026:INFO:Assigning column types.
2025-10-21 08:48:40,264:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-21 08:48:40,304:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-21 08:48:40,311:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 08:48:40,343:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 08:48:40,345:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 08:48:40,413:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-21 08:48:40,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 08:48:40,436:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 08:48:40,438:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 08:48:40,439:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-21 08:48:40,473:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 08:48:40,494:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 08:48:40,496:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 08:48:40,532:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 08:48:40,555:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 08:48:40,558:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 08:48:40,559:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-21 08:48:40,616:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 08:48:40,618:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 08:48:40,677:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 08:48:40,679:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 08:48:40,681:INFO:Preparing preprocessing pipeline...
2025-10-21 08:48:40,719:INFO:Set up simple imputation.
2025-10-21 08:48:40,885:INFO:Set up encoding of ordinal features.
2025-10-21 08:48:40,963:INFO:Set up encoding of categorical features.
2025-10-21 08:48:40,967:INFO:Set up removing multicollinearity.
2025-10-21 08:48:41,003:INFO:Set up column name cleaning.
2025-10-21 08:48:46,430:INFO:Finished creating preprocessing pipeline.
2025-10-21 08:48:46,449:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-21 08:48:46,449:INFO:Creating final display dataframe.
2025-10-21 08:48:49,643:INFO:Setup _display_container:                     Description             Value
0                    Session id              1968
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 28)
4        Transformed data shape       (80004, 97)
5   Transformed train set shape       (56002, 97)
6    Transformed test set shape       (24002, 97)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              2117
2025-10-21 08:48:49,712:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 08:48:49,714:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 08:48:49,777:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 08:48:49,779:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 08:48:49,781:INFO:setup() successfully completed in 17.04s...............
2025-10-21 08:48:49,781:INFO:Initializing compare_models()
2025-10-21 08:48:49,781:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-21 08:48:49,781:INFO:Checking exceptions
2025-10-21 08:48:49,967:INFO:Preparing display monitor
2025-10-21 08:48:49,994:INFO:Initializing Logistic Regression
2025-10-21 08:48:49,994:INFO:Total runtime is 0.0 minutes
2025-10-21 08:48:49,998:INFO:SubProcess create_model() called ==================================
2025-10-21 08:48:50,000:INFO:Initializing create_model()
2025-10-21 08:48:50,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:48:50,000:INFO:Checking exceptions
2025-10-21 08:48:50,000:INFO:Importing libraries
2025-10-21 08:48:50,000:INFO:Copying training dataset
2025-10-21 08:48:50,283:INFO:Defining folds
2025-10-21 08:48:50,283:INFO:Declaring metric variables
2025-10-21 08:48:50,286:INFO:Importing untrained model
2025-10-21 08:48:50,290:INFO:Logistic Regression Imported successfully
2025-10-21 08:48:50,295:INFO:Starting cross validation
2025-10-21 08:48:50,298:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:49:00,213:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-21 08:49:09,498:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-21 08:49:18,737:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-21 08:49:28,089:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-21 08:49:37,330:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-21 08:49:37,618:INFO:Calculating mean and std
2025-10-21 08:49:37,619:INFO:Creating metrics dataframe
2025-10-21 08:49:37,621:INFO:Uploading results into container
2025-10-21 08:49:37,621:INFO:Uploading model into container now
2025-10-21 08:49:37,621:INFO:_master_model_container: 1
2025-10-21 08:49:37,621:INFO:_display_container: 2
2025-10-21 08:49:37,622:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1968, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-21 08:49:37,622:INFO:create_model() successfully completed......................................
2025-10-21 08:49:37,775:INFO:SubProcess create_model() end ==================================
2025-10-21 08:49:37,775:INFO:Creating metrics dataframe
2025-10-21 08:49:37,779:INFO:Initializing K Neighbors Classifier
2025-10-21 08:49:37,779:INFO:Total runtime is 0.7964289426803589 minutes
2025-10-21 08:49:37,781:INFO:SubProcess create_model() called ==================================
2025-10-21 08:49:37,782:INFO:Initializing create_model()
2025-10-21 08:49:37,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:49:37,783:INFO:Checking exceptions
2025-10-21 08:49:37,783:INFO:Importing libraries
2025-10-21 08:49:37,783:INFO:Copying training dataset
2025-10-21 08:49:38,027:INFO:Defining folds
2025-10-21 08:49:38,027:INFO:Declaring metric variables
2025-10-21 08:49:38,031:INFO:Importing untrained model
2025-10-21 08:49:38,033:INFO:K Neighbors Classifier Imported successfully
2025-10-21 08:49:38,039:INFO:Starting cross validation
2025-10-21 08:49:38,043:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:50:06,890:INFO:Calculating mean and std
2025-10-21 08:50:06,891:INFO:Creating metrics dataframe
2025-10-21 08:50:06,894:INFO:Uploading results into container
2025-10-21 08:50:06,894:INFO:Uploading model into container now
2025-10-21 08:50:06,894:INFO:_master_model_container: 2
2025-10-21 08:50:06,894:INFO:_display_container: 2
2025-10-21 08:50:06,896:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-21 08:50:06,896:INFO:create_model() successfully completed......................................
2025-10-21 08:50:07,048:INFO:SubProcess create_model() end ==================================
2025-10-21 08:50:07,049:INFO:Creating metrics dataframe
2025-10-21 08:50:07,056:INFO:Initializing Naive Bayes
2025-10-21 08:50:07,056:INFO:Total runtime is 1.284366794427236 minutes
2025-10-21 08:50:07,059:INFO:SubProcess create_model() called ==================================
2025-10-21 08:50:07,061:INFO:Initializing create_model()
2025-10-21 08:50:07,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:50:07,061:INFO:Checking exceptions
2025-10-21 08:50:07,061:INFO:Importing libraries
2025-10-21 08:50:07,061:INFO:Copying training dataset
2025-10-21 08:50:07,309:INFO:Defining folds
2025-10-21 08:50:07,310:INFO:Declaring metric variables
2025-10-21 08:50:07,313:INFO:Importing untrained model
2025-10-21 08:50:07,315:INFO:Naive Bayes Imported successfully
2025-10-21 08:50:07,320:INFO:Starting cross validation
2025-10-21 08:50:07,323:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:50:16,545:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 08:50:22,985:INFO:Calculating mean and std
2025-10-21 08:50:22,987:INFO:Creating metrics dataframe
2025-10-21 08:50:22,988:INFO:Uploading results into container
2025-10-21 08:50:22,989:INFO:Uploading model into container now
2025-10-21 08:50:22,989:INFO:_master_model_container: 3
2025-10-21 08:50:22,989:INFO:_display_container: 2
2025-10-21 08:50:22,989:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-21 08:50:22,989:INFO:create_model() successfully completed......................................
2025-10-21 08:50:23,155:INFO:SubProcess create_model() end ==================================
2025-10-21 08:50:23,155:INFO:Creating metrics dataframe
2025-10-21 08:50:23,165:INFO:Initializing Decision Tree Classifier
2025-10-21 08:50:23,166:INFO:Total runtime is 1.5528708656628927 minutes
2025-10-21 08:50:23,170:INFO:SubProcess create_model() called ==================================
2025-10-21 08:50:23,171:INFO:Initializing create_model()
2025-10-21 08:50:23,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:50:23,171:INFO:Checking exceptions
2025-10-21 08:50:23,171:INFO:Importing libraries
2025-10-21 08:50:23,171:INFO:Copying training dataset
2025-10-21 08:50:23,498:INFO:Defining folds
2025-10-21 08:50:23,498:INFO:Declaring metric variables
2025-10-21 08:50:23,502:INFO:Importing untrained model
2025-10-21 08:50:23,504:INFO:Decision Tree Classifier Imported successfully
2025-10-21 08:50:23,511:INFO:Starting cross validation
2025-10-21 08:50:23,514:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:50:43,091:INFO:Calculating mean and std
2025-10-21 08:50:43,092:INFO:Creating metrics dataframe
2025-10-21 08:50:43,095:INFO:Uploading results into container
2025-10-21 08:50:43,096:INFO:Uploading model into container now
2025-10-21 08:50:43,096:INFO:_master_model_container: 4
2025-10-21 08:50:43,096:INFO:_display_container: 2
2025-10-21 08:50:43,097:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1968, splitter='best')
2025-10-21 08:50:43,097:INFO:create_model() successfully completed......................................
2025-10-21 08:50:43,257:INFO:SubProcess create_model() end ==================================
2025-10-21 08:50:43,258:INFO:Creating metrics dataframe
2025-10-21 08:50:43,266:INFO:Initializing SVM - Linear Kernel
2025-10-21 08:50:43,267:INFO:Total runtime is 1.8878907680511474 minutes
2025-10-21 08:50:43,270:INFO:SubProcess create_model() called ==================================
2025-10-21 08:50:43,271:INFO:Initializing create_model()
2025-10-21 08:50:43,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:50:43,272:INFO:Checking exceptions
2025-10-21 08:50:43,272:INFO:Importing libraries
2025-10-21 08:50:43,272:INFO:Copying training dataset
2025-10-21 08:50:43,565:INFO:Defining folds
2025-10-21 08:50:43,566:INFO:Declaring metric variables
2025-10-21 08:50:43,569:INFO:Importing untrained model
2025-10-21 08:50:43,573:INFO:SVM - Linear Kernel Imported successfully
2025-10-21 08:50:43,582:INFO:Starting cross validation
2025-10-21 08:50:43,585:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:50:58,382:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 08:51:07,056:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 08:51:15,858:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 08:51:24,946:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 08:51:24,960:INFO:Calculating mean and std
2025-10-21 08:51:24,961:INFO:Creating metrics dataframe
2025-10-21 08:51:24,963:INFO:Uploading results into container
2025-10-21 08:51:24,964:INFO:Uploading model into container now
2025-10-21 08:51:24,964:INFO:_master_model_container: 5
2025-10-21 08:51:24,964:INFO:_display_container: 2
2025-10-21 08:51:24,966:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=1968, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-21 08:51:24,966:INFO:create_model() successfully completed......................................
2025-10-21 08:51:25,129:INFO:SubProcess create_model() end ==================================
2025-10-21 08:51:25,129:INFO:Creating metrics dataframe
2025-10-21 08:51:25,136:INFO:Initializing Ridge Classifier
2025-10-21 08:51:25,136:INFO:Total runtime is 2.585709249973297 minutes
2025-10-21 08:51:25,139:INFO:SubProcess create_model() called ==================================
2025-10-21 08:51:25,140:INFO:Initializing create_model()
2025-10-21 08:51:25,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:51:25,141:INFO:Checking exceptions
2025-10-21 08:51:25,141:INFO:Importing libraries
2025-10-21 08:51:25,141:INFO:Copying training dataset
2025-10-21 08:51:25,378:INFO:Defining folds
2025-10-21 08:51:25,378:INFO:Declaring metric variables
2025-10-21 08:51:25,381:INFO:Importing untrained model
2025-10-21 08:51:25,384:INFO:Ridge Classifier Imported successfully
2025-10-21 08:51:25,389:INFO:Starting cross validation
2025-10-21 08:51:25,393:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:51:41,050:INFO:Calculating mean and std
2025-10-21 08:51:41,051:INFO:Creating metrics dataframe
2025-10-21 08:51:41,052:INFO:Uploading results into container
2025-10-21 08:51:41,052:INFO:Uploading model into container now
2025-10-21 08:51:41,053:INFO:_master_model_container: 6
2025-10-21 08:51:41,053:INFO:_display_container: 2
2025-10-21 08:51:41,053:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1968, solver='auto',
                tol=0.0001)
2025-10-21 08:51:41,053:INFO:create_model() successfully completed......................................
2025-10-21 08:51:41,220:INFO:SubProcess create_model() end ==================================
2025-10-21 08:51:41,220:INFO:Creating metrics dataframe
2025-10-21 08:51:41,226:INFO:Initializing Random Forest Classifier
2025-10-21 08:51:41,226:INFO:Total runtime is 2.853878390789032 minutes
2025-10-21 08:51:41,228:INFO:SubProcess create_model() called ==================================
2025-10-21 08:51:41,230:INFO:Initializing create_model()
2025-10-21 08:51:41,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:51:41,230:INFO:Checking exceptions
2025-10-21 08:51:41,230:INFO:Importing libraries
2025-10-21 08:51:41,230:INFO:Copying training dataset
2025-10-21 08:51:41,467:INFO:Defining folds
2025-10-21 08:51:41,468:INFO:Declaring metric variables
2025-10-21 08:51:41,471:INFO:Importing untrained model
2025-10-21 08:51:41,473:INFO:Random Forest Classifier Imported successfully
2025-10-21 08:51:41,478:INFO:Starting cross validation
2025-10-21 08:51:41,481:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:52:45,436:INFO:Calculating mean and std
2025-10-21 08:52:45,437:INFO:Creating metrics dataframe
2025-10-21 08:52:45,439:INFO:Uploading results into container
2025-10-21 08:52:45,439:INFO:Uploading model into container now
2025-10-21 08:52:45,440:INFO:_master_model_container: 7
2025-10-21 08:52:45,440:INFO:_display_container: 2
2025-10-21 08:52:45,440:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=1968, verbose=0,
                       warm_start=False)
2025-10-21 08:52:45,441:INFO:create_model() successfully completed......................................
2025-10-21 08:52:45,614:INFO:SubProcess create_model() end ==================================
2025-10-21 08:52:45,614:INFO:Creating metrics dataframe
2025-10-21 08:52:45,622:INFO:Initializing Quadratic Discriminant Analysis
2025-10-21 08:52:45,622:INFO:Total runtime is 3.9271382292111716 minutes
2025-10-21 08:52:45,625:INFO:SubProcess create_model() called ==================================
2025-10-21 08:52:45,627:INFO:Initializing create_model()
2025-10-21 08:52:45,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:52:45,627:INFO:Checking exceptions
2025-10-21 08:52:45,627:INFO:Importing libraries
2025-10-21 08:52:45,627:INFO:Copying training dataset
2025-10-21 08:52:45,920:INFO:Defining folds
2025-10-21 08:52:45,921:INFO:Declaring metric variables
2025-10-21 08:52:45,925:INFO:Importing untrained model
2025-10-21 08:52:45,929:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-21 08:52:45,936:INFO:Starting cross validation
2025-10-21 08:52:45,942:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:52:49,477:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-21 08:52:53,056:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-21 08:52:56,809:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-21 08:53:00,346:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-21 08:53:03,922:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-21 08:53:04,404:INFO:Calculating mean and std
2025-10-21 08:53:04,405:INFO:Creating metrics dataframe
2025-10-21 08:53:04,407:INFO:Uploading results into container
2025-10-21 08:53:04,407:INFO:Uploading model into container now
2025-10-21 08:53:04,407:INFO:_master_model_container: 8
2025-10-21 08:53:04,408:INFO:_display_container: 2
2025-10-21 08:53:04,408:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-21 08:53:04,408:INFO:create_model() successfully completed......................................
2025-10-21 08:53:04,577:INFO:SubProcess create_model() end ==================================
2025-10-21 08:53:04,577:INFO:Creating metrics dataframe
2025-10-21 08:53:04,586:INFO:Initializing Ada Boost Classifier
2025-10-21 08:53:04,587:INFO:Total runtime is 4.243224612871806 minutes
2025-10-21 08:53:04,589:INFO:SubProcess create_model() called ==================================
2025-10-21 08:53:04,591:INFO:Initializing create_model()
2025-10-21 08:53:04,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:53:04,591:INFO:Checking exceptions
2025-10-21 08:53:04,591:INFO:Importing libraries
2025-10-21 08:53:04,591:INFO:Copying training dataset
2025-10-21 08:53:04,863:INFO:Defining folds
2025-10-21 08:53:04,863:INFO:Declaring metric variables
2025-10-21 08:53:04,867:INFO:Importing untrained model
2025-10-21 08:53:04,872:INFO:Ada Boost Classifier Imported successfully
2025-10-21 08:53:04,877:INFO:Starting cross validation
2025-10-21 08:53:04,880:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:53:07,511:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 08:53:14,164:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 08:53:21,003:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 08:53:27,891:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 08:53:34,926:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 08:53:38,853:INFO:Calculating mean and std
2025-10-21 08:53:38,855:INFO:Creating metrics dataframe
2025-10-21 08:53:38,857:INFO:Uploading results into container
2025-10-21 08:53:38,857:INFO:Uploading model into container now
2025-10-21 08:53:38,857:INFO:_master_model_container: 9
2025-10-21 08:53:38,857:INFO:_display_container: 2
2025-10-21 08:53:38,858:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1968)
2025-10-21 08:53:38,858:INFO:create_model() successfully completed......................................
2025-10-21 08:53:39,028:INFO:SubProcess create_model() end ==================================
2025-10-21 08:53:39,028:INFO:Creating metrics dataframe
2025-10-21 08:53:39,041:INFO:Initializing Gradient Boosting Classifier
2025-10-21 08:53:39,041:INFO:Total runtime is 4.817456674575806 minutes
2025-10-21 08:53:39,044:INFO:SubProcess create_model() called ==================================
2025-10-21 08:53:39,045:INFO:Initializing create_model()
2025-10-21 08:53:39,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:53:39,045:INFO:Checking exceptions
2025-10-21 08:53:39,045:INFO:Importing libraries
2025-10-21 08:53:39,045:INFO:Copying training dataset
2025-10-21 08:53:39,313:INFO:Defining folds
2025-10-21 08:53:39,313:INFO:Declaring metric variables
2025-10-21 08:53:39,316:INFO:Importing untrained model
2025-10-21 08:53:39,319:INFO:Gradient Boosting Classifier Imported successfully
2025-10-21 08:53:39,326:INFO:Starting cross validation
2025-10-21 08:53:39,329:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:54:51,028:INFO:Calculating mean and std
2025-10-21 08:54:51,029:INFO:Creating metrics dataframe
2025-10-21 08:54:51,030:INFO:Uploading results into container
2025-10-21 08:54:51,031:INFO:Uploading model into container now
2025-10-21 08:54:51,031:INFO:_master_model_container: 10
2025-10-21 08:54:51,031:INFO:_display_container: 2
2025-10-21 08:54:51,032:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1968, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 08:54:51,032:INFO:create_model() successfully completed......................................
2025-10-21 08:54:51,188:INFO:SubProcess create_model() end ==================================
2025-10-21 08:54:51,188:INFO:Creating metrics dataframe
2025-10-21 08:54:51,197:INFO:Initializing Linear Discriminant Analysis
2025-10-21 08:54:51,197:INFO:Total runtime is 6.020062200228374 minutes
2025-10-21 08:54:51,201:INFO:SubProcess create_model() called ==================================
2025-10-21 08:54:51,202:INFO:Initializing create_model()
2025-10-21 08:54:51,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:54:51,202:INFO:Checking exceptions
2025-10-21 08:54:51,202:INFO:Importing libraries
2025-10-21 08:54:51,202:INFO:Copying training dataset
2025-10-21 08:54:51,453:INFO:Defining folds
2025-10-21 08:54:51,453:INFO:Declaring metric variables
2025-10-21 08:54:51,458:INFO:Importing untrained model
2025-10-21 08:54:51,463:INFO:Linear Discriminant Analysis Imported successfully
2025-10-21 08:54:51,468:INFO:Starting cross validation
2025-10-21 08:54:51,473:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:55:09,972:INFO:Calculating mean and std
2025-10-21 08:55:09,974:INFO:Creating metrics dataframe
2025-10-21 08:55:09,977:INFO:Uploading results into container
2025-10-21 08:55:09,977:INFO:Uploading model into container now
2025-10-21 08:55:09,978:INFO:_master_model_container: 11
2025-10-21 08:55:09,978:INFO:_display_container: 2
2025-10-21 08:55:09,978:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-21 08:55:09,978:INFO:create_model() successfully completed......................................
2025-10-21 08:55:10,134:INFO:SubProcess create_model() end ==================================
2025-10-21 08:55:10,134:INFO:Creating metrics dataframe
2025-10-21 08:55:10,142:INFO:Initializing Extra Trees Classifier
2025-10-21 08:55:10,143:INFO:Total runtime is 6.335815274715424 minutes
2025-10-21 08:55:10,146:INFO:SubProcess create_model() called ==================================
2025-10-21 08:55:10,147:INFO:Initializing create_model()
2025-10-21 08:55:10,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:55:10,147:INFO:Checking exceptions
2025-10-21 08:55:10,147:INFO:Importing libraries
2025-10-21 08:55:10,147:INFO:Copying training dataset
2025-10-21 08:55:10,417:INFO:Defining folds
2025-10-21 08:55:10,417:INFO:Declaring metric variables
2025-10-21 08:55:10,420:INFO:Importing untrained model
2025-10-21 08:55:10,424:INFO:Extra Trees Classifier Imported successfully
2025-10-21 08:55:10,430:INFO:Starting cross validation
2025-10-21 08:55:10,435:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:56:26,661:INFO:Calculating mean and std
2025-10-21 08:56:26,662:INFO:Creating metrics dataframe
2025-10-21 08:56:26,666:INFO:Uploading results into container
2025-10-21 08:56:26,667:INFO:Uploading model into container now
2025-10-21 08:56:26,667:INFO:_master_model_container: 12
2025-10-21 08:56:26,668:INFO:_display_container: 2
2025-10-21 08:56:26,669:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=1968, verbose=0,
                     warm_start=False)
2025-10-21 08:56:26,669:INFO:create_model() successfully completed......................................
2025-10-21 08:56:26,828:INFO:SubProcess create_model() end ==================================
2025-10-21 08:56:26,828:INFO:Creating metrics dataframe
2025-10-21 08:56:26,837:INFO:Initializing Extreme Gradient Boosting
2025-10-21 08:56:26,837:INFO:Total runtime is 7.614057258764904 minutes
2025-10-21 08:56:26,840:INFO:SubProcess create_model() called ==================================
2025-10-21 08:56:26,841:INFO:Initializing create_model()
2025-10-21 08:56:26,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=xgboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:56:26,841:INFO:Checking exceptions
2025-10-21 08:56:26,841:INFO:Importing libraries
2025-10-21 08:56:26,841:INFO:Copying training dataset
2025-10-21 08:56:27,099:INFO:Defining folds
2025-10-21 08:56:27,099:INFO:Declaring metric variables
2025-10-21 08:56:27,102:INFO:Importing untrained model
2025-10-21 08:56:27,107:INFO:Extreme Gradient Boosting Imported successfully
2025-10-21 08:56:27,116:INFO:Starting cross validation
2025-10-21 08:56:27,121:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:56:55,126:INFO:Calculating mean and std
2025-10-21 08:56:55,127:INFO:Creating metrics dataframe
2025-10-21 08:56:55,128:INFO:Uploading results into container
2025-10-21 08:56:55,129:INFO:Uploading model into container now
2025-10-21 08:56:55,129:INFO:_master_model_container: 13
2025-10-21 08:56:55,129:INFO:_display_container: 2
2025-10-21 08:56:55,130:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-10-21 08:56:55,130:INFO:create_model() successfully completed......................................
2025-10-21 08:56:55,287:INFO:SubProcess create_model() end ==================================
2025-10-21 08:56:55,287:INFO:Creating metrics dataframe
2025-10-21 08:56:55,295:INFO:Initializing Light Gradient Boosting Machine
2025-10-21 08:56:55,295:INFO:Total runtime is 8.088364998499554 minutes
2025-10-21 08:56:55,299:INFO:SubProcess create_model() called ==================================
2025-10-21 08:56:55,301:INFO:Initializing create_model()
2025-10-21 08:56:55,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:56:55,301:INFO:Checking exceptions
2025-10-21 08:56:55,301:INFO:Importing libraries
2025-10-21 08:56:55,301:INFO:Copying training dataset
2025-10-21 08:56:55,575:INFO:Defining folds
2025-10-21 08:56:55,575:INFO:Declaring metric variables
2025-10-21 08:56:55,579:INFO:Importing untrained model
2025-10-21 08:56:55,582:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-21 08:56:55,587:INFO:Starting cross validation
2025-10-21 08:56:55,590:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:56:58,584:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 08:56:58,588:INFO:[LightGBM] [Info] Number of positive: 14952, number of negative: 29849
2025-10-21 08:56:58,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013359 seconds.
2025-10-21 08:56:58,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 08:56:58,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 08:56:58,627:INFO:[LightGBM] [Info] Total Bins 1452
2025-10-21 08:56:58,629:INFO:[LightGBM] [Info] Number of data points in the train set: 44801, number of used features: 96
2025-10-21 08:56:58,633:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333743 -> initscore=-0.691306
2025-10-21 08:56:58,633:INFO:[LightGBM] [Info] Start training from score -0.691306
2025-10-21 08:57:02,473:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 08:57:02,475:INFO:[LightGBM] [Info] Number of positive: 14932, number of negative: 29869
2025-10-21 08:57:02,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011493 seconds.
2025-10-21 08:57:02,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 08:57:02,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 08:57:02,504:INFO:[LightGBM] [Info] Total Bins 1452
2025-10-21 08:57:02,504:INFO:[LightGBM] [Info] Number of data points in the train set: 44801, number of used features: 96
2025-10-21 08:57:02,504:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333296 -> initscore=-0.693315
2025-10-21 08:57:02,504:INFO:[LightGBM] [Info] Start training from score -0.693315
2025-10-21 08:57:06,243:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 08:57:06,245:INFO:[LightGBM] [Info] Number of positive: 14880, number of negative: 29922
2025-10-21 08:57:06,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010034 seconds.
2025-10-21 08:57:06,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 08:57:06,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 08:57:06,270:INFO:[LightGBM] [Info] Total Bins 1450
2025-10-21 08:57:06,270:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-21 08:57:06,271:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332128 -> initscore=-0.698576
2025-10-21 08:57:06,271:INFO:[LightGBM] [Info] Start training from score -0.698576
2025-10-21 08:57:09,848:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 08:57:09,851:INFO:[LightGBM] [Info] Number of positive: 14877, number of negative: 29925
2025-10-21 08:57:09,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010281 seconds.
2025-10-21 08:57:09,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 08:57:09,878:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 08:57:09,878:INFO:[LightGBM] [Info] Total Bins 1451
2025-10-21 08:57:09,879:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-21 08:57:09,879:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332061 -> initscore=-0.698878
2025-10-21 08:57:09,879:INFO:[LightGBM] [Info] Start training from score -0.698878
2025-10-21 08:57:13,727:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 08:57:13,729:INFO:[LightGBM] [Info] Number of positive: 14875, number of negative: 29927
2025-10-21 08:57:13,755:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008138 seconds.
2025-10-21 08:57:13,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 08:57:13,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 08:57:13,755:INFO:[LightGBM] [Info] Total Bins 1451
2025-10-21 08:57:13,756:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-21 08:57:13,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332016 -> initscore=-0.699079
2025-10-21 08:57:13,756:INFO:[LightGBM] [Info] Start training from score -0.699079
2025-10-21 08:57:14,807:INFO:Calculating mean and std
2025-10-21 08:57:14,808:INFO:Creating metrics dataframe
2025-10-21 08:57:14,810:INFO:Uploading results into container
2025-10-21 08:57:14,811:INFO:Uploading model into container now
2025-10-21 08:57:14,811:INFO:_master_model_container: 14
2025-10-21 08:57:14,812:INFO:_display_container: 2
2025-10-21 08:57:14,812:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=1968, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-21 08:57:14,812:INFO:create_model() successfully completed......................................
2025-10-21 08:57:14,976:INFO:SubProcess create_model() end ==================================
2025-10-21 08:57:14,976:INFO:Creating metrics dataframe
2025-10-21 08:57:14,986:INFO:Initializing CatBoost Classifier
2025-10-21 08:57:14,986:INFO:Total runtime is 8.416538619995118 minutes
2025-10-21 08:57:14,990:INFO:SubProcess create_model() called ==================================
2025-10-21 08:57:14,991:INFO:Initializing create_model()
2025-10-21 08:57:14,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:57:14,991:INFO:Checking exceptions
2025-10-21 08:57:14,991:INFO:Importing libraries
2025-10-21 08:57:14,991:INFO:Copying training dataset
2025-10-21 08:57:15,243:INFO:Defining folds
2025-10-21 08:57:15,243:INFO:Declaring metric variables
2025-10-21 08:57:15,247:INFO:Importing untrained model
2025-10-21 08:57:15,250:INFO:CatBoost Classifier Imported successfully
2025-10-21 08:57:15,256:INFO:Starting cross validation
2025-10-21 08:57:15,259:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:59:34,314:INFO:Calculating mean and std
2025-10-21 08:59:34,315:INFO:Creating metrics dataframe
2025-10-21 08:59:34,316:INFO:Uploading results into container
2025-10-21 08:59:34,317:INFO:Uploading model into container now
2025-10-21 08:59:34,318:INFO:_master_model_container: 15
2025-10-21 08:59:34,318:INFO:_display_container: 2
2025-10-21 08:59:34,318:INFO:<catboost.core.CatBoostClassifier object at 0x0000024EA38EDB90>
2025-10-21 08:59:34,318:INFO:create_model() successfully completed......................................
2025-10-21 08:59:34,487:INFO:SubProcess create_model() end ==================================
2025-10-21 08:59:34,487:INFO:Creating metrics dataframe
2025-10-21 08:59:34,498:INFO:Initializing Dummy Classifier
2025-10-21 08:59:34,498:INFO:Total runtime is 10.74173211256663 minutes
2025-10-21 08:59:34,501:INFO:SubProcess create_model() called ==================================
2025-10-21 08:59:34,502:INFO:Initializing create_model()
2025-10-21 08:59:34,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024EA3596650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:59:34,502:INFO:Checking exceptions
2025-10-21 08:59:34,502:INFO:Importing libraries
2025-10-21 08:59:34,502:INFO:Copying training dataset
2025-10-21 08:59:34,754:INFO:Defining folds
2025-10-21 08:59:34,754:INFO:Declaring metric variables
2025-10-21 08:59:34,759:INFO:Importing untrained model
2025-10-21 08:59:34,763:INFO:Dummy Classifier Imported successfully
2025-10-21 08:59:34,770:INFO:Starting cross validation
2025-10-21 08:59:34,775:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 08:59:37,911:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 08:59:41,286:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 08:59:44,308:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 08:59:47,351:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 08:59:50,300:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 08:59:50,316:INFO:Calculating mean and std
2025-10-21 08:59:50,317:INFO:Creating metrics dataframe
2025-10-21 08:59:50,319:INFO:Uploading results into container
2025-10-21 08:59:50,319:INFO:Uploading model into container now
2025-10-21 08:59:50,319:INFO:_master_model_container: 16
2025-10-21 08:59:50,319:INFO:_display_container: 2
2025-10-21 08:59:50,320:INFO:DummyClassifier(constant=None, random_state=1968, strategy='prior')
2025-10-21 08:59:50,320:INFO:create_model() successfully completed......................................
2025-10-21 08:59:50,478:INFO:SubProcess create_model() end ==================================
2025-10-21 08:59:50,478:INFO:Creating metrics dataframe
2025-10-21 08:59:50,488:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-21 08:59:50,498:INFO:Initializing create_model()
2025-10-21 08:59:50,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1968, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 08:59:50,498:INFO:Checking exceptions
2025-10-21 08:59:50,499:INFO:Importing libraries
2025-10-21 08:59:50,499:INFO:Copying training dataset
2025-10-21 08:59:50,737:INFO:Defining folds
2025-10-21 08:59:50,737:INFO:Declaring metric variables
2025-10-21 08:59:50,738:INFO:Importing untrained model
2025-10-21 08:59:50,738:INFO:Declaring custom model
2025-10-21 08:59:50,738:INFO:Gradient Boosting Classifier Imported successfully
2025-10-21 08:59:50,742:INFO:Cross validation set to False
2025-10-21 08:59:50,742:INFO:Fitting Model
2025-10-21 09:00:08,336:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1968, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 09:00:08,336:INFO:create_model() successfully completed......................................
2025-10-21 09:00:08,502:INFO:Initializing create_model()
2025-10-21 09:00:08,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1968, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:00:08,503:INFO:Checking exceptions
2025-10-21 09:00:08,504:INFO:Importing libraries
2025-10-21 09:00:08,504:INFO:Copying training dataset
2025-10-21 09:00:08,733:INFO:Defining folds
2025-10-21 09:00:08,734:INFO:Declaring metric variables
2025-10-21 09:00:08,734:INFO:Importing untrained model
2025-10-21 09:00:08,734:INFO:Declaring custom model
2025-10-21 09:00:08,734:INFO:Ridge Classifier Imported successfully
2025-10-21 09:00:08,737:INFO:Cross validation set to False
2025-10-21 09:00:08,737:INFO:Fitting Model
2025-10-21 09:00:12,351:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1968, solver='auto',
                tol=0.0001)
2025-10-21 09:00:12,351:INFO:create_model() successfully completed......................................
2025-10-21 09:00:12,514:INFO:Initializing create_model()
2025-10-21 09:00:12,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=6253     U19129
8478     U08620
3400     U01774
36042    U17125
6840     U00828
          ...  
27928    U17200
32540    U07054
62639    U16733
38413    U15722
76994    U09866
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:00:12,514:INFO:Checking exceptions
2025-10-21 09:00:12,517:INFO:Importing libraries
2025-10-21 09:00:12,517:INFO:Copying training dataset
2025-10-21 09:00:12,756:INFO:Defining folds
2025-10-21 09:00:12,756:INFO:Declaring metric variables
2025-10-21 09:00:12,756:INFO:Importing untrained model
2025-10-21 09:00:12,756:INFO:Declaring custom model
2025-10-21 09:00:12,756:INFO:Linear Discriminant Analysis Imported successfully
2025-10-21 09:00:12,759:INFO:Cross validation set to False
2025-10-21 09:00:12,759:INFO:Fitting Model
2025-10-21 09:00:16,966:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-21 09:00:16,966:INFO:create_model() successfully completed......................................
2025-10-21 09:00:17,147:INFO:_master_model_container: 16
2025-10-21 09:00:17,147:INFO:_display_container: 2
2025-10-21 09:00:17,148:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1968, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1968, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2025-10-21 09:00:17,148:INFO:compare_models() successfully completed......................................
2025-10-21 09:00:17,150:INFO:Initializing tune_model()
2025-10-21 09:00:17,150:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024EF8AC7150>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1968, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-21 09:00:17,150:INFO:Checking exceptions
2025-10-21 09:00:17,271:INFO:Copying training dataset
2025-10-21 09:00:17,443:INFO:Checking base model
2025-10-21 09:00:17,443:INFO:Base model : Gradient Boosting Classifier
2025-10-21 09:00:17,447:INFO:Declaring metric variables
2025-10-21 09:00:17,450:INFO:Defining Hyperparameters
2025-10-21 09:00:17,619:INFO:Tuning with n_jobs=1
2025-10-21 09:00:17,619:INFO:Initializing RandomizedSearchCV
2025-10-21 09:14:13,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 09:14:13,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 09:14:13,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 09:14:13,787:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 09:14:16,753:INFO:PyCaret ClassificationExperiment
2025-10-21 09:14:16,753:INFO:Logging name: clf-default-name
2025-10-21 09:14:16,753:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-21 09:14:16,753:INFO:version 3.3.2
2025-10-21 09:14:16,753:INFO:Initializing setup()
2025-10-21 09:14:16,754:INFO:self.USI: b1d4
2025-10-21 09:14:16,754:INFO:self._variable_keys: {'X', 'X_train', 'html_param', 'fold_groups_param', 'log_plots_param', 'exp_name_log', 'y', 'X_test', 'pipeline', 'gpu_n_jobs_param', 'memory', 'exp_id', 'n_jobs_param', 'target_param', 'is_multiclass', 'fold_shuffle_param', 'fix_imbalance', 'seed', 'gpu_param', '_ml_usecase', 'idx', 'data', 'USI', 'logging_param', 'y_train', 'y_test', 'fold_generator', '_available_plots'}
2025-10-21 09:14:16,754:INFO:Checking environment
2025-10-21 09:14:16,754:INFO:python_version: 3.11.13
2025-10-21 09:14:16,754:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-21 09:14:16,754:INFO:machine: AMD64
2025-10-21 09:14:16,754:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-21 09:14:16,761:INFO:Memory: svmem(total=16856211456, available=2876194816, percent=82.9, used=13980016640, free=2876194816)
2025-10-21 09:14:16,761:INFO:Physical Core: 4
2025-10-21 09:14:16,761:INFO:Logical Core: 8
2025-10-21 09:14:16,761:INFO:Checking libraries
2025-10-21 09:14:16,761:INFO:System:
2025-10-21 09:14:16,761:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-21 09:14:16,761:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-21 09:14:16,761:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-21 09:14:16,761:INFO:PyCaret required dependencies:
2025-10-21 09:14:17,950:INFO:                 pip: 25.2
2025-10-21 09:14:17,951:INFO:          setuptools: 80.9.0
2025-10-21 09:14:17,951:INFO:             pycaret: 3.3.2
2025-10-21 09:14:17,951:INFO:             IPython: 9.6.0
2025-10-21 09:14:17,951:INFO:          ipywidgets: 8.1.7
2025-10-21 09:14:17,951:INFO:                tqdm: 4.67.1
2025-10-21 09:14:17,951:INFO:               numpy: 1.26.4
2025-10-21 09:14:17,951:INFO:              pandas: 2.1.4
2025-10-21 09:14:17,951:INFO:              jinja2: 3.1.6
2025-10-21 09:14:17,951:INFO:               scipy: 1.11.4
2025-10-21 09:14:17,951:INFO:              joblib: 1.3.2
2025-10-21 09:14:17,951:INFO:             sklearn: 1.4.2
2025-10-21 09:14:17,951:INFO:                pyod: 2.0.5
2025-10-21 09:14:17,951:INFO:            imblearn: 0.14.0
2025-10-21 09:14:17,951:INFO:   category_encoders: 2.7.0
2025-10-21 09:14:17,951:INFO:            lightgbm: 4.6.0
2025-10-21 09:14:17,951:INFO:               numba: 0.61.0
2025-10-21 09:14:17,951:INFO:            requests: 2.32.5
2025-10-21 09:14:17,951:INFO:          matplotlib: 3.7.5
2025-10-21 09:14:17,951:INFO:          scikitplot: 0.3.7
2025-10-21 09:14:17,951:INFO:         yellowbrick: 1.5
2025-10-21 09:14:17,951:INFO:              plotly: 5.24.1
2025-10-21 09:14:17,951:INFO:    plotly-resampler: Not installed
2025-10-21 09:14:17,951:INFO:             kaleido: 1.1.0
2025-10-21 09:14:17,951:INFO:           schemdraw: 0.15
2025-10-21 09:14:17,951:INFO:         statsmodels: 0.14.5
2025-10-21 09:14:17,951:INFO:              sktime: 0.26.0
2025-10-21 09:14:17,951:INFO:               tbats: 1.1.3
2025-10-21 09:14:17,951:INFO:            pmdarima: 2.0.4
2025-10-21 09:14:17,951:INFO:              psutil: 7.1.1
2025-10-21 09:14:17,952:INFO:          markupsafe: 3.0.3
2025-10-21 09:14:17,952:INFO:             pickle5: Not installed
2025-10-21 09:14:17,952:INFO:         cloudpickle: 3.1.1
2025-10-21 09:14:17,952:INFO:         deprecation: 2.1.0
2025-10-21 09:14:17,952:INFO:              xxhash: 3.6.0
2025-10-21 09:14:17,952:INFO:           wurlitzer: Not installed
2025-10-21 09:14:17,952:INFO:PyCaret optional dependencies:
2025-10-21 09:14:22,512:INFO:                shap: 0.44.1
2025-10-21 09:14:22,512:INFO:           interpret: 0.7.3
2025-10-21 09:14:22,512:INFO:                umap: 0.5.7
2025-10-21 09:14:22,512:INFO:     ydata_profiling: 4.17.0
2025-10-21 09:14:22,512:INFO:  explainerdashboard: 0.5.1
2025-10-21 09:14:22,512:INFO:             autoviz: Not installed
2025-10-21 09:14:22,512:INFO:           fairlearn: 0.7.0
2025-10-21 09:14:22,512:INFO:          deepchecks: Not installed
2025-10-21 09:14:22,512:INFO:             xgboost: 3.1.0
2025-10-21 09:14:22,512:INFO:            catboost: 1.2.8
2025-10-21 09:14:22,512:INFO:              kmodes: 0.12.2
2025-10-21 09:14:22,512:INFO:             mlxtend: 0.23.4
2025-10-21 09:14:22,512:INFO:       statsforecast: 1.5.0
2025-10-21 09:14:22,512:INFO:        tune_sklearn: Not installed
2025-10-21 09:14:22,512:INFO:                 ray: Not installed
2025-10-21 09:14:22,512:INFO:            hyperopt: 0.2.7
2025-10-21 09:14:22,512:INFO:              optuna: 4.5.0
2025-10-21 09:14:22,512:INFO:               skopt: 0.10.2
2025-10-21 09:14:22,512:INFO:              mlflow: 3.5.0
2025-10-21 09:14:22,513:INFO:              gradio: 5.49.1
2025-10-21 09:14:22,513:INFO:             fastapi: 0.119.1
2025-10-21 09:14:22,513:INFO:             uvicorn: 0.38.0
2025-10-21 09:14:22,513:INFO:              m2cgen: 0.10.0
2025-10-21 09:14:22,513:INFO:           evidently: 0.4.40
2025-10-21 09:14:22,513:INFO:               fugue: 0.8.7
2025-10-21 09:14:22,513:INFO:           streamlit: Not installed
2025-10-21 09:14:22,513:INFO:             prophet: Not installed
2025-10-21 09:14:22,513:INFO:None
2025-10-21 09:14:22,513:INFO:Set up data.
2025-10-21 09:14:22,717:INFO:Set up folding strategy.
2025-10-21 09:14:22,928:INFO:Set up train/test split.
2025-10-21 09:14:23,143:INFO:Set up index.
2025-10-21 09:14:23,154:INFO:Assigning column types.
2025-10-21 09:14:23,381:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-21 09:14:23,417:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-21 09:14:23,421:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 09:14:23,463:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 09:14:23,467:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 09:14:23,540:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-21 09:14:23,540:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 09:14:23,565:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 09:14:23,567:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 09:14:23,568:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-21 09:14:23,611:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 09:14:23,636:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 09:14:23,638:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 09:14:23,677:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 09:14:23,705:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 09:14:23,710:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 09:14:23,711:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-21 09:14:23,777:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 09:14:23,779:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 09:14:23,840:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 09:14:23,843:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 09:14:23,845:INFO:Preparing preprocessing pipeline...
2025-10-21 09:14:23,882:INFO:Set up simple imputation.
2025-10-21 09:14:24,077:INFO:Set up encoding of ordinal features.
2025-10-21 09:14:24,162:INFO:Set up encoding of categorical features.
2025-10-21 09:14:24,168:INFO:Set up removing multicollinearity.
2025-10-21 09:14:24,168:INFO:Set up imbalanced handling.
2025-10-21 09:14:24,205:INFO:Set up column name cleaning.
2025-10-21 09:14:31,139:INFO:Finished creating preprocessing pipeline.
2025-10-21 09:14:31,169:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-21 09:14:31,169:INFO:Creating final display dataframe.
2025-10-21 09:14:35,941:INFO:Setup _display_container:                     Description             Value
0                    Session id              1391
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 28)
4        Transformed data shape       (98748, 97)
5   Transformed train set shape       (74746, 97)
6    Transformed test set shape       (24002, 97)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20               Fold Generator        GroupKFold
21                  Fold Number                 5
22                     CPU Jobs                 1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              b1d4
2025-10-21 09:14:36,000:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 09:14:36,002:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 09:14:36,059:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 09:14:36,062:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 09:14:36,063:INFO:setup() successfully completed in 19.61s...............
2025-10-21 09:14:36,064:INFO:Initializing compare_models()
2025-10-21 09:14:36,064:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-21 09:14:36,064:INFO:Checking exceptions
2025-10-21 09:14:36,251:INFO:Preparing display monitor
2025-10-21 09:14:36,282:INFO:Initializing Logistic Regression
2025-10-21 09:14:36,282:INFO:Total runtime is 0.0 minutes
2025-10-21 09:14:36,286:INFO:SubProcess create_model() called ==================================
2025-10-21 09:14:36,287:INFO:Initializing create_model()
2025-10-21 09:14:36,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:14:36,288:INFO:Checking exceptions
2025-10-21 09:14:36,288:INFO:Importing libraries
2025-10-21 09:14:36,288:INFO:Copying training dataset
2025-10-21 09:14:36,633:INFO:Defining folds
2025-10-21 09:14:36,633:INFO:Declaring metric variables
2025-10-21 09:14:36,636:INFO:Importing untrained model
2025-10-21 09:14:36,639:INFO:Logistic Regression Imported successfully
2025-10-21 09:14:36,648:INFO:Starting cross validation
2025-10-21 09:14:36,656:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:14:49,621:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-21 09:15:01,673:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-21 09:15:14,324:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-21 09:15:25,820:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-21 09:15:38,347:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-21 09:15:38,679:INFO:Calculating mean and std
2025-10-21 09:15:38,682:INFO:Creating metrics dataframe
2025-10-21 09:15:38,686:INFO:Uploading results into container
2025-10-21 09:15:38,687:INFO:Uploading model into container now
2025-10-21 09:15:38,688:INFO:_master_model_container: 1
2025-10-21 09:15:38,689:INFO:_display_container: 2
2025-10-21 09:15:38,689:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1391, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-21 09:15:38,689:INFO:create_model() successfully completed......................................
2025-10-21 09:15:38,869:INFO:SubProcess create_model() end ==================================
2025-10-21 09:15:38,870:INFO:Creating metrics dataframe
2025-10-21 09:15:38,875:INFO:Initializing K Neighbors Classifier
2025-10-21 09:15:38,876:INFO:Total runtime is 1.0432309230168662 minutes
2025-10-21 09:15:38,879:INFO:SubProcess create_model() called ==================================
2025-10-21 09:15:38,882:INFO:Initializing create_model()
2025-10-21 09:15:38,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:15:38,882:INFO:Checking exceptions
2025-10-21 09:15:38,882:INFO:Importing libraries
2025-10-21 09:15:38,882:INFO:Copying training dataset
2025-10-21 09:15:39,176:INFO:Defining folds
2025-10-21 09:15:39,176:INFO:Declaring metric variables
2025-10-21 09:15:39,182:INFO:Importing untrained model
2025-10-21 09:15:39,187:INFO:K Neighbors Classifier Imported successfully
2025-10-21 09:15:39,195:INFO:Starting cross validation
2025-10-21 09:15:39,205:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:16:15,651:INFO:Calculating mean and std
2025-10-21 09:16:15,652:INFO:Creating metrics dataframe
2025-10-21 09:16:15,656:INFO:Uploading results into container
2025-10-21 09:16:15,657:INFO:Uploading model into container now
2025-10-21 09:16:15,657:INFO:_master_model_container: 2
2025-10-21 09:16:15,657:INFO:_display_container: 2
2025-10-21 09:16:15,659:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-21 09:16:15,659:INFO:create_model() successfully completed......................................
2025-10-21 09:16:15,840:INFO:SubProcess create_model() end ==================================
2025-10-21 09:16:15,841:INFO:Creating metrics dataframe
2025-10-21 09:16:15,848:INFO:Initializing Naive Bayes
2025-10-21 09:16:15,849:INFO:Total runtime is 1.6594324509302776 minutes
2025-10-21 09:16:15,852:INFO:SubProcess create_model() called ==================================
2025-10-21 09:16:15,854:INFO:Initializing create_model()
2025-10-21 09:16:15,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:16:15,854:INFO:Checking exceptions
2025-10-21 09:16:15,854:INFO:Importing libraries
2025-10-21 09:16:15,854:INFO:Copying training dataset
2025-10-21 09:16:16,133:INFO:Defining folds
2025-10-21 09:16:16,134:INFO:Declaring metric variables
2025-10-21 09:16:16,138:INFO:Importing untrained model
2025-10-21 09:16:16,142:INFO:Naive Bayes Imported successfully
2025-10-21 09:16:16,149:INFO:Starting cross validation
2025-10-21 09:16:16,159:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:16:35,400:INFO:Calculating mean and std
2025-10-21 09:16:35,402:INFO:Creating metrics dataframe
2025-10-21 09:16:35,404:INFO:Uploading results into container
2025-10-21 09:16:35,405:INFO:Uploading model into container now
2025-10-21 09:16:35,405:INFO:_master_model_container: 3
2025-10-21 09:16:35,405:INFO:_display_container: 2
2025-10-21 09:16:35,406:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-21 09:16:35,406:INFO:create_model() successfully completed......................................
2025-10-21 09:16:35,597:INFO:SubProcess create_model() end ==================================
2025-10-21 09:16:35,598:INFO:Creating metrics dataframe
2025-10-21 09:16:35,609:INFO:Initializing Decision Tree Classifier
2025-10-21 09:16:35,609:INFO:Total runtime is 1.9887841025988262 minutes
2025-10-21 09:16:35,614:INFO:SubProcess create_model() called ==================================
2025-10-21 09:16:35,615:INFO:Initializing create_model()
2025-10-21 09:16:35,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:16:35,616:INFO:Checking exceptions
2025-10-21 09:16:35,616:INFO:Importing libraries
2025-10-21 09:16:35,616:INFO:Copying training dataset
2025-10-21 09:16:35,905:INFO:Defining folds
2025-10-21 09:16:35,905:INFO:Declaring metric variables
2025-10-21 09:16:35,909:INFO:Importing untrained model
2025-10-21 09:16:35,914:INFO:Decision Tree Classifier Imported successfully
2025-10-21 09:16:35,924:INFO:Starting cross validation
2025-10-21 09:16:35,932:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:17:01,359:INFO:Calculating mean and std
2025-10-21 09:17:01,360:INFO:Creating metrics dataframe
2025-10-21 09:17:01,362:INFO:Uploading results into container
2025-10-21 09:17:01,363:INFO:Uploading model into container now
2025-10-21 09:17:01,363:INFO:_master_model_container: 4
2025-10-21 09:17:01,363:INFO:_display_container: 2
2025-10-21 09:17:01,364:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1391, splitter='best')
2025-10-21 09:17:01,364:INFO:create_model() successfully completed......................................
2025-10-21 09:17:01,529:INFO:SubProcess create_model() end ==================================
2025-10-21 09:17:01,529:INFO:Creating metrics dataframe
2025-10-21 09:17:01,537:INFO:Initializing SVM - Linear Kernel
2025-10-21 09:17:01,537:INFO:Total runtime is 2.420914657910665 minutes
2025-10-21 09:17:01,544:INFO:SubProcess create_model() called ==================================
2025-10-21 09:17:01,546:INFO:Initializing create_model()
2025-10-21 09:17:01,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:17:01,546:INFO:Checking exceptions
2025-10-21 09:17:01,546:INFO:Importing libraries
2025-10-21 09:17:01,546:INFO:Copying training dataset
2025-10-21 09:17:01,805:INFO:Defining folds
2025-10-21 09:17:01,805:INFO:Declaring metric variables
2025-10-21 09:17:01,808:INFO:Importing untrained model
2025-10-21 09:17:01,813:INFO:SVM - Linear Kernel Imported successfully
2025-10-21 09:17:01,821:INFO:Starting cross validation
2025-10-21 09:17:01,829:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:17:16,389:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 09:17:41,561:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 09:17:54,497:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 09:18:08,495:INFO:Calculating mean and std
2025-10-21 09:18:08,495:INFO:Creating metrics dataframe
2025-10-21 09:18:08,499:INFO:Uploading results into container
2025-10-21 09:18:08,500:INFO:Uploading model into container now
2025-10-21 09:18:08,501:INFO:_master_model_container: 5
2025-10-21 09:18:08,501:INFO:_display_container: 2
2025-10-21 09:18:08,502:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=1391, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-21 09:18:08,502:INFO:create_model() successfully completed......................................
2025-10-21 09:18:08,679:INFO:SubProcess create_model() end ==================================
2025-10-21 09:18:08,679:INFO:Creating metrics dataframe
2025-10-21 09:18:08,685:INFO:Initializing Ridge Classifier
2025-10-21 09:18:08,686:INFO:Total runtime is 3.540042984485626 minutes
2025-10-21 09:18:08,689:INFO:SubProcess create_model() called ==================================
2025-10-21 09:18:08,691:INFO:Initializing create_model()
2025-10-21 09:18:08,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:18:08,691:INFO:Checking exceptions
2025-10-21 09:18:08,691:INFO:Importing libraries
2025-10-21 09:18:08,692:INFO:Copying training dataset
2025-10-21 09:18:08,950:INFO:Defining folds
2025-10-21 09:18:08,950:INFO:Declaring metric variables
2025-10-21 09:18:08,954:INFO:Importing untrained model
2025-10-21 09:18:08,960:INFO:Ridge Classifier Imported successfully
2025-10-21 09:18:08,967:INFO:Starting cross validation
2025-10-21 09:18:08,976:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:18:28,817:INFO:Calculating mean and std
2025-10-21 09:18:28,818:INFO:Creating metrics dataframe
2025-10-21 09:18:28,821:INFO:Uploading results into container
2025-10-21 09:18:28,822:INFO:Uploading model into container now
2025-10-21 09:18:28,823:INFO:_master_model_container: 6
2025-10-21 09:18:28,823:INFO:_display_container: 2
2025-10-21 09:18:28,823:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001)
2025-10-21 09:18:28,823:INFO:create_model() successfully completed......................................
2025-10-21 09:18:28,992:INFO:SubProcess create_model() end ==================================
2025-10-21 09:18:28,992:INFO:Creating metrics dataframe
2025-10-21 09:18:29,000:INFO:Initializing Random Forest Classifier
2025-10-21 09:18:29,000:INFO:Total runtime is 3.878630137443542 minutes
2025-10-21 09:18:29,003:INFO:SubProcess create_model() called ==================================
2025-10-21 09:18:29,005:INFO:Initializing create_model()
2025-10-21 09:18:29,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:18:29,005:INFO:Checking exceptions
2025-10-21 09:18:29,005:INFO:Importing libraries
2025-10-21 09:18:29,005:INFO:Copying training dataset
2025-10-21 09:18:29,316:INFO:Defining folds
2025-10-21 09:18:29,316:INFO:Declaring metric variables
2025-10-21 09:18:29,320:INFO:Importing untrained model
2025-10-21 09:18:29,328:INFO:Random Forest Classifier Imported successfully
2025-10-21 09:18:29,335:INFO:Starting cross validation
2025-10-21 09:18:29,344:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:19:56,229:INFO:Calculating mean and std
2025-10-21 09:19:56,230:INFO:Creating metrics dataframe
2025-10-21 09:19:56,233:INFO:Uploading results into container
2025-10-21 09:19:56,233:INFO:Uploading model into container now
2025-10-21 09:19:56,234:INFO:_master_model_container: 7
2025-10-21 09:19:56,234:INFO:_display_container: 2
2025-10-21 09:19:56,234:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=1391, verbose=0,
                       warm_start=False)
2025-10-21 09:19:56,234:INFO:create_model() successfully completed......................................
2025-10-21 09:19:56,401:INFO:SubProcess create_model() end ==================================
2025-10-21 09:19:56,402:INFO:Creating metrics dataframe
2025-10-21 09:19:56,411:INFO:Initializing Quadratic Discriminant Analysis
2025-10-21 09:19:56,411:INFO:Total runtime is 5.335482784112294 minutes
2025-10-21 09:19:56,416:INFO:SubProcess create_model() called ==================================
2025-10-21 09:19:56,418:INFO:Initializing create_model()
2025-10-21 09:19:56,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:19:56,418:INFO:Checking exceptions
2025-10-21 09:19:56,418:INFO:Importing libraries
2025-10-21 09:19:56,418:INFO:Copying training dataset
2025-10-21 09:19:56,683:INFO:Defining folds
2025-10-21 09:19:56,683:INFO:Declaring metric variables
2025-10-21 09:19:56,686:INFO:Importing untrained model
2025-10-21 09:19:56,692:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-21 09:19:56,702:INFO:Starting cross validation
2025-10-21 09:19:56,710:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:20:00,691:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-21 09:20:05,299:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-21 09:20:09,966:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-21 09:20:14,556:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-21 09:20:19,089:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-21 09:20:19,761:INFO:Calculating mean and std
2025-10-21 09:20:19,762:INFO:Creating metrics dataframe
2025-10-21 09:20:19,764:INFO:Uploading results into container
2025-10-21 09:20:19,765:INFO:Uploading model into container now
2025-10-21 09:20:19,765:INFO:_master_model_container: 8
2025-10-21 09:20:19,765:INFO:_display_container: 2
2025-10-21 09:20:19,765:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-21 09:20:19,766:INFO:create_model() successfully completed......................................
2025-10-21 09:20:19,915:INFO:SubProcess create_model() end ==================================
2025-10-21 09:20:19,915:INFO:Creating metrics dataframe
2025-10-21 09:20:19,922:INFO:Initializing Ada Boost Classifier
2025-10-21 09:20:19,922:INFO:Total runtime is 5.727337574958801 minutes
2025-10-21 09:20:19,927:INFO:SubProcess create_model() called ==================================
2025-10-21 09:20:19,929:INFO:Initializing create_model()
2025-10-21 09:20:19,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:20:19,930:INFO:Checking exceptions
2025-10-21 09:20:19,930:INFO:Importing libraries
2025-10-21 09:20:19,930:INFO:Copying training dataset
2025-10-21 09:20:20,166:INFO:Defining folds
2025-10-21 09:20:20,167:INFO:Declaring metric variables
2025-10-21 09:20:20,169:INFO:Importing untrained model
2025-10-21 09:20:20,173:INFO:Ada Boost Classifier Imported successfully
2025-10-21 09:20:20,191:INFO:Starting cross validation
2025-10-21 09:20:20,202:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:20:23,706:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 09:20:34,752:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 09:20:45,878:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 09:20:56,555:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 09:21:07,455:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 09:21:14,862:INFO:Calculating mean and std
2025-10-21 09:21:14,863:INFO:Creating metrics dataframe
2025-10-21 09:21:14,865:INFO:Uploading results into container
2025-10-21 09:21:14,866:INFO:Uploading model into container now
2025-10-21 09:21:14,866:INFO:_master_model_container: 9
2025-10-21 09:21:14,866:INFO:_display_container: 2
2025-10-21 09:21:14,867:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1391)
2025-10-21 09:21:14,867:INFO:create_model() successfully completed......................................
2025-10-21 09:21:15,027:INFO:SubProcess create_model() end ==================================
2025-10-21 09:21:15,027:INFO:Creating metrics dataframe
2025-10-21 09:21:15,034:INFO:Initializing Gradient Boosting Classifier
2025-10-21 09:21:15,035:INFO:Total runtime is 6.645874110857646 minutes
2025-10-21 09:21:15,041:INFO:SubProcess create_model() called ==================================
2025-10-21 09:21:15,042:INFO:Initializing create_model()
2025-10-21 09:21:15,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:21:15,043:INFO:Checking exceptions
2025-10-21 09:21:15,043:INFO:Importing libraries
2025-10-21 09:21:15,043:INFO:Copying training dataset
2025-10-21 09:21:15,285:INFO:Defining folds
2025-10-21 09:21:15,285:INFO:Declaring metric variables
2025-10-21 09:21:15,288:INFO:Importing untrained model
2025-10-21 09:21:15,294:INFO:Gradient Boosting Classifier Imported successfully
2025-10-21 09:21:15,304:INFO:Starting cross validation
2025-10-21 09:21:15,312:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:23:41,502:INFO:Calculating mean and std
2025-10-21 09:23:41,503:INFO:Creating metrics dataframe
2025-10-21 09:23:41,505:INFO:Uploading results into container
2025-10-21 09:23:41,506:INFO:Uploading model into container now
2025-10-21 09:23:41,507:INFO:_master_model_container: 10
2025-10-21 09:23:41,507:INFO:_display_container: 2
2025-10-21 09:23:41,508:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 09:23:41,508:INFO:create_model() successfully completed......................................
2025-10-21 09:23:41,677:INFO:SubProcess create_model() end ==================================
2025-10-21 09:23:41,677:INFO:Creating metrics dataframe
2025-10-21 09:23:41,688:INFO:Initializing Linear Discriminant Analysis
2025-10-21 09:23:41,688:INFO:Total runtime is 9.090105585257213 minutes
2025-10-21 09:23:41,692:INFO:SubProcess create_model() called ==================================
2025-10-21 09:23:41,694:INFO:Initializing create_model()
2025-10-21 09:23:41,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:23:41,695:INFO:Checking exceptions
2025-10-21 09:23:41,695:INFO:Importing libraries
2025-10-21 09:23:41,695:INFO:Copying training dataset
2025-10-21 09:23:41,949:INFO:Defining folds
2025-10-21 09:23:41,949:INFO:Declaring metric variables
2025-10-21 09:23:41,954:INFO:Importing untrained model
2025-10-21 09:23:41,960:INFO:Linear Discriminant Analysis Imported successfully
2025-10-21 09:23:41,969:INFO:Starting cross validation
2025-10-21 09:23:41,978:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:24:05,502:INFO:Calculating mean and std
2025-10-21 09:24:05,503:INFO:Creating metrics dataframe
2025-10-21 09:24:05,506:INFO:Uploading results into container
2025-10-21 09:24:05,506:INFO:Uploading model into container now
2025-10-21 09:24:05,506:INFO:_master_model_container: 11
2025-10-21 09:24:05,506:INFO:_display_container: 2
2025-10-21 09:24:05,507:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-21 09:24:05,507:INFO:create_model() successfully completed......................................
2025-10-21 09:24:05,677:INFO:SubProcess create_model() end ==================================
2025-10-21 09:24:05,677:INFO:Creating metrics dataframe
2025-10-21 09:24:05,688:INFO:Initializing Extra Trees Classifier
2025-10-21 09:24:05,688:INFO:Total runtime is 9.490102243423463 minutes
2025-10-21 09:24:05,693:INFO:SubProcess create_model() called ==================================
2025-10-21 09:24:05,695:INFO:Initializing create_model()
2025-10-21 09:24:05,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:24:05,695:INFO:Checking exceptions
2025-10-21 09:24:05,695:INFO:Importing libraries
2025-10-21 09:24:05,695:INFO:Copying training dataset
2025-10-21 09:24:05,964:INFO:Defining folds
2025-10-21 09:24:05,965:INFO:Declaring metric variables
2025-10-21 09:24:05,968:INFO:Importing untrained model
2025-10-21 09:24:05,974:INFO:Extra Trees Classifier Imported successfully
2025-10-21 09:24:05,981:INFO:Starting cross validation
2025-10-21 09:24:05,989:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:25:50,632:INFO:Calculating mean and std
2025-10-21 09:25:50,633:INFO:Creating metrics dataframe
2025-10-21 09:25:50,637:INFO:Uploading results into container
2025-10-21 09:25:50,638:INFO:Uploading model into container now
2025-10-21 09:25:50,639:INFO:_master_model_container: 12
2025-10-21 09:25:50,639:INFO:_display_container: 2
2025-10-21 09:25:50,640:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=1391, verbose=0,
                     warm_start=False)
2025-10-21 09:25:50,640:INFO:create_model() successfully completed......................................
2025-10-21 09:25:50,799:INFO:SubProcess create_model() end ==================================
2025-10-21 09:25:50,799:INFO:Creating metrics dataframe
2025-10-21 09:25:50,807:INFO:Initializing Extreme Gradient Boosting
2025-10-21 09:25:50,807:INFO:Total runtime is 11.242087368170422 minutes
2025-10-21 09:25:50,809:INFO:SubProcess create_model() called ==================================
2025-10-21 09:25:50,810:INFO:Initializing create_model()
2025-10-21 09:25:50,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=xgboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:25:50,810:INFO:Checking exceptions
2025-10-21 09:25:50,811:INFO:Importing libraries
2025-10-21 09:25:50,811:INFO:Copying training dataset
2025-10-21 09:25:51,038:INFO:Defining folds
2025-10-21 09:25:51,039:INFO:Declaring metric variables
2025-10-21 09:25:51,042:INFO:Importing untrained model
2025-10-21 09:25:51,046:INFO:Extreme Gradient Boosting Imported successfully
2025-10-21 09:25:51,054:INFO:Starting cross validation
2025-10-21 09:25:51,061:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:26:31,037:INFO:Calculating mean and std
2025-10-21 09:26:31,038:INFO:Creating metrics dataframe
2025-10-21 09:26:31,040:INFO:Uploading results into container
2025-10-21 09:26:31,041:INFO:Uploading model into container now
2025-10-21 09:26:31,041:INFO:_master_model_container: 13
2025-10-21 09:26:31,041:INFO:_display_container: 2
2025-10-21 09:26:31,042:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-10-21 09:26:31,042:INFO:create_model() successfully completed......................................
2025-10-21 09:26:31,194:INFO:SubProcess create_model() end ==================================
2025-10-21 09:26:31,194:INFO:Creating metrics dataframe
2025-10-21 09:26:31,203:INFO:Initializing Light Gradient Boosting Machine
2025-10-21 09:26:31,203:INFO:Total runtime is 11.915343900521599 minutes
2025-10-21 09:26:31,208:INFO:SubProcess create_model() called ==================================
2025-10-21 09:26:31,209:INFO:Initializing create_model()
2025-10-21 09:26:31,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:26:31,210:INFO:Checking exceptions
2025-10-21 09:26:31,210:INFO:Importing libraries
2025-10-21 09:26:31,210:INFO:Copying training dataset
2025-10-21 09:26:31,435:INFO:Defining folds
2025-10-21 09:26:31,436:INFO:Declaring metric variables
2025-10-21 09:26:31,440:INFO:Importing untrained model
2025-10-21 09:26:31,444:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-21 09:26:31,452:INFO:Starting cross validation
2025-10-21 09:26:31,459:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:26:35,026:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 09:26:35,029:INFO:[LightGBM] [Info] Number of positive: 29912, number of negative: 29912
2025-10-21 09:26:35,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034707 seconds.
2025-10-21 09:26:35,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 09:26:35,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 09:26:35,103:INFO:[LightGBM] [Info] Total Bins 23904
2025-10-21 09:26:35,104:INFO:[LightGBM] [Info] Number of data points in the train set: 59824, number of used features: 96
2025-10-21 09:26:35,104:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-21 09:26:40,218:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 09:26:40,220:INFO:[LightGBM] [Info] Number of positive: 29882, number of negative: 29882
2025-10-21 09:26:40,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030886 seconds.
2025-10-21 09:26:40,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 09:26:40,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 09:26:40,289:INFO:[LightGBM] [Info] Total Bins 24054
2025-10-21 09:26:40,291:INFO:[LightGBM] [Info] Number of data points in the train set: 59764, number of used features: 96
2025-10-21 09:26:40,292:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-21 09:26:45,598:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 09:26:45,601:INFO:[LightGBM] [Info] Number of positive: 29876, number of negative: 29876
2025-10-21 09:26:45,677:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035890 seconds.
2025-10-21 09:26:45,677:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 09:26:45,677:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 09:26:45,677:INFO:[LightGBM] [Info] Total Bins 23869
2025-10-21 09:26:45,678:INFO:[LightGBM] [Info] Number of data points in the train set: 59752, number of used features: 96
2025-10-21 09:26:45,678:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-21 09:26:50,855:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 09:26:50,858:INFO:[LightGBM] [Info] Number of positive: 29937, number of negative: 29937
2025-10-21 09:26:50,938:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037947 seconds.
2025-10-21 09:26:50,938:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 09:26:50,938:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 09:26:50,938:INFO:[LightGBM] [Info] Total Bins 24073
2025-10-21 09:26:50,939:INFO:[LightGBM] [Info] Number of data points in the train set: 59874, number of used features: 96
2025-10-21 09:26:50,940:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-21 09:26:56,149:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 09:26:56,152:INFO:[LightGBM] [Info] Number of positive: 29885, number of negative: 29885
2025-10-21 09:26:56,233:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040457 seconds.
2025-10-21 09:26:56,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 09:26:56,233:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 09:26:56,233:INFO:[LightGBM] [Info] Total Bins 24055
2025-10-21 09:26:56,234:INFO:[LightGBM] [Info] Number of data points in the train set: 59770, number of used features: 96
2025-10-21 09:26:56,235:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-21 09:26:57,910:INFO:Calculating mean and std
2025-10-21 09:26:57,911:INFO:Creating metrics dataframe
2025-10-21 09:26:57,915:INFO:Uploading results into container
2025-10-21 09:26:57,915:INFO:Uploading model into container now
2025-10-21 09:26:57,916:INFO:_master_model_container: 14
2025-10-21 09:26:57,916:INFO:_display_container: 2
2025-10-21 09:26:57,917:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=1391, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-21 09:26:57,919:INFO:create_model() successfully completed......................................
2025-10-21 09:26:58,084:INFO:SubProcess create_model() end ==================================
2025-10-21 09:26:58,084:INFO:Creating metrics dataframe
2025-10-21 09:26:58,095:INFO:Initializing CatBoost Classifier
2025-10-21 09:26:58,096:INFO:Total runtime is 12.363557151953382 minutes
2025-10-21 09:26:58,098:INFO:SubProcess create_model() called ==================================
2025-10-21 09:26:58,100:INFO:Initializing create_model()
2025-10-21 09:26:58,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:26:58,100:INFO:Checking exceptions
2025-10-21 09:26:58,100:INFO:Importing libraries
2025-10-21 09:26:58,100:INFO:Copying training dataset
2025-10-21 09:26:58,484:INFO:Defining folds
2025-10-21 09:26:58,485:INFO:Declaring metric variables
2025-10-21 09:26:58,490:INFO:Importing untrained model
2025-10-21 09:26:58,496:INFO:CatBoost Classifier Imported successfully
2025-10-21 09:26:58,505:INFO:Starting cross validation
2025-10-21 09:26:58,514:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:35:26,465:INFO:Calculating mean and std
2025-10-21 09:35:26,466:INFO:Creating metrics dataframe
2025-10-21 09:35:26,468:INFO:Uploading results into container
2025-10-21 09:35:26,469:INFO:Uploading model into container now
2025-10-21 09:35:26,469:INFO:_master_model_container: 15
2025-10-21 09:35:26,469:INFO:_display_container: 2
2025-10-21 09:35:26,469:INFO:<catboost.core.CatBoostClassifier object at 0x0000020403A84B50>
2025-10-21 09:35:26,469:INFO:create_model() successfully completed......................................
2025-10-21 09:35:26,627:INFO:SubProcess create_model() end ==================================
2025-10-21 09:35:26,628:INFO:Creating metrics dataframe
2025-10-21 09:35:26,639:INFO:Initializing Dummy Classifier
2025-10-21 09:35:26,639:INFO:Total runtime is 20.839285115400955 minutes
2025-10-21 09:35:26,641:INFO:SubProcess create_model() called ==================================
2025-10-21 09:35:26,643:INFO:Initializing create_model()
2025-10-21 09:35:26,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FD2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:35:26,643:INFO:Checking exceptions
2025-10-21 09:35:26,643:INFO:Importing libraries
2025-10-21 09:35:26,643:INFO:Copying training dataset
2025-10-21 09:35:26,911:INFO:Defining folds
2025-10-21 09:35:26,913:INFO:Declaring metric variables
2025-10-21 09:35:26,919:INFO:Importing untrained model
2025-10-21 09:35:26,922:INFO:Dummy Classifier Imported successfully
2025-10-21 09:35:26,930:INFO:Starting cross validation
2025-10-21 09:35:26,942:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 09:35:30,902:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 09:35:34,724:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 09:35:38,238:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 09:35:41,635:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 09:35:45,084:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-21 09:35:45,102:INFO:Calculating mean and std
2025-10-21 09:35:45,103:INFO:Creating metrics dataframe
2025-10-21 09:35:45,104:INFO:Uploading results into container
2025-10-21 09:35:45,105:INFO:Uploading model into container now
2025-10-21 09:35:45,105:INFO:_master_model_container: 16
2025-10-21 09:35:45,105:INFO:_display_container: 2
2025-10-21 09:35:45,105:INFO:DummyClassifier(constant=None, random_state=1391, strategy='prior')
2025-10-21 09:35:45,105:INFO:create_model() successfully completed......................................
2025-10-21 09:35:45,267:INFO:SubProcess create_model() end ==================================
2025-10-21 09:35:45,267:INFO:Creating metrics dataframe
2025-10-21 09:35:45,282:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-21 09:35:45,294:INFO:Initializing create_model()
2025-10-21 09:35:45,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:35:45,294:INFO:Checking exceptions
2025-10-21 09:35:45,297:INFO:Importing libraries
2025-10-21 09:35:45,297:INFO:Copying training dataset
2025-10-21 09:35:45,619:INFO:Defining folds
2025-10-21 09:35:45,619:INFO:Declaring metric variables
2025-10-21 09:35:45,620:INFO:Importing untrained model
2025-10-21 09:35:45,620:INFO:Declaring custom model
2025-10-21 09:35:45,621:INFO:Gradient Boosting Classifier Imported successfully
2025-10-21 09:35:45,628:INFO:Cross validation set to False
2025-10-21 09:35:45,628:INFO:Fitting Model
2025-10-21 09:36:19,965:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 09:36:19,966:INFO:create_model() successfully completed......................................
2025-10-21 09:36:20,132:INFO:Initializing create_model()
2025-10-21 09:36:20,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:36:20,132:INFO:Checking exceptions
2025-10-21 09:36:20,135:INFO:Importing libraries
2025-10-21 09:36:20,135:INFO:Copying training dataset
2025-10-21 09:36:20,362:INFO:Defining folds
2025-10-21 09:36:20,362:INFO:Declaring metric variables
2025-10-21 09:36:20,362:INFO:Importing untrained model
2025-10-21 09:36:20,362:INFO:Declaring custom model
2025-10-21 09:36:20,363:INFO:Ridge Classifier Imported successfully
2025-10-21 09:36:20,368:INFO:Cross validation set to False
2025-10-21 09:36:20,368:INFO:Fitting Model
2025-10-21 09:36:24,567:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001)
2025-10-21 09:36:24,567:INFO:create_model() successfully completed......................................
2025-10-21 09:36:24,723:INFO:Initializing create_model()
2025-10-21 09:36:24,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 09:36:24,724:INFO:Checking exceptions
2025-10-21 09:36:24,727:INFO:Importing libraries
2025-10-21 09:36:24,727:INFO:Copying training dataset
2025-10-21 09:36:24,969:INFO:Defining folds
2025-10-21 09:36:24,969:INFO:Declaring metric variables
2025-10-21 09:36:24,969:INFO:Importing untrained model
2025-10-21 09:36:24,969:INFO:Declaring custom model
2025-10-21 09:36:24,970:INFO:Linear Discriminant Analysis Imported successfully
2025-10-21 09:36:24,976:INFO:Cross validation set to False
2025-10-21 09:36:24,976:INFO:Fitting Model
2025-10-21 09:36:30,245:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-21 09:36:30,245:INFO:create_model() successfully completed......................................
2025-10-21 09:36:30,425:INFO:_master_model_container: 16
2025-10-21 09:36:30,425:INFO:_display_container: 2
2025-10-21 09:36:30,426:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2025-10-21 09:36:30,426:INFO:compare_models() successfully completed......................................
2025-10-21 09:36:30,427:INFO:Initializing tune_model()
2025-10-21 09:36:30,428:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-21 09:36:30,428:INFO:Checking exceptions
2025-10-21 09:36:30,546:INFO:Copying training dataset
2025-10-21 09:36:30,781:INFO:Checking base model
2025-10-21 09:36:30,781:INFO:Base model : Gradient Boosting Classifier
2025-10-21 09:36:30,784:INFO:Declaring metric variables
2025-10-21 09:36:30,787:INFO:Defining Hyperparameters
2025-10-21 09:36:30,946:INFO:Tuning with n_jobs=1
2025-10-21 09:36:30,946:INFO:Initializing RandomizedSearchCV
2025-10-21 09:59:53,806:INFO:best_params: {'actual_estimator__subsample': 0.55, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 4, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.005}
2025-10-21 09:59:53,808:INFO:Hyperparameter search completed
2025-10-21 09:59:53,808:INFO:SubProcess create_model() called ==================================
2025-10-21 09:59:53,810:INFO:Initializing create_model()
2025-10-21 09:59:53,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020473646550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.55, 'n_estimators': 280, 'min_samples_split': 4, 'min_samples_leaf': 5, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 9, 'learning_rate': 0.005})
2025-10-21 09:59:53,810:INFO:Checking exceptions
2025-10-21 09:59:53,810:INFO:Importing libraries
2025-10-21 09:59:53,810:INFO:Copying training dataset
2025-10-21 09:59:54,085:INFO:Defining folds
2025-10-21 09:59:54,085:INFO:Declaring metric variables
2025-10-21 09:59:54,088:INFO:Importing untrained model
2025-10-21 09:59:54,088:INFO:Declaring custom model
2025-10-21 09:59:54,094:INFO:Gradient Boosting Classifier Imported successfully
2025-10-21 09:59:54,101:INFO:Starting cross validation
2025-10-21 09:59:54,109:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 10:10:34,260:INFO:Calculating mean and std
2025-10-21 10:10:34,261:INFO:Creating metrics dataframe
2025-10-21 10:10:34,265:INFO:Finalizing model
2025-10-21 10:13:17,086:INFO:Uploading results into container
2025-10-21 10:13:17,087:INFO:Uploading model into container now
2025-10-21 10:13:17,088:INFO:_master_model_container: 17
2025-10-21 10:13:17,088:INFO:_display_container: 3
2025-10-21 10:13:17,089:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=9,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=5,
                           min_samples_split=4, min_weight_fraction_leaf=0.0,
                           n_estimators=280, n_iter_no_change=None,
                           random_state=1391, subsample=0.55, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 10:13:17,089:INFO:create_model() successfully completed......................................
2025-10-21 10:13:17,263:INFO:SubProcess create_model() end ==================================
2025-10-21 10:13:17,263:INFO:choose_better activated
2025-10-21 10:13:17,266:INFO:SubProcess create_model() called ==================================
2025-10-21 10:13:17,267:INFO:Initializing create_model()
2025-10-21 10:13:17,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 10:13:17,267:INFO:Checking exceptions
2025-10-21 10:13:17,268:INFO:Importing libraries
2025-10-21 10:13:17,269:INFO:Copying training dataset
2025-10-21 10:13:17,532:INFO:Defining folds
2025-10-21 10:13:17,532:INFO:Declaring metric variables
2025-10-21 10:13:17,532:INFO:Importing untrained model
2025-10-21 10:13:17,532:INFO:Declaring custom model
2025-10-21 10:13:17,533:INFO:Gradient Boosting Classifier Imported successfully
2025-10-21 10:13:17,533:INFO:Starting cross validation
2025-10-21 10:13:17,540:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 10:15:32,812:INFO:Calculating mean and std
2025-10-21 10:15:32,812:INFO:Creating metrics dataframe
2025-10-21 10:15:32,813:INFO:Finalizing model
2025-10-21 10:16:07,049:INFO:Uploading results into container
2025-10-21 10:16:07,049:INFO:Uploading model into container now
2025-10-21 10:16:07,050:INFO:_master_model_container: 18
2025-10-21 10:16:07,050:INFO:_display_container: 4
2025-10-21 10:16:07,050:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 10:16:07,050:INFO:create_model() successfully completed......................................
2025-10-21 10:16:07,204:INFO:SubProcess create_model() end ==================================
2025-10-21 10:16:07,205:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9223
2025-10-21 10:16:07,206:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=9,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=5,
                           min_samples_split=4, min_weight_fraction_leaf=0.0,
                           n_estimators=280, n_iter_no_change=None,
                           random_state=1391, subsample=0.55, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9214
2025-10-21 10:16:07,206:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-21 10:16:07,206:INFO:choose_better completed
2025-10-21 10:16:07,206:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-21 10:16:07,215:INFO:_master_model_container: 18
2025-10-21 10:16:07,216:INFO:_display_container: 3
2025-10-21 10:16:07,216:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 10:16:07,216:INFO:tune_model() successfully completed......................................
2025-10-21 10:16:07,387:INFO:Initializing tune_model()
2025-10-21 10:16:07,388:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-21 10:16:07,388:INFO:Checking exceptions
2025-10-21 10:16:07,497:INFO:Copying training dataset
2025-10-21 10:16:07,672:INFO:Checking base model
2025-10-21 10:16:07,672:INFO:Base model : Ridge Classifier
2025-10-21 10:16:07,676:INFO:Declaring metric variables
2025-10-21 10:16:07,679:INFO:Defining Hyperparameters
2025-10-21 10:16:07,839:INFO:Tuning with n_jobs=1
2025-10-21 10:16:07,839:INFO:Initializing RandomizedSearchCV
2025-10-21 10:20:13,904:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 8.25}
2025-10-21 10:20:13,904:INFO:Hyperparameter search completed
2025-10-21 10:20:13,905:INFO:SubProcess create_model() called ==================================
2025-10-21 10:20:13,905:INFO:Initializing create_model()
2025-10-21 10:20:13,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002046F701BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 8.25})
2025-10-21 10:20:13,906:INFO:Checking exceptions
2025-10-21 10:20:13,906:INFO:Importing libraries
2025-10-21 10:20:13,906:INFO:Copying training dataset
2025-10-21 10:20:14,143:INFO:Defining folds
2025-10-21 10:20:14,143:INFO:Declaring metric variables
2025-10-21 10:20:14,148:INFO:Importing untrained model
2025-10-21 10:20:14,149:INFO:Declaring custom model
2025-10-21 10:20:14,154:INFO:Ridge Classifier Imported successfully
2025-10-21 10:20:14,160:INFO:Starting cross validation
2025-10-21 10:20:14,167:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 10:20:32,545:INFO:Calculating mean and std
2025-10-21 10:20:32,546:INFO:Creating metrics dataframe
2025-10-21 10:20:32,550:INFO:Finalizing model
2025-10-21 10:20:37,051:INFO:Uploading results into container
2025-10-21 10:20:37,053:INFO:Uploading model into container now
2025-10-21 10:20:37,056:INFO:_master_model_container: 19
2025-10-21 10:20:37,056:INFO:_display_container: 4
2025-10-21 10:20:37,056:INFO:RidgeClassifier(alpha=8.25, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001)
2025-10-21 10:20:37,056:INFO:create_model() successfully completed......................................
2025-10-21 10:20:37,234:INFO:SubProcess create_model() end ==================================
2025-10-21 10:20:37,234:INFO:choose_better activated
2025-10-21 10:20:37,239:INFO:SubProcess create_model() called ==================================
2025-10-21 10:20:37,239:INFO:Initializing create_model()
2025-10-21 10:20:37,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 10:20:37,241:INFO:Checking exceptions
2025-10-21 10:20:37,241:INFO:Importing libraries
2025-10-21 10:20:37,241:INFO:Copying training dataset
2025-10-21 10:20:37,473:INFO:Defining folds
2025-10-21 10:20:37,473:INFO:Declaring metric variables
2025-10-21 10:20:37,473:INFO:Importing untrained model
2025-10-21 10:20:37,473:INFO:Declaring custom model
2025-10-21 10:20:37,474:INFO:Ridge Classifier Imported successfully
2025-10-21 10:20:37,474:INFO:Starting cross validation
2025-10-21 10:20:37,479:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 10:20:56,873:INFO:Calculating mean and std
2025-10-21 10:20:56,874:INFO:Creating metrics dataframe
2025-10-21 10:20:56,875:INFO:Finalizing model
2025-10-21 10:21:01,415:INFO:Uploading results into container
2025-10-21 10:21:01,416:INFO:Uploading model into container now
2025-10-21 10:21:01,416:INFO:_master_model_container: 20
2025-10-21 10:21:01,416:INFO:_display_container: 5
2025-10-21 10:21:01,417:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001)
2025-10-21 10:21:01,417:INFO:create_model() successfully completed......................................
2025-10-21 10:21:01,582:INFO:SubProcess create_model() end ==================================
2025-10-21 10:21:01,583:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001) result for AUC is 0.9217
2025-10-21 10:21:01,583:INFO:RidgeClassifier(alpha=8.25, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001) result for AUC is 0.922
2025-10-21 10:21:01,583:INFO:RidgeClassifier(alpha=8.25, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001) is best model
2025-10-21 10:21:01,583:INFO:choose_better completed
2025-10-21 10:21:01,593:INFO:_master_model_container: 20
2025-10-21 10:21:01,594:INFO:_display_container: 4
2025-10-21 10:21:01,594:INFO:RidgeClassifier(alpha=8.25, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001)
2025-10-21 10:21:01,594:INFO:tune_model() successfully completed......................................
2025-10-21 10:21:01,785:INFO:Initializing tune_model()
2025-10-21 10:21:01,785:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-21 10:21:01,785:INFO:Checking exceptions
2025-10-21 10:21:01,897:INFO:Copying training dataset
2025-10-21 10:21:02,111:INFO:Checking base model
2025-10-21 10:21:02,111:INFO:Base model : Linear Discriminant Analysis
2025-10-21 10:21:02,114:INFO:Declaring metric variables
2025-10-21 10:21:02,117:INFO:Defining Hyperparameters
2025-10-21 10:21:02,299:INFO:Tuning with n_jobs=1
2025-10-21 10:21:02,299:INFO:Initializing RandomizedSearchCV
2025-10-21 10:24:13,088:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 'auto'}
2025-10-21 10:24:13,089:INFO:Hyperparameter search completed
2025-10-21 10:24:13,089:INFO:SubProcess create_model() called ==================================
2025-10-21 10:24:13,090:INFO:Initializing create_model()
2025-10-21 10:24:13,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020454CDF690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 'auto'})
2025-10-21 10:24:13,090:INFO:Checking exceptions
2025-10-21 10:24:13,090:INFO:Importing libraries
2025-10-21 10:24:13,090:INFO:Copying training dataset
2025-10-21 10:24:13,327:INFO:Defining folds
2025-10-21 10:24:13,327:INFO:Declaring metric variables
2025-10-21 10:24:13,331:INFO:Importing untrained model
2025-10-21 10:24:13,331:INFO:Declaring custom model
2025-10-21 10:24:13,337:INFO:Linear Discriminant Analysis Imported successfully
2025-10-21 10:24:13,343:INFO:Starting cross validation
2025-10-21 10:24:13,352:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 10:24:32,106:INFO:Calculating mean and std
2025-10-21 10:24:32,107:INFO:Creating metrics dataframe
2025-10-21 10:24:32,111:INFO:Finalizing model
2025-10-21 10:24:36,567:INFO:Uploading results into container
2025-10-21 10:24:36,568:INFO:Uploading model into container now
2025-10-21 10:24:36,568:INFO:_master_model_container: 21
2025-10-21 10:24:36,568:INFO:_display_container: 5
2025-10-21 10:24:36,570:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-21 10:24:36,570:INFO:create_model() successfully completed......................................
2025-10-21 10:24:36,748:INFO:SubProcess create_model() end ==================================
2025-10-21 10:24:36,748:INFO:choose_better activated
2025-10-21 10:24:36,752:INFO:SubProcess create_model() called ==================================
2025-10-21 10:24:36,754:INFO:Initializing create_model()
2025-10-21 10:24:36,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 10:24:36,754:INFO:Checking exceptions
2025-10-21 10:24:36,756:INFO:Importing libraries
2025-10-21 10:24:36,756:INFO:Copying training dataset
2025-10-21 10:24:36,975:INFO:Defining folds
2025-10-21 10:24:36,975:INFO:Declaring metric variables
2025-10-21 10:24:36,975:INFO:Importing untrained model
2025-10-21 10:24:36,975:INFO:Declaring custom model
2025-10-21 10:24:36,976:INFO:Linear Discriminant Analysis Imported successfully
2025-10-21 10:24:36,976:INFO:Starting cross validation
2025-10-21 10:24:36,982:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 10:24:58,869:INFO:Calculating mean and std
2025-10-21 10:24:58,870:INFO:Creating metrics dataframe
2025-10-21 10:24:58,872:INFO:Finalizing model
2025-10-21 10:25:04,632:INFO:Uploading results into container
2025-10-21 10:25:04,632:INFO:Uploading model into container now
2025-10-21 10:25:04,632:INFO:_master_model_container: 22
2025-10-21 10:25:04,633:INFO:_display_container: 6
2025-10-21 10:25:04,633:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-21 10:25:04,633:INFO:create_model() successfully completed......................................
2025-10-21 10:25:04,791:INFO:SubProcess create_model() end ==================================
2025-10-21 10:25:04,791:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9216
2025-10-21 10:25:04,791:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9216
2025-10-21 10:25:04,792:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2025-10-21 10:25:04,792:INFO:choose_better completed
2025-10-21 10:25:04,792:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-21 10:25:04,801:INFO:_master_model_container: 22
2025-10-21 10:25:04,802:INFO:_display_container: 5
2025-10-21 10:25:04,802:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-21 10:25:04,802:INFO:tune_model() successfully completed......................................
2025-10-21 10:25:04,968:INFO:Initializing blend_models()
2025-10-21 10:25:04,968:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1391, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=8.25, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-21 10:25:04,968:INFO:Checking exceptions
2025-10-21 10:25:04,968:INFO:Estimator RidgeClassifier(alpha=8.25, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=1391, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-21 10:25:05,085:INFO:Importing libraries
2025-10-21 10:25:05,085:INFO:Copying training dataset
2025-10-21 10:25:05,090:INFO:Getting model names
2025-10-21 10:25:05,095:INFO:SubProcess create_model() called ==================================
2025-10-21 10:25:05,101:INFO:Initializing create_model()
2025-10-21 10:25:05,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=1391, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
6169     U01075
22606    U11490
39305    U07470
7250     U05909
58576    U10580
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020454CDF8D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 10:25:05,101:INFO:Checking exceptions
2025-10-21 10:25:05,101:INFO:Importing libraries
2025-10-21 10:25:05,101:INFO:Copying training dataset
2025-10-21 10:25:05,345:INFO:Defining folds
2025-10-21 10:25:05,345:INFO:Declaring metric variables
2025-10-21 10:25:05,348:INFO:Importing untrained model
2025-10-21 10:25:05,348:INFO:Declaring custom model
2025-10-21 10:25:05,354:INFO:Voting Classifier Imported successfully
2025-10-21 10:25:05,360:INFO:Starting cross validation
2025-10-21 10:25:05,370:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-21 10:25:35,010:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-21 10:26:03,713:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-21 10:26:46,728:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-21 10:27:17,134:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-21 10:27:46,381:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-21 10:27:46,419:INFO:Calculating mean and std
2025-10-21 10:27:46,420:INFO:Creating metrics dataframe
2025-10-21 10:27:46,424:INFO:Finalizing model
2025-10-21 10:28:22,084:INFO:Uploading results into container
2025-10-21 10:28:22,086:INFO:Uploading model into container now
2025-10-21 10:28:22,087:INFO:_master_model_container: 23
2025-10-21 10:28:22,087:INFO:_display_container: 6
2025-10-21 10:28:22,093:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=1391, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-21 10:28:22,093:INFO:create_model() successfully completed......................................
2025-10-21 10:28:22,277:INFO:SubProcess create_model() end ==================================
2025-10-21 10:28:22,286:INFO:_master_model_container: 23
2025-10-21 10:28:22,286:INFO:_display_container: 6
2025-10-21 10:28:22,290:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=1391, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-21 10:28:22,290:INFO:blend_models() successfully completed......................................
2025-10-21 10:28:22,463:INFO:Initializing finalize_model()
2025-10-21 10:28:22,463:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=1391, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-21 10:28:22,466:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=1391, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-21 10:28:22,650:INFO:Initializing create_model()
2025-10-21 10:28:22,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020465BB7910>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=1391, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=33602    U01120
41195    U05695
79009    U17454
5844     U13834
75806    U17781
          ...  
60168    U19398
51157    U02152
6290     U19911
28497    U19453
67927    U18068
Name: id_usuario, Length: 80004, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 10:28:22,651:INFO:Checking exceptions
2025-10-21 10:28:22,653:INFO:Importing libraries
2025-10-21 10:28:22,653:INFO:Copying training dataset
2025-10-21 10:28:22,686:INFO:Defining folds
2025-10-21 10:28:22,686:INFO:Declaring metric variables
2025-10-21 10:28:22,687:INFO:Importing untrained model
2025-10-21 10:28:22,687:INFO:Declaring custom model
2025-10-21 10:28:22,688:INFO:Voting Classifier Imported successfully
2025-10-21 10:28:22,694:INFO:Cross validation set to False
2025-10-21 10:28:22,694:INFO:Fitting Model
2025-10-21 10:29:14,915:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=1391,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-21 10:29:14,916:INFO:create_model() successfully completed......................................
2025-10-21 10:29:15,124:INFO:_master_model_container: 23
2025-10-21 10:29:15,124:INFO:_display_container: 6
2025-10-21 10:29:15,152:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=1391,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-21 10:29:15,153:INFO:finalize_model() successfully completed......................................
2025-10-21 10:29:15,357:INFO:Initializing save_model()
2025-10-21 10:29:15,357:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=1391,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), model_name=modelo_cls_like_v2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-21 10:29:15,358:INFO:Adding model into prep_pipe
2025-10-21 10:29:15,358:WARNING:Only Model saved as it was a pipeline.
2025-10-21 10:29:15,402:INFO:modelo_cls_like_v2.pkl saved in current working directory
2025-10-21 10:29:15,424:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=1391,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-21 10:29:15,424:INFO:save_model() successfully completed......................................
2025-10-21 11:00:02,783:INFO:PyCaret ClassificationExperiment
2025-10-21 11:00:02,783:INFO:Logging name: clf-default-name
2025-10-21 11:00:02,783:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-21 11:00:02,783:INFO:version 3.3.2
2025-10-21 11:00:02,783:INFO:Initializing setup()
2025-10-21 11:00:02,783:INFO:self.USI: 149b
2025-10-21 11:00:02,783:INFO:self._variable_keys: {'X', 'X_train', 'html_param', 'fold_groups_param', 'log_plots_param', 'exp_name_log', 'y', 'X_test', 'pipeline', 'gpu_n_jobs_param', 'memory', 'exp_id', 'n_jobs_param', 'target_param', 'is_multiclass', 'fold_shuffle_param', 'fix_imbalance', 'seed', 'gpu_param', '_ml_usecase', 'idx', 'data', 'USI', 'logging_param', 'y_train', 'y_test', 'fold_generator', '_available_plots'}
2025-10-21 11:00:02,783:INFO:Checking environment
2025-10-21 11:00:02,783:INFO:python_version: 3.11.13
2025-10-21 11:00:02,783:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-21 11:00:02,783:INFO:machine: AMD64
2025-10-21 11:00:02,783:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-21 11:00:02,790:INFO:Memory: svmem(total=16856211456, available=3725856768, percent=77.9, used=13130354688, free=3725856768)
2025-10-21 11:00:02,790:INFO:Physical Core: 4
2025-10-21 11:00:02,790:INFO:Logical Core: 8
2025-10-21 11:00:02,790:INFO:Checking libraries
2025-10-21 11:00:02,790:INFO:System:
2025-10-21 11:00:02,790:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-21 11:00:02,790:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-21 11:00:02,790:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-21 11:00:02,790:INFO:PyCaret required dependencies:
2025-10-21 11:00:02,790:INFO:                 pip: 25.2
2025-10-21 11:00:02,790:INFO:          setuptools: 80.9.0
2025-10-21 11:00:02,790:INFO:             pycaret: 3.3.2
2025-10-21 11:00:02,790:INFO:             IPython: 9.6.0
2025-10-21 11:00:02,790:INFO:          ipywidgets: 8.1.7
2025-10-21 11:00:02,790:INFO:                tqdm: 4.67.1
2025-10-21 11:00:02,790:INFO:               numpy: 1.26.4
2025-10-21 11:00:02,790:INFO:              pandas: 2.1.4
2025-10-21 11:00:02,790:INFO:              jinja2: 3.1.6
2025-10-21 11:00:02,790:INFO:               scipy: 1.11.4
2025-10-21 11:00:02,790:INFO:              joblib: 1.3.2
2025-10-21 11:00:02,790:INFO:             sklearn: 1.4.2
2025-10-21 11:00:02,790:INFO:                pyod: 2.0.5
2025-10-21 11:00:02,790:INFO:            imblearn: 0.14.0
2025-10-21 11:00:02,790:INFO:   category_encoders: 2.7.0
2025-10-21 11:00:02,790:INFO:            lightgbm: 4.6.0
2025-10-21 11:00:02,790:INFO:               numba: 0.61.0
2025-10-21 11:00:02,790:INFO:            requests: 2.32.5
2025-10-21 11:00:02,791:INFO:          matplotlib: 3.7.5
2025-10-21 11:00:02,791:INFO:          scikitplot: 0.3.7
2025-10-21 11:00:02,791:INFO:         yellowbrick: 1.5
2025-10-21 11:00:02,791:INFO:              plotly: 5.24.1
2025-10-21 11:00:02,791:INFO:    plotly-resampler: Not installed
2025-10-21 11:00:02,791:INFO:             kaleido: 1.1.0
2025-10-21 11:00:02,791:INFO:           schemdraw: 0.15
2025-10-21 11:00:02,791:INFO:         statsmodels: 0.14.5
2025-10-21 11:00:02,791:INFO:              sktime: 0.26.0
2025-10-21 11:00:02,791:INFO:               tbats: 1.1.3
2025-10-21 11:00:02,791:INFO:            pmdarima: 2.0.4
2025-10-21 11:00:02,791:INFO:              psutil: 7.1.1
2025-10-21 11:00:02,791:INFO:          markupsafe: 3.0.3
2025-10-21 11:00:02,791:INFO:             pickle5: Not installed
2025-10-21 11:00:02,791:INFO:         cloudpickle: 3.1.1
2025-10-21 11:00:02,791:INFO:         deprecation: 2.1.0
2025-10-21 11:00:02,791:INFO:              xxhash: 3.6.0
2025-10-21 11:00:02,791:INFO:           wurlitzer: Not installed
2025-10-21 11:00:02,791:INFO:PyCaret optional dependencies:
2025-10-21 11:00:02,791:INFO:                shap: 0.44.1
2025-10-21 11:00:02,791:INFO:           interpret: 0.7.3
2025-10-21 11:00:02,791:INFO:                umap: 0.5.7
2025-10-21 11:00:02,791:INFO:     ydata_profiling: 4.17.0
2025-10-21 11:00:02,791:INFO:  explainerdashboard: 0.5.1
2025-10-21 11:00:02,791:INFO:             autoviz: Not installed
2025-10-21 11:00:02,791:INFO:           fairlearn: 0.7.0
2025-10-21 11:00:02,791:INFO:          deepchecks: Not installed
2025-10-21 11:00:02,791:INFO:             xgboost: 3.1.0
2025-10-21 11:00:02,791:INFO:            catboost: 1.2.8
2025-10-21 11:00:02,791:INFO:              kmodes: 0.12.2
2025-10-21 11:00:02,791:INFO:             mlxtend: 0.23.4
2025-10-21 11:00:02,791:INFO:       statsforecast: 1.5.0
2025-10-21 11:00:02,791:INFO:        tune_sklearn: Not installed
2025-10-21 11:00:02,791:INFO:                 ray: Not installed
2025-10-21 11:00:02,791:INFO:            hyperopt: 0.2.7
2025-10-21 11:00:02,792:INFO:              optuna: 4.5.0
2025-10-21 11:00:02,792:INFO:               skopt: 0.10.2
2025-10-21 11:00:02,792:INFO:              mlflow: 3.5.0
2025-10-21 11:00:02,792:INFO:              gradio: 5.49.1
2025-10-21 11:00:02,792:INFO:             fastapi: 0.119.1
2025-10-21 11:00:02,792:INFO:             uvicorn: 0.38.0
2025-10-21 11:00:02,792:INFO:              m2cgen: 0.10.0
2025-10-21 11:00:02,792:INFO:           evidently: 0.4.40
2025-10-21 11:00:02,792:INFO:               fugue: 0.8.7
2025-10-21 11:00:02,792:INFO:           streamlit: Not installed
2025-10-21 11:00:02,792:INFO:             prophet: Not installed
2025-10-21 11:00:02,792:INFO:None
2025-10-21 11:00:02,792:INFO:Set up data.
2025-10-21 11:00:02,966:INFO:Set up folding strategy.
2025-10-21 11:00:03,188:INFO:Set up train/test split.
2025-10-21 11:00:03,458:INFO:Set up index.
2025-10-21 11:00:03,479:INFO:Assigning column types.
2025-10-21 11:00:03,747:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-21 11:00:03,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-21 11:00:03,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 11:00:03,819:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 11:00:03,823:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 11:00:03,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-21 11:00:03,867:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 11:00:03,890:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 11:00:03,893:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 11:00:03,894:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-21 11:00:03,933:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 11:00:03,957:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 11:00:03,961:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 11:00:04,013:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-21 11:00:04,042:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 11:00:04,044:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 11:00:04,045:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-21 11:00:04,116:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 11:00:04,119:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 11:00:04,176:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 11:00:04,178:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 11:00:04,180:INFO:Preparing preprocessing pipeline...
2025-10-21 11:00:04,213:INFO:Set up simple imputation.
2025-10-21 11:00:04,371:INFO:Set up encoding of ordinal features.
2025-10-21 11:00:04,437:INFO:Set up encoding of categorical features.
2025-10-21 11:00:04,441:INFO:Set up removing multicollinearity.
2025-10-21 11:00:04,441:INFO:Set up imbalanced handling.
2025-10-21 11:00:04,474:INFO:Set up column name cleaning.
2025-10-21 11:00:10,434:INFO:Finished creating preprocessing pipeline.
2025-10-21 11:00:10,451:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-21 11:00:10,451:INFO:Creating final display dataframe.
2025-10-21 11:00:14,449:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 28)
4        Transformed data shape       (98748, 97)
5   Transformed train set shape       (74746, 97)
6    Transformed test set shape       (24002, 97)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20               Fold Generator        GroupKFold
21                  Fold Number                 5
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              149b
2025-10-21 11:00:14,505:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 11:00:14,507:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 11:00:14,563:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-21 11:00:14,565:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-21 11:00:14,566:INFO:setup() successfully completed in 12.07s...............
2025-10-21 11:00:14,566:INFO:Initializing compare_models()
2025-10-21 11:00:14,566:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-21 11:00:14,566:INFO:Checking exceptions
2025-10-21 11:00:14,718:INFO:Preparing display monitor
2025-10-21 11:00:14,743:INFO:Initializing Logistic Regression
2025-10-21 11:00:14,743:INFO:Total runtime is 0.0 minutes
2025-10-21 11:00:14,747:INFO:SubProcess create_model() called ==================================
2025-10-21 11:00:14,748:INFO:Initializing create_model()
2025-10-21 11:00:14,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:00:14,748:INFO:Checking exceptions
2025-10-21 11:00:14,748:INFO:Importing libraries
2025-10-21 11:00:14,748:INFO:Copying training dataset
2025-10-21 11:00:14,990:INFO:Defining folds
2025-10-21 11:00:14,990:INFO:Declaring metric variables
2025-10-21 11:00:14,994:INFO:Importing untrained model
2025-10-21 11:00:14,998:INFO:Logistic Regression Imported successfully
2025-10-21 11:00:15,004:INFO:Starting cross validation
2025-10-21 11:00:15,012:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:00:50,794:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-21 11:00:51,503:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-21 11:00:51,603:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-21 11:00:51,626:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-21 11:00:51,630:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-10-21 11:00:52,324:INFO:Calculating mean and std
2025-10-21 11:00:52,326:INFO:Creating metrics dataframe
2025-10-21 11:00:52,331:INFO:Uploading results into container
2025-10-21 11:00:52,332:INFO:Uploading model into container now
2025-10-21 11:00:52,333:INFO:_master_model_container: 1
2025-10-21 11:00:52,333:INFO:_display_container: 2
2025-10-21 11:00:52,334:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-21 11:00:52,334:INFO:create_model() successfully completed......................................
2025-10-21 11:00:52,618:INFO:SubProcess create_model() end ==================================
2025-10-21 11:00:52,618:INFO:Creating metrics dataframe
2025-10-21 11:00:52,626:INFO:Initializing K Neighbors Classifier
2025-10-21 11:00:52,626:INFO:Total runtime is 0.6313870747884115 minutes
2025-10-21 11:00:52,630:INFO:SubProcess create_model() called ==================================
2025-10-21 11:00:52,631:INFO:Initializing create_model()
2025-10-21 11:00:52,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:00:52,632:INFO:Checking exceptions
2025-10-21 11:00:52,632:INFO:Importing libraries
2025-10-21 11:00:52,632:INFO:Copying training dataset
2025-10-21 11:00:52,909:INFO:Defining folds
2025-10-21 11:00:52,909:INFO:Declaring metric variables
2025-10-21 11:00:52,912:INFO:Importing untrained model
2025-10-21 11:00:52,916:INFO:K Neighbors Classifier Imported successfully
2025-10-21 11:00:52,925:INFO:Starting cross validation
2025-10-21 11:00:52,931:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:01:23,017:INFO:Calculating mean and std
2025-10-21 11:01:23,019:INFO:Creating metrics dataframe
2025-10-21 11:01:23,022:INFO:Uploading results into container
2025-10-21 11:01:23,024:INFO:Uploading model into container now
2025-10-21 11:01:23,025:INFO:_master_model_container: 2
2025-10-21 11:01:23,025:INFO:_display_container: 2
2025-10-21 11:01:23,025:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-21 11:01:23,026:INFO:create_model() successfully completed......................................
2025-10-21 11:01:23,230:INFO:SubProcess create_model() end ==================================
2025-10-21 11:01:23,230:INFO:Creating metrics dataframe
2025-10-21 11:01:23,237:INFO:Initializing Naive Bayes
2025-10-21 11:01:23,237:INFO:Total runtime is 1.1415559887886046 minutes
2025-10-21 11:01:23,240:INFO:SubProcess create_model() called ==================================
2025-10-21 11:01:23,242:INFO:Initializing create_model()
2025-10-21 11:01:23,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:01:23,243:INFO:Checking exceptions
2025-10-21 11:01:23,243:INFO:Importing libraries
2025-10-21 11:01:23,244:INFO:Copying training dataset
2025-10-21 11:01:23,480:INFO:Defining folds
2025-10-21 11:01:23,481:INFO:Declaring metric variables
2025-10-21 11:01:23,484:INFO:Importing untrained model
2025-10-21 11:01:23,488:INFO:Naive Bayes Imported successfully
2025-10-21 11:01:23,496:INFO:Starting cross validation
2025-10-21 11:01:23,505:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:01:34,314:INFO:Calculating mean and std
2025-10-21 11:01:34,315:INFO:Creating metrics dataframe
2025-10-21 11:01:34,319:INFO:Uploading results into container
2025-10-21 11:01:34,320:INFO:Uploading model into container now
2025-10-21 11:01:34,320:INFO:_master_model_container: 3
2025-10-21 11:01:34,321:INFO:_display_container: 2
2025-10-21 11:01:34,321:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-21 11:01:34,321:INFO:create_model() successfully completed......................................
2025-10-21 11:01:34,503:INFO:SubProcess create_model() end ==================================
2025-10-21 11:01:34,503:INFO:Creating metrics dataframe
2025-10-21 11:01:34,510:INFO:Initializing Decision Tree Classifier
2025-10-21 11:01:34,511:INFO:Total runtime is 1.3294569293657938 minutes
2025-10-21 11:01:34,514:INFO:SubProcess create_model() called ==================================
2025-10-21 11:01:34,516:INFO:Initializing create_model()
2025-10-21 11:01:34,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:01:34,516:INFO:Checking exceptions
2025-10-21 11:01:34,516:INFO:Importing libraries
2025-10-21 11:01:34,516:INFO:Copying training dataset
2025-10-21 11:01:34,762:INFO:Defining folds
2025-10-21 11:01:34,763:INFO:Declaring metric variables
2025-10-21 11:01:34,766:INFO:Importing untrained model
2025-10-21 11:01:34,771:INFO:Decision Tree Classifier Imported successfully
2025-10-21 11:01:34,778:INFO:Starting cross validation
2025-10-21 11:01:34,786:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:01:46,644:INFO:Calculating mean and std
2025-10-21 11:01:46,645:INFO:Creating metrics dataframe
2025-10-21 11:01:46,649:INFO:Uploading results into container
2025-10-21 11:01:46,650:INFO:Uploading model into container now
2025-10-21 11:01:46,651:INFO:_master_model_container: 4
2025-10-21 11:01:46,651:INFO:_display_container: 2
2025-10-21 11:01:46,651:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-21 11:01:46,652:INFO:create_model() successfully completed......................................
2025-10-21 11:01:46,831:INFO:SubProcess create_model() end ==================================
2025-10-21 11:01:46,831:INFO:Creating metrics dataframe
2025-10-21 11:01:46,838:INFO:Initializing SVM - Linear Kernel
2025-10-21 11:01:46,838:INFO:Total runtime is 1.5349084814389546 minutes
2025-10-21 11:01:46,841:INFO:SubProcess create_model() called ==================================
2025-10-21 11:01:46,844:INFO:Initializing create_model()
2025-10-21 11:01:46,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:01:46,845:INFO:Checking exceptions
2025-10-21 11:01:46,845:INFO:Importing libraries
2025-10-21 11:01:46,845:INFO:Copying training dataset
2025-10-21 11:01:47,187:INFO:Defining folds
2025-10-21 11:01:47,187:INFO:Declaring metric variables
2025-10-21 11:01:47,190:INFO:Importing untrained model
2025-10-21 11:01:47,196:INFO:SVM - Linear Kernel Imported successfully
2025-10-21 11:01:47,202:INFO:Starting cross validation
2025-10-21 11:01:47,209:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:02:07,345:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-21 11:02:08,511:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-21 11:02:12,169:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-21 11:02:13,244:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-21 11:02:13,269:INFO:Calculating mean and std
2025-10-21 11:02:13,272:INFO:Creating metrics dataframe
2025-10-21 11:02:13,276:INFO:Uploading results into container
2025-10-21 11:02:13,279:INFO:Uploading model into container now
2025-10-21 11:02:13,280:INFO:_master_model_container: 5
2025-10-21 11:02:13,280:INFO:_display_container: 2
2025-10-21 11:02:13,280:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-21 11:02:13,280:INFO:create_model() successfully completed......................................
2025-10-21 11:02:13,604:INFO:SubProcess create_model() end ==================================
2025-10-21 11:02:13,604:INFO:Creating metrics dataframe
2025-10-21 11:02:13,630:INFO:Initializing Ridge Classifier
2025-10-21 11:02:13,630:INFO:Total runtime is 1.9814462979634602 minutes
2025-10-21 11:02:13,640:INFO:SubProcess create_model() called ==================================
2025-10-21 11:02:13,643:INFO:Initializing create_model()
2025-10-21 11:02:13,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:02:13,643:INFO:Checking exceptions
2025-10-21 11:02:13,643:INFO:Importing libraries
2025-10-21 11:02:13,643:INFO:Copying training dataset
2025-10-21 11:02:14,228:INFO:Defining folds
2025-10-21 11:02:14,228:INFO:Declaring metric variables
2025-10-21 11:02:14,240:INFO:Importing untrained model
2025-10-21 11:02:14,252:INFO:Ridge Classifier Imported successfully
2025-10-21 11:02:14,271:INFO:Starting cross validation
2025-10-21 11:02:14,287:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:02:24,451:INFO:Calculating mean and std
2025-10-21 11:02:24,452:INFO:Creating metrics dataframe
2025-10-21 11:02:24,455:INFO:Uploading results into container
2025-10-21 11:02:24,455:INFO:Uploading model into container now
2025-10-21 11:02:24,455:INFO:_master_model_container: 6
2025-10-21 11:02:24,456:INFO:_display_container: 2
2025-10-21 11:02:24,456:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-21 11:02:24,456:INFO:create_model() successfully completed......................................
2025-10-21 11:02:24,627:INFO:SubProcess create_model() end ==================================
2025-10-21 11:02:24,627:INFO:Creating metrics dataframe
2025-10-21 11:02:24,636:INFO:Initializing Random Forest Classifier
2025-10-21 11:02:24,636:INFO:Total runtime is 2.1648789127667745 minutes
2025-10-21 11:02:24,638:INFO:SubProcess create_model() called ==================================
2025-10-21 11:02:24,639:INFO:Initializing create_model()
2025-10-21 11:02:24,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:02:24,639:INFO:Checking exceptions
2025-10-21 11:02:24,639:INFO:Importing libraries
2025-10-21 11:02:24,639:INFO:Copying training dataset
2025-10-21 11:02:24,876:INFO:Defining folds
2025-10-21 11:02:24,877:INFO:Declaring metric variables
2025-10-21 11:02:24,881:INFO:Importing untrained model
2025-10-21 11:02:24,886:INFO:Random Forest Classifier Imported successfully
2025-10-21 11:02:24,892:INFO:Starting cross validation
2025-10-21 11:02:24,899:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:02:59,189:INFO:Calculating mean and std
2025-10-21 11:02:59,190:INFO:Creating metrics dataframe
2025-10-21 11:02:59,194:INFO:Uploading results into container
2025-10-21 11:02:59,199:INFO:Uploading model into container now
2025-10-21 11:02:59,200:INFO:_master_model_container: 7
2025-10-21 11:02:59,200:INFO:_display_container: 2
2025-10-21 11:02:59,200:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-21 11:02:59,200:INFO:create_model() successfully completed......................................
2025-10-21 11:02:59,521:INFO:SubProcess create_model() end ==================================
2025-10-21 11:02:59,521:INFO:Creating metrics dataframe
2025-10-21 11:02:59,549:INFO:Initializing Quadratic Discriminant Analysis
2025-10-21 11:02:59,549:INFO:Total runtime is 2.7467617869377134 minutes
2025-10-21 11:02:59,559:INFO:SubProcess create_model() called ==================================
2025-10-21 11:02:59,565:INFO:Initializing create_model()
2025-10-21 11:02:59,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:02:59,567:INFO:Checking exceptions
2025-10-21 11:02:59,567:INFO:Importing libraries
2025-10-21 11:02:59,568:INFO:Copying training dataset
2025-10-21 11:03:00,139:INFO:Defining folds
2025-10-21 11:03:00,140:INFO:Declaring metric variables
2025-10-21 11:03:00,152:INFO:Importing untrained model
2025-10-21 11:03:00,164:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-21 11:03:00,181:INFO:Starting cross validation
2025-10-21 11:03:00,203:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:03:10,517:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-21 11:03:11,342:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-21 11:03:11,670:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-21 11:03:12,086:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-21 11:03:12,669:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-21 11:03:14,321:INFO:Calculating mean and std
2025-10-21 11:03:14,322:INFO:Creating metrics dataframe
2025-10-21 11:03:14,324:INFO:Uploading results into container
2025-10-21 11:03:14,325:INFO:Uploading model into container now
2025-10-21 11:03:14,325:INFO:_master_model_container: 8
2025-10-21 11:03:14,325:INFO:_display_container: 2
2025-10-21 11:03:14,326:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-21 11:03:14,326:INFO:create_model() successfully completed......................................
2025-10-21 11:03:14,485:INFO:SubProcess create_model() end ==================================
2025-10-21 11:03:14,485:INFO:Creating metrics dataframe
2025-10-21 11:03:14,492:INFO:Initializing Ada Boost Classifier
2025-10-21 11:03:14,492:INFO:Total runtime is 2.9958164652188617 minutes
2025-10-21 11:03:14,494:INFO:SubProcess create_model() called ==================================
2025-10-21 11:03:14,495:INFO:Initializing create_model()
2025-10-21 11:03:14,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:03:14,496:INFO:Checking exceptions
2025-10-21 11:03:14,496:INFO:Importing libraries
2025-10-21 11:03:14,497:INFO:Copying training dataset
2025-10-21 11:03:14,727:INFO:Defining folds
2025-10-21 11:03:14,728:INFO:Declaring metric variables
2025-10-21 11:03:14,733:INFO:Importing untrained model
2025-10-21 11:03:14,737:INFO:Ada Boost Classifier Imported successfully
2025-10-21 11:03:14,743:INFO:Starting cross validation
2025-10-21 11:03:14,750:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:03:22,679:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-21 11:03:22,789:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-21 11:03:23,011:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-21 11:03:23,063:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-21 11:03:23,134:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-21 11:03:36,243:INFO:Calculating mean and std
2025-10-21 11:03:36,245:INFO:Creating metrics dataframe
2025-10-21 11:03:36,252:INFO:Uploading results into container
2025-10-21 11:03:36,253:INFO:Uploading model into container now
2025-10-21 11:03:36,253:INFO:_master_model_container: 9
2025-10-21 11:03:36,254:INFO:_display_container: 2
2025-10-21 11:03:36,254:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-21 11:03:36,254:INFO:create_model() successfully completed......................................
2025-10-21 11:03:36,516:INFO:SubProcess create_model() end ==================================
2025-10-21 11:03:36,516:INFO:Creating metrics dataframe
2025-10-21 11:03:36,529:INFO:Initializing Gradient Boosting Classifier
2025-10-21 11:03:36,529:INFO:Total runtime is 3.3631012161572773 minutes
2025-10-21 11:03:36,537:INFO:SubProcess create_model() called ==================================
2025-10-21 11:03:36,538:INFO:Initializing create_model()
2025-10-21 11:03:36,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:03:36,539:INFO:Checking exceptions
2025-10-21 11:03:36,539:INFO:Importing libraries
2025-10-21 11:03:36,539:INFO:Copying training dataset
2025-10-21 11:03:36,807:INFO:Defining folds
2025-10-21 11:03:36,807:INFO:Declaring metric variables
2025-10-21 11:03:36,812:INFO:Importing untrained model
2025-10-21 11:03:36,818:INFO:Gradient Boosting Classifier Imported successfully
2025-10-21 11:03:36,826:INFO:Starting cross validation
2025-10-21 11:03:36,837:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:04:35,227:INFO:Calculating mean and std
2025-10-21 11:04:35,229:INFO:Creating metrics dataframe
2025-10-21 11:04:35,236:INFO:Uploading results into container
2025-10-21 11:04:35,238:INFO:Uploading model into container now
2025-10-21 11:04:35,239:INFO:_master_model_container: 10
2025-10-21 11:04:35,239:INFO:_display_container: 2
2025-10-21 11:04:35,240:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 11:04:35,241:INFO:create_model() successfully completed......................................
2025-10-21 11:04:35,537:INFO:SubProcess create_model() end ==================================
2025-10-21 11:04:35,538:INFO:Creating metrics dataframe
2025-10-21 11:04:35,547:INFO:Initializing Linear Discriminant Analysis
2025-10-21 11:04:35,547:INFO:Total runtime is 4.346736335754395 minutes
2025-10-21 11:04:35,556:INFO:SubProcess create_model() called ==================================
2025-10-21 11:04:35,556:INFO:Initializing create_model()
2025-10-21 11:04:35,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:04:35,558:INFO:Checking exceptions
2025-10-21 11:04:35,558:INFO:Importing libraries
2025-10-21 11:04:35,559:INFO:Copying training dataset
2025-10-21 11:04:35,996:INFO:Defining folds
2025-10-21 11:04:35,996:INFO:Declaring metric variables
2025-10-21 11:04:36,007:INFO:Importing untrained model
2025-10-21 11:04:36,015:INFO:Linear Discriminant Analysis Imported successfully
2025-10-21 11:04:36,039:INFO:Starting cross validation
2025-10-21 11:04:36,052:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:04:50,120:INFO:Calculating mean and std
2025-10-21 11:04:50,123:INFO:Creating metrics dataframe
2025-10-21 11:04:50,130:INFO:Uploading results into container
2025-10-21 11:04:50,131:INFO:Uploading model into container now
2025-10-21 11:04:50,132:INFO:_master_model_container: 11
2025-10-21 11:04:50,133:INFO:_display_container: 2
2025-10-21 11:04:50,135:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-21 11:04:50,136:INFO:create_model() successfully completed......................................
2025-10-21 11:04:50,423:INFO:SubProcess create_model() end ==================================
2025-10-21 11:04:50,424:INFO:Creating metrics dataframe
2025-10-21 11:04:50,451:INFO:Initializing Extra Trees Classifier
2025-10-21 11:04:50,452:INFO:Total runtime is 4.595146640141805 minutes
2025-10-21 11:04:50,460:INFO:SubProcess create_model() called ==================================
2025-10-21 11:04:50,463:INFO:Initializing create_model()
2025-10-21 11:04:50,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:04:50,463:INFO:Checking exceptions
2025-10-21 11:04:50,463:INFO:Importing libraries
2025-10-21 11:04:50,463:INFO:Copying training dataset
2025-10-21 11:04:50,927:INFO:Defining folds
2025-10-21 11:04:50,928:INFO:Declaring metric variables
2025-10-21 11:04:50,935:INFO:Importing untrained model
2025-10-21 11:04:50,943:INFO:Extra Trees Classifier Imported successfully
2025-10-21 11:04:50,963:INFO:Starting cross validation
2025-10-21 11:04:50,979:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:05:40,142:INFO:Calculating mean and std
2025-10-21 11:05:40,144:INFO:Creating metrics dataframe
2025-10-21 11:05:40,149:INFO:Uploading results into container
2025-10-21 11:05:40,150:INFO:Uploading model into container now
2025-10-21 11:05:40,153:INFO:_master_model_container: 12
2025-10-21 11:05:40,153:INFO:_display_container: 2
2025-10-21 11:05:40,154:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-21 11:05:40,154:INFO:create_model() successfully completed......................................
2025-10-21 11:05:40,443:INFO:SubProcess create_model() end ==================================
2025-10-21 11:05:40,443:INFO:Creating metrics dataframe
2025-10-21 11:05:40,458:INFO:Initializing Extreme Gradient Boosting
2025-10-21 11:05:40,458:INFO:Total runtime is 5.42857365210851 minutes
2025-10-21 11:05:40,462:INFO:SubProcess create_model() called ==================================
2025-10-21 11:05:40,464:INFO:Initializing create_model()
2025-10-21 11:05:40,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=xgboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:05:40,464:INFO:Checking exceptions
2025-10-21 11:05:40,465:INFO:Importing libraries
2025-10-21 11:05:40,465:INFO:Copying training dataset
2025-10-21 11:05:41,082:INFO:Defining folds
2025-10-21 11:05:41,083:INFO:Declaring metric variables
2025-10-21 11:05:41,093:INFO:Importing untrained model
2025-10-21 11:05:41,101:INFO:Extreme Gradient Boosting Imported successfully
2025-10-21 11:05:41,122:INFO:Starting cross validation
2025-10-21 11:05:41,149:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:05:59,618:INFO:Calculating mean and std
2025-10-21 11:05:59,623:INFO:Creating metrics dataframe
2025-10-21 11:05:59,629:INFO:Uploading results into container
2025-10-21 11:05:59,631:INFO:Uploading model into container now
2025-10-21 11:05:59,633:INFO:_master_model_container: 13
2025-10-21 11:05:59,633:INFO:_display_container: 2
2025-10-21 11:05:59,637:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-10-21 11:05:59,637:INFO:create_model() successfully completed......................................
2025-10-21 11:05:59,983:INFO:SubProcess create_model() end ==================================
2025-10-21 11:05:59,983:INFO:Creating metrics dataframe
2025-10-21 11:06:00,006:INFO:Initializing Light Gradient Boosting Machine
2025-10-21 11:06:00,007:INFO:Total runtime is 5.754393990834554 minutes
2025-10-21 11:06:00,013:INFO:SubProcess create_model() called ==================================
2025-10-21 11:06:00,015:INFO:Initializing create_model()
2025-10-21 11:06:00,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:06:00,016:INFO:Checking exceptions
2025-10-21 11:06:00,016:INFO:Importing libraries
2025-10-21 11:06:00,016:INFO:Copying training dataset
2025-10-21 11:06:00,478:INFO:Defining folds
2025-10-21 11:06:00,478:INFO:Declaring metric variables
2025-10-21 11:06:00,483:INFO:Importing untrained model
2025-10-21 11:06:00,494:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-21 11:06:00,511:INFO:Starting cross validation
2025-10-21 11:06:00,529:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:06:15,675:INFO:Calculating mean and std
2025-10-21 11:06:15,677:INFO:Creating metrics dataframe
2025-10-21 11:06:15,681:INFO:Uploading results into container
2025-10-21 11:06:15,682:INFO:Uploading model into container now
2025-10-21 11:06:15,682:INFO:_master_model_container: 14
2025-10-21 11:06:15,682:INFO:_display_container: 2
2025-10-21 11:06:15,684:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-21 11:06:15,684:INFO:create_model() successfully completed......................................
2025-10-21 11:06:15,884:INFO:SubProcess create_model() end ==================================
2025-10-21 11:06:15,884:INFO:Creating metrics dataframe
2025-10-21 11:06:15,895:INFO:Initializing CatBoost Classifier
2025-10-21 11:06:15,895:INFO:Total runtime is 6.019191594918569 minutes
2025-10-21 11:06:15,898:INFO:SubProcess create_model() called ==================================
2025-10-21 11:06:15,901:INFO:Initializing create_model()
2025-10-21 11:06:15,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:06:15,901:INFO:Checking exceptions
2025-10-21 11:06:15,901:INFO:Importing libraries
2025-10-21 11:06:15,901:INFO:Copying training dataset
2025-10-21 11:06:16,215:INFO:Defining folds
2025-10-21 11:06:16,215:INFO:Declaring metric variables
2025-10-21 11:06:16,228:INFO:Importing untrained model
2025-10-21 11:06:16,234:INFO:CatBoost Classifier Imported successfully
2025-10-21 11:06:16,247:INFO:Starting cross validation
2025-10-21 11:06:16,267:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:08:27,661:INFO:Calculating mean and std
2025-10-21 11:08:27,662:INFO:Creating metrics dataframe
2025-10-21 11:08:27,667:INFO:Uploading results into container
2025-10-21 11:08:27,667:INFO:Uploading model into container now
2025-10-21 11:08:27,668:INFO:_master_model_container: 15
2025-10-21 11:08:27,668:INFO:_display_container: 2
2025-10-21 11:08:27,668:INFO:<catboost.core.CatBoostClassifier object at 0x000002044E556D50>
2025-10-21 11:08:27,669:INFO:create_model() successfully completed......................................
2025-10-21 11:08:27,850:INFO:SubProcess create_model() end ==================================
2025-10-21 11:08:27,850:INFO:Creating metrics dataframe
2025-10-21 11:08:27,860:INFO:Initializing Dummy Classifier
2025-10-21 11:08:27,860:INFO:Total runtime is 8.21860792239507 minutes
2025-10-21 11:08:27,863:INFO:SubProcess create_model() called ==================================
2025-10-21 11:08:27,865:INFO:Initializing create_model()
2025-10-21 11:08:27,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020474FA8D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:08:27,865:INFO:Checking exceptions
2025-10-21 11:08:27,866:INFO:Importing libraries
2025-10-21 11:08:27,866:INFO:Copying training dataset
2025-10-21 11:08:28,120:INFO:Defining folds
2025-10-21 11:08:28,121:INFO:Declaring metric variables
2025-10-21 11:08:28,124:INFO:Importing untrained model
2025-10-21 11:08:28,127:INFO:Dummy Classifier Imported successfully
2025-10-21 11:08:28,134:INFO:Starting cross validation
2025-10-21 11:08:28,142:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:08:36,663:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-21 11:08:37,017:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-21 11:08:37,054:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-21 11:08:37,087:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-21 11:08:37,245:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-21 11:08:37,267:INFO:Calculating mean and std
2025-10-21 11:08:37,268:INFO:Creating metrics dataframe
2025-10-21 11:08:37,276:INFO:Uploading results into container
2025-10-21 11:08:37,277:INFO:Uploading model into container now
2025-10-21 11:08:37,277:INFO:_master_model_container: 16
2025-10-21 11:08:37,277:INFO:_display_container: 2
2025-10-21 11:08:37,278:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-21 11:08:37,278:INFO:create_model() successfully completed......................................
2025-10-21 11:08:37,463:INFO:SubProcess create_model() end ==================================
2025-10-21 11:08:37,463:INFO:Creating metrics dataframe
2025-10-21 11:08:37,474:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-21 11:08:37,488:INFO:Initializing create_model()
2025-10-21 11:08:37,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:08:37,489:INFO:Checking exceptions
2025-10-21 11:08:37,492:INFO:Importing libraries
2025-10-21 11:08:37,492:INFO:Copying training dataset
2025-10-21 11:08:37,760:INFO:Defining folds
2025-10-21 11:08:37,760:INFO:Declaring metric variables
2025-10-21 11:08:37,760:INFO:Importing untrained model
2025-10-21 11:08:37,760:INFO:Declaring custom model
2025-10-21 11:08:37,761:INFO:Gradient Boosting Classifier Imported successfully
2025-10-21 11:08:37,768:INFO:Cross validation set to False
2025-10-21 11:08:37,768:INFO:Fitting Model
2025-10-21 11:09:12,979:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 11:09:12,979:INFO:create_model() successfully completed......................................
2025-10-21 11:09:13,147:INFO:Initializing create_model()
2025-10-21 11:09:13,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:09:13,148:INFO:Checking exceptions
2025-10-21 11:09:13,152:INFO:Importing libraries
2025-10-21 11:09:13,152:INFO:Copying training dataset
2025-10-21 11:09:13,398:INFO:Defining folds
2025-10-21 11:09:13,398:INFO:Declaring metric variables
2025-10-21 11:09:13,398:INFO:Importing untrained model
2025-10-21 11:09:13,399:INFO:Declaring custom model
2025-10-21 11:09:13,399:INFO:Ridge Classifier Imported successfully
2025-10-21 11:09:13,405:INFO:Cross validation set to False
2025-10-21 11:09:13,405:INFO:Fitting Model
2025-10-21 11:09:17,674:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-21 11:09:17,674:INFO:create_model() successfully completed......................................
2025-10-21 11:09:17,834:INFO:Initializing create_model()
2025-10-21 11:09:17,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:09:17,836:INFO:Checking exceptions
2025-10-21 11:09:17,837:INFO:Importing libraries
2025-10-21 11:09:17,839:INFO:Copying training dataset
2025-10-21 11:09:18,115:INFO:Defining folds
2025-10-21 11:09:18,116:INFO:Declaring metric variables
2025-10-21 11:09:18,116:INFO:Importing untrained model
2025-10-21 11:09:18,117:INFO:Declaring custom model
2025-10-21 11:09:18,117:INFO:Linear Discriminant Analysis Imported successfully
2025-10-21 11:09:18,123:INFO:Cross validation set to False
2025-10-21 11:09:18,123:INFO:Fitting Model
2025-10-21 11:09:23,781:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-21 11:09:23,782:INFO:create_model() successfully completed......................................
2025-10-21 11:09:23,991:INFO:Initializing create_model()
2025-10-21 11:09:23,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:09:23,992:INFO:Checking exceptions
2025-10-21 11:09:23,995:INFO:Importing libraries
2025-10-21 11:09:23,995:INFO:Copying training dataset
2025-10-21 11:09:24,244:INFO:Defining folds
2025-10-21 11:09:24,244:INFO:Declaring metric variables
2025-10-21 11:09:24,245:INFO:Importing untrained model
2025-10-21 11:09:24,245:INFO:Declaring custom model
2025-10-21 11:09:24,246:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-21 11:09:24,254:INFO:Cross validation set to False
2025-10-21 11:09:24,254:INFO:Fitting Model
2025-10-21 11:09:29,088:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-21 11:09:29,093:INFO:[LightGBM] [Info] Number of positive: 37373, number of negative: 37373
2025-10-21 11:09:29,123:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014272 seconds.
2025-10-21 11:09:29,123:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-21 11:09:29,123:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-21 11:09:29,124:INFO:[LightGBM] [Info] Total Bins 24094
2025-10-21 11:09:29,125:INFO:[LightGBM] [Info] Number of data points in the train set: 74746, number of used features: 96
2025-10-21 11:09:29,126:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-21 11:09:29,787:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-21 11:09:29,787:INFO:create_model() successfully completed......................................
2025-10-21 11:09:29,988:INFO:Initializing create_model()
2025-10-21 11:09:29,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:09:29,989:INFO:Checking exceptions
2025-10-21 11:09:29,994:INFO:Importing libraries
2025-10-21 11:09:29,995:INFO:Copying training dataset
2025-10-21 11:09:30,512:INFO:Defining folds
2025-10-21 11:09:30,512:INFO:Declaring metric variables
2025-10-21 11:09:30,512:INFO:Importing untrained model
2025-10-21 11:09:30,513:INFO:Declaring custom model
2025-10-21 11:09:30,513:INFO:Ada Boost Classifier Imported successfully
2025-10-21 11:09:30,520:INFO:Cross validation set to False
2025-10-21 11:09:30,520:INFO:Fitting Model
2025-10-21 11:09:38,066:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-21 11:09:53,019:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-21 11:09:53,020:INFO:create_model() successfully completed......................................
2025-10-21 11:09:53,331:INFO:_master_model_container: 16
2025-10-21 11:09:53,332:INFO:_display_container: 2
2025-10-21 11:09:53,333:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)]
2025-10-21 11:09:53,333:INFO:compare_models() successfully completed......................................
2025-10-21 11:09:53,335:INFO:Initializing tune_model()
2025-10-21 11:09:53,335:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-21 11:09:53,335:INFO:Checking exceptions
2025-10-21 11:09:53,494:INFO:Copying training dataset
2025-10-21 11:09:53,847:INFO:Checking base model
2025-10-21 11:09:53,848:INFO:Base model : Gradient Boosting Classifier
2025-10-21 11:09:53,851:INFO:Declaring metric variables
2025-10-21 11:09:53,856:INFO:Defining Hyperparameters
2025-10-21 11:09:54,100:INFO:Tuning with n_jobs=-1
2025-10-21 11:09:54,101:INFO:Initializing RandomizedSearchCV
2025-10-21 11:12:55,608:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.4}
2025-10-21 11:12:55,609:INFO:Hyperparameter search completed
2025-10-21 11:12:55,609:INFO:SubProcess create_model() called ==================================
2025-10-21 11:12:55,611:INFO:Initializing create_model()
2025-10-21 11:12:55,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020473673D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 130, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 1, 'learning_rate': 0.4})
2025-10-21 11:12:55,611:INFO:Checking exceptions
2025-10-21 11:12:55,611:INFO:Importing libraries
2025-10-21 11:12:55,611:INFO:Copying training dataset
2025-10-21 11:12:55,855:INFO:Defining folds
2025-10-21 11:12:55,855:INFO:Declaring metric variables
2025-10-21 11:12:55,859:INFO:Importing untrained model
2025-10-21 11:12:55,860:INFO:Declaring custom model
2025-10-21 11:12:55,866:INFO:Gradient Boosting Classifier Imported successfully
2025-10-21 11:12:55,873:INFO:Starting cross validation
2025-10-21 11:12:55,881:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:13:18,880:INFO:Calculating mean and std
2025-10-21 11:13:18,881:INFO:Creating metrics dataframe
2025-10-21 11:13:18,885:INFO:Finalizing model
2025-10-21 11:13:34,719:INFO:Uploading results into container
2025-10-21 11:13:34,720:INFO:Uploading model into container now
2025-10-21 11:13:34,720:INFO:_master_model_container: 17
2025-10-21 11:13:34,721:INFO:_display_container: 3
2025-10-21 11:13:34,722:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 11:13:34,722:INFO:create_model() successfully completed......................................
2025-10-21 11:13:34,915:INFO:SubProcess create_model() end ==================================
2025-10-21 11:13:34,915:INFO:choose_better activated
2025-10-21 11:13:34,919:INFO:SubProcess create_model() called ==================================
2025-10-21 11:13:34,920:INFO:Initializing create_model()
2025-10-21 11:13:34,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:13:34,920:INFO:Checking exceptions
2025-10-21 11:13:34,921:INFO:Importing libraries
2025-10-21 11:13:34,921:INFO:Copying training dataset
2025-10-21 11:13:35,192:INFO:Defining folds
2025-10-21 11:13:35,192:INFO:Declaring metric variables
2025-10-21 11:13:35,193:INFO:Importing untrained model
2025-10-21 11:13:35,193:INFO:Declaring custom model
2025-10-21 11:13:35,194:INFO:Gradient Boosting Classifier Imported successfully
2025-10-21 11:13:35,194:INFO:Starting cross validation
2025-10-21 11:13:35,203:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:14:20,647:INFO:Calculating mean and std
2025-10-21 11:14:20,647:INFO:Creating metrics dataframe
2025-10-21 11:14:20,649:INFO:Finalizing model
2025-10-21 11:14:55,695:INFO:Uploading results into container
2025-10-21 11:14:55,696:INFO:Uploading model into container now
2025-10-21 11:14:55,696:INFO:_master_model_container: 18
2025-10-21 11:14:55,696:INFO:_display_container: 4
2025-10-21 11:14:55,697:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 11:14:55,697:INFO:create_model() successfully completed......................................
2025-10-21 11:14:55,871:INFO:SubProcess create_model() end ==================================
2025-10-21 11:14:55,872:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9218
2025-10-21 11:14:55,873:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9209
2025-10-21 11:14:55,873:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-21 11:14:55,873:INFO:choose_better completed
2025-10-21 11:14:55,873:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-21 11:14:55,880:INFO:_master_model_container: 18
2025-10-21 11:14:55,881:INFO:_display_container: 3
2025-10-21 11:14:55,881:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-21 11:14:55,881:INFO:tune_model() successfully completed......................................
2025-10-21 11:14:56,081:INFO:Initializing tune_model()
2025-10-21 11:14:56,081:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-21 11:14:56,081:INFO:Checking exceptions
2025-10-21 11:14:56,180:INFO:Copying training dataset
2025-10-21 11:14:56,336:INFO:Checking base model
2025-10-21 11:14:56,336:INFO:Base model : Ridge Classifier
2025-10-21 11:14:56,340:INFO:Declaring metric variables
2025-10-21 11:14:56,342:INFO:Defining Hyperparameters
2025-10-21 11:14:56,503:INFO:Tuning with n_jobs=-1
2025-10-21 11:14:56,503:INFO:Initializing RandomizedSearchCV
2025-10-21 11:16:01,373:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.30013e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-21 11:16:02,455:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.21107e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-21 11:16:02,995:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.27019e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-21 11:16:04,953:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.25968e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-21 11:16:05,082:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.24456e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-21 11:16:11,055:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.3}
2025-10-21 11:16:11,056:INFO:Hyperparameter search completed
2025-10-21 11:16:11,056:INFO:SubProcess create_model() called ==================================
2025-10-21 11:16:11,058:INFO:Initializing create_model()
2025-10-21 11:16:11,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020471BA65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 7.3})
2025-10-21 11:16:11,059:INFO:Checking exceptions
2025-10-21 11:16:11,059:INFO:Importing libraries
2025-10-21 11:16:11,059:INFO:Copying training dataset
2025-10-21 11:16:11,299:INFO:Defining folds
2025-10-21 11:16:11,300:INFO:Declaring metric variables
2025-10-21 11:16:11,304:INFO:Importing untrained model
2025-10-21 11:16:11,304:INFO:Declaring custom model
2025-10-21 11:16:11,309:INFO:Ridge Classifier Imported successfully
2025-10-21 11:16:11,315:INFO:Starting cross validation
2025-10-21 11:16:11,323:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:16:20,396:INFO:Calculating mean and std
2025-10-21 11:16:20,396:INFO:Creating metrics dataframe
2025-10-21 11:16:20,401:INFO:Finalizing model
2025-10-21 11:16:24,871:INFO:Uploading results into container
2025-10-21 11:16:24,873:INFO:Uploading model into container now
2025-10-21 11:16:24,873:INFO:_master_model_container: 19
2025-10-21 11:16:24,874:INFO:_display_container: 4
2025-10-21 11:16:24,874:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-21 11:16:24,875:INFO:create_model() successfully completed......................................
2025-10-21 11:16:25,045:INFO:SubProcess create_model() end ==================================
2025-10-21 11:16:25,045:INFO:choose_better activated
2025-10-21 11:16:25,048:INFO:SubProcess create_model() called ==================================
2025-10-21 11:16:25,049:INFO:Initializing create_model()
2025-10-21 11:16:25,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:16:25,050:INFO:Checking exceptions
2025-10-21 11:16:25,051:INFO:Importing libraries
2025-10-21 11:16:25,051:INFO:Copying training dataset
2025-10-21 11:16:25,260:INFO:Defining folds
2025-10-21 11:16:25,261:INFO:Declaring metric variables
2025-10-21 11:16:25,261:INFO:Importing untrained model
2025-10-21 11:16:25,261:INFO:Declaring custom model
2025-10-21 11:16:25,261:INFO:Ridge Classifier Imported successfully
2025-10-21 11:16:25,261:INFO:Starting cross validation
2025-10-21 11:16:25,267:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:16:34,320:INFO:Calculating mean and std
2025-10-21 11:16:34,320:INFO:Creating metrics dataframe
2025-10-21 11:16:34,322:INFO:Finalizing model
2025-10-21 11:16:38,626:INFO:Uploading results into container
2025-10-21 11:16:38,627:INFO:Uploading model into container now
2025-10-21 11:16:38,628:INFO:_master_model_container: 20
2025-10-21 11:16:38,628:INFO:_display_container: 5
2025-10-21 11:16:38,628:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-21 11:16:38,628:INFO:create_model() successfully completed......................................
2025-10-21 11:16:38,786:INFO:SubProcess create_model() end ==================================
2025-10-21 11:16:38,786:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9214
2025-10-21 11:16:38,787:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9217
2025-10-21 11:16:38,787:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) is best model
2025-10-21 11:16:38,788:INFO:choose_better completed
2025-10-21 11:16:38,797:INFO:_master_model_container: 20
2025-10-21 11:16:38,797:INFO:_display_container: 4
2025-10-21 11:16:38,797:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-21 11:16:38,797:INFO:tune_model() successfully completed......................................
2025-10-21 11:16:38,967:INFO:Initializing tune_model()
2025-10-21 11:16:38,967:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-21 11:16:38,967:INFO:Checking exceptions
2025-10-21 11:16:39,070:INFO:Copying training dataset
2025-10-21 11:16:39,226:INFO:Checking base model
2025-10-21 11:16:39,226:INFO:Base model : Linear Discriminant Analysis
2025-10-21 11:16:39,230:INFO:Declaring metric variables
2025-10-21 11:16:39,232:INFO:Defining Hyperparameters
2025-10-21 11:16:39,392:INFO:Tuning with n_jobs=-1
2025-10-21 11:16:39,392:INFO:Initializing RandomizedSearchCV
2025-10-21 11:17:59,273:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 'auto'}
2025-10-21 11:17:59,275:INFO:Hyperparameter search completed
2025-10-21 11:17:59,275:INFO:SubProcess create_model() called ==================================
2025-10-21 11:17:59,276:INFO:Initializing create_model()
2025-10-21 11:17:59,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020454AF4750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 'auto'})
2025-10-21 11:17:59,276:INFO:Checking exceptions
2025-10-21 11:17:59,276:INFO:Importing libraries
2025-10-21 11:17:59,276:INFO:Copying training dataset
2025-10-21 11:17:59,523:INFO:Defining folds
2025-10-21 11:17:59,523:INFO:Declaring metric variables
2025-10-21 11:17:59,526:INFO:Importing untrained model
2025-10-21 11:17:59,526:INFO:Declaring custom model
2025-10-21 11:17:59,534:INFO:Linear Discriminant Analysis Imported successfully
2025-10-21 11:17:59,542:INFO:Starting cross validation
2025-10-21 11:17:59,552:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:18:09,481:INFO:Calculating mean and std
2025-10-21 11:18:09,482:INFO:Creating metrics dataframe
2025-10-21 11:18:09,487:INFO:Finalizing model
2025-10-21 11:18:14,976:INFO:Uploading results into container
2025-10-21 11:18:14,977:INFO:Uploading model into container now
2025-10-21 11:18:14,978:INFO:_master_model_container: 21
2025-10-21 11:18:14,978:INFO:_display_container: 5
2025-10-21 11:18:14,978:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-21 11:18:14,978:INFO:create_model() successfully completed......................................
2025-10-21 11:18:15,150:INFO:SubProcess create_model() end ==================================
2025-10-21 11:18:15,150:INFO:choose_better activated
2025-10-21 11:18:15,154:INFO:SubProcess create_model() called ==================================
2025-10-21 11:18:15,156:INFO:Initializing create_model()
2025-10-21 11:18:15,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-21 11:18:15,156:INFO:Checking exceptions
2025-10-21 11:18:15,158:INFO:Importing libraries
2025-10-21 11:18:15,158:INFO:Copying training dataset
2025-10-21 11:18:15,419:INFO:Defining folds
2025-10-21 11:18:15,419:INFO:Declaring metric variables
2025-10-21 11:18:15,420:INFO:Importing untrained model
2025-10-21 11:18:15,420:INFO:Declaring custom model
2025-10-21 11:18:15,420:INFO:Linear Discriminant Analysis Imported successfully
2025-10-21 11:18:15,421:INFO:Starting cross validation
2025-10-21 11:18:15,429:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=-1
2025-10-21 11:18:29,767:INFO:Calculating mean and std
2025-10-21 11:18:29,768:INFO:Creating metrics dataframe
2025-10-21 11:18:29,770:INFO:Finalizing model
2025-10-21 11:18:38,765:INFO:Uploading results into container
2025-10-21 11:18:38,766:INFO:Uploading model into container now
2025-10-21 11:18:38,767:INFO:_master_model_container: 22
2025-10-21 11:18:38,767:INFO:_display_container: 6
2025-10-21 11:18:38,768:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-21 11:18:38,768:INFO:create_model() successfully completed......................................
2025-10-21 11:18:39,045:INFO:SubProcess create_model() end ==================================
2025-10-21 11:18:39,046:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9213
2025-10-21 11:18:39,046:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9213
2025-10-21 11:18:39,047:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2025-10-21 11:18:39,047:INFO:choose_better completed
2025-10-21 11:18:39,047:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-21 11:18:39,067:INFO:_master_model_container: 22
2025-10-21 11:18:39,068:INFO:_display_container: 5
2025-10-21 11:18:39,069:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-21 11:18:39,069:INFO:tune_model() successfully completed......................................
2025-10-21 11:18:39,347:INFO:Initializing tune_model()
2025-10-21 11:18:39,348:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002044D24AA50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-21 11:18:39,348:INFO:Checking exceptions
2025-10-21 11:18:39,591:INFO:Copying training dataset
2025-10-21 11:18:39,870:INFO:Checking base model
2025-10-21 11:18:39,871:INFO:Base model : Light Gradient Boosting Machine
2025-10-21 11:18:39,880:INFO:Declaring metric variables
2025-10-21 11:18:39,887:INFO:Defining Hyperparameters
2025-10-21 11:18:40,163:INFO:Tuning with n_jobs=-1
2025-10-21 11:18:40,163:INFO:Initializing RandomizedSearchCV
2025-10-21 11:47:04,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 11:47:04,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 11:47:04,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 11:47:04,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 11:47:44,800:INFO:Initializing load_model()
2025-10-21 11:47:44,800:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 11:47:46,455:INFO:Initializing predict_model()
2025-10-21 11:47:46,456:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B90F5F50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3B2CC7100>)
2025-10-21 11:47:46,456:INFO:Checking exceptions
2025-10-21 11:47:46,457:INFO:Preloading libraries
2025-10-21 11:47:46,457:INFO:Set up data.
2025-10-21 11:47:46,521:INFO:Set up index.
2025-10-21 12:03:26,290:INFO:Initializing load_model()
2025-10-21 12:03:26,290:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:03:26,360:INFO:Initializing predict_model()
2025-10-21 12:03:26,360:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3AFB6F310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3B0383B00>)
2025-10-21 12:03:26,360:INFO:Checking exceptions
2025-10-21 12:03:26,360:INFO:Preloading libraries
2025-10-21 12:03:26,360:INFO:Set up data.
2025-10-21 12:03:26,425:INFO:Set up index.
2025-10-21 12:04:42,182:INFO:Initializing load_model()
2025-10-21 12:04:42,183:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:04:42,279:INFO:Initializing predict_model()
2025-10-21 12:04:42,279:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B3092ED0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3B9F2FA60>)
2025-10-21 12:04:42,280:INFO:Checking exceptions
2025-10-21 12:04:42,280:INFO:Preloading libraries
2025-10-21 12:04:42,280:INFO:Set up data.
2025-10-21 12:04:42,287:INFO:Set up index.
2025-10-21 12:05:09,887:INFO:Initializing load_model()
2025-10-21 12:05:09,887:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:05:10,000:INFO:Initializing predict_model()
2025-10-21 12:05:10,001:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B30960D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1913C40>)
2025-10-21 12:05:10,001:INFO:Checking exceptions
2025-10-21 12:05:10,001:INFO:Preloading libraries
2025-10-21 12:05:10,002:INFO:Set up data.
2025-10-21 12:05:10,012:INFO:Set up index.
2025-10-21 12:05:33,751:INFO:Initializing load_model()
2025-10-21 12:05:33,752:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:05:33,905:INFO:Initializing predict_model()
2025-10-21 12:05:33,905:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E38C44DFD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3BF670680>)
2025-10-21 12:05:33,906:INFO:Checking exceptions
2025-10-21 12:05:33,906:INFO:Preloading libraries
2025-10-21 12:05:33,906:INFO:Set up data.
2025-10-21 12:05:33,914:INFO:Set up index.
2025-10-21 12:08:20,114:INFO:Initializing load_model()
2025-10-21 12:08:20,114:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:08:20,193:INFO:Initializing predict_model()
2025-10-21 12:08:20,193:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B338C550>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3B9A17A60>)
2025-10-21 12:08:20,193:INFO:Checking exceptions
2025-10-21 12:08:20,193:INFO:Preloading libraries
2025-10-21 12:08:20,193:INFO:Set up data.
2025-10-21 12:08:20,253:INFO:Set up index.
2025-10-21 12:11:07,302:INFO:Initializing load_model()
2025-10-21 12:11:07,302:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:11:07,375:INFO:Initializing predict_model()
2025-10-21 12:11:07,375:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3BBB1F410>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C19676A0>)
2025-10-21 12:11:07,375:INFO:Checking exceptions
2025-10-21 12:11:07,375:INFO:Preloading libraries
2025-10-21 12:11:07,376:INFO:Set up data.
2025-10-21 12:11:07,430:INFO:Set up index.
2025-10-21 12:18:12,906:INFO:Initializing load_model()
2025-10-21 12:18:12,906:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:18:12,974:INFO:Initializing predict_model()
2025-10-21 12:18:12,974:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3BF690D10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1083560>)
2025-10-21 12:18:12,974:INFO:Checking exceptions
2025-10-21 12:18:12,974:INFO:Preloading libraries
2025-10-21 12:18:12,975:INFO:Set up data.
2025-10-21 12:18:12,983:INFO:Set up index.
2025-10-21 12:18:13,456:INFO:Initializing load_model()
2025-10-21 12:18:13,457:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:18:13,529:INFO:Initializing predict_model()
2025-10-21 12:18:13,529:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B1388B10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C10822A0>)
2025-10-21 12:18:13,529:INFO:Checking exceptions
2025-10-21 12:18:13,529:INFO:Preloading libraries
2025-10-21 12:18:13,529:INFO:Set up data.
2025-10-21 12:18:13,536:INFO:Set up index.
2025-10-21 12:18:52,868:INFO:Initializing load_model()
2025-10-21 12:18:52,868:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:18:52,952:INFO:Initializing predict_model()
2025-10-21 12:18:52,952:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3BF368910>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1083C40>)
2025-10-21 12:18:52,952:INFO:Checking exceptions
2025-10-21 12:18:52,952:INFO:Preloading libraries
2025-10-21 12:18:52,952:INFO:Set up data.
2025-10-21 12:18:52,964:INFO:Set up index.
2025-10-21 12:18:53,305:INFO:Initializing load_model()
2025-10-21 12:18:53,305:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:18:53,380:INFO:Initializing predict_model()
2025-10-21 12:18:53,381:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B3D91510>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1081940>)
2025-10-21 12:18:53,381:INFO:Checking exceptions
2025-10-21 12:18:53,381:INFO:Preloading libraries
2025-10-21 12:18:53,381:INFO:Set up data.
2025-10-21 12:18:53,389:INFO:Set up index.
2025-10-21 12:19:05,557:INFO:Initializing load_model()
2025-10-21 12:19:05,558:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:19:05,635:INFO:Initializing predict_model()
2025-10-21 12:19:05,635:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B3011B50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1083BA0>)
2025-10-21 12:19:05,635:INFO:Checking exceptions
2025-10-21 12:19:05,635:INFO:Preloading libraries
2025-10-21 12:19:05,635:INFO:Set up data.
2025-10-21 12:19:05,651:INFO:Set up index.
2025-10-21 12:19:05,940:INFO:Initializing load_model()
2025-10-21 12:19:05,941:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:19:06,010:INFO:Initializing predict_model()
2025-10-21 12:19:06,010:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3BF615590>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3B9F2FA60>)
2025-10-21 12:19:06,010:INFO:Checking exceptions
2025-10-21 12:19:06,010:INFO:Preloading libraries
2025-10-21 12:19:06,011:INFO:Set up data.
2025-10-21 12:19:06,019:INFO:Set up index.
2025-10-21 12:20:38,433:INFO:Initializing load_model()
2025-10-21 12:20:38,433:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:20:38,503:INFO:Initializing predict_model()
2025-10-21 12:20:38,503:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B9834690>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1081D00>)
2025-10-21 12:20:38,503:INFO:Checking exceptions
2025-10-21 12:20:38,503:INFO:Preloading libraries
2025-10-21 12:20:38,503:INFO:Set up data.
2025-10-21 12:20:38,515:INFO:Set up index.
2025-10-21 12:20:38,804:INFO:Initializing load_model()
2025-10-21 12:20:38,804:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:20:38,863:INFO:Initializing predict_model()
2025-10-21 12:20:38,863:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3BBB5CA90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1083D80>)
2025-10-21 12:20:38,863:INFO:Checking exceptions
2025-10-21 12:20:38,863:INFO:Preloading libraries
2025-10-21 12:20:38,864:INFO:Set up data.
2025-10-21 12:20:38,870:INFO:Set up index.
2025-10-21 12:20:53,798:INFO:Initializing load_model()
2025-10-21 12:20:53,798:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:20:53,876:INFO:Initializing predict_model()
2025-10-21 12:20:53,876:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B577AF10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3BF670180>)
2025-10-21 12:20:53,877:INFO:Checking exceptions
2025-10-21 12:20:53,877:INFO:Preloading libraries
2025-10-21 12:20:53,877:INFO:Set up data.
2025-10-21 12:20:53,890:INFO:Set up index.
2025-10-21 12:20:54,213:INFO:Initializing load_model()
2025-10-21 12:20:54,213:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:20:54,280:INFO:Initializing predict_model()
2025-10-21 12:20:54,280:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B3D91510>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1081D00>)
2025-10-21 12:20:54,280:INFO:Checking exceptions
2025-10-21 12:20:54,280:INFO:Preloading libraries
2025-10-21 12:20:54,280:INFO:Set up data.
2025-10-21 12:20:54,288:INFO:Set up index.
2025-10-21 12:21:16,275:INFO:Initializing load_model()
2025-10-21 12:21:16,276:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:21:16,359:INFO:Initializing predict_model()
2025-10-21 12:21:16,359:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B3185810>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1911260>)
2025-10-21 12:21:16,359:INFO:Checking exceptions
2025-10-21 12:21:16,359:INFO:Preloading libraries
2025-10-21 12:21:16,360:INFO:Set up data.
2025-10-21 12:21:16,368:INFO:Set up index.
2025-10-21 12:21:16,673:INFO:Initializing load_model()
2025-10-21 12:21:16,674:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:21:16,742:INFO:Initializing predict_model()
2025-10-21 12:21:16,742:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E38C486A10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E38C49CCC0>)
2025-10-21 12:21:16,742:INFO:Checking exceptions
2025-10-21 12:21:16,742:INFO:Preloading libraries
2025-10-21 12:21:16,742:INFO:Set up data.
2025-10-21 12:21:16,749:INFO:Set up index.
2025-10-21 12:21:55,581:INFO:Initializing load_model()
2025-10-21 12:21:55,581:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:21:55,670:INFO:Initializing predict_model()
2025-10-21 12:21:55,670:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B338C590>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1911620>)
2025-10-21 12:21:55,670:INFO:Checking exceptions
2025-10-21 12:21:55,670:INFO:Preloading libraries
2025-10-21 12:21:55,671:INFO:Set up data.
2025-10-21 12:21:55,684:INFO:Set up index.
2025-10-21 12:21:56,081:INFO:Initializing load_model()
2025-10-21 12:21:56,081:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:21:56,144:INFO:Initializing predict_model()
2025-10-21 12:21:56,144:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3B577AF10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C19111C0>)
2025-10-21 12:21:56,144:INFO:Checking exceptions
2025-10-21 12:21:56,144:INFO:Preloading libraries
2025-10-21 12:21:56,144:INFO:Set up data.
2025-10-21 12:21:56,151:INFO:Set up index.
2025-10-21 12:22:06,323:INFO:Initializing load_model()
2025-10-21 12:22:06,324:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:22:06,411:INFO:Initializing predict_model()
2025-10-21 12:22:06,411:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3C18FCE50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1913920>)
2025-10-21 12:22:06,411:INFO:Checking exceptions
2025-10-21 12:22:06,411:INFO:Preloading libraries
2025-10-21 12:22:06,411:INFO:Set up data.
2025-10-21 12:22:06,419:INFO:Set up index.
2025-10-21 12:22:06,768:INFO:Initializing load_model()
2025-10-21 12:22:06,768:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:22:06,845:INFO:Initializing predict_model()
2025-10-21 12:22:06,845:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3C18F2910>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C10828E0>)
2025-10-21 12:22:06,845:INFO:Checking exceptions
2025-10-21 12:22:06,845:INFO:Preloading libraries
2025-10-21 12:22:06,846:INFO:Set up data.
2025-10-21 12:22:06,853:INFO:Set up index.
2025-10-21 12:22:39,025:INFO:Initializing load_model()
2025-10-21 12:22:39,026:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:22:39,105:INFO:Initializing predict_model()
2025-10-21 12:22:39,106:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3BF5D5790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C10831A0>)
2025-10-21 12:22:39,106:INFO:Checking exceptions
2025-10-21 12:22:39,106:INFO:Preloading libraries
2025-10-21 12:22:39,106:INFO:Set up data.
2025-10-21 12:22:39,118:INFO:Set up index.
2025-10-21 12:22:39,419:INFO:Initializing load_model()
2025-10-21 12:22:39,419:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:22:39,480:INFO:Initializing predict_model()
2025-10-21 12:22:39,480:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3BF49C310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C10820C0>)
2025-10-21 12:22:39,480:INFO:Checking exceptions
2025-10-21 12:22:39,480:INFO:Preloading libraries
2025-10-21 12:22:39,480:INFO:Set up data.
2025-10-21 12:22:39,486:INFO:Set up index.
2025-10-21 12:35:15,652:INFO:Initializing load_model()
2025-10-21 12:35:15,653:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:35:15,717:INFO:Initializing predict_model()
2025-10-21 12:35:15,717:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3C19409D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C19105E0>)
2025-10-21 12:35:15,717:INFO:Checking exceptions
2025-10-21 12:35:15,717:INFO:Preloading libraries
2025-10-21 12:35:15,717:INFO:Set up data.
2025-10-21 12:35:15,725:INFO:Set up index.
2025-10-21 12:35:16,050:INFO:Initializing load_model()
2025-10-21 12:35:16,050:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 12:35:16,114:INFO:Initializing predict_model()
2025-10-21 12:35:16,114:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E38C6189D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3C1912DE0>)
2025-10-21 12:35:16,114:INFO:Checking exceptions
2025-10-21 12:35:16,114:INFO:Preloading libraries
2025-10-21 12:35:16,114:INFO:Set up data.
2025-10-21 12:35:16,122:INFO:Set up index.
2025-10-21 14:21:31,015:INFO:Initializing load_model()
2025-10-21 14:21:31,015:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 14:21:31,128:INFO:Initializing predict_model()
2025-10-21 14:21:31,128:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E3BF67E090>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3B2CC4900>)
2025-10-21 14:21:31,128:INFO:Checking exceptions
2025-10-21 14:21:31,128:INFO:Preloading libraries
2025-10-21 14:21:31,128:INFO:Set up data.
2025-10-21 14:21:31,133:INFO:Set up index.
2025-10-21 14:44:35,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 14:44:35,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 14:44:35,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 14:44:35,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-21 14:44:52,831:INFO:Initializing load_model()
2025-10-21 14:44:52,832:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 14:45:09,331:INFO:Initializing load_model()
2025-10-21 14:45:09,331:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-21 14:45:58,587:INFO:Initializing load_model()
2025-10-21 14:45:58,587:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 14:45:58,658:INFO:Initializing load_model()
2025-10-21 14:45:58,658:INFO:load_model(model_name=modelo_reg_rating_v2, platform=None, authentication=None, verbose=True)
2025-10-21 14:45:59,707:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pipeline.py:148: UserWarning: Version mismatch:
current: {'deps_info': {'pip': '25.2', 'setuptools': '80.9.0', 'pycaret': '3.3.2', 'IPython': '9.6.0', 'ipywidgets': '8.1.7', 'tqdm': '4.67.1', 'numpy': '1.26.4', 'pandas': '2.1.4', 'jinja2': '3.1.6', 'scipy': '1.11.4', 'joblib': '1.3.2', 'sklearn': '1.4.2', 'pyod': '2.0.5', 'imblearn': '0.14.0', 'category_encoders': '2.7.0', 'lightgbm': '4.6.0', 'numba': '0.61.0', 'requests': '2.32.5', 'matplotlib': '3.7.5', 'scikitplot': '0.3.7', 'yellowbrick': '1.5', 'plotly': '5.24.1', 'plotly-resampler': 'Not installed', 'kaleido': '1.1.0', 'schemdraw': '0.15', 'statsmodels': '0.14.5', 'sktime': '0.26.0', 'tbats': '1.1.3', 'pmdarima': '2.0.4', 'psutil': '7.1.1', 'markupsafe': '3.0.3', 'pickle5': 'Not installed', 'cloudpickle': '3.1.1', 'deprecation': '2.1.0', 'xxhash': '3.6.0', 'wurlitzer': 'Not installed'}, 'python': {'version': '3.11.13', 'machine': 'AMD64'}}
pickle: {'deps_info': {'pip': '25.2', 'setuptools': '80.9.0', 'pycaret': '3.3.2', 'IPython': '9.6.0', 'ipywidgets': '8.1.7', 'tqdm': '4.67.1', 'numpy': '1.26.4', 'pandas': '2.1.4', 'jinja2': '3.1.6', 'scipy': '1.11.4', 'joblib': '1.3.2', 'sklearn': '1.4.2', 'pyod': '2.0.5', 'imblearn': '0.14.0', 'category_encoders': '2.7.0', 'lightgbm': '4.6.0', 'numba': '0.61.0', 'requests': '2.32.5', 'matplotlib': '3.7.5', 'scikitplot': '0.3.7', 'yellowbrick': '1.5', 'plotly': '5.24.1', 'plotly-resampler': 'Not installed', 'kaleido': '1.1.0', 'schemdraw': '0.15', 'statsmodels': '0.14.5', 'sktime': '0.26.0', 'tbats': '1.1.3', 'pmdarima': '2.0.4', 'psutil': '7.1.0', 'markupsafe': '3.0.3', 'pickle5': 'Not installed', 'cloudpickle': '3.1.1', 'deprecation': '2.1.0', 'xxhash': '3.6.0', 'wurlitzer': 'Not installed'}, 'python': {'version': '3.11.13', 'machine': 'AMD64'}}
  warnings.warn(

2025-10-21 15:22:14,940:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\IPython\core\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.
  warn("To exit: use 'exit', 'quit', or Ctrl-D.", stacklevel=1)

2025-10-21 15:55:05,563:INFO:Initializing load_model()
2025-10-21 15:55:05,564:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 15:55:05,739:INFO:Initializing predict_model()
2025-10-21 15:55:05,739:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F3C05D90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C3F076A5C0>)
2025-10-21 15:55:05,739:INFO:Checking exceptions
2025-10-21 15:55:05,739:INFO:Preloading libraries
2025-10-21 15:55:05,741:INFO:Set up data.
2025-10-21 15:55:05,772:INFO:Set up index.
2025-10-21 15:55:38,069:INFO:Initializing load_model()
2025-10-21 15:55:38,069:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-21 15:55:38,192:INFO:Initializing predict_model()
2025-10-21 15:55:38,192:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F8B36F10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleI...
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 VotingClassifier(estimators=[('Gradient Boosting Classifier',
                                               GradientBoostingClassifier(random_state=1391)),
                                              ('Ridge Classifier',
                                               RidgeClassifier(alpha=8.25,
                                                               fit_intercept=False,
                                                               random_state=1391)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis())],
                                  n_jobs=1))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C3F01D3C40>)
2025-10-21 15:55:38,193:INFO:Checking exceptions
2025-10-21 15:55:38,193:INFO:Preloading libraries
2025-10-21 15:55:38,193:INFO:Set up data.
2025-10-21 15:55:38,196:INFO:Set up index.
2025-10-22 09:33:05,447:INFO:PyCaret ClassificationExperiment
2025-10-22 09:33:05,448:INFO:Logging name: clf-default-name
2025-10-22 09:33:05,448:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-22 09:33:05,448:INFO:version 3.3.2
2025-10-22 09:33:05,448:INFO:Initializing setup()
2025-10-22 09:33:05,448:INFO:self.USI: 9ed8
2025-10-22 09:33:05,448:INFO:self._variable_keys: {'pipeline', 'y_train', 'seed', 'n_jobs_param', 'data', 'is_multiclass', 'y', 'exp_id', 'USI', 'gpu_param', 'fold_generator', 'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', 'logging_param', '_available_plots', 'gpu_n_jobs_param', 'html_param', 'target_param', 'idx', 'log_plots_param', 'X_test', 'X_train', 'memory', '_ml_usecase', 'X', 'y_test', 'exp_name_log'}
2025-10-22 09:33:05,448:INFO:Checking environment
2025-10-22 09:33:05,448:INFO:python_version: 3.11.13
2025-10-22 09:33:05,448:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-22 09:33:05,448:INFO:machine: AMD64
2025-10-22 09:33:05,448:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-22 09:33:05,454:INFO:Memory: svmem(total=16856211456, available=4733227008, percent=71.9, used=12122984448, free=4733227008)
2025-10-22 09:33:05,454:INFO:Physical Core: 4
2025-10-22 09:33:05,455:INFO:Logical Core: 8
2025-10-22 09:33:05,455:INFO:Checking libraries
2025-10-22 09:33:05,455:INFO:System:
2025-10-22 09:33:05,455:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-22 09:33:05,455:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-22 09:33:05,455:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-22 09:33:05,455:INFO:PyCaret required dependencies:
2025-10-22 09:33:05,455:INFO:                 pip: 25.2
2025-10-22 09:33:05,455:INFO:          setuptools: 80.9.0
2025-10-22 09:33:05,455:INFO:             pycaret: 3.3.2
2025-10-22 09:33:05,455:INFO:             IPython: 9.6.0
2025-10-22 09:33:05,455:INFO:          ipywidgets: 8.1.7
2025-10-22 09:33:05,455:INFO:                tqdm: 4.67.1
2025-10-22 09:33:05,455:INFO:               numpy: 1.26.4
2025-10-22 09:33:05,455:INFO:              pandas: 2.1.4
2025-10-22 09:33:05,455:INFO:              jinja2: 3.1.6
2025-10-22 09:33:05,455:INFO:               scipy: 1.11.4
2025-10-22 09:33:05,455:INFO:              joblib: 1.3.2
2025-10-22 09:33:05,456:INFO:             sklearn: 1.4.2
2025-10-22 09:33:05,456:INFO:                pyod: 2.0.5
2025-10-22 09:33:05,456:INFO:            imblearn: 0.14.0
2025-10-22 09:33:05,456:INFO:   category_encoders: 2.7.0
2025-10-22 09:33:05,456:INFO:            lightgbm: 4.6.0
2025-10-22 09:33:05,456:INFO:               numba: 0.61.0
2025-10-22 09:33:05,456:INFO:            requests: 2.32.5
2025-10-22 09:33:05,456:INFO:          matplotlib: 3.7.5
2025-10-22 09:33:05,456:INFO:          scikitplot: 0.3.7
2025-10-22 09:33:05,456:INFO:         yellowbrick: 1.5
2025-10-22 09:33:05,456:INFO:              plotly: 5.24.1
2025-10-22 09:33:05,456:INFO:    plotly-resampler: Not installed
2025-10-22 09:33:05,456:INFO:             kaleido: 1.1.0
2025-10-22 09:33:05,456:INFO:           schemdraw: 0.15
2025-10-22 09:33:05,456:INFO:         statsmodels: 0.14.5
2025-10-22 09:33:05,456:INFO:              sktime: 0.26.0
2025-10-22 09:33:05,456:INFO:               tbats: 1.1.3
2025-10-22 09:33:05,456:INFO:            pmdarima: 2.0.4
2025-10-22 09:33:05,456:INFO:              psutil: 7.1.1
2025-10-22 09:33:05,456:INFO:          markupsafe: 3.0.3
2025-10-22 09:33:05,456:INFO:             pickle5: Not installed
2025-10-22 09:33:05,456:INFO:         cloudpickle: 3.1.1
2025-10-22 09:33:05,456:INFO:         deprecation: 2.1.0
2025-10-22 09:33:05,456:INFO:              xxhash: 3.6.0
2025-10-22 09:33:05,456:INFO:           wurlitzer: Not installed
2025-10-22 09:33:05,456:INFO:PyCaret optional dependencies:
2025-10-22 09:33:21,408:INFO:                shap: 0.44.1
2025-10-22 09:33:21,408:INFO:           interpret: 0.7.3
2025-10-22 09:33:21,408:INFO:                umap: 0.5.7
2025-10-22 09:33:21,408:INFO:     ydata_profiling: 4.17.0
2025-10-22 09:33:21,408:INFO:  explainerdashboard: 0.5.1
2025-10-22 09:33:21,408:INFO:             autoviz: Not installed
2025-10-22 09:33:21,408:INFO:           fairlearn: 0.7.0
2025-10-22 09:33:21,408:INFO:          deepchecks: Not installed
2025-10-22 09:33:21,409:INFO:             xgboost: 3.1.0
2025-10-22 09:33:21,409:INFO:            catboost: 1.2.8
2025-10-22 09:33:21,409:INFO:              kmodes: 0.12.2
2025-10-22 09:33:21,409:INFO:             mlxtend: 0.23.4
2025-10-22 09:33:21,409:INFO:       statsforecast: 1.5.0
2025-10-22 09:33:21,409:INFO:        tune_sklearn: Not installed
2025-10-22 09:33:21,409:INFO:                 ray: Not installed
2025-10-22 09:33:21,409:INFO:            hyperopt: 0.2.7
2025-10-22 09:33:21,409:INFO:              optuna: 4.5.0
2025-10-22 09:33:21,409:INFO:               skopt: 0.10.2
2025-10-22 09:33:21,409:INFO:              mlflow: 3.5.0
2025-10-22 09:33:21,409:INFO:              gradio: 5.49.1
2025-10-22 09:33:21,409:INFO:             fastapi: 0.119.1
2025-10-22 09:33:21,409:INFO:             uvicorn: 0.38.0
2025-10-22 09:33:21,409:INFO:              m2cgen: 0.10.0
2025-10-22 09:33:21,409:INFO:           evidently: 0.4.40
2025-10-22 09:33:21,409:INFO:               fugue: 0.8.7
2025-10-22 09:33:21,409:INFO:           streamlit: Not installed
2025-10-22 09:33:21,409:INFO:             prophet: Not installed
2025-10-22 09:33:21,409:INFO:None
2025-10-22 09:33:21,410:INFO:Set up data.
2025-10-22 09:33:21,645:INFO:Set up folding strategy.
2025-10-22 09:33:21,885:INFO:Set up train/test split.
2025-10-22 09:33:22,150:INFO:Set up index.
2025-10-22 09:33:22,180:INFO:Assigning column types.
2025-10-22 09:33:22,523:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-22 09:33:22,557:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-22 09:33:22,567:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 09:33:22,608:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 09:33:22,610:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 09:33:22,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-22 09:33:22,668:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 09:33:22,689:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 09:33:22,691:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 09:33:22,691:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-22 09:33:22,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 09:33:22,750:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 09:33:22,752:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 09:33:22,788:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 09:33:22,810:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 09:33:22,812:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 09:33:22,813:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-22 09:33:22,867:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 09:33:22,869:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 09:33:22,924:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 09:33:22,927:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 09:33:22,929:INFO:Preparing preprocessing pipeline...
2025-10-22 09:33:22,994:INFO:Set up simple imputation.
2025-10-22 09:33:23,258:INFO:Set up encoding of ordinal features.
2025-10-22 09:33:23,390:INFO:Set up encoding of categorical features.
2025-10-22 09:33:23,399:INFO:Set up removing multicollinearity.
2025-10-22 09:33:30,059:INFO:Finished creating preprocessing pipeline.
2025-10-22 09:33:30,074:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                    transformer=TargetEncoder(cols=['nombre_sitio',
                                                                    'x_tipoTur__tipoSit',
                                                                    'x_epoca__tipoSit'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False)
2025-10-22 09:33:30,074:INFO:Creating final display dataframe.
2025-10-22 09:33:33,877:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 28)
4        Transformed data shape       (80004, 97)
5   Transformed train set shape       (56002, 97)
6    Transformed test set shape       (24002, 97)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation     most_frequent
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              9ed8
2025-10-22 09:33:33,932:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 09:33:33,934:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 09:33:33,993:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 09:33:33,997:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 09:33:33,998:INFO:setup() successfully completed in 28.92s...............
2025-10-22 09:33:33,999:INFO:Initializing compare_models()
2025-10-22 09:33:33,999:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-22 09:33:34,000:INFO:Checking exceptions
2025-10-22 09:33:34,255:INFO:Preparing display monitor
2025-10-22 09:33:34,261:INFO:Initializing Logistic Regression
2025-10-22 09:33:34,262:INFO:Total runtime is 1.6709168752034504e-05 minutes
2025-10-22 09:33:34,262:INFO:SubProcess create_model() called ==================================
2025-10-22 09:33:34,264:INFO:Initializing create_model()
2025-10-22 09:33:34,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:33:34,264:INFO:Checking exceptions
2025-10-22 09:33:34,264:INFO:Importing libraries
2025-10-22 09:33:34,264:INFO:Copying training dataset
2025-10-22 09:33:34,649:INFO:Defining folds
2025-10-22 09:33:34,650:INFO:Declaring metric variables
2025-10-22 09:33:34,650:INFO:Importing untrained model
2025-10-22 09:33:34,650:INFO:Logistic Regression Imported successfully
2025-10-22 09:33:34,651:INFO:Starting cross validation
2025-10-22 09:33:34,654:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:33:43,067:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 09:33:51,536:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 09:34:00,372:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 09:34:09,002:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 09:34:17,390:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 09:34:17,753:INFO:Calculating mean and std
2025-10-22 09:34:17,755:INFO:Creating metrics dataframe
2025-10-22 09:34:17,757:INFO:Uploading results into container
2025-10-22 09:34:17,757:INFO:Uploading model into container now
2025-10-22 09:34:17,758:INFO:_master_model_container: 1
2025-10-22 09:34:17,758:INFO:_display_container: 2
2025-10-22 09:34:17,758:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-22 09:34:17,759:INFO:create_model() successfully completed......................................
2025-10-22 09:34:17,991:INFO:SubProcess create_model() end ==================================
2025-10-22 09:34:17,992:INFO:Creating metrics dataframe
2025-10-22 09:34:17,993:INFO:Initializing K Neighbors Classifier
2025-10-22 09:34:17,993:INFO:Total runtime is 0.7288809180259705 minutes
2025-10-22 09:34:17,993:INFO:SubProcess create_model() called ==================================
2025-10-22 09:34:17,994:INFO:Initializing create_model()
2025-10-22 09:34:17,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:34:17,994:INFO:Checking exceptions
2025-10-22 09:34:17,994:INFO:Importing libraries
2025-10-22 09:34:17,994:INFO:Copying training dataset
2025-10-22 09:34:18,392:INFO:Defining folds
2025-10-22 09:34:18,393:INFO:Declaring metric variables
2025-10-22 09:34:18,393:INFO:Importing untrained model
2025-10-22 09:34:18,393:INFO:K Neighbors Classifier Imported successfully
2025-10-22 09:34:18,393:INFO:Starting cross validation
2025-10-22 09:34:18,397:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:34:47,336:INFO:Calculating mean and std
2025-10-22 09:34:47,338:INFO:Creating metrics dataframe
2025-10-22 09:34:47,340:INFO:Uploading results into container
2025-10-22 09:34:47,341:INFO:Uploading model into container now
2025-10-22 09:34:47,342:INFO:_master_model_container: 2
2025-10-22 09:34:47,342:INFO:_display_container: 2
2025-10-22 09:34:47,342:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-22 09:34:47,342:INFO:create_model() successfully completed......................................
2025-10-22 09:34:47,580:INFO:SubProcess create_model() end ==================================
2025-10-22 09:34:47,580:INFO:Creating metrics dataframe
2025-10-22 09:34:47,582:INFO:Initializing Naive Bayes
2025-10-22 09:34:47,582:INFO:Total runtime is 1.222022024790446 minutes
2025-10-22 09:34:47,582:INFO:SubProcess create_model() called ==================================
2025-10-22 09:34:47,583:INFO:Initializing create_model()
2025-10-22 09:34:47,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:34:47,584:INFO:Checking exceptions
2025-10-22 09:34:47,584:INFO:Importing libraries
2025-10-22 09:34:47,584:INFO:Copying training dataset
2025-10-22 09:34:47,978:INFO:Defining folds
2025-10-22 09:34:47,978:INFO:Declaring metric variables
2025-10-22 09:34:47,978:INFO:Importing untrained model
2025-10-22 09:34:47,979:INFO:Naive Bayes Imported successfully
2025-10-22 09:34:47,979:INFO:Starting cross validation
2025-10-22 09:34:47,983:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:34:51,307:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:34:54,459:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:34:57,935:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:35:01,982:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:35:05,664:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:35:05,681:INFO:Calculating mean and std
2025-10-22 09:35:05,683:INFO:Creating metrics dataframe
2025-10-22 09:35:05,684:INFO:Uploading results into container
2025-10-22 09:35:05,685:INFO:Uploading model into container now
2025-10-22 09:35:05,685:INFO:_master_model_container: 3
2025-10-22 09:35:05,685:INFO:_display_container: 2
2025-10-22 09:35:05,686:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-22 09:35:05,686:INFO:create_model() successfully completed......................................
2025-10-22 09:35:05,908:INFO:SubProcess create_model() end ==================================
2025-10-22 09:35:05,908:INFO:Creating metrics dataframe
2025-10-22 09:35:05,910:INFO:Initializing Decision Tree Classifier
2025-10-22 09:35:05,910:INFO:Total runtime is 1.527486570676168 minutes
2025-10-22 09:35:05,910:INFO:SubProcess create_model() called ==================================
2025-10-22 09:35:05,910:INFO:Initializing create_model()
2025-10-22 09:35:05,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:35:05,910:INFO:Checking exceptions
2025-10-22 09:35:05,911:INFO:Importing libraries
2025-10-22 09:35:05,911:INFO:Copying training dataset
2025-10-22 09:35:06,287:INFO:Defining folds
2025-10-22 09:35:06,287:INFO:Declaring metric variables
2025-10-22 09:35:06,288:INFO:Importing untrained model
2025-10-22 09:35:06,288:INFO:Decision Tree Classifier Imported successfully
2025-10-22 09:35:06,289:INFO:Starting cross validation
2025-10-22 09:35:06,293:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:35:28,167:INFO:Calculating mean and std
2025-10-22 09:35:28,168:INFO:Creating metrics dataframe
2025-10-22 09:35:28,170:INFO:Uploading results into container
2025-10-22 09:35:28,171:INFO:Uploading model into container now
2025-10-22 09:35:28,172:INFO:_master_model_container: 4
2025-10-22 09:35:28,172:INFO:_display_container: 2
2025-10-22 09:35:28,172:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-22 09:35:28,172:INFO:create_model() successfully completed......................................
2025-10-22 09:35:28,388:INFO:SubProcess create_model() end ==================================
2025-10-22 09:35:28,388:INFO:Creating metrics dataframe
2025-10-22 09:35:28,390:INFO:Initializing SVM - Linear Kernel
2025-10-22 09:35:28,390:INFO:Total runtime is 1.9021536707878115 minutes
2025-10-22 09:35:28,391:INFO:SubProcess create_model() called ==================================
2025-10-22 09:35:28,392:INFO:Initializing create_model()
2025-10-22 09:35:28,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:35:28,392:INFO:Checking exceptions
2025-10-22 09:35:28,392:INFO:Importing libraries
2025-10-22 09:35:28,392:INFO:Copying training dataset
2025-10-22 09:35:28,766:INFO:Defining folds
2025-10-22 09:35:28,766:INFO:Declaring metric variables
2025-10-22 09:35:28,766:INFO:Importing untrained model
2025-10-22 09:35:28,766:INFO:SVM - Linear Kernel Imported successfully
2025-10-22 09:35:28,766:INFO:Starting cross validation
2025-10-22 09:35:28,770:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:35:37,824:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:35:45,355:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:35:54,365:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:36:08,811:INFO:Calculating mean and std
2025-10-22 09:36:08,813:INFO:Creating metrics dataframe
2025-10-22 09:36:08,815:INFO:Uploading results into container
2025-10-22 09:36:08,816:INFO:Uploading model into container now
2025-10-22 09:36:08,816:INFO:_master_model_container: 5
2025-10-22 09:36:08,816:INFO:_display_container: 2
2025-10-22 09:36:08,816:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-22 09:36:08,816:INFO:create_model() successfully completed......................................
2025-10-22 09:36:09,068:INFO:SubProcess create_model() end ==================================
2025-10-22 09:36:09,069:INFO:Creating metrics dataframe
2025-10-22 09:36:09,072:INFO:Initializing Ridge Classifier
2025-10-22 09:36:09,072:INFO:Total runtime is 2.5801876544952393 minutes
2025-10-22 09:36:09,072:INFO:SubProcess create_model() called ==================================
2025-10-22 09:36:09,073:INFO:Initializing create_model()
2025-10-22 09:36:09,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:36:09,073:INFO:Checking exceptions
2025-10-22 09:36:09,073:INFO:Importing libraries
2025-10-22 09:36:09,073:INFO:Copying training dataset
2025-10-22 09:36:09,592:INFO:Defining folds
2025-10-22 09:36:09,592:INFO:Declaring metric variables
2025-10-22 09:36:09,592:INFO:Importing untrained model
2025-10-22 09:36:09,592:INFO:Ridge Classifier Imported successfully
2025-10-22 09:36:09,593:INFO:Starting cross validation
2025-10-22 09:36:09,599:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:36:26,669:INFO:Calculating mean and std
2025-10-22 09:36:26,670:INFO:Creating metrics dataframe
2025-10-22 09:36:26,671:INFO:Uploading results into container
2025-10-22 09:36:26,671:INFO:Uploading model into container now
2025-10-22 09:36:26,672:INFO:_master_model_container: 6
2025-10-22 09:36:26,672:INFO:_display_container: 2
2025-10-22 09:36:26,672:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 09:36:26,672:INFO:create_model() successfully completed......................................
2025-10-22 09:36:26,880:INFO:SubProcess create_model() end ==================================
2025-10-22 09:36:26,880:INFO:Creating metrics dataframe
2025-10-22 09:36:26,882:INFO:Initializing Random Forest Classifier
2025-10-22 09:36:26,883:INFO:Total runtime is 2.8770316640535993 minutes
2025-10-22 09:36:26,883:INFO:SubProcess create_model() called ==================================
2025-10-22 09:36:26,884:INFO:Initializing create_model()
2025-10-22 09:36:26,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:36:26,884:INFO:Checking exceptions
2025-10-22 09:36:26,884:INFO:Importing libraries
2025-10-22 09:36:26,884:INFO:Copying training dataset
2025-10-22 09:36:27,230:INFO:Defining folds
2025-10-22 09:36:27,231:INFO:Declaring metric variables
2025-10-22 09:36:27,231:INFO:Importing untrained model
2025-10-22 09:36:27,232:INFO:Random Forest Classifier Imported successfully
2025-10-22 09:36:27,232:INFO:Starting cross validation
2025-10-22 09:36:27,237:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:37:28,062:INFO:Calculating mean and std
2025-10-22 09:37:28,064:INFO:Creating metrics dataframe
2025-10-22 09:37:28,066:INFO:Uploading results into container
2025-10-22 09:37:28,067:INFO:Uploading model into container now
2025-10-22 09:37:28,067:INFO:_master_model_container: 7
2025-10-22 09:37:28,067:INFO:_display_container: 2
2025-10-22 09:37:28,067:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-22 09:37:28,068:INFO:create_model() successfully completed......................................
2025-10-22 09:37:28,294:INFO:SubProcess create_model() end ==================================
2025-10-22 09:37:28,294:INFO:Creating metrics dataframe
2025-10-22 09:37:28,297:INFO:Initializing Quadratic Discriminant Analysis
2025-10-22 09:37:28,297:INFO:Total runtime is 3.9005991895993555 minutes
2025-10-22 09:37:28,297:INFO:SubProcess create_model() called ==================================
2025-10-22 09:37:28,298:INFO:Initializing create_model()
2025-10-22 09:37:28,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:37:28,298:INFO:Checking exceptions
2025-10-22 09:37:28,298:INFO:Importing libraries
2025-10-22 09:37:28,298:INFO:Copying training dataset
2025-10-22 09:37:28,658:INFO:Defining folds
2025-10-22 09:37:28,658:INFO:Declaring metric variables
2025-10-22 09:37:28,658:INFO:Importing untrained model
2025-10-22 09:37:28,659:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-22 09:37:28,659:INFO:Starting cross validation
2025-10-22 09:37:28,663:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:37:31,989:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 09:37:35,583:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 09:37:39,165:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 09:37:42,689:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 09:37:46,254:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 09:37:46,719:INFO:Calculating mean and std
2025-10-22 09:37:46,720:INFO:Creating metrics dataframe
2025-10-22 09:37:46,722:INFO:Uploading results into container
2025-10-22 09:37:46,723:INFO:Uploading model into container now
2025-10-22 09:37:46,724:INFO:_master_model_container: 8
2025-10-22 09:37:46,724:INFO:_display_container: 2
2025-10-22 09:37:46,724:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-22 09:37:46,724:INFO:create_model() successfully completed......................................
2025-10-22 09:37:46,934:INFO:SubProcess create_model() end ==================================
2025-10-22 09:37:46,934:INFO:Creating metrics dataframe
2025-10-22 09:37:46,936:INFO:Initializing Ada Boost Classifier
2025-10-22 09:37:46,936:INFO:Total runtime is 4.211259460449219 minutes
2025-10-22 09:37:46,936:INFO:SubProcess create_model() called ==================================
2025-10-22 09:37:46,937:INFO:Initializing create_model()
2025-10-22 09:37:46,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:37:46,937:INFO:Checking exceptions
2025-10-22 09:37:46,937:INFO:Importing libraries
2025-10-22 09:37:46,937:INFO:Copying training dataset
2025-10-22 09:37:47,297:INFO:Defining folds
2025-10-22 09:37:47,297:INFO:Declaring metric variables
2025-10-22 09:37:47,298:INFO:Importing untrained model
2025-10-22 09:37:47,298:INFO:Ada Boost Classifier Imported successfully
2025-10-22 09:37:47,298:INFO:Starting cross validation
2025-10-22 09:37:47,302:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:37:50,147:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 09:37:56,880:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 09:38:03,553:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 09:38:10,290:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 09:38:16,902:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 09:38:20,746:INFO:Calculating mean and std
2025-10-22 09:38:20,748:INFO:Creating metrics dataframe
2025-10-22 09:38:20,749:INFO:Uploading results into container
2025-10-22 09:38:20,749:INFO:Uploading model into container now
2025-10-22 09:38:20,749:INFO:_master_model_container: 9
2025-10-22 09:38:20,749:INFO:_display_container: 2
2025-10-22 09:38:20,750:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-22 09:38:20,750:INFO:create_model() successfully completed......................................
2025-10-22 09:38:20,960:INFO:SubProcess create_model() end ==================================
2025-10-22 09:38:20,961:INFO:Creating metrics dataframe
2025-10-22 09:38:20,964:INFO:Initializing Gradient Boosting Classifier
2025-10-22 09:38:20,964:INFO:Total runtime is 4.778396332263947 minutes
2025-10-22 09:38:20,964:INFO:SubProcess create_model() called ==================================
2025-10-22 09:38:20,965:INFO:Initializing create_model()
2025-10-22 09:38:20,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:38:20,965:INFO:Checking exceptions
2025-10-22 09:38:20,965:INFO:Importing libraries
2025-10-22 09:38:20,965:INFO:Copying training dataset
2025-10-22 09:38:21,340:INFO:Defining folds
2025-10-22 09:38:21,341:INFO:Declaring metric variables
2025-10-22 09:38:21,341:INFO:Importing untrained model
2025-10-22 09:38:21,341:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 09:38:21,341:INFO:Starting cross validation
2025-10-22 09:38:21,345:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:39:29,603:INFO:Calculating mean and std
2025-10-22 09:39:29,604:INFO:Creating metrics dataframe
2025-10-22 09:39:29,606:INFO:Uploading results into container
2025-10-22 09:39:29,607:INFO:Uploading model into container now
2025-10-22 09:39:29,608:INFO:_master_model_container: 10
2025-10-22 09:39:29,608:INFO:_display_container: 2
2025-10-22 09:39:29,608:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 09:39:29,608:INFO:create_model() successfully completed......................................
2025-10-22 09:39:29,827:INFO:SubProcess create_model() end ==================================
2025-10-22 09:39:29,827:INFO:Creating metrics dataframe
2025-10-22 09:39:29,829:INFO:Initializing Linear Discriminant Analysis
2025-10-22 09:39:29,829:INFO:Total runtime is 5.9261423746744795 minutes
2025-10-22 09:39:29,829:INFO:SubProcess create_model() called ==================================
2025-10-22 09:39:29,830:INFO:Initializing create_model()
2025-10-22 09:39:29,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:39:29,830:INFO:Checking exceptions
2025-10-22 09:39:29,830:INFO:Importing libraries
2025-10-22 09:39:29,830:INFO:Copying training dataset
2025-10-22 09:39:30,203:INFO:Defining folds
2025-10-22 09:39:30,203:INFO:Declaring metric variables
2025-10-22 09:39:30,203:INFO:Importing untrained model
2025-10-22 09:39:30,204:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 09:39:30,204:INFO:Starting cross validation
2025-10-22 09:39:30,207:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:39:48,806:INFO:Calculating mean and std
2025-10-22 09:39:48,807:INFO:Creating metrics dataframe
2025-10-22 09:39:48,808:INFO:Uploading results into container
2025-10-22 09:39:48,808:INFO:Uploading model into container now
2025-10-22 09:39:48,809:INFO:_master_model_container: 11
2025-10-22 09:39:48,809:INFO:_display_container: 2
2025-10-22 09:39:48,809:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 09:39:48,809:INFO:create_model() successfully completed......................................
2025-10-22 09:39:49,022:INFO:SubProcess create_model() end ==================================
2025-10-22 09:39:49,022:INFO:Creating metrics dataframe
2025-10-22 09:39:49,024:INFO:Initializing Extra Trees Classifier
2025-10-22 09:39:49,024:INFO:Total runtime is 6.2460613767306015 minutes
2025-10-22 09:39:49,024:INFO:SubProcess create_model() called ==================================
2025-10-22 09:39:49,025:INFO:Initializing create_model()
2025-10-22 09:39:49,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:39:49,025:INFO:Checking exceptions
2025-10-22 09:39:49,025:INFO:Importing libraries
2025-10-22 09:39:49,025:INFO:Copying training dataset
2025-10-22 09:39:49,415:INFO:Defining folds
2025-10-22 09:39:49,415:INFO:Declaring metric variables
2025-10-22 09:39:49,416:INFO:Importing untrained model
2025-10-22 09:39:49,417:INFO:Extra Trees Classifier Imported successfully
2025-10-22 09:39:49,417:INFO:Starting cross validation
2025-10-22 09:39:49,421:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:40:57,579:INFO:Calculating mean and std
2025-10-22 09:40:57,580:INFO:Creating metrics dataframe
2025-10-22 09:40:57,582:INFO:Uploading results into container
2025-10-22 09:40:57,583:INFO:Uploading model into container now
2025-10-22 09:40:57,583:INFO:_master_model_container: 12
2025-10-22 09:40:57,584:INFO:_display_container: 2
2025-10-22 09:40:57,584:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-22 09:40:57,584:INFO:create_model() successfully completed......................................
2025-10-22 09:40:57,824:INFO:SubProcess create_model() end ==================================
2025-10-22 09:40:57,824:INFO:Creating metrics dataframe
2025-10-22 09:40:57,826:INFO:Initializing Extreme Gradient Boosting
2025-10-22 09:40:57,826:INFO:Total runtime is 7.392754340171814 minutes
2025-10-22 09:40:57,826:INFO:SubProcess create_model() called ==================================
2025-10-22 09:40:57,827:INFO:Initializing create_model()
2025-10-22 09:40:57,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=xgboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:40:57,827:INFO:Checking exceptions
2025-10-22 09:40:57,827:INFO:Importing libraries
2025-10-22 09:40:57,827:INFO:Copying training dataset
2025-10-22 09:40:58,264:INFO:Defining folds
2025-10-22 09:40:58,265:INFO:Declaring metric variables
2025-10-22 09:40:58,265:INFO:Importing untrained model
2025-10-22 09:40:58,266:INFO:Extreme Gradient Boosting Imported successfully
2025-10-22 09:40:58,267:INFO:Starting cross validation
2025-10-22 09:40:58,271:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:41:26,373:INFO:Calculating mean and std
2025-10-22 09:41:26,374:INFO:Creating metrics dataframe
2025-10-22 09:41:26,376:INFO:Uploading results into container
2025-10-22 09:41:26,376:INFO:Uploading model into container now
2025-10-22 09:41:26,376:INFO:_master_model_container: 13
2025-10-22 09:41:26,376:INFO:_display_container: 2
2025-10-22 09:41:26,377:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-10-22 09:41:26,377:INFO:create_model() successfully completed......................................
2025-10-22 09:41:26,607:INFO:SubProcess create_model() end ==================================
2025-10-22 09:41:26,607:INFO:Creating metrics dataframe
2025-10-22 09:41:26,609:INFO:Initializing Light Gradient Boosting Machine
2025-10-22 09:41:26,609:INFO:Total runtime is 7.872473728656769 minutes
2025-10-22 09:41:26,609:INFO:SubProcess create_model() called ==================================
2025-10-22 09:41:26,609:INFO:Initializing create_model()
2025-10-22 09:41:26,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:41:26,609:INFO:Checking exceptions
2025-10-22 09:41:26,609:INFO:Importing libraries
2025-10-22 09:41:26,609:INFO:Copying training dataset
2025-10-22 09:41:26,960:INFO:Defining folds
2025-10-22 09:41:26,960:INFO:Declaring metric variables
2025-10-22 09:41:26,960:INFO:Importing untrained model
2025-10-22 09:41:26,961:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-22 09:41:26,961:INFO:Starting cross validation
2025-10-22 09:41:26,965:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:41:30,184:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 09:41:30,189:INFO:[LightGBM] [Info] Number of positive: 14883, number of negative: 29918
2025-10-22 09:41:30,219:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008944 seconds.
2025-10-22 09:41:30,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 09:41:30,219:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 09:41:30,219:INFO:[LightGBM] [Info] Total Bins 1451
2025-10-22 09:41:30,221:INFO:[LightGBM] [Info] Number of data points in the train set: 44801, number of used features: 96
2025-10-22 09:41:30,224:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332202 -> initscore=-0.698241
2025-10-22 09:41:30,224:INFO:[LightGBM] [Info] Start training from score -0.698241
2025-10-22 09:41:34,065:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 09:41:34,067:INFO:[LightGBM] [Info] Number of positive: 15015, number of negative: 29786
2025-10-22 09:41:34,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009977 seconds.
2025-10-22 09:41:34,093:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 09:41:34,093:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 09:41:34,093:INFO:[LightGBM] [Info] Total Bins 1452
2025-10-22 09:41:34,093:INFO:[LightGBM] [Info] Number of data points in the train set: 44801, number of used features: 96
2025-10-22 09:41:34,093:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.335149 -> initscore=-0.684989
2025-10-22 09:41:34,094:INFO:[LightGBM] [Info] Start training from score -0.684989
2025-10-22 09:41:38,061:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 09:41:38,063:INFO:[LightGBM] [Info] Number of positive: 14903, number of negative: 29899
2025-10-22 09:41:38,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010350 seconds.
2025-10-22 09:41:38,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 09:41:38,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 09:41:38,089:INFO:[LightGBM] [Info] Total Bins 1452
2025-10-22 09:41:38,089:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-22 09:41:38,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332641 -> initscore=-0.696263
2025-10-22 09:41:38,090:INFO:[LightGBM] [Info] Start training from score -0.696263
2025-10-22 09:41:41,957:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 09:41:41,960:INFO:[LightGBM] [Info] Number of positive: 14818, number of negative: 29984
2025-10-22 09:41:41,986:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011048 seconds.
2025-10-22 09:41:41,986:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 09:41:41,986:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 09:41:41,987:INFO:[LightGBM] [Info] Total Bins 1453
2025-10-22 09:41:41,987:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-22 09:41:41,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.330744 -> initscore=-0.704821
2025-10-22 09:41:41,987:INFO:[LightGBM] [Info] Start training from score -0.704821
2025-10-22 09:41:45,928:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 09:41:45,930:INFO:[LightGBM] [Info] Number of positive: 14897, number of negative: 29905
2025-10-22 09:41:45,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010283 seconds.
2025-10-22 09:41:45,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 09:41:45,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 09:41:45,957:INFO:[LightGBM] [Info] Total Bins 1453
2025-10-22 09:41:45,957:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 96
2025-10-22 09:41:45,957:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332507 -> initscore=-0.696866
2025-10-22 09:41:45,957:INFO:[LightGBM] [Info] Start training from score -0.696866
2025-10-22 09:41:46,843:INFO:Calculating mean and std
2025-10-22 09:41:46,844:INFO:Creating metrics dataframe
2025-10-22 09:41:46,846:INFO:Uploading results into container
2025-10-22 09:41:46,847:INFO:Uploading model into container now
2025-10-22 09:41:46,848:INFO:_master_model_container: 14
2025-10-22 09:41:46,848:INFO:_display_container: 2
2025-10-22 09:41:46,849:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-22 09:41:46,849:INFO:create_model() successfully completed......................................
2025-10-22 09:41:47,064:INFO:SubProcess create_model() end ==================================
2025-10-22 09:41:47,064:INFO:Creating metrics dataframe
2025-10-22 09:41:47,066:INFO:Initializing CatBoost Classifier
2025-10-22 09:41:47,066:INFO:Total runtime is 8.213426001866658 minutes
2025-10-22 09:41:47,067:INFO:SubProcess create_model() called ==================================
2025-10-22 09:41:47,067:INFO:Initializing create_model()
2025-10-22 09:41:47,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:41:47,067:INFO:Checking exceptions
2025-10-22 09:41:47,067:INFO:Importing libraries
2025-10-22 09:41:47,067:INFO:Copying training dataset
2025-10-22 09:41:47,423:INFO:Defining folds
2025-10-22 09:41:47,424:INFO:Declaring metric variables
2025-10-22 09:41:47,424:INFO:Importing untrained model
2025-10-22 09:41:47,424:INFO:CatBoost Classifier Imported successfully
2025-10-22 09:41:47,424:INFO:Starting cross validation
2025-10-22 09:41:47,429:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:43:56,991:INFO:Calculating mean and std
2025-10-22 09:43:56,992:INFO:Creating metrics dataframe
2025-10-22 09:43:56,994:INFO:Uploading results into container
2025-10-22 09:43:56,994:INFO:Uploading model into container now
2025-10-22 09:43:56,995:INFO:_master_model_container: 15
2025-10-22 09:43:56,995:INFO:_display_container: 2
2025-10-22 09:43:56,995:INFO:<catboost.core.CatBoostClassifier object at 0x000001C386E7CFD0>
2025-10-22 09:43:56,995:INFO:create_model() successfully completed......................................
2025-10-22 09:43:57,240:INFO:SubProcess create_model() end ==================================
2025-10-22 09:43:57,240:INFO:Creating metrics dataframe
2025-10-22 09:43:57,242:INFO:Initializing Dummy Classifier
2025-10-22 09:43:57,242:INFO:Total runtime is 10.383024044831593 minutes
2025-10-22 09:43:57,242:INFO:SubProcess create_model() called ==================================
2025-10-22 09:43:57,243:INFO:Initializing create_model()
2025-10-22 09:43:57,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3877AF510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:43:57,243:INFO:Checking exceptions
2025-10-22 09:43:57,243:INFO:Importing libraries
2025-10-22 09:43:57,243:INFO:Copying training dataset
2025-10-22 09:43:57,624:INFO:Defining folds
2025-10-22 09:43:57,624:INFO:Declaring metric variables
2025-10-22 09:43:57,624:INFO:Importing untrained model
2025-10-22 09:43:57,625:INFO:Dummy Classifier Imported successfully
2025-10-22 09:43:57,625:INFO:Starting cross validation
2025-10-22 09:43:57,629:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:44:01,160:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:44:04,542:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:44:07,571:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:44:10,692:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:44:13,726:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 09:44:13,745:INFO:Calculating mean and std
2025-10-22 09:44:13,746:INFO:Creating metrics dataframe
2025-10-22 09:44:13,749:INFO:Uploading results into container
2025-10-22 09:44:13,749:INFO:Uploading model into container now
2025-10-22 09:44:13,749:INFO:_master_model_container: 16
2025-10-22 09:44:13,749:INFO:_display_container: 2
2025-10-22 09:44:13,750:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-22 09:44:13,750:INFO:create_model() successfully completed......................................
2025-10-22 09:44:13,959:INFO:SubProcess create_model() end ==================================
2025-10-22 09:44:13,960:INFO:Creating metrics dataframe
2025-10-22 09:44:13,963:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-22 09:44:13,966:INFO:Initializing create_model()
2025-10-22 09:44:13,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:44:13,966:INFO:Checking exceptions
2025-10-22 09:44:13,966:INFO:Importing libraries
2025-10-22 09:44:13,966:INFO:Copying training dataset
2025-10-22 09:44:14,328:INFO:Defining folds
2025-10-22 09:44:14,328:INFO:Declaring metric variables
2025-10-22 09:44:14,328:INFO:Importing untrained model
2025-10-22 09:44:14,329:INFO:Declaring custom model
2025-10-22 09:44:14,329:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 09:44:14,332:INFO:Cross validation set to False
2025-10-22 09:44:14,332:INFO:Fitting Model
2025-10-22 09:44:31,026:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 09:44:31,026:INFO:create_model() successfully completed......................................
2025-10-22 09:44:31,243:INFO:Initializing create_model()
2025-10-22 09:44:31,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:44:31,244:INFO:Checking exceptions
2025-10-22 09:44:31,244:INFO:Importing libraries
2025-10-22 09:44:31,244:INFO:Copying training dataset
2025-10-22 09:44:31,601:INFO:Defining folds
2025-10-22 09:44:31,601:INFO:Declaring metric variables
2025-10-22 09:44:31,601:INFO:Importing untrained model
2025-10-22 09:44:31,601:INFO:Declaring custom model
2025-10-22 09:44:31,601:INFO:Ridge Classifier Imported successfully
2025-10-22 09:44:31,605:INFO:Cross validation set to False
2025-10-22 09:44:31,605:INFO:Fitting Model
2025-10-22 09:44:35,186:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 09:44:35,186:INFO:create_model() successfully completed......................................
2025-10-22 09:44:35,401:INFO:Initializing create_model()
2025-10-22 09:44:35,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:44:35,401:INFO:Checking exceptions
2025-10-22 09:44:35,401:INFO:Importing libraries
2025-10-22 09:44:35,401:INFO:Copying training dataset
2025-10-22 09:44:35,750:INFO:Defining folds
2025-10-22 09:44:35,750:INFO:Declaring metric variables
2025-10-22 09:44:35,750:INFO:Importing untrained model
2025-10-22 09:44:35,750:INFO:Declaring custom model
2025-10-22 09:44:35,751:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 09:44:35,753:INFO:Cross validation set to False
2025-10-22 09:44:35,753:INFO:Fitting Model
2025-10-22 09:44:39,929:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 09:44:39,929:INFO:create_model() successfully completed......................................
2025-10-22 09:44:40,176:INFO:_master_model_container: 16
2025-10-22 09:44:40,176:INFO:_display_container: 2
2025-10-22 09:44:40,177:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2025-10-22 09:44:40,177:INFO:compare_models() successfully completed......................................
2025-10-22 09:44:40,186:INFO:Initializing tune_model()
2025-10-22 09:44:40,186:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-22 09:44:40,186:INFO:Checking exceptions
2025-10-22 09:44:40,346:INFO:Copying training dataset
2025-10-22 09:44:40,586:INFO:Checking base model
2025-10-22 09:44:40,586:INFO:Base model : Gradient Boosting Classifier
2025-10-22 09:44:40,587:INFO:Declaring metric variables
2025-10-22 09:44:40,587:INFO:Defining Hyperparameters
2025-10-22 09:44:40,805:INFO:Tuning with n_jobs=1
2025-10-22 09:44:40,805:INFO:Initializing RandomizedSearchCV
2025-10-22 09:52:52,544:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.4}
2025-10-22 09:52:52,545:INFO:Hyperparameter search completed
2025-10-22 09:52:52,545:INFO:SubProcess create_model() called ==================================
2025-10-22 09:52:52,546:INFO:Initializing create_model()
2025-10-22 09:52:52,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3842F6010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 130, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 1, 'learning_rate': 0.4})
2025-10-22 09:52:52,546:INFO:Checking exceptions
2025-10-22 09:52:52,546:INFO:Importing libraries
2025-10-22 09:52:52,546:INFO:Copying training dataset
2025-10-22 09:52:52,977:INFO:Defining folds
2025-10-22 09:52:52,977:INFO:Declaring metric variables
2025-10-22 09:52:52,977:INFO:Importing untrained model
2025-10-22 09:52:52,977:INFO:Declaring custom model
2025-10-22 09:52:52,978:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 09:52:52,978:INFO:Starting cross validation
2025-10-22 09:52:52,985:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:53:56,454:INFO:Calculating mean and std
2025-10-22 09:53:56,457:INFO:Creating metrics dataframe
2025-10-22 09:53:56,459:INFO:Finalizing model
2025-10-22 09:54:12,353:INFO:Uploading results into container
2025-10-22 09:54:12,354:INFO:Uploading model into container now
2025-10-22 09:54:12,355:INFO:_master_model_container: 17
2025-10-22 09:54:12,355:INFO:_display_container: 3
2025-10-22 09:54:12,357:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 09:54:12,357:INFO:create_model() successfully completed......................................
2025-10-22 09:54:12,770:INFO:SubProcess create_model() end ==================================
2025-10-22 09:54:12,770:INFO:choose_better activated
2025-10-22 09:54:12,771:INFO:SubProcess create_model() called ==================================
2025-10-22 09:54:12,777:INFO:Initializing create_model()
2025-10-22 09:54:12,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 09:54:12,778:INFO:Checking exceptions
2025-10-22 09:54:12,781:INFO:Importing libraries
2025-10-22 09:54:12,781:INFO:Copying training dataset
2025-10-22 09:54:13,457:INFO:Defining folds
2025-10-22 09:54:13,458:INFO:Declaring metric variables
2025-10-22 09:54:13,459:INFO:Importing untrained model
2025-10-22 09:54:13,459:INFO:Declaring custom model
2025-10-22 09:54:13,462:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 09:54:13,463:INFO:Starting cross validation
2025-10-22 09:54:13,472:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 09:56:18,386:INFO:Calculating mean and std
2025-10-22 09:56:18,386:INFO:Creating metrics dataframe
2025-10-22 09:56:18,388:INFO:Finalizing model
2025-10-22 09:56:35,029:INFO:Uploading results into container
2025-10-22 09:56:35,029:INFO:Uploading model into container now
2025-10-22 09:56:35,030:INFO:_master_model_container: 18
2025-10-22 09:56:35,030:INFO:_display_container: 4
2025-10-22 09:56:35,030:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 09:56:35,030:INFO:create_model() successfully completed......................................
2025-10-22 09:56:35,245:INFO:SubProcess create_model() end ==================================
2025-10-22 09:56:35,245:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9215
2025-10-22 09:56:35,246:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9207
2025-10-22 09:56:35,246:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-22 09:56:35,246:INFO:choose_better completed
2025-10-22 09:56:35,246:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-22 09:56:35,249:INFO:_master_model_container: 18
2025-10-22 09:56:35,249:INFO:_display_container: 3
2025-10-22 09:56:35,249:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 09:56:35,249:INFO:tune_model() successfully completed......................................
2025-10-22 09:56:35,466:INFO:Initializing tune_model()
2025-10-22 09:56:35,466:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-22 09:56:35,466:INFO:Checking exceptions
2025-10-22 09:56:35,618:INFO:Copying training dataset
2025-10-22 09:56:35,868:INFO:Checking base model
2025-10-22 09:56:35,868:INFO:Base model : Ridge Classifier
2025-10-22 09:56:35,869:INFO:Declaring metric variables
2025-10-22 09:56:35,869:INFO:Defining Hyperparameters
2025-10-22 09:56:36,083:INFO:Tuning with n_jobs=1
2025-10-22 09:56:36,083:INFO:Initializing RandomizedSearchCV
2025-10-22 09:59:04,520:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.26434e-17): result may not be accurate.

2025-10-22 09:59:10,461:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.35296e-17): result may not be accurate.

2025-10-22 09:59:16,720:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.32695e-17): result may not be accurate.

2025-10-22 09:59:22,729:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.3293e-17): result may not be accurate.

2025-10-22 09:59:28,810:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.29531e-17): result may not be accurate.

2025-10-22 09:59:50,306:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.3}
2025-10-22 09:59:50,307:INFO:Hyperparameter search completed
2025-10-22 09:59:50,307:INFO:SubProcess create_model() called ==================================
2025-10-22 09:59:50,308:INFO:Initializing create_model()
2025-10-22 09:59:50,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3852CAB10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 7.3})
2025-10-22 09:59:50,308:INFO:Checking exceptions
2025-10-22 09:59:50,308:INFO:Importing libraries
2025-10-22 09:59:50,309:INFO:Copying training dataset
2025-10-22 09:59:50,673:INFO:Defining folds
2025-10-22 09:59:50,673:INFO:Declaring metric variables
2025-10-22 09:59:50,673:INFO:Importing untrained model
2025-10-22 09:59:50,673:INFO:Declaring custom model
2025-10-22 09:59:50,674:INFO:Ridge Classifier Imported successfully
2025-10-22 09:59:50,674:INFO:Starting cross validation
2025-10-22 09:59:50,678:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 10:00:08,951:INFO:Calculating mean and std
2025-10-22 10:00:08,952:INFO:Creating metrics dataframe
2025-10-22 10:00:08,954:INFO:Finalizing model
2025-10-22 10:00:12,767:INFO:Uploading results into container
2025-10-22 10:00:12,767:INFO:Uploading model into container now
2025-10-22 10:00:12,768:INFO:_master_model_container: 19
2025-10-22 10:00:12,768:INFO:_display_container: 4
2025-10-22 10:00:12,768:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 10:00:12,768:INFO:create_model() successfully completed......................................
2025-10-22 10:00:13,027:INFO:SubProcess create_model() end ==================================
2025-10-22 10:00:13,027:INFO:choose_better activated
2025-10-22 10:00:13,028:INFO:SubProcess create_model() called ==================================
2025-10-22 10:00:13,029:INFO:Initializing create_model()
2025-10-22 10:00:13,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 10:00:13,029:INFO:Checking exceptions
2025-10-22 10:00:13,029:INFO:Importing libraries
2025-10-22 10:00:13,029:INFO:Copying training dataset
2025-10-22 10:00:13,418:INFO:Defining folds
2025-10-22 10:00:13,418:INFO:Declaring metric variables
2025-10-22 10:00:13,418:INFO:Importing untrained model
2025-10-22 10:00:13,418:INFO:Declaring custom model
2025-10-22 10:00:13,418:INFO:Ridge Classifier Imported successfully
2025-10-22 10:00:13,418:INFO:Starting cross validation
2025-10-22 10:00:13,421:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 10:00:31,703:INFO:Calculating mean and std
2025-10-22 10:00:31,703:INFO:Creating metrics dataframe
2025-10-22 10:00:31,705:INFO:Finalizing model
2025-10-22 10:00:35,662:INFO:Uploading results into container
2025-10-22 10:00:35,663:INFO:Uploading model into container now
2025-10-22 10:00:35,663:INFO:_master_model_container: 20
2025-10-22 10:00:35,663:INFO:_display_container: 5
2025-10-22 10:00:35,663:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 10:00:35,663:INFO:create_model() successfully completed......................................
2025-10-22 10:00:35,896:INFO:SubProcess create_model() end ==================================
2025-10-22 10:00:35,896:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9213
2025-10-22 10:00:35,896:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9217
2025-10-22 10:00:35,897:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) is best model
2025-10-22 10:00:35,897:INFO:choose_better completed
2025-10-22 10:00:35,899:INFO:_master_model_container: 20
2025-10-22 10:00:35,900:INFO:_display_container: 4
2025-10-22 10:00:35,900:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 10:00:35,900:INFO:tune_model() successfully completed......................................
2025-10-22 10:00:36,147:INFO:Initializing tune_model()
2025-10-22 10:00:36,147:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-22 10:00:36,147:INFO:Checking exceptions
2025-10-22 10:00:36,339:INFO:Copying training dataset
2025-10-22 10:00:36,597:INFO:Checking base model
2025-10-22 10:00:36,597:INFO:Base model : Linear Discriminant Analysis
2025-10-22 10:00:36,597:INFO:Declaring metric variables
2025-10-22 10:00:36,597:INFO:Defining Hyperparameters
2025-10-22 10:00:36,840:INFO:Tuning with n_jobs=1
2025-10-22 10:00:36,840:INFO:Initializing RandomizedSearchCV
2025-10-22 10:03:28,452:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 'auto'}
2025-10-22 10:03:28,453:INFO:Hyperparameter search completed
2025-10-22 10:03:28,454:INFO:SubProcess create_model() called ==================================
2025-10-22 10:03:28,455:INFO:Initializing create_model()
2025-10-22 10:03:28,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3838226D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 'auto'})
2025-10-22 10:03:28,455:INFO:Checking exceptions
2025-10-22 10:03:28,455:INFO:Importing libraries
2025-10-22 10:03:28,455:INFO:Copying training dataset
2025-10-22 10:03:28,840:INFO:Defining folds
2025-10-22 10:03:28,840:INFO:Declaring metric variables
2025-10-22 10:03:28,841:INFO:Importing untrained model
2025-10-22 10:03:28,841:INFO:Declaring custom model
2025-10-22 10:03:28,842:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 10:03:28,842:INFO:Starting cross validation
2025-10-22 10:03:28,846:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 10:03:45,952:INFO:Calculating mean and std
2025-10-22 10:03:45,953:INFO:Creating metrics dataframe
2025-10-22 10:03:45,955:INFO:Finalizing model
2025-10-22 10:03:49,972:INFO:Uploading results into container
2025-10-22 10:03:49,973:INFO:Uploading model into container now
2025-10-22 10:03:49,974:INFO:_master_model_container: 21
2025-10-22 10:03:49,976:INFO:_display_container: 5
2025-10-22 10:03:49,977:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-22 10:03:49,977:INFO:create_model() successfully completed......................................
2025-10-22 10:03:50,239:INFO:SubProcess create_model() end ==================================
2025-10-22 10:03:50,239:INFO:choose_better activated
2025-10-22 10:03:50,239:INFO:SubProcess create_model() called ==================================
2025-10-22 10:03:50,240:INFO:Initializing create_model()
2025-10-22 10:03:50,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 10:03:50,240:INFO:Checking exceptions
2025-10-22 10:03:50,241:INFO:Importing libraries
2025-10-22 10:03:50,241:INFO:Copying training dataset
2025-10-22 10:03:50,672:INFO:Defining folds
2025-10-22 10:03:50,672:INFO:Declaring metric variables
2025-10-22 10:03:50,672:INFO:Importing untrained model
2025-10-22 10:03:50,672:INFO:Declaring custom model
2025-10-22 10:03:50,672:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 10:03:50,672:INFO:Starting cross validation
2025-10-22 10:03:50,676:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 10:04:10,404:INFO:Calculating mean and std
2025-10-22 10:04:10,405:INFO:Creating metrics dataframe
2025-10-22 10:04:10,406:INFO:Finalizing model
2025-10-22 10:04:14,664:INFO:Uploading results into container
2025-10-22 10:04:14,665:INFO:Uploading model into container now
2025-10-22 10:04:14,665:INFO:_master_model_container: 22
2025-10-22 10:04:14,665:INFO:_display_container: 6
2025-10-22 10:04:14,666:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 10:04:14,666:INFO:create_model() successfully completed......................................
2025-10-22 10:04:14,898:INFO:SubProcess create_model() end ==================================
2025-10-22 10:04:14,898:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9212
2025-10-22 10:04:14,899:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9213
2025-10-22 10:04:14,899:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) is best model
2025-10-22 10:04:14,899:INFO:choose_better completed
2025-10-22 10:04:14,902:INFO:_master_model_container: 22
2025-10-22 10:04:14,902:INFO:_display_container: 5
2025-10-22 10:04:14,903:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-22 10:04:14,903:INFO:tune_model() successfully completed......................................
2025-10-22 10:04:15,114:INFO:Initializing blend_models()
2025-10-22 10:04:15,114:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-22 10:04:15,114:INFO:Checking exceptions
2025-10-22 10:04:15,114:INFO:Estimator RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-22 10:04:15,273:INFO:Importing libraries
2025-10-22 10:04:15,273:INFO:Copying training dataset
2025-10-22 10:04:15,274:INFO:Getting model names
2025-10-22 10:04:15,274:INFO:SubProcess create_model() called ==================================
2025-10-22 10:04:15,278:INFO:Initializing create_model()
2025-10-22 10:04:15,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3838226D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 10:04:15,279:INFO:Checking exceptions
2025-10-22 10:04:15,279:INFO:Importing libraries
2025-10-22 10:04:15,279:INFO:Copying training dataset
2025-10-22 10:04:15,638:INFO:Defining folds
2025-10-22 10:04:15,639:INFO:Declaring metric variables
2025-10-22 10:04:15,639:INFO:Importing untrained model
2025-10-22 10:04:15,639:INFO:Declaring custom model
2025-10-22 10:04:15,640:INFO:Voting Classifier Imported successfully
2025-10-22 10:04:15,641:INFO:Starting cross validation
2025-10-22 10:04:15,644:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 10:04:29,690:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 10:04:43,605:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 10:04:57,481:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 10:05:11,393:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 10:05:25,410:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 10:05:25,438:INFO:Calculating mean and std
2025-10-22 10:05:25,439:INFO:Creating metrics dataframe
2025-10-22 10:05:25,441:INFO:Finalizing model
2025-10-22 10:05:42,497:INFO:Uploading results into container
2025-10-22 10:05:42,498:INFO:Uploading model into container now
2025-10-22 10:05:42,499:INFO:_master_model_container: 23
2025-10-22 10:05:42,499:INFO:_display_container: 6
2025-10-22 10:05:42,504:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-22 10:05:42,504:INFO:create_model() successfully completed......................................
2025-10-22 10:05:42,729:INFO:SubProcess create_model() end ==================================
2025-10-22 10:05:42,731:INFO:_master_model_container: 23
2025-10-22 10:05:42,731:INFO:_display_container: 6
2025-10-22 10:05:42,733:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-22 10:05:42,733:INFO:blend_models() successfully completed......................................
2025-10-22 10:05:42,945:INFO:Initializing finalize_model()
2025-10-22 10:05:42,946:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-22 10:05:42,948:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-22 10:05:43,255:INFO:Initializing create_model()
2025-10-22 10:05:43,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage='auto',
                                                         solver='lsqr',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
74123    U04452
20513    U07023
54794    U14666
77090    U07455
71177    U08938
Name: id_usuario, Length: 80004, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 10:05:43,255:INFO:Checking exceptions
2025-10-22 10:05:43,256:INFO:Importing libraries
2025-10-22 10:05:43,256:INFO:Copying training dataset
2025-10-22 10:05:43,302:INFO:Defining folds
2025-10-22 10:05:43,302:INFO:Declaring metric variables
2025-10-22 10:05:43,302:INFO:Importing untrained model
2025-10-22 10:05:43,303:INFO:Declaring custom model
2025-10-22 10:05:43,304:INFO:Voting Classifier Imported successfully
2025-10-22 10:05:43,307:INFO:Cross validation set to False
2025-10-22 10:05:43,307:INFO:Fitting Model
2025-10-22 10:06:08,107:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-22 10:06:08,107:INFO:create_model() successfully completed......................................
2025-10-22 10:06:08,364:INFO:_master_model_container: 23
2025-10-22 10:06:08,364:INFO:_display_container: 6
2025-10-22 10:06:08,399:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-22 10:06:08,399:INFO:finalize_model() successfully completed......................................
2025-10-22 10:06:08,665:INFO:Initializing save_model()
2025-10-22 10:06:08,665:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), model_name=modelo_cls_like_v2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                    transformer=TargetEncoder(cols=['nombre_sitio',
                                                                    'x_tipoTur__tipoSit',
                                                                    'x_epoca__tipoSit'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-22 10:06:08,665:INFO:Adding model into prep_pipe
2025-10-22 10:06:08,665:WARNING:Only Model saved as it was a pipeline.
2025-10-22 10:06:08,696:INFO:modelo_cls_like_v2.pkl saved in current working directory
2025-10-22 10:06:08,725:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-22 10:06:08,726:INFO:save_model() successfully completed......................................
2025-10-22 10:07:23,153:INFO:Initializing load_model()
2025-10-22 10:07:23,153:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 10:07:23,224:INFO:Initializing predict_model()
2025-10-22 10:07:23,224:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C385095120>)
2025-10-22 10:07:23,224:INFO:Checking exceptions
2025-10-22 10:07:23,224:INFO:Preloading libraries
2025-10-22 10:07:23,224:INFO:Set up data.
2025-10-22 10:07:23,255:INFO:Set up index.
2025-10-22 10:19:14,345:INFO:Initializing load_model()
2025-10-22 10:19:14,346:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 10:19:14,408:INFO:Initializing predict_model()
2025-10-22 10:19:14,408:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C3F82E47D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage='auto',
                                                                          solver='lsqr',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C381A377E0>)
2025-10-22 10:19:14,408:INFO:Checking exceptions
2025-10-22 10:19:14,408:INFO:Preloading libraries
2025-10-22 10:19:14,408:INFO:Set up data.
2025-10-22 10:19:14,436:INFO:Set up index.
2025-10-22 10:22:11,496:INFO:Initializing load_model()
2025-10-22 10:22:11,496:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 10:25:26,932:INFO:Initializing load_model()
2025-10-22 10:25:26,933:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 10:30:23,405:INFO:Initializing load_model()
2025-10-22 10:30:23,405:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 11:26:12,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-22 11:26:12,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-22 11:26:12,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-22 11:26:12,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-22 11:26:27,309:INFO:PyCaret ClassificationExperiment
2025-10-22 11:26:27,309:INFO:Logging name: clf-default-name
2025-10-22 11:26:27,309:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-22 11:26:27,309:INFO:version 3.3.2
2025-10-22 11:26:27,309:INFO:Initializing setup()
2025-10-22 11:26:27,309:INFO:self.USI: c1bf
2025-10-22 11:26:27,309:INFO:self._variable_keys: {'gpu_param', 'y', 'fold_groups_param', 'html_param', 'logging_param', 'is_multiclass', 'USI', 'seed', '_available_plots', 'exp_id', 'y_train', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_test', 'X_train', 'data', 'fix_imbalance', 'fold_generator', 'y_test', 'log_plots_param', 'exp_name_log', 'idx', 'target_param', 'n_jobs_param', 'memory', 'pipeline', '_ml_usecase'}
2025-10-22 11:26:27,310:INFO:Checking environment
2025-10-22 11:26:27,310:INFO:python_version: 3.11.13
2025-10-22 11:26:27,310:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-22 11:26:27,310:INFO:machine: AMD64
2025-10-22 11:26:27,310:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-22 11:26:27,314:INFO:Memory: svmem(total=16856211456, available=3713318912, percent=78.0, used=13142892544, free=3713318912)
2025-10-22 11:26:27,314:INFO:Physical Core: 4
2025-10-22 11:26:27,315:INFO:Logical Core: 8
2025-10-22 11:26:27,315:INFO:Checking libraries
2025-10-22 11:26:27,315:INFO:System:
2025-10-22 11:26:27,315:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-22 11:26:27,315:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-22 11:26:27,315:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-22 11:26:27,315:INFO:PyCaret required dependencies:
2025-10-22 11:26:33,770:INFO:                 pip: 25.2
2025-10-22 11:26:33,771:INFO:          setuptools: 80.9.0
2025-10-22 11:26:33,771:INFO:             pycaret: 3.3.2
2025-10-22 11:26:33,771:INFO:             IPython: 9.6.0
2025-10-22 11:26:33,771:INFO:          ipywidgets: 8.1.7
2025-10-22 11:26:33,771:INFO:                tqdm: 4.67.1
2025-10-22 11:26:33,771:INFO:               numpy: 1.26.4
2025-10-22 11:26:33,771:INFO:              pandas: 2.1.4
2025-10-22 11:26:33,771:INFO:              jinja2: 3.1.6
2025-10-22 11:26:33,771:INFO:               scipy: 1.11.4
2025-10-22 11:26:33,771:INFO:              joblib: 1.3.2
2025-10-22 11:26:33,771:INFO:             sklearn: 1.4.2
2025-10-22 11:26:33,771:INFO:                pyod: 2.0.5
2025-10-22 11:26:33,771:INFO:            imblearn: 0.14.0
2025-10-22 11:26:33,771:INFO:   category_encoders: 2.7.0
2025-10-22 11:26:33,771:INFO:            lightgbm: 4.6.0
2025-10-22 11:26:33,771:INFO:               numba: 0.61.0
2025-10-22 11:26:33,771:INFO:            requests: 2.32.5
2025-10-22 11:26:33,771:INFO:          matplotlib: 3.7.5
2025-10-22 11:26:33,771:INFO:          scikitplot: 0.3.7
2025-10-22 11:26:33,771:INFO:         yellowbrick: 1.5
2025-10-22 11:26:33,771:INFO:              plotly: 5.24.1
2025-10-22 11:26:33,771:INFO:    plotly-resampler: Not installed
2025-10-22 11:26:33,771:INFO:             kaleido: 1.1.0
2025-10-22 11:26:33,772:INFO:           schemdraw: 0.15
2025-10-22 11:26:33,772:INFO:         statsmodels: 0.14.5
2025-10-22 11:26:33,772:INFO:              sktime: 0.26.0
2025-10-22 11:26:33,772:INFO:               tbats: 1.1.3
2025-10-22 11:26:33,772:INFO:            pmdarima: 2.0.4
2025-10-22 11:26:33,772:INFO:              psutil: 7.1.1
2025-10-22 11:26:33,772:INFO:          markupsafe: 3.0.3
2025-10-22 11:26:33,772:INFO:             pickle5: Not installed
2025-10-22 11:26:33,772:INFO:         cloudpickle: 3.1.1
2025-10-22 11:26:33,772:INFO:         deprecation: 2.1.0
2025-10-22 11:26:33,772:INFO:              xxhash: 3.6.0
2025-10-22 11:26:33,772:INFO:           wurlitzer: Not installed
2025-10-22 11:26:33,772:INFO:PyCaret optional dependencies:
2025-10-22 11:26:51,223:INFO:                shap: 0.44.1
2025-10-22 11:26:51,223:INFO:           interpret: 0.7.3
2025-10-22 11:26:51,223:INFO:                umap: 0.5.7
2025-10-22 11:26:51,223:INFO:     ydata_profiling: 4.17.0
2025-10-22 11:26:51,223:INFO:  explainerdashboard: 0.5.1
2025-10-22 11:26:51,223:INFO:             autoviz: Not installed
2025-10-22 11:26:51,223:INFO:           fairlearn: 0.7.0
2025-10-22 11:26:51,223:INFO:          deepchecks: Not installed
2025-10-22 11:26:51,223:INFO:             xgboost: 3.1.0
2025-10-22 11:26:51,223:INFO:            catboost: 1.2.8
2025-10-22 11:26:51,223:INFO:              kmodes: 0.12.2
2025-10-22 11:26:51,223:INFO:             mlxtend: 0.23.4
2025-10-22 11:26:51,223:INFO:       statsforecast: 1.5.0
2025-10-22 11:26:51,223:INFO:        tune_sklearn: Not installed
2025-10-22 11:26:51,223:INFO:                 ray: Not installed
2025-10-22 11:26:51,223:INFO:            hyperopt: 0.2.7
2025-10-22 11:26:51,223:INFO:              optuna: 4.5.0
2025-10-22 11:26:51,223:INFO:               skopt: 0.10.2
2025-10-22 11:26:51,224:INFO:              mlflow: 3.5.0
2025-10-22 11:26:51,224:INFO:              gradio: 5.49.1
2025-10-22 11:26:51,224:INFO:             fastapi: 0.119.1
2025-10-22 11:26:51,224:INFO:             uvicorn: 0.38.0
2025-10-22 11:26:51,224:INFO:              m2cgen: 0.10.0
2025-10-22 11:26:51,224:INFO:           evidently: 0.4.40
2025-10-22 11:26:51,224:INFO:               fugue: 0.8.7
2025-10-22 11:26:51,224:INFO:           streamlit: Not installed
2025-10-22 11:26:51,224:INFO:             prophet: Not installed
2025-10-22 11:26:51,224:INFO:None
2025-10-22 11:26:51,224:INFO:Set up data.
2025-10-22 11:26:51,491:INFO:Set up folding strategy.
2025-10-22 11:26:51,756:INFO:Set up train/test split.
2025-10-22 11:26:52,015:INFO:Set up index.
2025-10-22 11:26:52,040:INFO:Assigning column types.
2025-10-22 11:26:52,398:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-22 11:26:52,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-22 11:26:52,445:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 11:26:52,492:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:26:52,494:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:26:53,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-22 11:26:53,128:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 11:26:53,152:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:26:53,154:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:26:53,155:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-22 11:26:53,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 11:26:53,223:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:26:53,225:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:26:53,263:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 11:26:53,294:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:26:53,299:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:26:53,299:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-22 11:26:53,361:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:26:53,365:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:26:53,448:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:26:53,453:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:26:53,456:INFO:Preparing preprocessing pipeline...
2025-10-22 11:26:53,524:INFO:Set up simple imputation.
2025-10-22 11:26:53,804:INFO:Set up encoding of ordinal features.
2025-10-22 11:26:53,934:INFO:Set up encoding of categorical features.
2025-10-22 11:26:53,944:INFO:Set up removing multicollinearity.
2025-10-22 11:27:00,314:INFO:Finished creating preprocessing pipeline.
2025-10-22 11:27:00,329:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                    transformer=TargetEncoder(cols=['nombre_sitio',
                                                                    'x_tipoTur__tipoSit',
                                                                    'x_epoca__tipoSit'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95)))],
         verbose=False)
2025-10-22 11:27:00,329:INFO:Creating final display dataframe.
2025-10-22 11:27:04,106:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 28)
4        Transformed data shape       (80004, 96)
5   Transformed train set shape       (56002, 96)
6    Transformed test set shape       (24002, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation     most_frequent
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Fold Generator        GroupKFold
19                  Fold Number                 5
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              c1bf
2025-10-22 11:27:04,163:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:27:04,165:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:27:04,222:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:27:04,224:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:27:04,226:INFO:setup() successfully completed in 37.33s...............
2025-10-22 11:27:04,226:INFO:Initializing compare_models()
2025-10-22 11:27:04,226:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-22 11:27:04,226:INFO:Checking exceptions
2025-10-22 11:27:04,495:INFO:Preparing display monitor
2025-10-22 11:27:04,523:INFO:Initializing Logistic Regression
2025-10-22 11:27:04,523:INFO:Total runtime is 1.668532689412435e-05 minutes
2025-10-22 11:27:04,528:INFO:SubProcess create_model() called ==================================
2025-10-22 11:27:04,530:INFO:Initializing create_model()
2025-10-22 11:27:04,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:27:04,530:INFO:Checking exceptions
2025-10-22 11:27:04,530:INFO:Importing libraries
2025-10-22 11:27:04,530:INFO:Copying training dataset
2025-10-22 11:27:05,042:INFO:Defining folds
2025-10-22 11:27:05,042:INFO:Declaring metric variables
2025-10-22 11:27:05,045:INFO:Importing untrained model
2025-10-22 11:27:05,047:INFO:Logistic Regression Imported successfully
2025-10-22 11:27:05,055:INFO:Starting cross validation
2025-10-22 11:27:05,059:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:27:14,683:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 11:27:24,815:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 11:27:34,942:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 11:27:44,536:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 11:27:54,218:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 11:27:54,582:INFO:Calculating mean and std
2025-10-22 11:27:54,583:INFO:Creating metrics dataframe
2025-10-22 11:27:54,585:INFO:Uploading results into container
2025-10-22 11:27:54,585:INFO:Uploading model into container now
2025-10-22 11:27:54,586:INFO:_master_model_container: 1
2025-10-22 11:27:54,586:INFO:_display_container: 2
2025-10-22 11:27:54,586:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-22 11:27:54,586:INFO:create_model() successfully completed......................................
2025-10-22 11:27:54,782:INFO:SubProcess create_model() end ==================================
2025-10-22 11:27:54,782:INFO:Creating metrics dataframe
2025-10-22 11:27:54,789:INFO:Initializing K Neighbors Classifier
2025-10-22 11:27:54,791:INFO:Total runtime is 0.8378118832906087 minutes
2025-10-22 11:27:54,794:INFO:SubProcess create_model() called ==================================
2025-10-22 11:27:54,794:INFO:Initializing create_model()
2025-10-22 11:27:54,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:27:54,794:INFO:Checking exceptions
2025-10-22 11:27:54,794:INFO:Importing libraries
2025-10-22 11:27:54,796:INFO:Copying training dataset
2025-10-22 11:27:55,165:INFO:Defining folds
2025-10-22 11:27:55,166:INFO:Declaring metric variables
2025-10-22 11:27:55,170:INFO:Importing untrained model
2025-10-22 11:27:55,174:INFO:K Neighbors Classifier Imported successfully
2025-10-22 11:27:55,181:INFO:Starting cross validation
2025-10-22 11:27:55,184:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:28:24,016:INFO:Calculating mean and std
2025-10-22 11:28:24,017:INFO:Creating metrics dataframe
2025-10-22 11:28:24,020:INFO:Uploading results into container
2025-10-22 11:28:24,021:INFO:Uploading model into container now
2025-10-22 11:28:24,021:INFO:_master_model_container: 2
2025-10-22 11:28:24,021:INFO:_display_container: 2
2025-10-22 11:28:24,022:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-22 11:28:24,022:INFO:create_model() successfully completed......................................
2025-10-22 11:28:24,222:INFO:SubProcess create_model() end ==================================
2025-10-22 11:28:24,222:INFO:Creating metrics dataframe
2025-10-22 11:28:24,234:INFO:Initializing Naive Bayes
2025-10-22 11:28:24,235:INFO:Total runtime is 1.3285507798194884 minutes
2025-10-22 11:28:24,240:INFO:SubProcess create_model() called ==================================
2025-10-22 11:28:24,242:INFO:Initializing create_model()
2025-10-22 11:28:24,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:28:24,243:INFO:Checking exceptions
2025-10-22 11:28:24,243:INFO:Importing libraries
2025-10-22 11:28:24,243:INFO:Copying training dataset
2025-10-22 11:28:24,634:INFO:Defining folds
2025-10-22 11:28:24,634:INFO:Declaring metric variables
2025-10-22 11:28:24,637:INFO:Importing untrained model
2025-10-22 11:28:24,642:INFO:Naive Bayes Imported successfully
2025-10-22 11:28:24,650:INFO:Starting cross validation
2025-10-22 11:28:24,653:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:28:27,979:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:28:31,232:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:28:34,563:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:28:37,851:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:28:41,084:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:28:41,102:INFO:Calculating mean and std
2025-10-22 11:28:41,103:INFO:Creating metrics dataframe
2025-10-22 11:28:41,105:INFO:Uploading results into container
2025-10-22 11:28:41,105:INFO:Uploading model into container now
2025-10-22 11:28:41,105:INFO:_master_model_container: 3
2025-10-22 11:28:41,105:INFO:_display_container: 2
2025-10-22 11:28:41,106:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-22 11:28:41,106:INFO:create_model() successfully completed......................................
2025-10-22 11:28:41,294:INFO:SubProcess create_model() end ==================================
2025-10-22 11:28:41,294:INFO:Creating metrics dataframe
2025-10-22 11:28:41,299:INFO:Initializing Decision Tree Classifier
2025-10-22 11:28:41,300:INFO:Total runtime is 1.6129706581433614 minutes
2025-10-22 11:28:41,303:INFO:SubProcess create_model() called ==================================
2025-10-22 11:28:41,304:INFO:Initializing create_model()
2025-10-22 11:28:41,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:28:41,305:INFO:Checking exceptions
2025-10-22 11:28:41,305:INFO:Importing libraries
2025-10-22 11:28:41,305:INFO:Copying training dataset
2025-10-22 11:28:41,693:INFO:Defining folds
2025-10-22 11:28:41,694:INFO:Declaring metric variables
2025-10-22 11:28:41,698:INFO:Importing untrained model
2025-10-22 11:28:41,701:INFO:Decision Tree Classifier Imported successfully
2025-10-22 11:28:41,708:INFO:Starting cross validation
2025-10-22 11:28:41,714:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:29:02,170:INFO:Calculating mean and std
2025-10-22 11:29:02,171:INFO:Creating metrics dataframe
2025-10-22 11:29:02,171:INFO:Uploading results into container
2025-10-22 11:29:02,172:INFO:Uploading model into container now
2025-10-22 11:29:02,172:INFO:_master_model_container: 4
2025-10-22 11:29:02,172:INFO:_display_container: 2
2025-10-22 11:29:02,173:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-22 11:29:02,173:INFO:create_model() successfully completed......................................
2025-10-22 11:29:02,365:INFO:SubProcess create_model() end ==================================
2025-10-22 11:29:02,365:INFO:Creating metrics dataframe
2025-10-22 11:29:02,371:INFO:Initializing SVM - Linear Kernel
2025-10-22 11:29:02,371:INFO:Total runtime is 1.9641605059305827 minutes
2025-10-22 11:29:02,374:INFO:SubProcess create_model() called ==================================
2025-10-22 11:29:02,378:INFO:Initializing create_model()
2025-10-22 11:29:02,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:29:02,378:INFO:Checking exceptions
2025-10-22 11:29:02,378:INFO:Importing libraries
2025-10-22 11:29:02,378:INFO:Copying training dataset
2025-10-22 11:29:02,783:INFO:Defining folds
2025-10-22 11:29:02,783:INFO:Declaring metric variables
2025-10-22 11:29:02,787:INFO:Importing untrained model
2025-10-22 11:29:02,791:INFO:SVM - Linear Kernel Imported successfully
2025-10-22 11:29:02,799:INFO:Starting cross validation
2025-10-22 11:29:02,804:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:29:12,809:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:29:20,924:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:29:29,865:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:29:44,875:INFO:Calculating mean and std
2025-10-22 11:29:44,876:INFO:Creating metrics dataframe
2025-10-22 11:29:44,877:INFO:Uploading results into container
2025-10-22 11:29:44,878:INFO:Uploading model into container now
2025-10-22 11:29:44,879:INFO:_master_model_container: 5
2025-10-22 11:29:44,879:INFO:_display_container: 2
2025-10-22 11:29:44,879:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-22 11:29:44,880:INFO:create_model() successfully completed......................................
2025-10-22 11:29:45,073:INFO:SubProcess create_model() end ==================================
2025-10-22 11:29:45,073:INFO:Creating metrics dataframe
2025-10-22 11:29:45,081:INFO:Initializing Ridge Classifier
2025-10-22 11:29:45,081:INFO:Total runtime is 2.6759870330492657 minutes
2025-10-22 11:29:45,084:INFO:SubProcess create_model() called ==================================
2025-10-22 11:29:45,086:INFO:Initializing create_model()
2025-10-22 11:29:45,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:29:45,086:INFO:Checking exceptions
2025-10-22 11:29:45,086:INFO:Importing libraries
2025-10-22 11:29:45,087:INFO:Copying training dataset
2025-10-22 11:29:45,506:INFO:Defining folds
2025-10-22 11:29:45,507:INFO:Declaring metric variables
2025-10-22 11:29:45,510:INFO:Importing untrained model
2025-10-22 11:29:45,516:INFO:Ridge Classifier Imported successfully
2025-10-22 11:29:45,522:INFO:Starting cross validation
2025-10-22 11:29:45,527:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:30:02,755:INFO:Calculating mean and std
2025-10-22 11:30:02,756:INFO:Creating metrics dataframe
2025-10-22 11:30:02,758:INFO:Uploading results into container
2025-10-22 11:30:02,758:INFO:Uploading model into container now
2025-10-22 11:30:02,758:INFO:_master_model_container: 6
2025-10-22 11:30:02,758:INFO:_display_container: 2
2025-10-22 11:30:02,759:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 11:30:02,759:INFO:create_model() successfully completed......................................
2025-10-22 11:30:02,956:INFO:SubProcess create_model() end ==================================
2025-10-22 11:30:02,956:INFO:Creating metrics dataframe
2025-10-22 11:30:02,964:INFO:Initializing Random Forest Classifier
2025-10-22 11:30:02,964:INFO:Total runtime is 2.97403998374939 minutes
2025-10-22 11:30:02,967:INFO:SubProcess create_model() called ==================================
2025-10-22 11:30:02,969:INFO:Initializing create_model()
2025-10-22 11:30:02,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:30:02,969:INFO:Checking exceptions
2025-10-22 11:30:02,969:INFO:Importing libraries
2025-10-22 11:30:02,969:INFO:Copying training dataset
2025-10-22 11:30:03,383:INFO:Defining folds
2025-10-22 11:30:03,383:INFO:Declaring metric variables
2025-10-22 11:30:03,386:INFO:Importing untrained model
2025-10-22 11:30:03,390:INFO:Random Forest Classifier Imported successfully
2025-10-22 11:30:03,399:INFO:Starting cross validation
2025-10-22 11:30:03,403:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:31:08,104:INFO:Calculating mean and std
2025-10-22 11:31:08,105:INFO:Creating metrics dataframe
2025-10-22 11:31:08,107:INFO:Uploading results into container
2025-10-22 11:31:08,107:INFO:Uploading model into container now
2025-10-22 11:31:08,108:INFO:_master_model_container: 7
2025-10-22 11:31:08,108:INFO:_display_container: 2
2025-10-22 11:31:08,108:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-22 11:31:08,108:INFO:create_model() successfully completed......................................
2025-10-22 11:31:08,292:INFO:SubProcess create_model() end ==================================
2025-10-22 11:31:08,292:INFO:Creating metrics dataframe
2025-10-22 11:31:08,299:INFO:Initializing Quadratic Discriminant Analysis
2025-10-22 11:31:08,300:INFO:Total runtime is 4.062969378630321 minutes
2025-10-22 11:31:08,305:INFO:SubProcess create_model() called ==================================
2025-10-22 11:31:08,306:INFO:Initializing create_model()
2025-10-22 11:31:08,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:31:08,306:INFO:Checking exceptions
2025-10-22 11:31:08,306:INFO:Importing libraries
2025-10-22 11:31:08,307:INFO:Copying training dataset
2025-10-22 11:31:08,699:INFO:Defining folds
2025-10-22 11:31:08,699:INFO:Declaring metric variables
2025-10-22 11:31:08,702:INFO:Importing untrained model
2025-10-22 11:31:08,706:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-22 11:31:08,713:INFO:Starting cross validation
2025-10-22 11:31:08,717:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:31:11,945:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 11:31:15,347:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 11:31:18,763:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 11:31:22,192:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 11:31:25,592:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 11:31:26,045:INFO:Calculating mean and std
2025-10-22 11:31:26,046:INFO:Creating metrics dataframe
2025-10-22 11:31:26,047:INFO:Uploading results into container
2025-10-22 11:31:26,047:INFO:Uploading model into container now
2025-10-22 11:31:26,048:INFO:_master_model_container: 8
2025-10-22 11:31:26,048:INFO:_display_container: 2
2025-10-22 11:31:26,048:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-22 11:31:26,048:INFO:create_model() successfully completed......................................
2025-10-22 11:31:26,227:INFO:SubProcess create_model() end ==================================
2025-10-22 11:31:26,227:INFO:Creating metrics dataframe
2025-10-22 11:31:26,236:INFO:Initializing Ada Boost Classifier
2025-10-22 11:31:26,236:INFO:Total runtime is 4.361894659201305 minutes
2025-10-22 11:31:26,238:INFO:SubProcess create_model() called ==================================
2025-10-22 11:31:26,239:INFO:Initializing create_model()
2025-10-22 11:31:26,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:31:26,239:INFO:Checking exceptions
2025-10-22 11:31:26,240:INFO:Importing libraries
2025-10-22 11:31:26,240:INFO:Copying training dataset
2025-10-22 11:31:26,613:INFO:Defining folds
2025-10-22 11:31:26,614:INFO:Declaring metric variables
2025-10-22 11:31:26,616:INFO:Importing untrained model
2025-10-22 11:31:26,622:INFO:Ada Boost Classifier Imported successfully
2025-10-22 11:31:26,627:INFO:Starting cross validation
2025-10-22 11:31:26,631:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:31:29,469:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 11:31:36,015:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 11:31:42,677:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 11:31:49,472:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 11:31:56,246:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 11:32:00,234:INFO:Calculating mean and std
2025-10-22 11:32:00,234:INFO:Creating metrics dataframe
2025-10-22 11:32:00,236:INFO:Uploading results into container
2025-10-22 11:32:00,237:INFO:Uploading model into container now
2025-10-22 11:32:00,238:INFO:_master_model_container: 9
2025-10-22 11:32:00,238:INFO:_display_container: 2
2025-10-22 11:32:00,238:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-22 11:32:00,238:INFO:create_model() successfully completed......................................
2025-10-22 11:32:00,417:INFO:SubProcess create_model() end ==================================
2025-10-22 11:32:00,417:INFO:Creating metrics dataframe
2025-10-22 11:32:00,424:INFO:Initializing Gradient Boosting Classifier
2025-10-22 11:32:00,425:INFO:Total runtime is 4.931726551055909 minutes
2025-10-22 11:32:00,431:INFO:SubProcess create_model() called ==================================
2025-10-22 11:32:00,431:INFO:Initializing create_model()
2025-10-22 11:32:00,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:32:00,432:INFO:Checking exceptions
2025-10-22 11:32:00,432:INFO:Importing libraries
2025-10-22 11:32:00,432:INFO:Copying training dataset
2025-10-22 11:32:00,805:INFO:Defining folds
2025-10-22 11:32:00,805:INFO:Declaring metric variables
2025-10-22 11:32:00,810:INFO:Importing untrained model
2025-10-22 11:32:00,814:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 11:32:00,822:INFO:Starting cross validation
2025-10-22 11:32:00,828:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:33:10,376:INFO:Calculating mean and std
2025-10-22 11:33:10,378:INFO:Creating metrics dataframe
2025-10-22 11:33:10,380:INFO:Uploading results into container
2025-10-22 11:33:10,380:INFO:Uploading model into container now
2025-10-22 11:33:10,381:INFO:_master_model_container: 10
2025-10-22 11:33:10,381:INFO:_display_container: 2
2025-10-22 11:33:10,381:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 11:33:10,382:INFO:create_model() successfully completed......................................
2025-10-22 11:33:10,607:INFO:SubProcess create_model() end ==================================
2025-10-22 11:33:10,607:INFO:Creating metrics dataframe
2025-10-22 11:33:10,616:INFO:Initializing Linear Discriminant Analysis
2025-10-22 11:33:10,616:INFO:Total runtime is 6.101563147703807 minutes
2025-10-22 11:33:10,619:INFO:SubProcess create_model() called ==================================
2025-10-22 11:33:10,621:INFO:Initializing create_model()
2025-10-22 11:33:10,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:33:10,621:INFO:Checking exceptions
2025-10-22 11:33:10,622:INFO:Importing libraries
2025-10-22 11:33:10,622:INFO:Copying training dataset
2025-10-22 11:33:11,023:INFO:Defining folds
2025-10-22 11:33:11,024:INFO:Declaring metric variables
2025-10-22 11:33:11,029:INFO:Importing untrained model
2025-10-22 11:33:11,032:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 11:33:11,037:INFO:Starting cross validation
2025-10-22 11:33:11,042:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:33:30,248:INFO:Calculating mean and std
2025-10-22 11:33:30,249:INFO:Creating metrics dataframe
2025-10-22 11:33:30,251:INFO:Uploading results into container
2025-10-22 11:33:30,251:INFO:Uploading model into container now
2025-10-22 11:33:30,251:INFO:_master_model_container: 11
2025-10-22 11:33:30,251:INFO:_display_container: 2
2025-10-22 11:33:30,252:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 11:33:30,252:INFO:create_model() successfully completed......................................
2025-10-22 11:33:30,434:INFO:SubProcess create_model() end ==================================
2025-10-22 11:33:30,434:INFO:Creating metrics dataframe
2025-10-22 11:33:30,442:INFO:Initializing Extra Trees Classifier
2025-10-22 11:33:30,442:INFO:Total runtime is 6.431997962792715 minutes
2025-10-22 11:33:30,445:INFO:SubProcess create_model() called ==================================
2025-10-22 11:33:30,446:INFO:Initializing create_model()
2025-10-22 11:33:30,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:33:30,446:INFO:Checking exceptions
2025-10-22 11:33:30,446:INFO:Importing libraries
2025-10-22 11:33:30,447:INFO:Copying training dataset
2025-10-22 11:33:30,857:INFO:Defining folds
2025-10-22 11:33:30,857:INFO:Declaring metric variables
2025-10-22 11:33:30,864:INFO:Importing untrained model
2025-10-22 11:33:30,869:INFO:Extra Trees Classifier Imported successfully
2025-10-22 11:33:30,880:INFO:Starting cross validation
2025-10-22 11:33:30,886:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:34:44,736:INFO:Calculating mean and std
2025-10-22 11:34:44,737:INFO:Creating metrics dataframe
2025-10-22 11:34:44,739:INFO:Uploading results into container
2025-10-22 11:34:44,740:INFO:Uploading model into container now
2025-10-22 11:34:44,740:INFO:_master_model_container: 12
2025-10-22 11:34:44,740:INFO:_display_container: 2
2025-10-22 11:34:44,740:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-22 11:34:44,740:INFO:create_model() successfully completed......................................
2025-10-22 11:34:44,926:INFO:SubProcess create_model() end ==================================
2025-10-22 11:34:44,926:INFO:Creating metrics dataframe
2025-10-22 11:34:44,936:INFO:Initializing Extreme Gradient Boosting
2025-10-22 11:34:44,936:INFO:Total runtime is 7.67356839577357 minutes
2025-10-22 11:34:44,941:INFO:SubProcess create_model() called ==================================
2025-10-22 11:34:44,942:INFO:Initializing create_model()
2025-10-22 11:34:44,942:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=xgboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:34:44,943:INFO:Checking exceptions
2025-10-22 11:34:44,943:INFO:Importing libraries
2025-10-22 11:34:44,943:INFO:Copying training dataset
2025-10-22 11:34:45,326:INFO:Defining folds
2025-10-22 11:34:45,326:INFO:Declaring metric variables
2025-10-22 11:34:45,331:INFO:Importing untrained model
2025-10-22 11:34:45,336:INFO:Extreme Gradient Boosting Imported successfully
2025-10-22 11:34:45,340:INFO:Starting cross validation
2025-10-22 11:34:45,345:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:35:15,969:INFO:Calculating mean and std
2025-10-22 11:35:15,969:INFO:Creating metrics dataframe
2025-10-22 11:35:15,971:INFO:Uploading results into container
2025-10-22 11:35:15,973:INFO:Uploading model into container now
2025-10-22 11:35:15,973:INFO:_master_model_container: 13
2025-10-22 11:35:15,973:INFO:_display_container: 2
2025-10-22 11:35:15,974:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-10-22 11:35:15,974:INFO:create_model() successfully completed......................................
2025-10-22 11:35:16,191:INFO:SubProcess create_model() end ==================================
2025-10-22 11:35:16,191:INFO:Creating metrics dataframe
2025-10-22 11:35:16,201:INFO:Initializing Light Gradient Boosting Machine
2025-10-22 11:35:16,201:INFO:Total runtime is 8.194644403457641 minutes
2025-10-22 11:35:16,204:INFO:SubProcess create_model() called ==================================
2025-10-22 11:35:16,206:INFO:Initializing create_model()
2025-10-22 11:35:16,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:35:16,206:INFO:Checking exceptions
2025-10-22 11:35:16,206:INFO:Importing libraries
2025-10-22 11:35:16,207:INFO:Copying training dataset
2025-10-22 11:35:16,626:INFO:Defining folds
2025-10-22 11:35:16,626:INFO:Declaring metric variables
2025-10-22 11:35:16,629:INFO:Importing untrained model
2025-10-22 11:35:16,634:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-22 11:35:16,640:INFO:Starting cross validation
2025-10-22 11:35:16,644:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:35:19,709:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 11:35:19,714:INFO:[LightGBM] [Info] Number of positive: 14883, number of negative: 29918
2025-10-22 11:35:19,742:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008659 seconds.
2025-10-22 11:35:19,742:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 11:35:19,742:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 11:35:19,743:INFO:[LightGBM] [Info] Total Bins 1436
2025-10-22 11:35:19,745:INFO:[LightGBM] [Info] Number of data points in the train set: 44801, number of used features: 95
2025-10-22 11:35:19,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332202 -> initscore=-0.698241
2025-10-22 11:35:19,749:INFO:[LightGBM] [Info] Start training from score -0.698241
2025-10-22 11:35:23,601:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 11:35:23,604:INFO:[LightGBM] [Info] Number of positive: 15015, number of negative: 29786
2025-10-22 11:35:23,629:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009638 seconds.
2025-10-22 11:35:23,629:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 11:35:23,629:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 11:35:23,630:INFO:[LightGBM] [Info] Total Bins 1437
2025-10-22 11:35:23,630:INFO:[LightGBM] [Info] Number of data points in the train set: 44801, number of used features: 95
2025-10-22 11:35:23,631:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.335149 -> initscore=-0.684989
2025-10-22 11:35:23,631:INFO:[LightGBM] [Info] Start training from score -0.684989
2025-10-22 11:35:27,509:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 11:35:27,511:INFO:[LightGBM] [Info] Number of positive: 14903, number of negative: 29899
2025-10-22 11:35:27,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010415 seconds.
2025-10-22 11:35:27,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 11:35:27,537:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 11:35:27,537:INFO:[LightGBM] [Info] Total Bins 1437
2025-10-22 11:35:27,537:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 95
2025-10-22 11:35:27,538:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332641 -> initscore=-0.696263
2025-10-22 11:35:27,538:INFO:[LightGBM] [Info] Start training from score -0.696263
2025-10-22 11:35:31,382:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 11:35:31,385:INFO:[LightGBM] [Info] Number of positive: 14818, number of negative: 29984
2025-10-22 11:35:31,410:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009948 seconds.
2025-10-22 11:35:31,410:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 11:35:31,410:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 11:35:31,410:INFO:[LightGBM] [Info] Total Bins 1438
2025-10-22 11:35:31,410:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 95
2025-10-22 11:35:31,410:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.330744 -> initscore=-0.704821
2025-10-22 11:35:31,411:INFO:[LightGBM] [Info] Start training from score -0.704821
2025-10-22 11:35:35,296:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 11:35:35,299:INFO:[LightGBM] [Info] Number of positive: 14897, number of negative: 29905
2025-10-22 11:35:35,324:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010177 seconds.
2025-10-22 11:35:35,324:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 11:35:35,324:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 11:35:35,325:INFO:[LightGBM] [Info] Total Bins 1438
2025-10-22 11:35:35,325:INFO:[LightGBM] [Info] Number of data points in the train set: 44802, number of used features: 95
2025-10-22 11:35:35,325:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332507 -> initscore=-0.696866
2025-10-22 11:35:35,325:INFO:[LightGBM] [Info] Start training from score -0.696866
2025-10-22 11:35:36,318:INFO:Calculating mean and std
2025-10-22 11:35:36,319:INFO:Creating metrics dataframe
2025-10-22 11:35:36,321:INFO:Uploading results into container
2025-10-22 11:35:36,322:INFO:Uploading model into container now
2025-10-22 11:35:36,322:INFO:_master_model_container: 14
2025-10-22 11:35:36,322:INFO:_display_container: 2
2025-10-22 11:35:36,323:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-22 11:35:36,323:INFO:create_model() successfully completed......................................
2025-10-22 11:35:36,505:INFO:SubProcess create_model() end ==================================
2025-10-22 11:35:36,506:INFO:Creating metrics dataframe
2025-10-22 11:35:36,514:INFO:Initializing CatBoost Classifier
2025-10-22 11:35:36,515:INFO:Total runtime is 8.533221081892648 minutes
2025-10-22 11:35:36,519:INFO:SubProcess create_model() called ==================================
2025-10-22 11:35:36,519:INFO:Initializing create_model()
2025-10-22 11:35:36,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:35:36,520:INFO:Checking exceptions
2025-10-22 11:35:36,520:INFO:Importing libraries
2025-10-22 11:35:36,520:INFO:Copying training dataset
2025-10-22 11:35:36,885:INFO:Defining folds
2025-10-22 11:35:36,885:INFO:Declaring metric variables
2025-10-22 11:35:36,890:INFO:Importing untrained model
2025-10-22 11:35:36,892:INFO:CatBoost Classifier Imported successfully
2025-10-22 11:35:36,899:INFO:Starting cross validation
2025-10-22 11:35:36,905:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:37:53,052:INFO:Calculating mean and std
2025-10-22 11:37:53,053:INFO:Creating metrics dataframe
2025-10-22 11:37:53,054:INFO:Uploading results into container
2025-10-22 11:37:53,055:INFO:Uploading model into container now
2025-10-22 11:37:53,056:INFO:_master_model_container: 15
2025-10-22 11:37:53,056:INFO:_display_container: 2
2025-10-22 11:37:53,056:INFO:<catboost.core.CatBoostClassifier object at 0x000001E20C511C90>
2025-10-22 11:37:53,056:INFO:create_model() successfully completed......................................
2025-10-22 11:37:53,282:INFO:SubProcess create_model() end ==================================
2025-10-22 11:37:53,283:INFO:Creating metrics dataframe
2025-10-22 11:37:53,293:INFO:Initializing Dummy Classifier
2025-10-22 11:37:53,294:INFO:Total runtime is 10.812873895963032 minutes
2025-10-22 11:37:53,297:INFO:SubProcess create_model() called ==================================
2025-10-22 11:37:53,298:INFO:Initializing create_model()
2025-10-22 11:37:53,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E210A16ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:37:53,298:INFO:Checking exceptions
2025-10-22 11:37:53,298:INFO:Importing libraries
2025-10-22 11:37:53,299:INFO:Copying training dataset
2025-10-22 11:37:53,748:INFO:Defining folds
2025-10-22 11:37:53,748:INFO:Declaring metric variables
2025-10-22 11:37:53,753:INFO:Importing untrained model
2025-10-22 11:37:53,760:INFO:Dummy Classifier Imported successfully
2025-10-22 11:37:53,768:INFO:Starting cross validation
2025-10-22 11:37:53,772:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:37:57,679:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:38:01,669:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:38:05,728:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:38:08,879:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:38:12,054:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:38:12,069:INFO:Calculating mean and std
2025-10-22 11:38:12,070:INFO:Creating metrics dataframe
2025-10-22 11:38:12,072:INFO:Uploading results into container
2025-10-22 11:38:12,073:INFO:Uploading model into container now
2025-10-22 11:38:12,073:INFO:_master_model_container: 16
2025-10-22 11:38:12,073:INFO:_display_container: 2
2025-10-22 11:38:12,074:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-22 11:38:12,074:INFO:create_model() successfully completed......................................
2025-10-22 11:38:12,260:INFO:SubProcess create_model() end ==================================
2025-10-22 11:38:12,260:INFO:Creating metrics dataframe
2025-10-22 11:38:12,269:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-22 11:38:12,279:INFO:Initializing create_model()
2025-10-22 11:38:12,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:38:12,279:INFO:Checking exceptions
2025-10-22 11:38:12,282:INFO:Importing libraries
2025-10-22 11:38:12,282:INFO:Copying training dataset
2025-10-22 11:38:12,790:INFO:Defining folds
2025-10-22 11:38:12,790:INFO:Declaring metric variables
2025-10-22 11:38:12,790:INFO:Importing untrained model
2025-10-22 11:38:12,792:INFO:Declaring custom model
2025-10-22 11:38:12,793:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 11:38:12,798:INFO:Cross validation set to False
2025-10-22 11:38:12,798:INFO:Fitting Model
2025-10-22 11:38:32,789:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 11:38:32,789:INFO:create_model() successfully completed......................................
2025-10-22 11:38:32,986:INFO:Initializing create_model()
2025-10-22 11:38:32,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:38:32,986:INFO:Checking exceptions
2025-10-22 11:38:32,988:INFO:Importing libraries
2025-10-22 11:38:32,988:INFO:Copying training dataset
2025-10-22 11:38:33,434:INFO:Defining folds
2025-10-22 11:38:33,434:INFO:Declaring metric variables
2025-10-22 11:38:33,435:INFO:Importing untrained model
2025-10-22 11:38:33,435:INFO:Declaring custom model
2025-10-22 11:38:33,435:INFO:Ridge Classifier Imported successfully
2025-10-22 11:38:33,438:INFO:Cross validation set to False
2025-10-22 11:38:33,438:INFO:Fitting Model
2025-10-22 11:38:37,734:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 11:38:37,734:INFO:create_model() successfully completed......................................
2025-10-22 11:38:37,946:INFO:Initializing create_model()
2025-10-22 11:38:37,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:38:37,946:INFO:Checking exceptions
2025-10-22 11:38:37,949:INFO:Importing libraries
2025-10-22 11:38:37,949:INFO:Copying training dataset
2025-10-22 11:38:38,348:INFO:Defining folds
2025-10-22 11:38:38,348:INFO:Declaring metric variables
2025-10-22 11:38:38,348:INFO:Importing untrained model
2025-10-22 11:38:38,349:INFO:Declaring custom model
2025-10-22 11:38:38,349:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 11:38:38,352:INFO:Cross validation set to False
2025-10-22 11:38:38,352:INFO:Fitting Model
2025-10-22 11:38:42,990:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 11:38:42,990:INFO:create_model() successfully completed......................................
2025-10-22 11:38:43,218:INFO:_master_model_container: 16
2025-10-22 11:38:43,219:INFO:_display_container: 2
2025-10-22 11:38:43,220:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2025-10-22 11:38:43,220:INFO:compare_models() successfully completed......................................
2025-10-22 11:38:43,223:INFO:Initializing tune_model()
2025-10-22 11:38:43,223:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E27FEC4D90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-22 11:38:43,223:INFO:Checking exceptions
2025-10-22 11:38:43,385:INFO:Copying training dataset
2025-10-22 11:38:43,630:INFO:Checking base model
2025-10-22 11:38:43,630:INFO:Base model : Gradient Boosting Classifier
2025-10-22 11:38:43,634:INFO:Declaring metric variables
2025-10-22 11:38:43,636:INFO:Defining Hyperparameters
2025-10-22 11:38:43,815:INFO:Tuning with n_jobs=1
2025-10-22 11:38:43,815:INFO:Initializing RandomizedSearchCV
2025-10-22 11:40:02,808:INFO:PyCaret ClassificationExperiment
2025-10-22 11:40:02,809:INFO:Logging name: clf-default-name
2025-10-22 11:40:02,809:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-22 11:40:02,809:INFO:version 3.3.2
2025-10-22 11:40:02,809:INFO:Initializing setup()
2025-10-22 11:40:02,809:INFO:self.USI: e03c
2025-10-22 11:40:02,809:INFO:self._variable_keys: {'gpu_param', 'y', 'fold_groups_param', 'html_param', 'logging_param', 'is_multiclass', 'USI', 'seed', '_available_plots', 'exp_id', 'y_train', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_test', 'X_train', 'data', 'fix_imbalance', 'fold_generator', 'y_test', 'log_plots_param', 'exp_name_log', 'idx', 'target_param', 'n_jobs_param', 'memory', 'pipeline', '_ml_usecase'}
2025-10-22 11:40:02,809:INFO:Checking environment
2025-10-22 11:40:02,809:INFO:python_version: 3.11.13
2025-10-22 11:40:02,809:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-22 11:40:02,809:INFO:machine: AMD64
2025-10-22 11:40:02,809:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-22 11:40:02,816:INFO:Memory: svmem(total=16856211456, available=4258979840, percent=74.7, used=12597231616, free=4258979840)
2025-10-22 11:40:02,816:INFO:Physical Core: 4
2025-10-22 11:40:02,816:INFO:Logical Core: 8
2025-10-22 11:40:02,816:INFO:Checking libraries
2025-10-22 11:40:02,816:INFO:System:
2025-10-22 11:40:02,816:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-22 11:40:02,816:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-22 11:40:02,816:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-22 11:40:02,816:INFO:PyCaret required dependencies:
2025-10-22 11:40:02,816:INFO:                 pip: 25.2
2025-10-22 11:40:02,816:INFO:          setuptools: 80.9.0
2025-10-22 11:40:02,816:INFO:             pycaret: 3.3.2
2025-10-22 11:40:02,816:INFO:             IPython: 9.6.0
2025-10-22 11:40:02,816:INFO:          ipywidgets: 8.1.7
2025-10-22 11:40:02,816:INFO:                tqdm: 4.67.1
2025-10-22 11:40:02,816:INFO:               numpy: 1.26.4
2025-10-22 11:40:02,816:INFO:              pandas: 2.1.4
2025-10-22 11:40:02,816:INFO:              jinja2: 3.1.6
2025-10-22 11:40:02,816:INFO:               scipy: 1.11.4
2025-10-22 11:40:02,816:INFO:              joblib: 1.3.2
2025-10-22 11:40:02,817:INFO:             sklearn: 1.4.2
2025-10-22 11:40:02,817:INFO:                pyod: 2.0.5
2025-10-22 11:40:02,817:INFO:            imblearn: 0.14.0
2025-10-22 11:40:02,817:INFO:   category_encoders: 2.7.0
2025-10-22 11:40:02,817:INFO:            lightgbm: 4.6.0
2025-10-22 11:40:02,817:INFO:               numba: 0.61.0
2025-10-22 11:40:02,817:INFO:            requests: 2.32.5
2025-10-22 11:40:02,817:INFO:          matplotlib: 3.7.5
2025-10-22 11:40:02,817:INFO:          scikitplot: 0.3.7
2025-10-22 11:40:02,817:INFO:         yellowbrick: 1.5
2025-10-22 11:40:02,817:INFO:              plotly: 5.24.1
2025-10-22 11:40:02,817:INFO:    plotly-resampler: Not installed
2025-10-22 11:40:02,817:INFO:             kaleido: 1.1.0
2025-10-22 11:40:02,817:INFO:           schemdraw: 0.15
2025-10-22 11:40:02,817:INFO:         statsmodels: 0.14.5
2025-10-22 11:40:02,817:INFO:              sktime: 0.26.0
2025-10-22 11:40:02,817:INFO:               tbats: 1.1.3
2025-10-22 11:40:02,817:INFO:            pmdarima: 2.0.4
2025-10-22 11:40:02,817:INFO:              psutil: 7.1.1
2025-10-22 11:40:02,817:INFO:          markupsafe: 3.0.3
2025-10-22 11:40:02,817:INFO:             pickle5: Not installed
2025-10-22 11:40:02,817:INFO:         cloudpickle: 3.1.1
2025-10-22 11:40:02,817:INFO:         deprecation: 2.1.0
2025-10-22 11:40:02,817:INFO:              xxhash: 3.6.0
2025-10-22 11:40:02,817:INFO:           wurlitzer: Not installed
2025-10-22 11:40:02,817:INFO:PyCaret optional dependencies:
2025-10-22 11:40:02,818:INFO:                shap: 0.44.1
2025-10-22 11:40:02,818:INFO:           interpret: 0.7.3
2025-10-22 11:40:02,818:INFO:                umap: 0.5.7
2025-10-22 11:40:02,818:INFO:     ydata_profiling: 4.17.0
2025-10-22 11:40:02,818:INFO:  explainerdashboard: 0.5.1
2025-10-22 11:40:02,818:INFO:             autoviz: Not installed
2025-10-22 11:40:02,818:INFO:           fairlearn: 0.7.0
2025-10-22 11:40:02,818:INFO:          deepchecks: Not installed
2025-10-22 11:40:02,818:INFO:             xgboost: 3.1.0
2025-10-22 11:40:02,818:INFO:            catboost: 1.2.8
2025-10-22 11:40:02,818:INFO:              kmodes: 0.12.2
2025-10-22 11:40:02,818:INFO:             mlxtend: 0.23.4
2025-10-22 11:40:02,818:INFO:       statsforecast: 1.5.0
2025-10-22 11:40:02,818:INFO:        tune_sklearn: Not installed
2025-10-22 11:40:02,818:INFO:                 ray: Not installed
2025-10-22 11:40:02,818:INFO:            hyperopt: 0.2.7
2025-10-22 11:40:02,818:INFO:              optuna: 4.5.0
2025-10-22 11:40:02,818:INFO:               skopt: 0.10.2
2025-10-22 11:40:02,818:INFO:              mlflow: 3.5.0
2025-10-22 11:40:02,818:INFO:              gradio: 5.49.1
2025-10-22 11:40:02,818:INFO:             fastapi: 0.119.1
2025-10-22 11:40:02,818:INFO:             uvicorn: 0.38.0
2025-10-22 11:40:02,819:INFO:              m2cgen: 0.10.0
2025-10-22 11:40:02,819:INFO:           evidently: 0.4.40
2025-10-22 11:40:02,819:INFO:               fugue: 0.8.7
2025-10-22 11:40:02,819:INFO:           streamlit: Not installed
2025-10-22 11:40:02,819:INFO:             prophet: Not installed
2025-10-22 11:40:02,819:INFO:None
2025-10-22 11:40:02,819:INFO:Set up data.
2025-10-22 11:40:03,103:INFO:Set up folding strategy.
2025-10-22 11:40:03,394:INFO:Set up train/test split.
2025-10-22 11:40:03,718:INFO:Set up index.
2025-10-22 11:40:03,740:INFO:Assigning column types.
2025-10-22 11:40:04,101:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-22 11:40:04,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-22 11:40:04,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 11:40:04,168:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:40:04,171:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:40:04,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-22 11:40:04,212:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 11:40:04,240:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:40:04,242:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:40:04,243:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-22 11:40:04,279:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 11:40:04,302:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:40:04,304:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:40:04,340:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 11:40:04,368:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:40:04,370:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:40:04,370:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-22 11:40:04,429:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:40:04,431:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:40:04,490:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:40:04,493:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:40:04,494:INFO:Preparing preprocessing pipeline...
2025-10-22 11:40:04,550:INFO:Set up simple imputation.
2025-10-22 11:40:04,795:INFO:Set up encoding of ordinal features.
2025-10-22 11:40:04,920:INFO:Set up encoding of categorical features.
2025-10-22 11:40:04,928:INFO:Set up removing multicollinearity.
2025-10-22 11:40:04,929:INFO:Set up imbalanced handling.
2025-10-22 11:40:08,404:INFO:Finished creating preprocessing pipeline.
2025-10-22 11:40:08,421:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-10-22 11:40:08,421:INFO:Creating final display dataframe.
2025-10-22 11:40:15,570:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 28)
4        Transformed data shape       (98748, 96)
5   Transformed train set shape       (74746, 96)
6    Transformed test set shape       (24002, 96)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation     most_frequent
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20               Fold Generator        GroupKFold
21                  Fold Number                 5
22                     CPU Jobs                 1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              e03c
2025-10-22 11:40:15,626:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:40:15,628:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:40:15,687:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 11:40:15,689:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 11:40:15,690:INFO:setup() successfully completed in 13.27s...............
2025-10-22 11:40:15,691:INFO:Initializing compare_models()
2025-10-22 11:40:15,691:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-22 11:40:15,691:INFO:Checking exceptions
2025-10-22 11:40:15,937:INFO:Preparing display monitor
2025-10-22 11:40:15,960:INFO:Initializing Logistic Regression
2025-10-22 11:40:15,960:INFO:Total runtime is 0.0 minutes
2025-10-22 11:40:15,965:INFO:SubProcess create_model() called ==================================
2025-10-22 11:40:15,966:INFO:Initializing create_model()
2025-10-22 11:40:15,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:40:15,967:INFO:Checking exceptions
2025-10-22 11:40:15,967:INFO:Importing libraries
2025-10-22 11:40:15,967:INFO:Copying training dataset
2025-10-22 11:40:16,400:INFO:Defining folds
2025-10-22 11:40:16,400:INFO:Declaring metric variables
2025-10-22 11:40:16,403:INFO:Importing untrained model
2025-10-22 11:40:16,406:INFO:Logistic Regression Imported successfully
2025-10-22 11:40:16,412:INFO:Starting cross validation
2025-10-22 11:40:16,421:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:40:29,160:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 11:40:42,028:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 11:40:57,306:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 11:41:11,778:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 11:41:24,681:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 11:41:25,077:INFO:Calculating mean and std
2025-10-22 11:41:25,078:INFO:Creating metrics dataframe
2025-10-22 11:41:25,080:INFO:Uploading results into container
2025-10-22 11:41:25,082:INFO:Uploading model into container now
2025-10-22 11:41:25,082:INFO:_master_model_container: 1
2025-10-22 11:41:25,082:INFO:_display_container: 2
2025-10-22 11:41:25,083:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-22 11:41:25,083:INFO:create_model() successfully completed......................................
2025-10-22 11:41:25,328:INFO:SubProcess create_model() end ==================================
2025-10-22 11:41:25,328:INFO:Creating metrics dataframe
2025-10-22 11:41:25,333:INFO:Initializing K Neighbors Classifier
2025-10-22 11:41:25,333:INFO:Total runtime is 1.1562102675437926 minutes
2025-10-22 11:41:25,337:INFO:SubProcess create_model() called ==================================
2025-10-22 11:41:25,338:INFO:Initializing create_model()
2025-10-22 11:41:25,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:41:25,339:INFO:Checking exceptions
2025-10-22 11:41:25,339:INFO:Importing libraries
2025-10-22 11:41:25,340:INFO:Copying training dataset
2025-10-22 11:41:25,768:INFO:Defining folds
2025-10-22 11:41:25,768:INFO:Declaring metric variables
2025-10-22 11:41:25,775:INFO:Importing untrained model
2025-10-22 11:41:25,779:INFO:K Neighbors Classifier Imported successfully
2025-10-22 11:41:25,788:INFO:Starting cross validation
2025-10-22 11:41:25,797:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:42:03,000:INFO:Calculating mean and std
2025-10-22 11:42:03,002:INFO:Creating metrics dataframe
2025-10-22 11:42:03,006:INFO:Uploading results into container
2025-10-22 11:42:03,007:INFO:Uploading model into container now
2025-10-22 11:42:03,008:INFO:_master_model_container: 2
2025-10-22 11:42:03,008:INFO:_display_container: 2
2025-10-22 11:42:03,008:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-22 11:42:03,008:INFO:create_model() successfully completed......................................
2025-10-22 11:42:03,249:INFO:SubProcess create_model() end ==================================
2025-10-22 11:42:03,249:INFO:Creating metrics dataframe
2025-10-22 11:42:03,255:INFO:Initializing Naive Bayes
2025-10-22 11:42:03,256:INFO:Total runtime is 1.788262093067169 minutes
2025-10-22 11:42:03,259:INFO:SubProcess create_model() called ==================================
2025-10-22 11:42:03,261:INFO:Initializing create_model()
2025-10-22 11:42:03,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:42:03,261:INFO:Checking exceptions
2025-10-22 11:42:03,261:INFO:Importing libraries
2025-10-22 11:42:03,261:INFO:Copying training dataset
2025-10-22 11:42:03,702:INFO:Defining folds
2025-10-22 11:42:03,702:INFO:Declaring metric variables
2025-10-22 11:42:03,706:INFO:Importing untrained model
2025-10-22 11:42:03,710:INFO:Naive Bayes Imported successfully
2025-10-22 11:42:03,718:INFO:Starting cross validation
2025-10-22 11:42:03,727:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:42:24,051:INFO:Calculating mean and std
2025-10-22 11:42:24,052:INFO:Creating metrics dataframe
2025-10-22 11:42:24,054:INFO:Uploading results into container
2025-10-22 11:42:24,055:INFO:Uploading model into container now
2025-10-22 11:42:24,055:INFO:_master_model_container: 3
2025-10-22 11:42:24,055:INFO:_display_container: 2
2025-10-22 11:42:24,055:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-22 11:42:24,056:INFO:create_model() successfully completed......................................
2025-10-22 11:42:24,264:INFO:SubProcess create_model() end ==================================
2025-10-22 11:42:24,264:INFO:Creating metrics dataframe
2025-10-22 11:42:24,269:INFO:Initializing Decision Tree Classifier
2025-10-22 11:42:24,269:INFO:Total runtime is 2.1384711782137553 minutes
2025-10-22 11:42:24,272:INFO:SubProcess create_model() called ==================================
2025-10-22 11:42:24,273:INFO:Initializing create_model()
2025-10-22 11:42:24,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:42:24,274:INFO:Checking exceptions
2025-10-22 11:42:24,274:INFO:Importing libraries
2025-10-22 11:42:24,275:INFO:Copying training dataset
2025-10-22 11:42:24,661:INFO:Defining folds
2025-10-22 11:42:24,661:INFO:Declaring metric variables
2025-10-22 11:42:24,665:INFO:Importing untrained model
2025-10-22 11:42:24,669:INFO:Decision Tree Classifier Imported successfully
2025-10-22 11:42:24,678:INFO:Starting cross validation
2025-10-22 11:42:24,685:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:42:50,968:INFO:Calculating mean and std
2025-10-22 11:42:50,969:INFO:Creating metrics dataframe
2025-10-22 11:42:50,973:INFO:Uploading results into container
2025-10-22 11:42:50,974:INFO:Uploading model into container now
2025-10-22 11:42:50,975:INFO:_master_model_container: 4
2025-10-22 11:42:50,975:INFO:_display_container: 2
2025-10-22 11:42:50,976:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-22 11:42:50,976:INFO:create_model() successfully completed......................................
2025-10-22 11:42:51,186:INFO:SubProcess create_model() end ==================================
2025-10-22 11:42:51,187:INFO:Creating metrics dataframe
2025-10-22 11:42:51,193:INFO:Initializing SVM - Linear Kernel
2025-10-22 11:42:51,194:INFO:Total runtime is 2.5872313658396404 minutes
2025-10-22 11:42:51,198:INFO:SubProcess create_model() called ==================================
2025-10-22 11:42:51,198:INFO:Initializing create_model()
2025-10-22 11:42:51,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:42:51,199:INFO:Checking exceptions
2025-10-22 11:42:51,199:INFO:Importing libraries
2025-10-22 11:42:51,199:INFO:Copying training dataset
2025-10-22 11:42:51,570:INFO:Defining folds
2025-10-22 11:42:51,571:INFO:Declaring metric variables
2025-10-22 11:42:51,576:INFO:Importing untrained model
2025-10-22 11:42:51,580:INFO:SVM - Linear Kernel Imported successfully
2025-10-22 11:42:51,585:INFO:Starting cross validation
2025-10-22 11:42:51,594:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:43:01,643:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:43:25,627:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 11:43:46,025:INFO:Calculating mean and std
2025-10-22 11:43:46,027:INFO:Creating metrics dataframe
2025-10-22 11:43:46,030:INFO:Uploading results into container
2025-10-22 11:43:46,030:INFO:Uploading model into container now
2025-10-22 11:43:46,030:INFO:_master_model_container: 5
2025-10-22 11:43:46,030:INFO:_display_container: 2
2025-10-22 11:43:46,031:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-22 11:43:46,031:INFO:create_model() successfully completed......................................
2025-10-22 11:43:46,252:INFO:SubProcess create_model() end ==================================
2025-10-22 11:43:46,252:INFO:Creating metrics dataframe
2025-10-22 11:43:46,259:INFO:Initializing Ridge Classifier
2025-10-22 11:43:46,260:INFO:Total runtime is 3.504991046587626 minutes
2025-10-22 11:43:46,266:INFO:SubProcess create_model() called ==================================
2025-10-22 11:43:46,267:INFO:Initializing create_model()
2025-10-22 11:43:46,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:43:46,267:INFO:Checking exceptions
2025-10-22 11:43:46,267:INFO:Importing libraries
2025-10-22 11:43:46,267:INFO:Copying training dataset
2025-10-22 11:43:46,690:INFO:Defining folds
2025-10-22 11:43:46,690:INFO:Declaring metric variables
2025-10-22 11:43:46,695:INFO:Importing untrained model
2025-10-22 11:43:46,699:INFO:Ridge Classifier Imported successfully
2025-10-22 11:43:46,706:INFO:Starting cross validation
2025-10-22 11:43:46,714:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:44:08,413:INFO:Calculating mean and std
2025-10-22 11:44:08,414:INFO:Creating metrics dataframe
2025-10-22 11:44:08,418:INFO:Uploading results into container
2025-10-22 11:44:08,419:INFO:Uploading model into container now
2025-10-22 11:44:08,419:INFO:_master_model_container: 6
2025-10-22 11:44:08,419:INFO:_display_container: 2
2025-10-22 11:44:08,420:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 11:44:08,420:INFO:create_model() successfully completed......................................
2025-10-22 11:44:08,650:INFO:SubProcess create_model() end ==================================
2025-10-22 11:44:08,650:INFO:Creating metrics dataframe
2025-10-22 11:44:08,656:INFO:Initializing Random Forest Classifier
2025-10-22 11:44:08,656:INFO:Total runtime is 3.8782532294591268 minutes
2025-10-22 11:44:08,660:INFO:SubProcess create_model() called ==================================
2025-10-22 11:44:08,663:INFO:Initializing create_model()
2025-10-22 11:44:08,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:44:08,663:INFO:Checking exceptions
2025-10-22 11:44:08,663:INFO:Importing libraries
2025-10-22 11:44:08,663:INFO:Copying training dataset
2025-10-22 11:44:09,078:INFO:Defining folds
2025-10-22 11:44:09,079:INFO:Declaring metric variables
2025-10-22 11:44:09,084:INFO:Importing untrained model
2025-10-22 11:44:09,087:INFO:Random Forest Classifier Imported successfully
2025-10-22 11:44:09,094:INFO:Starting cross validation
2025-10-22 11:44:09,103:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:45:31,916:INFO:Calculating mean and std
2025-10-22 11:45:31,917:INFO:Creating metrics dataframe
2025-10-22 11:45:31,920:INFO:Uploading results into container
2025-10-22 11:45:31,921:INFO:Uploading model into container now
2025-10-22 11:45:31,921:INFO:_master_model_container: 7
2025-10-22 11:45:31,921:INFO:_display_container: 2
2025-10-22 11:45:31,922:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-22 11:45:31,922:INFO:create_model() successfully completed......................................
2025-10-22 11:45:32,145:INFO:SubProcess create_model() end ==================================
2025-10-22 11:45:32,145:INFO:Creating metrics dataframe
2025-10-22 11:45:32,152:INFO:Initializing Quadratic Discriminant Analysis
2025-10-22 11:45:32,153:INFO:Total runtime is 5.269874282677968 minutes
2025-10-22 11:45:32,157:INFO:SubProcess create_model() called ==================================
2025-10-22 11:45:32,159:INFO:Initializing create_model()
2025-10-22 11:45:32,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:45:32,159:INFO:Checking exceptions
2025-10-22 11:45:32,159:INFO:Importing libraries
2025-10-22 11:45:32,159:INFO:Copying training dataset
2025-10-22 11:45:32,559:INFO:Defining folds
2025-10-22 11:45:32,559:INFO:Declaring metric variables
2025-10-22 11:45:32,564:INFO:Importing untrained model
2025-10-22 11:45:32,569:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-22 11:45:32,578:INFO:Starting cross validation
2025-10-22 11:45:32,586:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:45:36,751:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 11:45:41,408:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 11:45:45,996:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 11:45:50,784:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 11:45:55,665:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 11:45:56,586:INFO:Calculating mean and std
2025-10-22 11:45:56,587:INFO:Creating metrics dataframe
2025-10-22 11:45:56,589:INFO:Uploading results into container
2025-10-22 11:45:56,590:INFO:Uploading model into container now
2025-10-22 11:45:56,591:INFO:_master_model_container: 8
2025-10-22 11:45:56,591:INFO:_display_container: 2
2025-10-22 11:45:56,591:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-22 11:45:56,592:INFO:create_model() successfully completed......................................
2025-10-22 11:45:56,816:INFO:SubProcess create_model() end ==================================
2025-10-22 11:45:56,817:INFO:Creating metrics dataframe
2025-10-22 11:45:56,824:INFO:Initializing Ada Boost Classifier
2025-10-22 11:45:56,824:INFO:Total runtime is 5.681066743532816 minutes
2025-10-22 11:45:56,827:INFO:SubProcess create_model() called ==================================
2025-10-22 11:45:56,828:INFO:Initializing create_model()
2025-10-22 11:45:56,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:45:56,828:INFO:Checking exceptions
2025-10-22 11:45:56,828:INFO:Importing libraries
2025-10-22 11:45:56,829:INFO:Copying training dataset
2025-10-22 11:45:57,204:INFO:Defining folds
2025-10-22 11:45:57,204:INFO:Declaring metric variables
2025-10-22 11:45:57,208:INFO:Importing untrained model
2025-10-22 11:45:57,212:INFO:Ada Boost Classifier Imported successfully
2025-10-22 11:45:57,218:INFO:Starting cross validation
2025-10-22 11:45:57,227:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:46:01,034:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 11:46:12,078:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 11:46:22,525:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 11:46:33,586:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 11:46:44,352:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 11:46:51,282:INFO:Calculating mean and std
2025-10-22 11:46:51,283:INFO:Creating metrics dataframe
2025-10-22 11:46:51,286:INFO:Uploading results into container
2025-10-22 11:46:51,287:INFO:Uploading model into container now
2025-10-22 11:46:51,288:INFO:_master_model_container: 9
2025-10-22 11:46:51,288:INFO:_display_container: 2
2025-10-22 11:46:51,288:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-22 11:46:51,288:INFO:create_model() successfully completed......................................
2025-10-22 11:46:51,512:INFO:SubProcess create_model() end ==================================
2025-10-22 11:46:51,512:INFO:Creating metrics dataframe
2025-10-22 11:46:51,519:INFO:Initializing Gradient Boosting Classifier
2025-10-22 11:46:51,519:INFO:Total runtime is 6.592650445302327 minutes
2025-10-22 11:46:51,523:INFO:SubProcess create_model() called ==================================
2025-10-22 11:46:51,524:INFO:Initializing create_model()
2025-10-22 11:46:51,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:46:51,524:INFO:Checking exceptions
2025-10-22 11:46:51,524:INFO:Importing libraries
2025-10-22 11:46:51,524:INFO:Copying training dataset
2025-10-22 11:46:51,934:INFO:Defining folds
2025-10-22 11:46:51,934:INFO:Declaring metric variables
2025-10-22 11:46:51,941:INFO:Importing untrained model
2025-10-22 11:46:51,945:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 11:46:51,951:INFO:Starting cross validation
2025-10-22 11:46:51,961:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:49:21,008:INFO:Calculating mean and std
2025-10-22 11:49:21,009:INFO:Creating metrics dataframe
2025-10-22 11:49:21,011:INFO:Uploading results into container
2025-10-22 11:49:21,012:INFO:Uploading model into container now
2025-10-22 11:49:21,012:INFO:_master_model_container: 10
2025-10-22 11:49:21,012:INFO:_display_container: 2
2025-10-22 11:49:21,012:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 11:49:21,012:INFO:create_model() successfully completed......................................
2025-10-22 11:49:21,225:INFO:SubProcess create_model() end ==================================
2025-10-22 11:49:21,226:INFO:Creating metrics dataframe
2025-10-22 11:49:21,233:INFO:Initializing Linear Discriminant Analysis
2025-10-22 11:49:21,234:INFO:Total runtime is 9.087889111042022 minutes
2025-10-22 11:49:21,238:INFO:SubProcess create_model() called ==================================
2025-10-22 11:49:21,240:INFO:Initializing create_model()
2025-10-22 11:49:21,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:49:21,240:INFO:Checking exceptions
2025-10-22 11:49:21,240:INFO:Importing libraries
2025-10-22 11:49:21,240:INFO:Copying training dataset
2025-10-22 11:49:21,607:INFO:Defining folds
2025-10-22 11:49:21,608:INFO:Declaring metric variables
2025-10-22 11:49:21,610:INFO:Importing untrained model
2025-10-22 11:49:21,617:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 11:49:21,622:INFO:Starting cross validation
2025-10-22 11:49:21,634:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:49:46,072:INFO:Calculating mean and std
2025-10-22 11:49:46,072:INFO:Creating metrics dataframe
2025-10-22 11:49:46,075:INFO:Uploading results into container
2025-10-22 11:49:46,076:INFO:Uploading model into container now
2025-10-22 11:49:46,076:INFO:_master_model_container: 11
2025-10-22 11:49:46,076:INFO:_display_container: 2
2025-10-22 11:49:46,081:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 11:49:46,081:INFO:create_model() successfully completed......................................
2025-10-22 11:49:46,293:INFO:SubProcess create_model() end ==================================
2025-10-22 11:49:46,293:INFO:Creating metrics dataframe
2025-10-22 11:49:46,300:INFO:Initializing Extra Trees Classifier
2025-10-22 11:49:46,301:INFO:Total runtime is 9.505673464139303 minutes
2025-10-22 11:49:46,306:INFO:SubProcess create_model() called ==================================
2025-10-22 11:49:46,307:INFO:Initializing create_model()
2025-10-22 11:49:46,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:49:46,307:INFO:Checking exceptions
2025-10-22 11:49:46,307:INFO:Importing libraries
2025-10-22 11:49:46,307:INFO:Copying training dataset
2025-10-22 11:49:46,687:INFO:Defining folds
2025-10-22 11:49:46,688:INFO:Declaring metric variables
2025-10-22 11:49:46,691:INFO:Importing untrained model
2025-10-22 11:49:46,697:INFO:Extra Trees Classifier Imported successfully
2025-10-22 11:49:46,703:INFO:Starting cross validation
2025-10-22 11:49:46,714:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:51:41,497:INFO:Calculating mean and std
2025-10-22 11:51:41,499:INFO:Creating metrics dataframe
2025-10-22 11:51:41,504:INFO:Uploading results into container
2025-10-22 11:51:41,504:INFO:Uploading model into container now
2025-10-22 11:51:41,505:INFO:_master_model_container: 12
2025-10-22 11:51:41,505:INFO:_display_container: 2
2025-10-22 11:51:41,505:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-22 11:51:41,505:INFO:create_model() successfully completed......................................
2025-10-22 11:51:41,727:INFO:SubProcess create_model() end ==================================
2025-10-22 11:51:41,727:INFO:Creating metrics dataframe
2025-10-22 11:51:41,736:INFO:Initializing Extreme Gradient Boosting
2025-10-22 11:51:41,737:INFO:Total runtime is 11.429590900739035 minutes
2025-10-22 11:51:41,741:INFO:SubProcess create_model() called ==================================
2025-10-22 11:51:41,743:INFO:Initializing create_model()
2025-10-22 11:51:41,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=xgboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:51:41,743:INFO:Checking exceptions
2025-10-22 11:51:41,743:INFO:Importing libraries
2025-10-22 11:51:41,743:INFO:Copying training dataset
2025-10-22 11:51:42,130:INFO:Defining folds
2025-10-22 11:51:42,130:INFO:Declaring metric variables
2025-10-22 11:51:42,134:INFO:Importing untrained model
2025-10-22 11:51:42,139:INFO:Extreme Gradient Boosting Imported successfully
2025-10-22 11:51:42,145:INFO:Starting cross validation
2025-10-22 11:51:42,152:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:52:24,565:INFO:Calculating mean and std
2025-10-22 11:52:24,566:INFO:Creating metrics dataframe
2025-10-22 11:52:24,569:INFO:Uploading results into container
2025-10-22 11:52:24,569:INFO:Uploading model into container now
2025-10-22 11:52:24,569:INFO:_master_model_container: 13
2025-10-22 11:52:24,569:INFO:_display_container: 2
2025-10-22 11:52:24,570:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-10-22 11:52:24,570:INFO:create_model() successfully completed......................................
2025-10-22 11:52:24,779:INFO:SubProcess create_model() end ==================================
2025-10-22 11:52:24,779:INFO:Creating metrics dataframe
2025-10-22 11:52:24,788:INFO:Initializing Light Gradient Boosting Machine
2025-10-22 11:52:24,789:INFO:Total runtime is 12.147134915987651 minutes
2025-10-22 11:52:24,794:INFO:SubProcess create_model() called ==================================
2025-10-22 11:52:24,795:INFO:Initializing create_model()
2025-10-22 11:52:24,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:52:24,795:INFO:Checking exceptions
2025-10-22 11:52:24,795:INFO:Importing libraries
2025-10-22 11:52:24,795:INFO:Copying training dataset
2025-10-22 11:52:25,169:INFO:Defining folds
2025-10-22 11:52:25,169:INFO:Declaring metric variables
2025-10-22 11:52:25,173:INFO:Importing untrained model
2025-10-22 11:52:25,177:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-22 11:52:25,183:INFO:Starting cross validation
2025-10-22 11:52:25,192:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 11:52:29,214:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 11:52:29,217:INFO:[LightGBM] [Info] Number of positive: 29918, number of negative: 29918
2025-10-22 11:52:29,300:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036247 seconds.
2025-10-22 11:52:29,300:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 11:52:29,300:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 11:52:29,300:INFO:[LightGBM] [Info] Total Bins 23636
2025-10-22 11:52:29,303:INFO:[LightGBM] [Info] Number of data points in the train set: 59836, number of used features: 95
2025-10-22 11:52:29,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-22 11:52:34,972:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 11:52:34,975:INFO:[LightGBM] [Info] Number of positive: 29786, number of negative: 29786
2025-10-22 11:52:35,057:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039206 seconds.
2025-10-22 11:52:35,057:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 11:52:35,057:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 11:52:35,058:INFO:[LightGBM] [Info] Total Bins 23606
2025-10-22 11:52:35,059:INFO:[LightGBM] [Info] Number of data points in the train set: 59572, number of used features: 95
2025-10-22 11:52:35,059:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-22 11:52:40,638:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 11:52:40,641:INFO:[LightGBM] [Info] Number of positive: 29899, number of negative: 29899
2025-10-22 11:52:40,716:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034862 seconds.
2025-10-22 11:52:40,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 11:52:40,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 11:52:40,716:INFO:[LightGBM] [Info] Total Bins 23821
2025-10-22 11:52:40,718:INFO:[LightGBM] [Info] Number of data points in the train set: 59798, number of used features: 95
2025-10-22 11:52:40,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-22 11:52:46,244:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 11:52:46,247:INFO:[LightGBM] [Info] Number of positive: 29984, number of negative: 29984
2025-10-22 11:52:46,320:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046310 seconds.
2025-10-22 11:52:46,320:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-22 11:52:46,320:INFO:[LightGBM] [Info] Total Bins 23646
2025-10-22 11:52:46,322:INFO:[LightGBM] [Info] Number of data points in the train set: 59968, number of used features: 95
2025-10-22 11:52:46,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-22 11:52:52,142:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 11:52:52,145:INFO:[LightGBM] [Info] Number of positive: 29905, number of negative: 29905
2025-10-22 11:52:52,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031668 seconds.
2025-10-22 11:52:52,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 11:52:52,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 11:52:52,215:INFO:[LightGBM] [Info] Total Bins 23831
2025-10-22 11:52:52,216:INFO:[LightGBM] [Info] Number of data points in the train set: 59810, number of used features: 95
2025-10-22 11:52:52,216:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-22 11:52:53,896:INFO:Calculating mean and std
2025-10-22 11:52:53,897:INFO:Creating metrics dataframe
2025-10-22 11:52:53,901:INFO:Uploading results into container
2025-10-22 11:52:53,902:INFO:Uploading model into container now
2025-10-22 11:52:53,903:INFO:_master_model_container: 14
2025-10-22 11:52:53,903:INFO:_display_container: 2
2025-10-22 11:52:53,904:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-22 11:52:53,905:INFO:create_model() successfully completed......................................
2025-10-22 11:52:54,141:INFO:SubProcess create_model() end ==================================
2025-10-22 11:52:54,141:INFO:Creating metrics dataframe
2025-10-22 11:52:54,150:INFO:Initializing CatBoost Classifier
2025-10-22 11:52:54,150:INFO:Total runtime is 12.636491179466248 minutes
2025-10-22 11:52:54,155:INFO:SubProcess create_model() called ==================================
2025-10-22 11:52:54,156:INFO:Initializing create_model()
2025-10-22 11:52:54,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 11:52:54,156:INFO:Checking exceptions
2025-10-22 11:52:54,157:INFO:Importing libraries
2025-10-22 11:52:54,157:INFO:Copying training dataset
2025-10-22 11:52:54,576:INFO:Defining folds
2025-10-22 11:52:54,577:INFO:Declaring metric variables
2025-10-22 11:52:54,580:INFO:Importing untrained model
2025-10-22 11:52:54,586:INFO:CatBoost Classifier Imported successfully
2025-10-22 11:52:54,594:INFO:Starting cross validation
2025-10-22 11:52:54,601:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 12:01:12,244:INFO:Calculating mean and std
2025-10-22 12:01:12,245:INFO:Creating metrics dataframe
2025-10-22 12:01:12,250:INFO:Uploading results into container
2025-10-22 12:01:12,250:INFO:Uploading model into container now
2025-10-22 12:01:12,251:INFO:_master_model_container: 15
2025-10-22 12:01:12,251:INFO:_display_container: 2
2025-10-22 12:01:12,251:INFO:<catboost.core.CatBoostClassifier object at 0x000001E21506FB10>
2025-10-22 12:01:12,252:INFO:create_model() successfully completed......................................
2025-10-22 12:01:12,497:INFO:SubProcess create_model() end ==================================
2025-10-22 12:01:12,498:INFO:Creating metrics dataframe
2025-10-22 12:01:12,508:INFO:Initializing Dummy Classifier
2025-10-22 12:01:12,509:INFO:Total runtime is 20.942481044928233 minutes
2025-10-22 12:01:12,512:INFO:SubProcess create_model() called ==================================
2025-10-22 12:01:12,514:INFO:Initializing create_model()
2025-10-22 12:01:12,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E230E31F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 12:01:12,514:INFO:Checking exceptions
2025-10-22 12:01:12,514:INFO:Importing libraries
2025-10-22 12:01:12,515:INFO:Copying training dataset
2025-10-22 12:01:12,958:INFO:Defining folds
2025-10-22 12:01:12,959:INFO:Declaring metric variables
2025-10-22 12:01:12,964:INFO:Importing untrained model
2025-10-22 12:01:12,968:INFO:Dummy Classifier Imported successfully
2025-10-22 12:01:12,974:INFO:Starting cross validation
2025-10-22 12:01:12,984:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 12:01:19,144:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 12:01:26,556:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 12:01:34,055:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 12:01:41,408:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 12:01:48,151:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 12:01:48,173:INFO:Calculating mean and std
2025-10-22 12:01:48,174:INFO:Creating metrics dataframe
2025-10-22 12:01:48,177:INFO:Uploading results into container
2025-10-22 12:01:48,179:INFO:Uploading model into container now
2025-10-22 12:01:48,180:INFO:_master_model_container: 16
2025-10-22 12:01:48,180:INFO:_display_container: 2
2025-10-22 12:01:48,180:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-22 12:01:48,180:INFO:create_model() successfully completed......................................
2025-10-22 12:01:48,441:INFO:SubProcess create_model() end ==================================
2025-10-22 12:01:48,441:INFO:Creating metrics dataframe
2025-10-22 12:01:48,453:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-22 12:01:48,464:INFO:Initializing create_model()
2025-10-22 12:01:48,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 12:01:48,465:INFO:Checking exceptions
2025-10-22 12:01:48,469:INFO:Importing libraries
2025-10-22 12:01:48,469:INFO:Copying training dataset
2025-10-22 12:01:48,912:INFO:Defining folds
2025-10-22 12:01:48,913:INFO:Declaring metric variables
2025-10-22 12:01:48,913:INFO:Importing untrained model
2025-10-22 12:01:48,914:INFO:Declaring custom model
2025-10-22 12:01:48,915:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 12:01:48,922:INFO:Cross validation set to False
2025-10-22 12:01:48,922:INFO:Fitting Model
2025-10-22 12:02:35,465:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 12:02:35,465:INFO:create_model() successfully completed......................................
2025-10-22 12:02:35,708:INFO:Initializing create_model()
2025-10-22 12:02:35,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 12:02:35,708:INFO:Checking exceptions
2025-10-22 12:02:35,711:INFO:Importing libraries
2025-10-22 12:02:35,711:INFO:Copying training dataset
2025-10-22 12:02:36,075:INFO:Defining folds
2025-10-22 12:02:36,075:INFO:Declaring metric variables
2025-10-22 12:02:36,075:INFO:Importing untrained model
2025-10-22 12:02:36,075:INFO:Declaring custom model
2025-10-22 12:02:36,076:INFO:Ridge Classifier Imported successfully
2025-10-22 12:02:36,081:INFO:Cross validation set to False
2025-10-22 12:02:36,081:INFO:Fitting Model
2025-10-22 12:02:40,942:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 12:02:40,942:INFO:create_model() successfully completed......................................
2025-10-22 12:02:41,182:INFO:Initializing create_model()
2025-10-22 12:02:41,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 12:02:41,183:INFO:Checking exceptions
2025-10-22 12:02:41,186:INFO:Importing libraries
2025-10-22 12:02:41,186:INFO:Copying training dataset
2025-10-22 12:02:41,550:INFO:Defining folds
2025-10-22 12:02:41,550:INFO:Declaring metric variables
2025-10-22 12:02:41,550:INFO:Importing untrained model
2025-10-22 12:02:41,551:INFO:Declaring custom model
2025-10-22 12:02:41,551:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 12:02:41,557:INFO:Cross validation set to False
2025-10-22 12:02:41,557:INFO:Fitting Model
2025-10-22 12:02:47,168:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 12:02:47,169:INFO:create_model() successfully completed......................................
2025-10-22 12:02:47,402:INFO:_master_model_container: 16
2025-10-22 12:02:47,402:INFO:_display_container: 2
2025-10-22 12:02:47,403:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2025-10-22 12:02:47,403:INFO:compare_models() successfully completed......................................
2025-10-22 12:02:47,405:INFO:Initializing tune_model()
2025-10-22 12:02:47,405:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-22 12:02:47,405:INFO:Checking exceptions
2025-10-22 12:02:47,581:INFO:Copying training dataset
2025-10-22 12:02:47,882:INFO:Checking base model
2025-10-22 12:02:47,882:INFO:Base model : Gradient Boosting Classifier
2025-10-22 12:02:47,885:INFO:Declaring metric variables
2025-10-22 12:02:47,887:INFO:Defining Hyperparameters
2025-10-22 12:02:48,121:INFO:Tuning with n_jobs=1
2025-10-22 12:02:48,121:INFO:Initializing RandomizedSearchCV
2025-10-22 12:14:10,900:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.4}
2025-10-22 12:14:10,901:INFO:Hyperparameter search completed
2025-10-22 12:14:10,901:INFO:SubProcess create_model() called ==================================
2025-10-22 12:14:10,903:INFO:Initializing create_model()
2025-10-22 12:14:10,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26276BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 130, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 1, 'learning_rate': 0.4})
2025-10-22 12:14:10,903:INFO:Checking exceptions
2025-10-22 12:14:10,903:INFO:Importing libraries
2025-10-22 12:14:10,903:INFO:Copying training dataset
2025-10-22 12:14:11,286:INFO:Defining folds
2025-10-22 12:14:11,287:INFO:Declaring metric variables
2025-10-22 12:14:11,290:INFO:Importing untrained model
2025-10-22 12:14:11,290:INFO:Declaring custom model
2025-10-22 12:14:11,296:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 12:14:11,302:INFO:Starting cross validation
2025-10-22 12:14:11,311:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 12:15:07,065:INFO:Calculating mean and std
2025-10-22 12:15:07,067:INFO:Creating metrics dataframe
2025-10-22 12:15:07,072:INFO:Finalizing model
2025-10-22 12:15:21,014:INFO:Uploading results into container
2025-10-22 12:15:21,016:INFO:Uploading model into container now
2025-10-22 12:15:21,016:INFO:_master_model_container: 17
2025-10-22 12:15:21,017:INFO:_display_container: 3
2025-10-22 12:15:21,017:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 12:15:21,017:INFO:create_model() successfully completed......................................
2025-10-22 12:15:21,269:INFO:SubProcess create_model() end ==================================
2025-10-22 12:15:21,270:INFO:choose_better activated
2025-10-22 12:15:21,273:INFO:SubProcess create_model() called ==================================
2025-10-22 12:15:21,275:INFO:Initializing create_model()
2025-10-22 12:15:21,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 12:15:21,275:INFO:Checking exceptions
2025-10-22 12:15:21,276:INFO:Importing libraries
2025-10-22 12:15:21,276:INFO:Copying training dataset
2025-10-22 12:15:21,641:INFO:Defining folds
2025-10-22 12:15:21,641:INFO:Declaring metric variables
2025-10-22 12:15:21,641:INFO:Importing untrained model
2025-10-22 12:15:21,641:INFO:Declaring custom model
2025-10-22 12:15:21,642:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 12:15:21,642:INFO:Starting cross validation
2025-10-22 12:15:21,648:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 12:18:31,718:INFO:Calculating mean and std
2025-10-22 12:18:31,718:INFO:Creating metrics dataframe
2025-10-22 12:18:31,720:INFO:Finalizing model
2025-10-22 12:19:06,774:INFO:Uploading results into container
2025-10-22 12:19:06,775:INFO:Uploading model into container now
2025-10-22 12:19:06,775:INFO:_master_model_container: 18
2025-10-22 12:19:06,775:INFO:_display_container: 4
2025-10-22 12:19:06,776:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 12:19:06,776:INFO:create_model() successfully completed......................................
2025-10-22 12:19:07,011:INFO:SubProcess create_model() end ==================================
2025-10-22 12:19:07,012:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9219
2025-10-22 12:19:07,012:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9208
2025-10-22 12:19:07,013:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-22 12:19:07,013:INFO:choose_better completed
2025-10-22 12:19:07,013:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-22 12:19:07,021:INFO:_master_model_container: 18
2025-10-22 12:19:07,021:INFO:_display_container: 3
2025-10-22 12:19:07,022:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 12:19:07,022:INFO:tune_model() successfully completed......................................
2025-10-22 12:19:07,250:INFO:Initializing tune_model()
2025-10-22 12:19:07,250:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-22 12:19:07,250:INFO:Checking exceptions
2025-10-22 12:19:07,397:INFO:Copying training dataset
2025-10-22 12:19:07,640:INFO:Checking base model
2025-10-22 12:19:07,640:INFO:Base model : Ridge Classifier
2025-10-22 12:19:07,643:INFO:Declaring metric variables
2025-10-22 12:19:07,645:INFO:Defining Hyperparameters
2025-10-22 12:19:07,856:INFO:Tuning with n_jobs=1
2025-10-22 12:19:07,856:INFO:Initializing RandomizedSearchCV
2025-10-22 12:22:19,828:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.21688e-17): result may not be accurate.

2025-10-22 12:22:23,877:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.30614e-17): result may not be accurate.

2025-10-22 12:22:27,673:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.2762e-17): result may not be accurate.

2025-10-22 12:22:31,899:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.26564e-17): result may not be accurate.

2025-10-22 12:22:37,234:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.25029e-17): result may not be accurate.

2025-10-22 12:23:15,628:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.3}
2025-10-22 12:23:15,629:INFO:Hyperparameter search completed
2025-10-22 12:23:15,629:INFO:SubProcess create_model() called ==================================
2025-10-22 12:23:15,631:INFO:Initializing create_model()
2025-10-22 12:23:15,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E27FEAF8D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 7.3})
2025-10-22 12:23:15,631:INFO:Checking exceptions
2025-10-22 12:23:15,632:INFO:Importing libraries
2025-10-22 12:23:15,633:INFO:Copying training dataset
2025-10-22 12:23:16,147:INFO:Defining folds
2025-10-22 12:23:16,147:INFO:Declaring metric variables
2025-10-22 12:23:16,154:INFO:Importing untrained model
2025-10-22 12:23:16,155:INFO:Declaring custom model
2025-10-22 12:23:16,161:INFO:Ridge Classifier Imported successfully
2025-10-22 12:23:16,170:INFO:Starting cross validation
2025-10-22 12:23:16,182:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 12:23:54,703:INFO:Calculating mean and std
2025-10-22 12:23:54,706:INFO:Creating metrics dataframe
2025-10-22 12:23:54,719:INFO:Finalizing model
2025-10-22 12:24:03,331:INFO:Uploading results into container
2025-10-22 12:24:03,333:INFO:Uploading model into container now
2025-10-22 12:24:03,335:INFO:_master_model_container: 19
2025-10-22 12:24:03,336:INFO:_display_container: 4
2025-10-22 12:24:03,337:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 12:24:03,337:INFO:create_model() successfully completed......................................
2025-10-22 12:24:03,819:INFO:SubProcess create_model() end ==================================
2025-10-22 12:24:03,819:INFO:choose_better activated
2025-10-22 12:24:03,824:INFO:SubProcess create_model() called ==================================
2025-10-22 12:24:03,826:INFO:Initializing create_model()
2025-10-22 12:24:03,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 12:24:03,827:INFO:Checking exceptions
2025-10-22 12:24:03,831:INFO:Importing libraries
2025-10-22 12:24:03,832:INFO:Copying training dataset
2025-10-22 12:24:04,627:INFO:Defining folds
2025-10-22 12:24:04,627:INFO:Declaring metric variables
2025-10-22 12:24:04,628:INFO:Importing untrained model
2025-10-22 12:24:04,628:INFO:Declaring custom model
2025-10-22 12:24:04,629:INFO:Ridge Classifier Imported successfully
2025-10-22 12:24:04,629:INFO:Starting cross validation
2025-10-22 12:24:04,639:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 12:24:42,279:INFO:Calculating mean and std
2025-10-22 12:24:42,279:INFO:Creating metrics dataframe
2025-10-22 12:24:42,281:INFO:Finalizing model
2025-10-22 12:24:50,914:INFO:Uploading results into container
2025-10-22 12:24:50,914:INFO:Uploading model into container now
2025-10-22 12:24:50,915:INFO:_master_model_container: 20
2025-10-22 12:24:50,915:INFO:_display_container: 5
2025-10-22 12:24:50,916:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 12:24:50,916:INFO:create_model() successfully completed......................................
2025-10-22 12:24:51,282:INFO:SubProcess create_model() end ==================================
2025-10-22 12:24:51,283:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9215
2025-10-22 12:24:51,284:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9218
2025-10-22 12:24:51,285:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) is best model
2025-10-22 12:24:51,285:INFO:choose_better completed
2025-10-22 12:24:51,303:INFO:_master_model_container: 20
2025-10-22 12:24:51,303:INFO:_display_container: 4
2025-10-22 12:24:51,304:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 12:24:51,304:INFO:tune_model() successfully completed......................................
2025-10-22 12:24:51,655:INFO:Initializing tune_model()
2025-10-22 12:24:51,655:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-22 12:24:51,656:INFO:Checking exceptions
2025-10-22 12:24:51,934:INFO:Copying training dataset
2025-10-22 12:24:52,322:INFO:Checking base model
2025-10-22 12:24:52,322:INFO:Base model : Linear Discriminant Analysis
2025-10-22 12:24:52,331:INFO:Declaring metric variables
2025-10-22 12:24:52,338:INFO:Defining Hyperparameters
2025-10-22 12:24:52,676:INFO:Tuning with n_jobs=1
2025-10-22 12:24:52,677:INFO:Initializing RandomizedSearchCV
2025-10-22 12:29:38,173:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 'auto'}
2025-10-22 12:29:38,174:INFO:Hyperparameter search completed
2025-10-22 12:29:38,174:INFO:SubProcess create_model() called ==================================
2025-10-22 12:29:38,175:INFO:Initializing create_model()
2025-10-22 12:29:38,175:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E20BD90C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 'auto'})
2025-10-22 12:29:38,175:INFO:Checking exceptions
2025-10-22 12:29:38,176:INFO:Importing libraries
2025-10-22 12:29:38,176:INFO:Copying training dataset
2025-10-22 12:29:38,657:INFO:Defining folds
2025-10-22 12:29:38,658:INFO:Declaring metric variables
2025-10-22 12:29:38,661:INFO:Importing untrained model
2025-10-22 12:29:38,661:INFO:Declaring custom model
2025-10-22 12:29:38,666:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 12:29:38,675:INFO:Starting cross validation
2025-10-22 12:29:38,684:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 12:30:17,790:INFO:Calculating mean and std
2025-10-22 12:30:17,791:INFO:Creating metrics dataframe
2025-10-22 12:30:17,797:INFO:Finalizing model
2025-10-22 12:30:22,867:INFO:Uploading results into container
2025-10-22 12:30:22,868:INFO:Uploading model into container now
2025-10-22 12:30:22,869:INFO:_master_model_container: 21
2025-10-22 12:30:22,869:INFO:_display_container: 5
2025-10-22 12:30:22,870:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-22 12:30:22,870:INFO:create_model() successfully completed......................................
2025-10-22 12:30:23,110:INFO:SubProcess create_model() end ==================================
2025-10-22 12:30:23,110:INFO:choose_better activated
2025-10-22 12:30:23,112:INFO:SubProcess create_model() called ==================================
2025-10-22 12:30:23,113:INFO:Initializing create_model()
2025-10-22 12:30:23,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 12:30:23,114:INFO:Checking exceptions
2025-10-22 12:30:23,115:INFO:Importing libraries
2025-10-22 12:30:23,115:INFO:Copying training dataset
2025-10-22 12:30:23,486:INFO:Defining folds
2025-10-22 12:30:23,486:INFO:Declaring metric variables
2025-10-22 12:30:23,486:INFO:Importing untrained model
2025-10-22 12:30:23,486:INFO:Declaring custom model
2025-10-22 12:30:23,487:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 12:30:23,487:INFO:Starting cross validation
2025-10-22 12:30:23,494:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 12:30:47,339:INFO:Calculating mean and std
2025-10-22 12:30:47,340:INFO:Creating metrics dataframe
2025-10-22 12:30:47,341:INFO:Finalizing model
2025-10-22 12:30:52,844:INFO:Uploading results into container
2025-10-22 12:30:52,845:INFO:Uploading model into container now
2025-10-22 12:30:52,846:INFO:_master_model_container: 22
2025-10-22 12:30:52,846:INFO:_display_container: 6
2025-10-22 12:30:52,846:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 12:30:52,846:INFO:create_model() successfully completed......................................
2025-10-22 12:30:53,073:INFO:SubProcess create_model() end ==================================
2025-10-22 12:30:53,074:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9214
2025-10-22 12:30:53,074:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9214
2025-10-22 12:30:53,074:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2025-10-22 12:30:53,075:INFO:choose_better completed
2025-10-22 12:30:53,075:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-22 12:30:53,084:INFO:_master_model_container: 22
2025-10-22 12:30:53,085:INFO:_display_container: 5
2025-10-22 12:30:53,085:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 12:30:53,085:INFO:tune_model() successfully completed......................................
2025-10-22 12:30:53,341:INFO:Initializing blend_models()
2025-10-22 12:30:53,341:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-22 12:30:53,341:INFO:Checking exceptions
2025-10-22 12:30:53,341:INFO:Estimator RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-22 12:30:53,512:INFO:Importing libraries
2025-10-22 12:30:53,512:INFO:Copying training dataset
2025-10-22 12:30:53,515:INFO:Getting model names
2025-10-22 12:30:53,518:INFO:SubProcess create_model() called ==================================
2025-10-22 12:30:53,522:INFO:Initializing create_model()
2025-10-22 12:30:53,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E20DA22410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 12:30:53,524:INFO:Checking exceptions
2025-10-22 12:30:53,524:INFO:Importing libraries
2025-10-22 12:30:53,524:INFO:Copying training dataset
2025-10-22 12:30:53,962:INFO:Defining folds
2025-10-22 12:30:53,962:INFO:Declaring metric variables
2025-10-22 12:30:53,966:INFO:Importing untrained model
2025-10-22 12:30:53,966:INFO:Declaring custom model
2025-10-22 12:30:53,970:INFO:Voting Classifier Imported successfully
2025-10-22 12:30:53,976:INFO:Starting cross validation
2025-10-22 12:30:53,985:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 12:31:34,600:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 12:32:12,690:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 12:32:41,960:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 12:33:30,286:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 12:34:05,246:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 12:34:05,274:INFO:Calculating mean and std
2025-10-22 12:34:05,276:INFO:Creating metrics dataframe
2025-10-22 12:34:05,280:INFO:Finalizing model
2025-10-22 12:34:41,426:INFO:Uploading results into container
2025-10-22 12:34:41,427:INFO:Uploading model into container now
2025-10-22 12:34:41,428:INFO:_master_model_container: 23
2025-10-22 12:34:41,428:INFO:_display_container: 6
2025-10-22 12:34:41,431:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-22 12:34:41,431:INFO:create_model() successfully completed......................................
2025-10-22 12:34:41,670:INFO:SubProcess create_model() end ==================================
2025-10-22 12:34:41,679:INFO:_master_model_container: 23
2025-10-22 12:34:41,680:INFO:_display_container: 6
2025-10-22 12:34:41,683:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-22 12:34:41,683:INFO:blend_models() successfully completed......................................
2025-10-22 12:34:41,899:INFO:Initializing finalize_model()
2025-10-22 12:34:41,899:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-22 12:34:41,901:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-22 12:34:42,195:INFO:Initializing create_model()
2025-10-22 12:34:42,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E20C51A190>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
74123    U04452
20513    U07023
54794    U14666
77090    U07455
71177    U08938
Name: id_usuario, Length: 80004, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 12:34:42,195:INFO:Checking exceptions
2025-10-22 12:34:42,197:INFO:Importing libraries
2025-10-22 12:34:42,197:INFO:Copying training dataset
2025-10-22 12:34:42,250:INFO:Defining folds
2025-10-22 12:34:42,250:INFO:Declaring metric variables
2025-10-22 12:34:42,250:INFO:Importing untrained model
2025-10-22 12:34:42,251:INFO:Declaring custom model
2025-10-22 12:34:42,252:INFO:Voting Classifier Imported successfully
2025-10-22 12:34:42,260:INFO:Cross validation set to False
2025-10-22 12:34:42,260:INFO:Fitting Model
2025-10-22 12:35:54,123:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-22 12:35:54,123:INFO:create_model() successfully completed......................................
2025-10-22 12:35:54,574:INFO:_master_model_container: 23
2025-10-22 12:35:54,574:INFO:_display_container: 6
2025-10-22 12:35:54,619:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-22 12:35:54,619:INFO:finalize_model() successfully completed......................................
2025-10-22 12:35:55,025:INFO:Initializing save_model()
2025-10-22 12:35:55,025:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), model_name=modelo_cls_like_v3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-22 12:35:55,026:INFO:Adding model into prep_pipe
2025-10-22 12:35:55,026:WARNING:Only Model saved as it was a pipeline.
2025-10-22 12:35:55,096:INFO:modelo_cls_like_v3.pkl saved in current working directory
2025-10-22 12:35:55,147:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-22 12:35:55,147:INFO:save_model() successfully completed......................................
2025-10-22 12:36:24,508:INFO:Initializing load_model()
2025-10-22 12:36:24,508:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 12:41:33,686:WARNING:C:\Users\Usuario\AppData\Local\Temp\ipykernel_10700\2980922816.py:19: FutureWarning: The provided callable <function nanmean at 0x000001E260157560> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string "mean" instead.

2025-10-22 12:41:33,687:WARNING:C:\Users\Usuario\AppData\Local\Temp\ipykernel_10700\2980922816.py:20: FutureWarning: The provided callable <function nanmean at 0x000001E260157560> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string "mean" instead.

2025-10-22 13:07:43,558:INFO:Initializing load_model()
2025-10-22 13:07:43,558:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 13:07:43,633:INFO:Initializing load_model()
2025-10-22 13:07:43,633:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 13:08:21,013:INFO:Initializing load_model()
2025-10-22 13:08:21,013:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 13:08:21,103:INFO:Initializing load_model()
2025-10-22 13:08:21,103:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 13:09:20,260:INFO:Initializing load_model()
2025-10-22 13:09:20,260:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:09:20,547:INFO:Initializing load_model()
2025-10-22 13:09:20,547:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:12:41,429:INFO:Initializing load_model()
2025-10-22 13:12:41,429:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:12:41,486:INFO:Initializing load_model()
2025-10-22 13:12:41,486:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:12:59,831:INFO:Initializing load_model()
2025-10-22 13:12:59,831:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:12:59,889:INFO:Initializing load_model()
2025-10-22 13:12:59,890:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:13:00,510:INFO:Initializing load_model()
2025-10-22 13:13:00,511:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:13:00,574:INFO:Initializing load_model()
2025-10-22 13:13:00,574:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:13:39,143:INFO:Initializing load_model()
2025-10-22 13:13:39,143:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 13:13:39,195:INFO:Initializing load_model()
2025-10-22 13:13:39,195:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 13:13:52,772:INFO:Initializing load_model()
2025-10-22 13:13:52,772:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:13:52,839:INFO:Initializing load_model()
2025-10-22 13:13:52,839:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:17:20,199:INFO:Initializing load_model()
2025-10-22 13:17:20,199:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 13:17:32,660:INFO:Initializing load_model()
2025-10-22 13:17:32,660:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:17:48,489:INFO:Initializing load_model()
2025-10-22 13:17:48,490:INFO:load_model(model_name=modelo_cls_like_v2, platform=None, authentication=None, verbose=True)
2025-10-22 13:24:17,126:INFO:Initializing load_model()
2025-10-22 13:24:17,126:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:24:18,115:INFO:Initializing load_model()
2025-10-22 13:24:18,115:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:26:06,591:INFO:Initializing load_model()
2025-10-22 13:26:06,591:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:26:06,848:INFO:Initializing load_model()
2025-10-22 13:26:06,848:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:29:22,110:INFO:Initializing load_model()
2025-10-22 13:29:22,110:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:29:22,939:INFO:Initializing load_model()
2025-10-22 13:29:22,940:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:30:07,076:INFO:Initializing load_model()
2025-10-22 13:30:07,076:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 13:30:07,756:INFO:Initializing load_model()
2025-10-22 13:30:07,756:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 19:23:58,277:INFO:Initializing load_model()
2025-10-22 19:23:58,277:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 19:23:58,454:INFO:Initializing load_model()
2025-10-22 19:23:58,454:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 19:24:07,786:INFO:Initializing load_model()
2025-10-22 19:24:07,786:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 19:24:07,911:INFO:Initializing load_model()
2025-10-22 19:24:07,911:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 19:43:26,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-22 19:43:26,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-22 19:43:26,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-22 19:43:26,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-22 19:43:33,963:INFO:PyCaret ClassificationExperiment
2025-10-22 19:43:33,963:INFO:Logging name: clf-default-name
2025-10-22 19:43:33,963:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-22 19:43:33,963:INFO:version 3.3.2
2025-10-22 19:43:33,963:INFO:Initializing setup()
2025-10-22 19:43:33,964:INFO:self.USI: 7cf7
2025-10-22 19:43:33,964:INFO:self._variable_keys: {'gpu_n_jobs_param', 'pipeline', 'idx', 'html_param', 'n_jobs_param', 'data', 'gpu_param', '_ml_usecase', 'is_multiclass', 'y_test', 'X', 'X_test', 'log_plots_param', '_available_plots', 'y', 'seed', 'fold_shuffle_param', 'fold_generator', 'target_param', 'exp_name_log', 'fold_groups_param', 'memory', 'USI', 'exp_id', 'y_train', 'logging_param', 'X_train', 'fix_imbalance'}
2025-10-22 19:43:33,964:INFO:Checking environment
2025-10-22 19:43:33,964:INFO:python_version: 3.11.13
2025-10-22 19:43:33,964:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-22 19:43:33,964:INFO:machine: AMD64
2025-10-22 19:43:33,964:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-22 19:43:33,968:INFO:Memory: svmem(total=16856211456, available=4950138880, percent=70.6, used=11906072576, free=4950138880)
2025-10-22 19:43:33,968:INFO:Physical Core: 4
2025-10-22 19:43:33,968:INFO:Logical Core: 8
2025-10-22 19:43:33,968:INFO:Checking libraries
2025-10-22 19:43:33,968:INFO:System:
2025-10-22 19:43:33,968:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-22 19:43:33,968:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-22 19:43:33,968:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-22 19:43:33,968:INFO:PyCaret required dependencies:
2025-10-22 19:43:36,468:INFO:                 pip: 25.2
2025-10-22 19:43:36,468:INFO:          setuptools: 80.9.0
2025-10-22 19:43:36,468:INFO:             pycaret: 3.3.2
2025-10-22 19:43:36,469:INFO:             IPython: 9.6.0
2025-10-22 19:43:36,469:INFO:          ipywidgets: 8.1.7
2025-10-22 19:43:36,469:INFO:                tqdm: 4.67.1
2025-10-22 19:43:36,469:INFO:               numpy: 1.26.4
2025-10-22 19:43:36,469:INFO:              pandas: 2.1.4
2025-10-22 19:43:36,469:INFO:              jinja2: 3.1.6
2025-10-22 19:43:36,469:INFO:               scipy: 1.11.4
2025-10-22 19:43:36,469:INFO:              joblib: 1.3.2
2025-10-22 19:43:36,469:INFO:             sklearn: 1.4.2
2025-10-22 19:43:36,469:INFO:                pyod: 2.0.5
2025-10-22 19:43:36,469:INFO:            imblearn: 0.14.0
2025-10-22 19:43:36,469:INFO:   category_encoders: 2.7.0
2025-10-22 19:43:36,469:INFO:            lightgbm: 4.6.0
2025-10-22 19:43:36,469:INFO:               numba: 0.61.0
2025-10-22 19:43:36,469:INFO:            requests: 2.32.5
2025-10-22 19:43:36,469:INFO:          matplotlib: 3.7.5
2025-10-22 19:43:36,469:INFO:          scikitplot: 0.3.7
2025-10-22 19:43:36,470:INFO:         yellowbrick: 1.5
2025-10-22 19:43:36,470:INFO:              plotly: 5.24.1
2025-10-22 19:43:36,470:INFO:    plotly-resampler: Not installed
2025-10-22 19:43:36,470:INFO:             kaleido: 1.1.0
2025-10-22 19:43:36,470:INFO:           schemdraw: 0.15
2025-10-22 19:43:36,470:INFO:         statsmodels: 0.14.5
2025-10-22 19:43:36,470:INFO:              sktime: 0.26.0
2025-10-22 19:43:36,470:INFO:               tbats: 1.1.3
2025-10-22 19:43:36,470:INFO:            pmdarima: 2.0.4
2025-10-22 19:43:36,470:INFO:              psutil: 7.1.1
2025-10-22 19:43:36,470:INFO:          markupsafe: 3.0.3
2025-10-22 19:43:36,470:INFO:             pickle5: Not installed
2025-10-22 19:43:36,470:INFO:         cloudpickle: 3.1.1
2025-10-22 19:43:36,470:INFO:         deprecation: 2.1.0
2025-10-22 19:43:36,470:INFO:              xxhash: 3.6.0
2025-10-22 19:43:36,470:INFO:           wurlitzer: Not installed
2025-10-22 19:43:36,470:INFO:PyCaret optional dependencies:
2025-10-22 19:43:51,335:INFO:                shap: 0.44.1
2025-10-22 19:43:51,335:INFO:           interpret: 0.7.3
2025-10-22 19:43:51,335:INFO:                umap: 0.5.7
2025-10-22 19:43:51,335:INFO:     ydata_profiling: 4.17.0
2025-10-22 19:43:51,335:INFO:  explainerdashboard: 0.5.1
2025-10-22 19:43:51,335:INFO:             autoviz: Not installed
2025-10-22 19:43:51,335:INFO:           fairlearn: 0.7.0
2025-10-22 19:43:51,335:INFO:          deepchecks: Not installed
2025-10-22 19:43:51,335:INFO:             xgboost: 3.1.0
2025-10-22 19:43:51,335:INFO:            catboost: 1.2.8
2025-10-22 19:43:51,335:INFO:              kmodes: 0.12.2
2025-10-22 19:43:51,336:INFO:             mlxtend: 0.23.4
2025-10-22 19:43:51,336:INFO:       statsforecast: 1.5.0
2025-10-22 19:43:51,336:INFO:        tune_sklearn: Not installed
2025-10-22 19:43:51,336:INFO:                 ray: Not installed
2025-10-22 19:43:51,336:INFO:            hyperopt: 0.2.7
2025-10-22 19:43:51,336:INFO:              optuna: 4.5.0
2025-10-22 19:43:51,336:INFO:               skopt: 0.10.2
2025-10-22 19:43:51,336:INFO:              mlflow: 3.5.0
2025-10-22 19:43:51,336:INFO:              gradio: 5.49.1
2025-10-22 19:43:51,336:INFO:             fastapi: 0.119.1
2025-10-22 19:43:51,336:INFO:             uvicorn: 0.38.0
2025-10-22 19:43:51,336:INFO:              m2cgen: 0.10.0
2025-10-22 19:43:51,336:INFO:           evidently: 0.4.40
2025-10-22 19:43:51,336:INFO:               fugue: 0.8.7
2025-10-22 19:43:51,336:INFO:           streamlit: Not installed
2025-10-22 19:43:51,336:INFO:             prophet: Not installed
2025-10-22 19:43:51,336:INFO:None
2025-10-22 19:43:51,336:INFO:Set up data.
2025-10-22 19:43:51,557:INFO:Set up folding strategy.
2025-10-22 19:43:51,796:INFO:Set up train/test split.
2025-10-22 19:43:52,086:INFO:Set up index.
2025-10-22 19:43:52,110:INFO:Assigning column types.
2025-10-22 19:43:52,445:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-22 19:43:52,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-22 19:43:52,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 19:43:52,552:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 19:43:52,554:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 19:43:53,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-22 19:43:53,022:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 19:43:53,043:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 19:43:53,045:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 19:43:53,045:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-22 19:43:53,080:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 19:43:53,103:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 19:43:53,105:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 19:43:53,140:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-22 19:43:53,160:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 19:43:53,162:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 19:43:53,163:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-22 19:43:53,217:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 19:43:53,219:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 19:43:53,276:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 19:43:53,278:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 19:43:53,283:INFO:Preparing preprocessing pipeline...
2025-10-22 19:43:53,336:INFO:Set up simple imputation.
2025-10-22 19:43:53,576:INFO:Set up encoding of ordinal features.
2025-10-22 19:43:53,688:INFO:Set up encoding of categorical features.
2025-10-22 19:43:53,697:INFO:Set up removing multicollinearity.
2025-10-22 19:43:53,697:INFO:Set up imbalanced handling.
2025-10-22 19:43:59,535:INFO:Finished creating preprocessing pipeline.
2025-10-22 19:43:59,554:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-10-22 19:43:59,554:INFO:Creating final display dataframe.
2025-10-22 19:44:06,478:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 28)
4        Transformed data shape       (98748, 95)
5   Transformed train set shape       (74746, 95)
6    Transformed test set shape       (24002, 95)
7               Ignore features                 1
8              Numeric features                12
9          Categorical features                14
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation     most_frequent
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20               Fold Generator        GroupKFold
21                  Fold Number                 5
22                     CPU Jobs                 1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              7cf7
2025-10-22 19:44:06,534:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 19:44:06,536:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 19:44:06,597:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-22 19:44:06,599:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-22 19:44:06,601:INFO:setup() successfully completed in 32.84s...............
2025-10-22 19:44:06,601:INFO:Initializing compare_models()
2025-10-22 19:44:06,601:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-22 19:44:06,601:INFO:Checking exceptions
2025-10-22 19:44:06,889:INFO:Preparing display monitor
2025-10-22 19:44:06,916:INFO:Initializing Logistic Regression
2025-10-22 19:44:06,917:INFO:Total runtime is 1.6609827677408855e-05 minutes
2025-10-22 19:44:06,922:INFO:SubProcess create_model() called ==================================
2025-10-22 19:44:06,924:INFO:Initializing create_model()
2025-10-22 19:44:06,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:44:06,924:INFO:Checking exceptions
2025-10-22 19:44:06,924:INFO:Importing libraries
2025-10-22 19:44:06,925:INFO:Copying training dataset
2025-10-22 19:44:07,346:INFO:Defining folds
2025-10-22 19:44:07,347:INFO:Declaring metric variables
2025-10-22 19:44:07,349:INFO:Importing untrained model
2025-10-22 19:44:07,352:INFO:Logistic Regression Imported successfully
2025-10-22 19:44:07,361:INFO:Starting cross validation
2025-10-22 19:44:07,368:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:44:19,137:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 19:44:31,416:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 19:44:43,769:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 19:44:56,101:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 19:45:08,447:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2025-10-22 19:45:08,803:INFO:Calculating mean and std
2025-10-22 19:45:08,805:INFO:Creating metrics dataframe
2025-10-22 19:45:08,807:INFO:Uploading results into container
2025-10-22 19:45:08,808:INFO:Uploading model into container now
2025-10-22 19:45:08,809:INFO:_master_model_container: 1
2025-10-22 19:45:08,809:INFO:_display_container: 2
2025-10-22 19:45:08,810:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-22 19:45:08,810:INFO:create_model() successfully completed......................................
2025-10-22 19:45:08,965:INFO:SubProcess create_model() end ==================================
2025-10-22 19:45:08,966:INFO:Creating metrics dataframe
2025-10-22 19:45:08,971:INFO:Initializing K Neighbors Classifier
2025-10-22 19:45:08,971:INFO:Total runtime is 1.034247120221456 minutes
2025-10-22 19:45:08,976:INFO:SubProcess create_model() called ==================================
2025-10-22 19:45:08,976:INFO:Initializing create_model()
2025-10-22 19:45:08,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:45:08,977:INFO:Checking exceptions
2025-10-22 19:45:08,977:INFO:Importing libraries
2025-10-22 19:45:08,977:INFO:Copying training dataset
2025-10-22 19:45:09,333:INFO:Defining folds
2025-10-22 19:45:09,333:INFO:Declaring metric variables
2025-10-22 19:45:09,336:INFO:Importing untrained model
2025-10-22 19:45:09,342:INFO:K Neighbors Classifier Imported successfully
2025-10-22 19:45:09,346:INFO:Starting cross validation
2025-10-22 19:45:09,354:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:45:59,708:INFO:Calculating mean and std
2025-10-22 19:45:59,710:INFO:Creating metrics dataframe
2025-10-22 19:45:59,714:INFO:Uploading results into container
2025-10-22 19:45:59,715:INFO:Uploading model into container now
2025-10-22 19:45:59,716:INFO:_master_model_container: 2
2025-10-22 19:45:59,716:INFO:_display_container: 2
2025-10-22 19:45:59,717:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-22 19:45:59,718:INFO:create_model() successfully completed......................................
2025-10-22 19:46:00,005:INFO:SubProcess create_model() end ==================================
2025-10-22 19:46:00,005:INFO:Creating metrics dataframe
2025-10-22 19:46:00,018:INFO:Initializing Naive Bayes
2025-10-22 19:46:00,018:INFO:Total runtime is 1.8850252787272137 minutes
2025-10-22 19:46:00,027:INFO:SubProcess create_model() called ==================================
2025-10-22 19:46:00,029:INFO:Initializing create_model()
2025-10-22 19:46:00,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:46:00,029:INFO:Checking exceptions
2025-10-22 19:46:00,029:INFO:Importing libraries
2025-10-22 19:46:00,029:INFO:Copying training dataset
2025-10-22 19:46:00,727:INFO:Defining folds
2025-10-22 19:46:00,727:INFO:Declaring metric variables
2025-10-22 19:46:00,734:INFO:Importing untrained model
2025-10-22 19:46:00,741:INFO:Naive Bayes Imported successfully
2025-10-22 19:46:00,750:INFO:Starting cross validation
2025-10-22 19:46:00,760:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:46:31,026:INFO:Calculating mean and std
2025-10-22 19:46:31,027:INFO:Creating metrics dataframe
2025-10-22 19:46:31,031:INFO:Uploading results into container
2025-10-22 19:46:31,032:INFO:Uploading model into container now
2025-10-22 19:46:31,033:INFO:_master_model_container: 3
2025-10-22 19:46:31,033:INFO:_display_container: 2
2025-10-22 19:46:31,033:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-22 19:46:31,033:INFO:create_model() successfully completed......................................
2025-10-22 19:46:31,194:INFO:SubProcess create_model() end ==================================
2025-10-22 19:46:31,194:INFO:Creating metrics dataframe
2025-10-22 19:46:31,201:INFO:Initializing Decision Tree Classifier
2025-10-22 19:46:31,201:INFO:Total runtime is 2.404742026329041 minutes
2025-10-22 19:46:31,206:INFO:SubProcess create_model() called ==================================
2025-10-22 19:46:31,206:INFO:Initializing create_model()
2025-10-22 19:46:31,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:46:31,207:INFO:Checking exceptions
2025-10-22 19:46:31,207:INFO:Importing libraries
2025-10-22 19:46:31,207:INFO:Copying training dataset
2025-10-22 19:46:31,609:INFO:Defining folds
2025-10-22 19:46:31,609:INFO:Declaring metric variables
2025-10-22 19:46:31,614:INFO:Importing untrained model
2025-10-22 19:46:31,619:INFO:Decision Tree Classifier Imported successfully
2025-10-22 19:46:31,625:INFO:Starting cross validation
2025-10-22 19:46:31,632:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:46:57,374:INFO:Calculating mean and std
2025-10-22 19:46:57,375:INFO:Creating metrics dataframe
2025-10-22 19:46:57,377:INFO:Uploading results into container
2025-10-22 19:46:57,377:INFO:Uploading model into container now
2025-10-22 19:46:57,378:INFO:_master_model_container: 4
2025-10-22 19:46:57,378:INFO:_display_container: 2
2025-10-22 19:46:57,378:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-22 19:46:57,378:INFO:create_model() successfully completed......................................
2025-10-22 19:46:57,536:INFO:SubProcess create_model() end ==================================
2025-10-22 19:46:57,536:INFO:Creating metrics dataframe
2025-10-22 19:46:57,542:INFO:Initializing SVM - Linear Kernel
2025-10-22 19:46:57,542:INFO:Total runtime is 2.8437685608863834 minutes
2025-10-22 19:46:57,544:INFO:SubProcess create_model() called ==================================
2025-10-22 19:46:57,545:INFO:Initializing create_model()
2025-10-22 19:46:57,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:46:57,545:INFO:Checking exceptions
2025-10-22 19:46:57,545:INFO:Importing libraries
2025-10-22 19:46:57,545:INFO:Copying training dataset
2025-10-22 19:46:57,923:INFO:Defining folds
2025-10-22 19:46:57,924:INFO:Declaring metric variables
2025-10-22 19:46:57,928:INFO:Importing untrained model
2025-10-22 19:46:57,931:INFO:SVM - Linear Kernel Imported successfully
2025-10-22 19:46:57,939:INFO:Starting cross validation
2025-10-22 19:46:57,946:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:47:08,017:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 19:47:20,498:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 19:47:39,892:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 19:48:22,643:INFO:Calculating mean and std
2025-10-22 19:48:22,646:INFO:Creating metrics dataframe
2025-10-22 19:48:22,651:INFO:Uploading results into container
2025-10-22 19:48:22,651:INFO:Uploading model into container now
2025-10-22 19:48:22,652:INFO:_master_model_container: 5
2025-10-22 19:48:22,652:INFO:_display_container: 2
2025-10-22 19:48:22,653:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-22 19:48:22,653:INFO:create_model() successfully completed......................................
2025-10-22 19:48:22,905:INFO:SubProcess create_model() end ==================================
2025-10-22 19:48:22,906:INFO:Creating metrics dataframe
2025-10-22 19:48:22,917:INFO:Initializing Ridge Classifier
2025-10-22 19:48:22,918:INFO:Total runtime is 4.266701594988506 minutes
2025-10-22 19:48:22,928:INFO:SubProcess create_model() called ==================================
2025-10-22 19:48:22,931:INFO:Initializing create_model()
2025-10-22 19:48:22,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:48:22,931:INFO:Checking exceptions
2025-10-22 19:48:22,932:INFO:Importing libraries
2025-10-22 19:48:22,932:INFO:Copying training dataset
2025-10-22 19:48:23,528:INFO:Defining folds
2025-10-22 19:48:23,529:INFO:Declaring metric variables
2025-10-22 19:48:23,539:INFO:Importing untrained model
2025-10-22 19:48:23,548:INFO:Ridge Classifier Imported successfully
2025-10-22 19:48:23,562:INFO:Starting cross validation
2025-10-22 19:48:23,575:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:49:00,269:INFO:Calculating mean and std
2025-10-22 19:49:00,271:INFO:Creating metrics dataframe
2025-10-22 19:49:00,275:INFO:Uploading results into container
2025-10-22 19:49:00,276:INFO:Uploading model into container now
2025-10-22 19:49:00,277:INFO:_master_model_container: 6
2025-10-22 19:49:00,277:INFO:_display_container: 2
2025-10-22 19:49:00,278:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 19:49:00,278:INFO:create_model() successfully completed......................................
2025-10-22 19:49:00,538:INFO:SubProcess create_model() end ==================================
2025-10-22 19:49:00,539:INFO:Creating metrics dataframe
2025-10-22 19:49:00,555:INFO:Initializing Random Forest Classifier
2025-10-22 19:49:00,555:INFO:Total runtime is 4.893979024887086 minutes
2025-10-22 19:49:00,562:INFO:SubProcess create_model() called ==================================
2025-10-22 19:49:00,565:INFO:Initializing create_model()
2025-10-22 19:49:00,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:49:00,566:INFO:Checking exceptions
2025-10-22 19:49:00,566:INFO:Importing libraries
2025-10-22 19:49:00,566:INFO:Copying training dataset
2025-10-22 19:49:01,315:INFO:Defining folds
2025-10-22 19:49:01,315:INFO:Declaring metric variables
2025-10-22 19:49:01,322:INFO:Importing untrained model
2025-10-22 19:49:01,331:INFO:Random Forest Classifier Imported successfully
2025-10-22 19:49:01,345:INFO:Starting cross validation
2025-10-22 19:49:01,365:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:51:43,506:INFO:Calculating mean and std
2025-10-22 19:51:43,508:INFO:Creating metrics dataframe
2025-10-22 19:51:43,515:INFO:Uploading results into container
2025-10-22 19:51:43,517:INFO:Uploading model into container now
2025-10-22 19:51:43,518:INFO:_master_model_container: 7
2025-10-22 19:51:43,518:INFO:_display_container: 2
2025-10-22 19:51:43,519:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-22 19:51:43,519:INFO:create_model() successfully completed......................................
2025-10-22 19:51:43,765:INFO:SubProcess create_model() end ==================================
2025-10-22 19:51:43,766:INFO:Creating metrics dataframe
2025-10-22 19:51:43,775:INFO:Initializing Quadratic Discriminant Analysis
2025-10-22 19:51:43,775:INFO:Total runtime is 7.614306875069937 minutes
2025-10-22 19:51:43,779:INFO:SubProcess create_model() called ==================================
2025-10-22 19:51:43,780:INFO:Initializing create_model()
2025-10-22 19:51:43,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:51:43,780:INFO:Checking exceptions
2025-10-22 19:51:43,780:INFO:Importing libraries
2025-10-22 19:51:43,780:INFO:Copying training dataset
2025-10-22 19:51:44,423:INFO:Defining folds
2025-10-22 19:51:44,424:INFO:Declaring metric variables
2025-10-22 19:51:44,434:INFO:Importing untrained model
2025-10-22 19:51:44,443:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-22 19:51:44,453:INFO:Starting cross validation
2025-10-22 19:51:44,463:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:51:51,220:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 19:51:59,118:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 19:52:07,060:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 19:52:15,115:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 19:52:23,127:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-22 19:52:24,283:INFO:Calculating mean and std
2025-10-22 19:52:24,286:INFO:Creating metrics dataframe
2025-10-22 19:52:24,292:INFO:Uploading results into container
2025-10-22 19:52:24,294:INFO:Uploading model into container now
2025-10-22 19:52:24,295:INFO:_master_model_container: 8
2025-10-22 19:52:24,295:INFO:_display_container: 2
2025-10-22 19:52:24,295:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-22 19:52:24,295:INFO:create_model() successfully completed......................................
2025-10-22 19:52:24,532:INFO:SubProcess create_model() end ==================================
2025-10-22 19:52:24,532:INFO:Creating metrics dataframe
2025-10-22 19:52:24,549:INFO:Initializing Ada Boost Classifier
2025-10-22 19:52:24,550:INFO:Total runtime is 8.293891549110414 minutes
2025-10-22 19:52:24,558:INFO:SubProcess create_model() called ==================================
2025-10-22 19:52:24,561:INFO:Initializing create_model()
2025-10-22 19:52:24,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:52:24,562:INFO:Checking exceptions
2025-10-22 19:52:24,562:INFO:Importing libraries
2025-10-22 19:52:24,562:INFO:Copying training dataset
2025-10-22 19:52:25,217:INFO:Defining folds
2025-10-22 19:52:25,217:INFO:Declaring metric variables
2025-10-22 19:52:25,230:INFO:Importing untrained model
2025-10-22 19:52:25,240:INFO:Ada Boost Classifier Imported successfully
2025-10-22 19:52:25,257:INFO:Starting cross validation
2025-10-22 19:52:25,271:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:52:32,268:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 19:52:53,543:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 19:53:14,253:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 19:53:34,489:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 19:53:55,079:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-22 19:54:02,768:INFO:Calculating mean and std
2025-10-22 19:54:02,768:INFO:Creating metrics dataframe
2025-10-22 19:54:02,770:INFO:Uploading results into container
2025-10-22 19:54:02,771:INFO:Uploading model into container now
2025-10-22 19:54:02,771:INFO:_master_model_container: 9
2025-10-22 19:54:02,771:INFO:_display_container: 2
2025-10-22 19:54:02,772:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-22 19:54:02,772:INFO:create_model() successfully completed......................................
2025-10-22 19:54:02,928:INFO:SubProcess create_model() end ==================================
2025-10-22 19:54:02,929:INFO:Creating metrics dataframe
2025-10-22 19:54:02,939:INFO:Initializing Gradient Boosting Classifier
2025-10-22 19:54:02,939:INFO:Total runtime is 9.93371843894323 minutes
2025-10-22 19:54:02,943:INFO:SubProcess create_model() called ==================================
2025-10-22 19:54:02,944:INFO:Initializing create_model()
2025-10-22 19:54:02,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:54:02,944:INFO:Checking exceptions
2025-10-22 19:54:02,944:INFO:Importing libraries
2025-10-22 19:54:02,944:INFO:Copying training dataset
2025-10-22 19:54:03,334:INFO:Defining folds
2025-10-22 19:54:03,334:INFO:Declaring metric variables
2025-10-22 19:54:03,336:INFO:Importing untrained model
2025-10-22 19:54:03,341:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 19:54:03,349:INFO:Starting cross validation
2025-10-22 19:54:03,356:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:56:21,833:INFO:Calculating mean and std
2025-10-22 19:56:21,833:INFO:Creating metrics dataframe
2025-10-22 19:56:21,836:INFO:Uploading results into container
2025-10-22 19:56:21,837:INFO:Uploading model into container now
2025-10-22 19:56:21,838:INFO:_master_model_container: 10
2025-10-22 19:56:21,838:INFO:_display_container: 2
2025-10-22 19:56:21,839:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 19:56:21,839:INFO:create_model() successfully completed......................................
2025-10-22 19:56:21,997:INFO:SubProcess create_model() end ==================================
2025-10-22 19:56:21,997:INFO:Creating metrics dataframe
2025-10-22 19:56:22,004:INFO:Initializing Linear Discriminant Analysis
2025-10-22 19:56:22,004:INFO:Total runtime is 12.251465646425885 minutes
2025-10-22 19:56:22,009:INFO:SubProcess create_model() called ==================================
2025-10-22 19:56:22,010:INFO:Initializing create_model()
2025-10-22 19:56:22,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:56:22,010:INFO:Checking exceptions
2025-10-22 19:56:22,010:INFO:Importing libraries
2025-10-22 19:56:22,010:INFO:Copying training dataset
2025-10-22 19:56:22,391:INFO:Defining folds
2025-10-22 19:56:22,392:INFO:Declaring metric variables
2025-10-22 19:56:22,396:INFO:Importing untrained model
2025-10-22 19:56:22,399:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 19:56:22,406:INFO:Starting cross validation
2025-10-22 19:56:22,414:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:56:45,558:INFO:Calculating mean and std
2025-10-22 19:56:45,559:INFO:Creating metrics dataframe
2025-10-22 19:56:45,561:INFO:Uploading results into container
2025-10-22 19:56:45,562:INFO:Uploading model into container now
2025-10-22 19:56:45,562:INFO:_master_model_container: 11
2025-10-22 19:56:45,562:INFO:_display_container: 2
2025-10-22 19:56:45,562:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 19:56:45,562:INFO:create_model() successfully completed......................................
2025-10-22 19:56:45,719:INFO:SubProcess create_model() end ==================================
2025-10-22 19:56:45,719:INFO:Creating metrics dataframe
2025-10-22 19:56:45,729:INFO:Initializing Extra Trees Classifier
2025-10-22 19:56:45,729:INFO:Total runtime is 12.6468882838885 minutes
2025-10-22 19:56:45,732:INFO:SubProcess create_model() called ==================================
2025-10-22 19:56:45,733:INFO:Initializing create_model()
2025-10-22 19:56:45,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:56:45,733:INFO:Checking exceptions
2025-10-22 19:56:45,733:INFO:Importing libraries
2025-10-22 19:56:45,734:INFO:Copying training dataset
2025-10-22 19:56:46,091:INFO:Defining folds
2025-10-22 19:56:46,091:INFO:Declaring metric variables
2025-10-22 19:56:46,094:INFO:Importing untrained model
2025-10-22 19:56:46,098:INFO:Extra Trees Classifier Imported successfully
2025-10-22 19:56:46,105:INFO:Starting cross validation
2025-10-22 19:56:46,112:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:58:28,011:INFO:Calculating mean and std
2025-10-22 19:58:28,012:INFO:Creating metrics dataframe
2025-10-22 19:58:28,014:INFO:Uploading results into container
2025-10-22 19:58:28,014:INFO:Uploading model into container now
2025-10-22 19:58:28,014:INFO:_master_model_container: 12
2025-10-22 19:58:28,014:INFO:_display_container: 2
2025-10-22 19:58:28,015:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-22 19:58:28,015:INFO:create_model() successfully completed......................................
2025-10-22 19:58:28,180:INFO:SubProcess create_model() end ==================================
2025-10-22 19:58:28,181:INFO:Creating metrics dataframe
2025-10-22 19:58:28,191:INFO:Initializing Extreme Gradient Boosting
2025-10-22 19:58:28,191:INFO:Total runtime is 14.354584217071535 minutes
2025-10-22 19:58:28,196:INFO:SubProcess create_model() called ==================================
2025-10-22 19:58:28,196:INFO:Initializing create_model()
2025-10-22 19:58:28,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=xgboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:58:28,197:INFO:Checking exceptions
2025-10-22 19:58:28,197:INFO:Importing libraries
2025-10-22 19:58:28,197:INFO:Copying training dataset
2025-10-22 19:58:28,619:INFO:Defining folds
2025-10-22 19:58:28,620:INFO:Declaring metric variables
2025-10-22 19:58:28,623:INFO:Importing untrained model
2025-10-22 19:58:28,627:INFO:Extreme Gradient Boosting Imported successfully
2025-10-22 19:58:28,633:INFO:Starting cross validation
2025-10-22 19:58:28,642:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:59:11,127:INFO:Calculating mean and std
2025-10-22 19:59:11,128:INFO:Creating metrics dataframe
2025-10-22 19:59:11,131:INFO:Uploading results into container
2025-10-22 19:59:11,132:INFO:Uploading model into container now
2025-10-22 19:59:11,133:INFO:_master_model_container: 13
2025-10-22 19:59:11,133:INFO:_display_container: 2
2025-10-22 19:59:11,135:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-10-22 19:59:11,135:INFO:create_model() successfully completed......................................
2025-10-22 19:59:11,300:INFO:SubProcess create_model() end ==================================
2025-10-22 19:59:11,300:INFO:Creating metrics dataframe
2025-10-22 19:59:11,308:INFO:Initializing Light Gradient Boosting Machine
2025-10-22 19:59:11,308:INFO:Total runtime is 15.073194932937623 minutes
2025-10-22 19:59:11,312:INFO:SubProcess create_model() called ==================================
2025-10-22 19:59:11,312:INFO:Initializing create_model()
2025-10-22 19:59:11,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:59:11,312:INFO:Checking exceptions
2025-10-22 19:59:11,312:INFO:Importing libraries
2025-10-22 19:59:11,312:INFO:Copying training dataset
2025-10-22 19:59:11,669:INFO:Defining folds
2025-10-22 19:59:11,669:INFO:Declaring metric variables
2025-10-22 19:59:11,672:INFO:Importing untrained model
2025-10-22 19:59:11,675:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-22 19:59:11,681:INFO:Starting cross validation
2025-10-22 19:59:11,690:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 19:59:15,533:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 19:59:15,536:INFO:[LightGBM] [Info] Number of positive: 29918, number of negative: 29918
2025-10-22 19:59:15,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033766 seconds.
2025-10-22 19:59:15,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 19:59:15,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 19:59:15,614:INFO:[LightGBM] [Info] Total Bins 23390
2025-10-22 19:59:15,617:INFO:[LightGBM] [Info] Number of data points in the train set: 59836, number of used features: 94
2025-10-22 19:59:15,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-22 19:59:21,060:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 19:59:21,062:INFO:[LightGBM] [Info] Number of positive: 29786, number of negative: 29786
2025-10-22 19:59:21,135:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033844 seconds.
2025-10-22 19:59:21,135:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 19:59:21,136:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 19:59:21,136:INFO:[LightGBM] [Info] Total Bins 23345
2025-10-22 19:59:21,137:INFO:[LightGBM] [Info] Number of data points in the train set: 59572, number of used features: 94
2025-10-22 19:59:21,138:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-22 19:59:26,602:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 19:59:26,604:INFO:[LightGBM] [Info] Number of positive: 29899, number of negative: 29899
2025-10-22 19:59:26,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034059 seconds.
2025-10-22 19:59:26,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 19:59:26,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 19:59:26,678:INFO:[LightGBM] [Info] Total Bins 23568
2025-10-22 19:59:26,680:INFO:[LightGBM] [Info] Number of data points in the train set: 59798, number of used features: 94
2025-10-22 19:59:26,680:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-22 19:59:32,015:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 19:59:32,018:INFO:[LightGBM] [Info] Number of positive: 29984, number of negative: 29984
2025-10-22 19:59:32,091:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033830 seconds.
2025-10-22 19:59:32,091:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 19:59:32,091:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 19:59:32,092:INFO:[LightGBM] [Info] Total Bins 23401
2025-10-22 19:59:32,094:INFO:[LightGBM] [Info] Number of data points in the train set: 59968, number of used features: 94
2025-10-22 19:59:32,094:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-22 19:59:37,550:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-22 19:59:37,552:INFO:[LightGBM] [Info] Number of positive: 29905, number of negative: 29905
2025-10-22 19:59:37,621:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029659 seconds.
2025-10-22 19:59:37,621:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-22 19:59:37,621:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-22 19:59:37,621:INFO:[LightGBM] [Info] Total Bins 23581
2025-10-22 19:59:37,623:INFO:[LightGBM] [Info] Number of data points in the train set: 59810, number of used features: 94
2025-10-22 19:59:37,623:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-22 19:59:39,283:INFO:Calculating mean and std
2025-10-22 19:59:39,284:INFO:Creating metrics dataframe
2025-10-22 19:59:39,286:INFO:Uploading results into container
2025-10-22 19:59:39,287:INFO:Uploading model into container now
2025-10-22 19:59:39,287:INFO:_master_model_container: 14
2025-10-22 19:59:39,287:INFO:_display_container: 2
2025-10-22 19:59:39,288:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-22 19:59:39,288:INFO:create_model() successfully completed......................................
2025-10-22 19:59:39,441:INFO:SubProcess create_model() end ==================================
2025-10-22 19:59:39,441:INFO:Creating metrics dataframe
2025-10-22 19:59:39,450:INFO:Initializing CatBoost Classifier
2025-10-22 19:59:39,450:INFO:Total runtime is 15.54223226706187 minutes
2025-10-22 19:59:39,454:INFO:SubProcess create_model() called ==================================
2025-10-22 19:59:39,456:INFO:Initializing create_model()
2025-10-22 19:59:39,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=catboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 19:59:39,456:INFO:Checking exceptions
2025-10-22 19:59:39,457:INFO:Importing libraries
2025-10-22 19:59:39,457:INFO:Copying training dataset
2025-10-22 19:59:39,815:INFO:Defining folds
2025-10-22 19:59:39,815:INFO:Declaring metric variables
2025-10-22 19:59:39,819:INFO:Importing untrained model
2025-10-22 19:59:39,824:INFO:CatBoost Classifier Imported successfully
2025-10-22 19:59:39,830:INFO:Starting cross validation
2025-10-22 19:59:39,838:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 20:07:49,513:INFO:Calculating mean and std
2025-10-22 20:07:49,515:INFO:Creating metrics dataframe
2025-10-22 20:07:49,517:INFO:Uploading results into container
2025-10-22 20:07:49,518:INFO:Uploading model into container now
2025-10-22 20:07:49,518:INFO:_master_model_container: 15
2025-10-22 20:07:49,518:INFO:_display_container: 2
2025-10-22 20:07:49,518:INFO:<catboost.core.CatBoostClassifier object at 0x00000206321C5510>
2025-10-22 20:07:49,518:INFO:create_model() successfully completed......................................
2025-10-22 20:07:49,700:INFO:SubProcess create_model() end ==================================
2025-10-22 20:07:49,700:INFO:Creating metrics dataframe
2025-10-22 20:07:49,711:INFO:Initializing Dummy Classifier
2025-10-22 20:07:49,712:INFO:Total runtime is 23.713246766726176 minutes
2025-10-22 20:07:49,716:INFO:SubProcess create_model() called ==================================
2025-10-22 20:07:49,718:INFO:Initializing create_model()
2025-10-22 20:07:49,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=dummy, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AFAF190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 20:07:49,718:INFO:Checking exceptions
2025-10-22 20:07:49,718:INFO:Importing libraries
2025-10-22 20:07:49,718:INFO:Copying training dataset
2025-10-22 20:07:50,088:INFO:Defining folds
2025-10-22 20:07:50,089:INFO:Declaring metric variables
2025-10-22 20:07:50,093:INFO:Importing untrained model
2025-10-22 20:07:50,098:INFO:Dummy Classifier Imported successfully
2025-10-22 20:07:50,104:INFO:Starting cross validation
2025-10-22 20:07:50,114:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 20:07:54,067:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 20:07:57,807:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 20:08:01,525:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 20:08:05,346:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 20:08:09,080:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-22 20:08:09,101:INFO:Calculating mean and std
2025-10-22 20:08:09,101:INFO:Creating metrics dataframe
2025-10-22 20:08:09,103:INFO:Uploading results into container
2025-10-22 20:08:09,104:INFO:Uploading model into container now
2025-10-22 20:08:09,104:INFO:_master_model_container: 16
2025-10-22 20:08:09,104:INFO:_display_container: 2
2025-10-22 20:08:09,104:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-10-22 20:08:09,104:INFO:create_model() successfully completed......................................
2025-10-22 20:08:09,261:INFO:SubProcess create_model() end ==================================
2025-10-22 20:08:09,261:INFO:Creating metrics dataframe
2025-10-22 20:08:09,270:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-22 20:08:09,282:INFO:Initializing create_model()
2025-10-22 20:08:09,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 20:08:09,282:INFO:Checking exceptions
2025-10-22 20:08:09,283:INFO:Importing libraries
2025-10-22 20:08:09,283:INFO:Copying training dataset
2025-10-22 20:08:09,712:INFO:Defining folds
2025-10-22 20:08:09,712:INFO:Declaring metric variables
2025-10-22 20:08:09,712:INFO:Importing untrained model
2025-10-22 20:08:09,712:INFO:Declaring custom model
2025-10-22 20:08:09,713:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 20:08:09,718:INFO:Cross validation set to False
2025-10-22 20:08:09,718:INFO:Fitting Model
2025-10-22 20:08:44,474:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 20:08:44,474:INFO:create_model() successfully completed......................................
2025-10-22 20:08:44,646:INFO:Initializing create_model()
2025-10-22 20:08:44,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 20:08:44,647:INFO:Checking exceptions
2025-10-22 20:08:44,650:INFO:Importing libraries
2025-10-22 20:08:44,650:INFO:Copying training dataset
2025-10-22 20:08:45,019:INFO:Defining folds
2025-10-22 20:08:45,020:INFO:Declaring metric variables
2025-10-22 20:08:45,020:INFO:Importing untrained model
2025-10-22 20:08:45,020:INFO:Declaring custom model
2025-10-22 20:08:45,020:INFO:Ridge Classifier Imported successfully
2025-10-22 20:08:45,026:INFO:Cross validation set to False
2025-10-22 20:08:45,026:INFO:Fitting Model
2025-10-22 20:08:49,603:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 20:08:49,603:INFO:create_model() successfully completed......................................
2025-10-22 20:08:49,761:INFO:Initializing create_model()
2025-10-22 20:08:49,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 20:08:49,762:INFO:Checking exceptions
2025-10-22 20:08:49,764:INFO:Importing libraries
2025-10-22 20:08:49,764:INFO:Copying training dataset
2025-10-22 20:08:50,130:INFO:Defining folds
2025-10-22 20:08:50,130:INFO:Declaring metric variables
2025-10-22 20:08:50,130:INFO:Importing untrained model
2025-10-22 20:08:50,130:INFO:Declaring custom model
2025-10-22 20:08:50,130:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 20:08:50,135:INFO:Cross validation set to False
2025-10-22 20:08:50,136:INFO:Fitting Model
2025-10-22 20:08:55,745:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 20:08:55,746:INFO:create_model() successfully completed......................................
2025-10-22 20:08:55,944:INFO:_master_model_container: 16
2025-10-22 20:08:55,944:INFO:_display_container: 2
2025-10-22 20:08:55,945:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2025-10-22 20:08:55,945:INFO:compare_models() successfully completed......................................
2025-10-22 20:08:55,947:INFO:Initializing tune_model()
2025-10-22 20:08:55,947:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-22 20:08:55,947:INFO:Checking exceptions
2025-10-22 20:08:56,107:INFO:Copying training dataset
2025-10-22 20:08:56,343:INFO:Checking base model
2025-10-22 20:08:56,343:INFO:Base model : Gradient Boosting Classifier
2025-10-22 20:08:56,346:INFO:Declaring metric variables
2025-10-22 20:08:56,349:INFO:Defining Hyperparameters
2025-10-22 20:08:56,502:INFO:Tuning with n_jobs=1
2025-10-22 20:08:56,502:INFO:Initializing RandomizedSearchCV
2025-10-22 20:17:18,843:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.4}
2025-10-22 20:17:18,844:INFO:Hyperparameter search completed
2025-10-22 20:17:18,844:INFO:SubProcess create_model() called ==================================
2025-10-22 20:17:18,845:INFO:Initializing create_model()
2025-10-22 20:17:18,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062A5723D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 130, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 1, 'learning_rate': 0.4})
2025-10-22 20:17:18,845:INFO:Checking exceptions
2025-10-22 20:17:18,845:INFO:Importing libraries
2025-10-22 20:17:18,845:INFO:Copying training dataset
2025-10-22 20:17:19,185:INFO:Defining folds
2025-10-22 20:17:19,185:INFO:Declaring metric variables
2025-10-22 20:17:19,191:INFO:Importing untrained model
2025-10-22 20:17:19,191:INFO:Declaring custom model
2025-10-22 20:17:19,194:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 20:17:19,202:INFO:Starting cross validation
2025-10-22 20:17:19,209:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 20:18:12,921:INFO:Calculating mean and std
2025-10-22 20:18:12,921:INFO:Creating metrics dataframe
2025-10-22 20:18:12,925:INFO:Finalizing model
2025-10-22 20:18:26,247:INFO:Uploading results into container
2025-10-22 20:18:26,248:INFO:Uploading model into container now
2025-10-22 20:18:26,249:INFO:_master_model_container: 17
2025-10-22 20:18:26,249:INFO:_display_container: 3
2025-10-22 20:18:26,250:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 20:18:26,250:INFO:create_model() successfully completed......................................
2025-10-22 20:18:26,421:INFO:SubProcess create_model() end ==================================
2025-10-22 20:18:26,421:INFO:choose_better activated
2025-10-22 20:18:26,424:INFO:SubProcess create_model() called ==================================
2025-10-22 20:18:26,425:INFO:Initializing create_model()
2025-10-22 20:18:26,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 20:18:26,425:INFO:Checking exceptions
2025-10-22 20:18:26,426:INFO:Importing libraries
2025-10-22 20:18:26,426:INFO:Copying training dataset
2025-10-22 20:18:26,788:INFO:Defining folds
2025-10-22 20:18:26,788:INFO:Declaring metric variables
2025-10-22 20:18:26,788:INFO:Importing untrained model
2025-10-22 20:18:26,788:INFO:Declaring custom model
2025-10-22 20:18:26,788:INFO:Gradient Boosting Classifier Imported successfully
2025-10-22 20:18:26,788:INFO:Starting cross validation
2025-10-22 20:18:26,794:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 20:20:45,179:INFO:Calculating mean and std
2025-10-22 20:20:45,179:INFO:Creating metrics dataframe
2025-10-22 20:20:45,180:INFO:Finalizing model
2025-10-22 20:21:19,609:INFO:Uploading results into container
2025-10-22 20:21:19,609:INFO:Uploading model into container now
2025-10-22 20:21:19,609:INFO:_master_model_container: 18
2025-10-22 20:21:19,610:INFO:_display_container: 4
2025-10-22 20:21:19,610:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 20:21:19,610:INFO:create_model() successfully completed......................................
2025-10-22 20:21:19,787:INFO:SubProcess create_model() end ==================================
2025-10-22 20:21:19,788:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9219
2025-10-22 20:21:19,788:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.921
2025-10-22 20:21:19,788:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-10-22 20:21:19,789:INFO:choose_better completed
2025-10-22 20:21:19,789:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-22 20:21:19,796:INFO:_master_model_container: 18
2025-10-22 20:21:19,796:INFO:_display_container: 3
2025-10-22 20:21:19,797:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-22 20:21:19,797:INFO:tune_model() successfully completed......................................
2025-10-22 20:21:19,958:INFO:Initializing tune_model()
2025-10-22 20:21:19,958:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-22 20:21:19,958:INFO:Checking exceptions
2025-10-22 20:21:20,106:INFO:Copying training dataset
2025-10-22 20:21:20,398:INFO:Checking base model
2025-10-22 20:21:20,398:INFO:Base model : Ridge Classifier
2025-10-22 20:21:20,401:INFO:Declaring metric variables
2025-10-22 20:21:20,406:INFO:Defining Hyperparameters
2025-10-22 20:21:20,557:INFO:Tuning with n_jobs=1
2025-10-22 20:21:20,558:INFO:Initializing RandomizedSearchCV
2025-10-22 20:24:01,111:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.24163e-17): result may not be accurate.

2025-10-22 20:24:05,187:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.33156e-17): result may not be accurate.

2025-10-22 20:24:09,375:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.3013e-17): result may not be accurate.

2025-10-22 20:24:13,439:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.29068e-17): result may not be accurate.

2025-10-22 20:24:17,544:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.27526e-17): result may not be accurate.

2025-10-22 20:24:38,282:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.3}
2025-10-22 20:24:38,282:INFO:Hyperparameter search completed
2025-10-22 20:24:38,283:INFO:SubProcess create_model() called ==================================
2025-10-22 20:24:38,285:INFO:Initializing create_model()
2025-10-22 20:24:38,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AF099D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 7.3})
2025-10-22 20:24:38,286:INFO:Checking exceptions
2025-10-22 20:24:38,286:INFO:Importing libraries
2025-10-22 20:24:38,286:INFO:Copying training dataset
2025-10-22 20:24:38,646:INFO:Defining folds
2025-10-22 20:24:38,646:INFO:Declaring metric variables
2025-10-22 20:24:38,652:INFO:Importing untrained model
2025-10-22 20:24:38,652:INFO:Declaring custom model
2025-10-22 20:24:38,656:INFO:Ridge Classifier Imported successfully
2025-10-22 20:24:38,661:INFO:Starting cross validation
2025-10-22 20:24:38,668:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 20:24:58,238:INFO:Calculating mean and std
2025-10-22 20:24:58,239:INFO:Creating metrics dataframe
2025-10-22 20:24:58,243:INFO:Finalizing model
2025-10-22 20:25:02,801:INFO:Uploading results into container
2025-10-22 20:25:02,803:INFO:Uploading model into container now
2025-10-22 20:25:02,805:INFO:_master_model_container: 19
2025-10-22 20:25:02,805:INFO:_display_container: 4
2025-10-22 20:25:02,805:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 20:25:02,805:INFO:create_model() successfully completed......................................
2025-10-22 20:25:02,994:INFO:SubProcess create_model() end ==================================
2025-10-22 20:25:02,994:INFO:choose_better activated
2025-10-22 20:25:02,997:INFO:SubProcess create_model() called ==================================
2025-10-22 20:25:02,998:INFO:Initializing create_model()
2025-10-22 20:25:02,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 20:25:02,998:INFO:Checking exceptions
2025-10-22 20:25:03,001:INFO:Importing libraries
2025-10-22 20:25:03,002:INFO:Copying training dataset
2025-10-22 20:25:03,366:INFO:Defining folds
2025-10-22 20:25:03,366:INFO:Declaring metric variables
2025-10-22 20:25:03,366:INFO:Importing untrained model
2025-10-22 20:25:03,366:INFO:Declaring custom model
2025-10-22 20:25:03,366:INFO:Ridge Classifier Imported successfully
2025-10-22 20:25:03,367:INFO:Starting cross validation
2025-10-22 20:25:03,372:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 20:25:24,073:INFO:Calculating mean and std
2025-10-22 20:25:24,073:INFO:Creating metrics dataframe
2025-10-22 20:25:24,075:INFO:Finalizing model
2025-10-22 20:25:28,838:INFO:Uploading results into container
2025-10-22 20:25:28,839:INFO:Uploading model into container now
2025-10-22 20:25:28,839:INFO:_master_model_container: 20
2025-10-22 20:25:28,839:INFO:_display_container: 5
2025-10-22 20:25:28,839:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 20:25:28,840:INFO:create_model() successfully completed......................................
2025-10-22 20:25:29,007:INFO:SubProcess create_model() end ==================================
2025-10-22 20:25:29,008:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9215
2025-10-22 20:25:29,009:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) result for AUC is 0.9218
2025-10-22 20:25:29,009:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) is best model
2025-10-22 20:25:29,009:INFO:choose_better completed
2025-10-22 20:25:29,016:INFO:_master_model_container: 20
2025-10-22 20:25:29,016:INFO:_display_container: 4
2025-10-22 20:25:29,017:INFO:RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-22 20:25:29,017:INFO:tune_model() successfully completed......................................
2025-10-22 20:25:29,195:INFO:Initializing tune_model()
2025-10-22 20:25:29,195:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-22 20:25:29,195:INFO:Checking exceptions
2025-10-22 20:25:29,352:INFO:Copying training dataset
2025-10-22 20:25:29,625:INFO:Checking base model
2025-10-22 20:25:29,625:INFO:Base model : Linear Discriminant Analysis
2025-10-22 20:25:29,628:INFO:Declaring metric variables
2025-10-22 20:25:29,630:INFO:Defining Hyperparameters
2025-10-22 20:25:29,799:INFO:Tuning with n_jobs=1
2025-10-22 20:25:29,799:INFO:Initializing RandomizedSearchCV
2025-10-22 20:29:03,448:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 'auto'}
2025-10-22 20:29:03,449:INFO:Hyperparameter search completed
2025-10-22 20:29:03,450:INFO:SubProcess create_model() called ==================================
2025-10-22 20:29:03,451:INFO:Initializing create_model()
2025-10-22 20:29:03,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062AF099D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 'auto'})
2025-10-22 20:29:03,452:INFO:Checking exceptions
2025-10-22 20:29:03,452:INFO:Importing libraries
2025-10-22 20:29:03,452:INFO:Copying training dataset
2025-10-22 20:29:03,872:INFO:Defining folds
2025-10-22 20:29:03,873:INFO:Declaring metric variables
2025-10-22 20:29:03,877:INFO:Importing untrained model
2025-10-22 20:29:03,877:INFO:Declaring custom model
2025-10-22 20:29:03,881:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 20:29:03,890:INFO:Starting cross validation
2025-10-22 20:29:03,898:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 20:29:25,051:INFO:Calculating mean and std
2025-10-22 20:29:25,052:INFO:Creating metrics dataframe
2025-10-22 20:29:25,058:INFO:Finalizing model
2025-10-22 20:29:30,044:INFO:Uploading results into container
2025-10-22 20:29:30,045:INFO:Uploading model into container now
2025-10-22 20:29:30,045:INFO:_master_model_container: 21
2025-10-22 20:29:30,047:INFO:_display_container: 5
2025-10-22 20:29:30,047:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2025-10-22 20:29:30,048:INFO:create_model() successfully completed......................................
2025-10-22 20:29:30,226:INFO:SubProcess create_model() end ==================================
2025-10-22 20:29:30,226:INFO:choose_better activated
2025-10-22 20:29:30,229:INFO:SubProcess create_model() called ==================================
2025-10-22 20:29:30,230:INFO:Initializing create_model()
2025-10-22 20:29:30,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 20:29:30,230:INFO:Checking exceptions
2025-10-22 20:29:30,231:INFO:Importing libraries
2025-10-22 20:29:30,231:INFO:Copying training dataset
2025-10-22 20:29:30,616:INFO:Defining folds
2025-10-22 20:29:30,616:INFO:Declaring metric variables
2025-10-22 20:29:30,616:INFO:Importing untrained model
2025-10-22 20:29:30,616:INFO:Declaring custom model
2025-10-22 20:29:30,616:INFO:Linear Discriminant Analysis Imported successfully
2025-10-22 20:29:30,617:INFO:Starting cross validation
2025-10-22 20:29:30,623:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 20:29:54,536:INFO:Calculating mean and std
2025-10-22 20:29:54,536:INFO:Creating metrics dataframe
2025-10-22 20:29:54,538:INFO:Finalizing model
2025-10-22 20:30:00,077:INFO:Uploading results into container
2025-10-22 20:30:00,078:INFO:Uploading model into container now
2025-10-22 20:30:00,079:INFO:_master_model_container: 22
2025-10-22 20:30:00,079:INFO:_display_container: 6
2025-10-22 20:30:00,079:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 20:30:00,079:INFO:create_model() successfully completed......................................
2025-10-22 20:30:00,248:INFO:SubProcess create_model() end ==================================
2025-10-22 20:30:00,250:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9214
2025-10-22 20:30:00,251:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9214
2025-10-22 20:30:00,251:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2025-10-22 20:30:00,251:INFO:choose_better completed
2025-10-22 20:30:00,252:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-22 20:30:00,260:INFO:_master_model_container: 22
2025-10-22 20:30:00,260:INFO:_display_container: 5
2025-10-22 20:30:00,261:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-22 20:30:00,263:INFO:tune_model() successfully completed......................................
2025-10-22 20:30:00,449:INFO:Initializing blend_models()
2025-10-22 20:30:00,450:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-10-22 20:30:00,450:INFO:Checking exceptions
2025-10-22 20:30:00,450:INFO:Estimator RidgeClassifier(alpha=7.3, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2025-10-22 20:30:00,601:INFO:Importing libraries
2025-10-22 20:30:00,602:INFO:Copying training dataset
2025-10-22 20:30:00,606:INFO:Getting model names
2025-10-22 20:30:00,612:INFO:SubProcess create_model() called ==================================
2025-10-22 20:30:00,618:INFO:Initializing create_model()
2025-10-22 20:30:00,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002062A689050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 20:30:00,618:INFO:Checking exceptions
2025-10-22 20:30:00,618:INFO:Importing libraries
2025-10-22 20:30:00,618:INFO:Copying training dataset
2025-10-22 20:30:01,038:INFO:Defining folds
2025-10-22 20:30:01,038:INFO:Declaring metric variables
2025-10-22 20:30:01,042:INFO:Importing untrained model
2025-10-22 20:30:01,042:INFO:Declaring custom model
2025-10-22 20:30:01,046:INFO:Voting Classifier Imported successfully
2025-10-22 20:30:01,053:INFO:Starting cross validation
2025-10-22 20:30:01,060:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-22 20:30:30,818:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 20:31:00,965:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 20:31:31,523:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 20:32:02,596:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 20:32:33,667:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.


2025-10-22 20:32:33,700:INFO:Calculating mean and std
2025-10-22 20:32:33,702:INFO:Creating metrics dataframe
2025-10-22 20:32:33,707:INFO:Finalizing model
2025-10-22 20:33:13,804:INFO:Uploading results into container
2025-10-22 20:33:13,806:INFO:Uploading model into container now
2025-10-22 20:33:13,807:INFO:_master_model_container: 23
2025-10-22 20:33:13,807:INFO:_display_container: 6
2025-10-22 20:33:13,811:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-22 20:33:13,811:INFO:create_model() successfully completed......................................
2025-10-22 20:33:14,027:INFO:SubProcess create_model() end ==================================
2025-10-22 20:33:14,037:INFO:_master_model_container: 23
2025-10-22 20:33:14,038:INFO:_display_container: 6
2025-10-22 20:33:14,041:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-22 20:33:14,041:INFO:blend_models() successfully completed......................................
2025-10-22 20:33:14,226:INFO:Initializing finalize_model()
2025-10-22 20:33:14,226:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-10-22 20:33:14,229:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None)
2025-10-22 20:33:14,555:INFO:Initializing create_model()
2025-10-22 20:33:14,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                              copy_X=True, fit_intercept=False,
                                              max_iter=None, positive=False,
                                              random_state=42, solver='auto',
                                              tol=0.0001)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='hard',
                 weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
74123    U04452
20513    U07023
54794    U14666
77090    U07455
71177    U08938
Name: id_usuario, Length: 80004, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-10-22 20:33:14,555:INFO:Checking exceptions
2025-10-22 20:33:14,557:INFO:Importing libraries
2025-10-22 20:33:14,557:INFO:Copying training dataset
2025-10-22 20:33:14,608:INFO:Defining folds
2025-10-22 20:33:14,608:INFO:Declaring metric variables
2025-10-22 20:33:14,608:INFO:Importing untrained model
2025-10-22 20:33:14,608:INFO:Declaring custom model
2025-10-22 20:33:14,609:INFO:Voting Classifier Imported successfully
2025-10-22 20:33:14,615:INFO:Cross validation set to False
2025-10-22 20:33:14,615:INFO:Fitting Model
2025-10-22 20:34:08,066:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-22 20:34:08,066:INFO:create_model() successfully completed......................................
2025-10-22 20:34:08,234:INFO:_master_model_container: 23
2025-10-22 20:34:08,234:INFO:_display_container: 6
2025-10-22 20:34:08,257:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-22 20:34:08,257:INFO:finalize_model() successfully completed......................................
2025-10-22 20:34:08,440:INFO:Initializing save_model()
2025-10-22 20:34:08,440:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False), model_name=modelo_cls_like_v3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             '...
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-22 20:34:08,440:INFO:Adding model into prep_pipe
2025-10-22 20:34:08,440:WARNING:Only Model saved as it was a pipeline.
2025-10-22 20:34:08,480:INFO:modelo_cls_like_v3.pkl saved in current working directory
2025-10-22 20:34:08,500:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'frecuencia_viaje',
                                             'presupuesto_estimado',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'costo_entrada',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transf...
                                                               fit_intercept=False,
                                                               max_iter=None,
                                                               positive=False,
                                                               random_state=42,
                                                               solver='auto',
                                                               tol=0.0001)),
                                              ('Linear Discriminant Analysis',
                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                          n_components=None,
                                                                          priors=None,
                                                                          shrinkage=None,
                                                                          solver='svd',
                                                                          store_covariance=False,
                                                                          tol=0.0001))],
                                  flatten_transform=True, n_jobs=1,
                                  verbose=False, voting='hard',
                                  weights=None))],
         verbose=False)
2025-10-22 20:34:08,501:INFO:save_model() successfully completed......................................
2025-10-22 20:34:08,644:INFO:Initializing get_config()
2025-10-22 20:34:08,644:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 20:34:08,644:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 20:34:08,645:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 20:34:08,842:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 20:34:08,842:INFO:get_config() successfully completed......................................
2025-10-22 22:25:17,858:INFO:Initializing load_model()
2025-10-22 22:25:17,859:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:25:17,934:INFO:Initializing get_config()
2025-10-22 22:25:17,934:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:25:17,935:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:25:17,935:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:25:18,206:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:25:18,206:INFO:get_config() successfully completed......................................
2025-10-22 22:28:54,519:INFO:Initializing load_model()
2025-10-22 22:28:54,520:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:28:54,552:INFO:Initializing get_config()
2025-10-22 22:28:54,552:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:28:54,553:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:28:54,553:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:28:54,814:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:28:54,814:INFO:get_config() successfully completed......................................
2025-10-22 22:30:08,740:INFO:Initializing load_model()
2025-10-22 22:30:08,740:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:30:08,787:INFO:Initializing get_config()
2025-10-22 22:30:08,787:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:30:08,788:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:30:08,788:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:30:09,041:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:30:09,041:INFO:get_config() successfully completed......................................
2025-10-22 22:38:36,081:INFO:Initializing load_model()
2025-10-22 22:38:36,081:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:38:36,113:INFO:Initializing get_config()
2025-10-22 22:38:36,113:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:38:36,113:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:38:36,113:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:38:36,333:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:38:36,333:INFO:get_config() successfully completed......................................
2025-10-22 22:39:58,216:INFO:Initializing load_model()
2025-10-22 22:39:58,216:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:39:58,325:INFO:Initializing get_config()
2025-10-22 22:39:58,326:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:39:58,326:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:39:58,326:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:39:58,617:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:39:58,617:INFO:get_config() successfully completed......................................
2025-10-22 22:42:10,513:INFO:Initializing load_model()
2025-10-22 22:42:10,514:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:42:10,909:INFO:Initializing get_config()
2025-10-22 22:42:10,909:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:42:10,909:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:42:10,909:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:42:11,183:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:42:11,183:INFO:get_config() successfully completed......................................
2025-10-22 22:42:11,296:INFO:Initializing load_model()
2025-10-22 22:42:11,296:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:42:11,337:INFO:Initializing get_config()
2025-10-22 22:42:11,337:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:42:11,337:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:42:11,337:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:42:11,559:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:42:11,559:INFO:get_config() successfully completed......................................
2025-10-22 22:43:15,250:INFO:Initializing load_model()
2025-10-22 22:43:15,251:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:43:15,284:INFO:Initializing get_config()
2025-10-22 22:43:15,284:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:43:15,284:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:43:15,284:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:43:15,525:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:43:15,525:INFO:get_config() successfully completed......................................
2025-10-22 22:43:15,621:INFO:Initializing load_model()
2025-10-22 22:43:15,621:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:43:15,664:INFO:Initializing get_config()
2025-10-22 22:43:15,664:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:43:15,664:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:43:15,665:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:43:15,861:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:43:15,861:INFO:get_config() successfully completed......................................
2025-10-22 22:43:41,158:INFO:Initializing load_model()
2025-10-22 22:43:41,158:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:43:41,192:INFO:Initializing get_config()
2025-10-22 22:43:41,192:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:43:41,192:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:43:41,192:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:43:41,426:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:43:41,426:INFO:get_config() successfully completed......................................
2025-10-22 22:43:41,507:INFO:Initializing load_model()
2025-10-22 22:43:41,507:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:43:41,541:INFO:Initializing get_config()
2025-10-22 22:43:41,541:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:43:41,541:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:43:41,541:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:43:41,732:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:43:41,733:INFO:get_config() successfully completed......................................
2025-10-22 22:43:43,042:INFO:Initializing load_model()
2025-10-22 22:43:43,042:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:43:43,093:INFO:Initializing get_config()
2025-10-22 22:43:43,093:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:43:43,093:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:43:43,093:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:43:43,303:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:43:43,303:INFO:get_config() successfully completed......................................
2025-10-22 22:43:43,382:INFO:Initializing load_model()
2025-10-22 22:43:43,383:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:43:43,622:INFO:Initializing get_config()
2025-10-22 22:43:43,622:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:43:43,622:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:43:43,622:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:43:43,818:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:43:43,818:INFO:get_config() successfully completed......................................
2025-10-22 22:44:13,036:INFO:Initializing load_model()
2025-10-22 22:44:13,036:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:44:13,066:INFO:Initializing get_config()
2025-10-22 22:44:13,066:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:44:13,066:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:44:13,066:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:44:13,278:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:44:13,278:INFO:get_config() successfully completed......................................
2025-10-22 22:44:13,359:INFO:Initializing load_model()
2025-10-22 22:44:13,359:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:44:13,391:INFO:Initializing get_config()
2025-10-22 22:44:13,391:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:44:13,391:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:44:13,391:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:44:13,586:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:44:13,586:INFO:get_config() successfully completed......................................
2025-10-22 22:44:25,592:INFO:Initializing load_model()
2025-10-22 22:44:25,592:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:44:25,622:INFO:Initializing get_config()
2025-10-22 22:44:25,622:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:44:25,622:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:44:25,623:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:44:25,870:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:44:25,870:INFO:get_config() successfully completed......................................
2025-10-22 22:44:25,966:INFO:Initializing load_model()
2025-10-22 22:44:25,966:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:44:25,999:INFO:Initializing get_config()
2025-10-22 22:44:25,999:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:44:26,000:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:44:26,000:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:44:26,201:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:44:26,202:INFO:get_config() successfully completed......................................
2025-10-22 22:44:28,408:INFO:Initializing load_model()
2025-10-22 22:44:28,408:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:44:28,447:INFO:Initializing get_config()
2025-10-22 22:44:28,447:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:44:28,447:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:44:28,447:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:44:28,705:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:44:28,705:INFO:get_config() successfully completed......................................
2025-10-22 22:44:28,785:INFO:Initializing load_model()
2025-10-22 22:44:28,785:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:44:29,030:INFO:Initializing get_config()
2025-10-22 22:44:29,031:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:44:29,031:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:44:29,031:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:44:29,224:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:44:29,224:INFO:get_config() successfully completed......................................
2025-10-22 22:44:37,939:INFO:Initializing load_model()
2025-10-22 22:44:37,939:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:44:37,977:INFO:Initializing get_config()
2025-10-22 22:44:37,977:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:44:37,977:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:44:37,977:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:44:38,179:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:44:38,179:INFO:get_config() successfully completed......................................
2025-10-22 22:44:38,269:INFO:Initializing load_model()
2025-10-22 22:44:38,269:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:44:38,302:INFO:Initializing get_config()
2025-10-22 22:44:38,303:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:44:38,303:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:44:38,303:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:44:38,494:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:44:38,494:INFO:get_config() successfully completed......................................
2025-10-22 22:45:03,871:INFO:Initializing load_model()
2025-10-22 22:45:03,872:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:45:03,906:INFO:Initializing get_config()
2025-10-22 22:45:03,906:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:45:03,906:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:45:03,906:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:45:04,127:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:45:04,127:INFO:get_config() successfully completed......................................
2025-10-22 22:45:04,206:INFO:Initializing load_model()
2025-10-22 22:45:04,207:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:45:04,239:INFO:Initializing get_config()
2025-10-22 22:45:04,240:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:45:04,240:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:45:04,240:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:45:04,439:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:45:04,439:INFO:get_config() successfully completed......................................
2025-10-22 22:45:27,955:INFO:Initializing load_model()
2025-10-22 22:45:27,955:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:45:27,985:INFO:Initializing get_config()
2025-10-22 22:45:27,985:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:45:27,985:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:45:27,985:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:45:28,187:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:45:28,187:INFO:get_config() successfully completed......................................
2025-10-22 22:45:28,279:INFO:Initializing load_model()
2025-10-22 22:45:28,279:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:45:28,315:INFO:Initializing get_config()
2025-10-22 22:45:28,316:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:45:28,316:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:45:28,316:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:45:28,554:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:45:28,554:INFO:get_config() successfully completed......................................
2025-10-22 22:45:42,157:INFO:Initializing load_model()
2025-10-22 22:45:42,157:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:45:42,438:INFO:Initializing get_config()
2025-10-22 22:45:42,438:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:45:42,438:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:45:42,438:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:45:42,631:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:45:42,631:INFO:get_config() successfully completed......................................
2025-10-22 22:45:42,715:INFO:Initializing load_model()
2025-10-22 22:45:42,715:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:45:42,750:INFO:Initializing get_config()
2025-10-22 22:45:42,750:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:45:42,750:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:45:42,750:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:45:42,962:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:45:42,962:INFO:get_config() successfully completed......................................
2025-10-22 22:45:57,686:INFO:Initializing load_model()
2025-10-22 22:45:57,686:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:45:57,716:INFO:Initializing get_config()
2025-10-22 22:45:57,716:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:45:57,716:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:45:57,716:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:45:57,931:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:45:57,931:INFO:get_config() successfully completed......................................
2025-10-22 22:45:58,023:INFO:Initializing load_model()
2025-10-22 22:45:58,023:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:45:58,054:INFO:Initializing get_config()
2025-10-22 22:45:58,054:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:45:58,054:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:45:58,054:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:45:58,257:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:45:58,257:INFO:get_config() successfully completed......................................
2025-10-22 22:46:10,274:INFO:Initializing load_model()
2025-10-22 22:46:10,274:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:46:10,310:INFO:Initializing get_config()
2025-10-22 22:46:10,310:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:46:10,310:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:46:10,310:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:46:10,512:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:46:10,512:INFO:get_config() successfully completed......................................
2025-10-22 22:46:10,590:INFO:Initializing load_model()
2025-10-22 22:46:10,590:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:46:10,623:INFO:Initializing get_config()
2025-10-22 22:46:10,623:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:46:10,623:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:46:10,623:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:46:10,829:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:46:10,829:INFO:get_config() successfully completed......................................
2025-10-22 22:46:17,871:INFO:Initializing load_model()
2025-10-22 22:46:17,871:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:46:17,900:INFO:Initializing get_config()
2025-10-22 22:46:17,900:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:46:17,900:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:46:17,900:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:46:18,126:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:46:18,126:INFO:get_config() successfully completed......................................
2025-10-22 22:46:18,214:INFO:Initializing load_model()
2025-10-22 22:46:18,214:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:46:18,469:INFO:Initializing get_config()
2025-10-22 22:46:18,469:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:46:18,470:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:46:18,470:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:46:18,666:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:46:18,667:INFO:get_config() successfully completed......................................
2025-10-22 22:46:35,179:INFO:Initializing load_model()
2025-10-22 22:46:35,180:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:46:35,224:INFO:Initializing get_config()
2025-10-22 22:46:35,224:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:46:35,225:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:46:35,225:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:46:35,457:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:46:35,457:INFO:get_config() successfully completed......................................
2025-10-22 22:46:35,544:INFO:Initializing load_model()
2025-10-22 22:46:35,544:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:46:35,574:INFO:Initializing get_config()
2025-10-22 22:46:35,574:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:46:35,574:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:46:35,574:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:46:35,786:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:46:35,786:INFO:get_config() successfully completed......................................
2025-10-22 22:47:02,281:INFO:Initializing load_model()
2025-10-22 22:47:02,281:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:47:02,311:INFO:Initializing get_config()
2025-10-22 22:47:02,311:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:47:02,311:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:47:02,311:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:47:02,567:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:47:02,567:INFO:get_config() successfully completed......................................
2025-10-22 22:47:02,656:INFO:Initializing load_model()
2025-10-22 22:47:02,656:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:47:02,697:INFO:Initializing get_config()
2025-10-22 22:47:02,697:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:47:02,697:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:47:02,697:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:47:02,893:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:47:02,894:INFO:get_config() successfully completed......................................
2025-10-22 22:47:15,575:INFO:Initializing load_model()
2025-10-22 22:47:15,575:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:47:15,606:INFO:Initializing get_config()
2025-10-22 22:47:15,607:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:47:15,607:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:47:15,607:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:47:15,861:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:47:15,861:INFO:get_config() successfully completed......................................
2025-10-22 22:47:15,951:INFO:Initializing load_model()
2025-10-22 22:47:15,951:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:47:16,198:INFO:Initializing get_config()
2025-10-22 22:47:16,199:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:47:16,199:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:47:16,199:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:47:16,401:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:47:16,402:INFO:get_config() successfully completed......................................
2025-10-22 22:47:33,472:INFO:Initializing load_model()
2025-10-22 22:47:33,472:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:47:33,503:INFO:Initializing get_config()
2025-10-22 22:47:33,504:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:47:33,504:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:47:33,504:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:47:33,706:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:47:33,707:INFO:get_config() successfully completed......................................
2025-10-22 22:47:33,802:INFO:Initializing load_model()
2025-10-22 22:47:33,802:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:47:33,840:INFO:Initializing get_config()
2025-10-22 22:47:33,840:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:47:33,840:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:47:33,840:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:47:34,056:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:47:34,058:INFO:get_config() successfully completed......................................
2025-10-22 22:47:50,855:INFO:Initializing load_model()
2025-10-22 22:47:50,856:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:47:50,894:INFO:Initializing get_config()
2025-10-22 22:47:50,894:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:47:50,895:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:47:50,895:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:47:51,147:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:47:51,147:INFO:get_config() successfully completed......................................
2025-10-22 22:47:51,235:INFO:Initializing load_model()
2025-10-22 22:47:51,235:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:47:51,270:INFO:Initializing get_config()
2025-10-22 22:47:51,270:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:47:51,270:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:47:51,270:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:47:51,541:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:47:51,542:INFO:get_config() successfully completed......................................
2025-10-22 22:48:21,957:INFO:Initializing load_model()
2025-10-22 22:48:21,957:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:48:21,994:INFO:Initializing get_config()
2025-10-22 22:48:21,994:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:48:21,994:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:48:21,994:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:48:22,213:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:48:22,213:INFO:get_config() successfully completed......................................
2025-10-22 22:48:22,298:INFO:Initializing load_model()
2025-10-22 22:48:22,298:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:48:22,330:INFO:Initializing get_config()
2025-10-22 22:48:22,330:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:48:22,331:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:48:22,331:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:48:22,546:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:48:22,546:INFO:get_config() successfully completed......................................
2025-10-22 22:48:51,778:INFO:Initializing load_model()
2025-10-22 22:48:51,778:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:48:52,120:INFO:Initializing get_config()
2025-10-22 22:48:52,120:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:48:52,120:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:48:52,120:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:48:52,302:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:48:52,302:INFO:get_config() successfully completed......................................
2025-10-22 22:48:52,379:INFO:Initializing load_model()
2025-10-22 22:48:52,379:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:48:52,411:INFO:Initializing get_config()
2025-10-22 22:48:52,411:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:48:52,411:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:48:52,411:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:48:52,607:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:48:52,607:INFO:get_config() successfully completed......................................
2025-10-22 22:49:06,132:INFO:Initializing load_model()
2025-10-22 22:49:06,133:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:49:06,158:INFO:Initializing get_config()
2025-10-22 22:49:06,158:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:49:06,159:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:49:06,159:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:49:06,363:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:49:06,363:INFO:get_config() successfully completed......................................
2025-10-22 22:49:06,455:INFO:Initializing load_model()
2025-10-22 22:49:06,455:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:49:06,494:INFO:Initializing get_config()
2025-10-22 22:49:06,494:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:49:06,494:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:49:06,494:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:49:06,706:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:49:06,706:INFO:get_config() successfully completed......................................
2025-10-22 22:52:39,209:INFO:Initializing load_model()
2025-10-22 22:52:39,209:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:52:39,274:INFO:Initializing get_config()
2025-10-22 22:52:39,274:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:52:39,275:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:52:39,275:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:52:39,686:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:52:39,687:INFO:get_config() successfully completed......................................
2025-10-22 22:52:39,953:INFO:Initializing load_model()
2025-10-22 22:52:39,954:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:52:40,026:INFO:Initializing get_config()
2025-10-22 22:52:40,026:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:52:40,027:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:52:40,027:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:52:40,360:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:52:40,361:INFO:get_config() successfully completed......................................
2025-10-22 22:54:59,376:INFO:Initializing load_model()
2025-10-22 22:54:59,376:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:54:59,409:INFO:Initializing get_config()
2025-10-22 22:54:59,409:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:54:59,409:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:54:59,409:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:54:59,628:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:54:59,628:INFO:get_config() successfully completed......................................
2025-10-22 22:54:59,711:INFO:Initializing load_model()
2025-10-22 22:54:59,711:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:55:00,044:INFO:Initializing get_config()
2025-10-22 22:55:00,044:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:55:00,044:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:55:00,044:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:55:00,311:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:55:00,311:INFO:get_config() successfully completed......................................
2025-10-22 22:55:14,137:INFO:Initializing load_model()
2025-10-22 22:55:14,137:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:55:14,182:INFO:Initializing get_config()
2025-10-22 22:55:14,182:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:55:14,183:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:55:14,183:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:55:14,414:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:55:14,414:INFO:get_config() successfully completed......................................
2025-10-22 22:55:14,522:INFO:Initializing load_model()
2025-10-22 22:55:14,522:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:55:14,557:INFO:Initializing get_config()
2025-10-22 22:55:14,557:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:55:14,557:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:55:14,557:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:55:14,786:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:55:14,786:INFO:get_config() successfully completed......................................
2025-10-22 22:55:43,827:INFO:Initializing load_model()
2025-10-22 22:55:43,828:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:55:43,859:INFO:Initializing get_config()
2025-10-22 22:55:43,860:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:55:43,860:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:55:43,860:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:55:44,093:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:55:44,093:INFO:get_config() successfully completed......................................
2025-10-22 22:55:44,173:INFO:Initializing load_model()
2025-10-22 22:55:44,173:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:55:44,206:INFO:Initializing get_config()
2025-10-22 22:55:44,207:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:55:44,207:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:55:44,207:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:55:44,438:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:55:44,438:INFO:get_config() successfully completed......................................
2025-10-22 22:56:10,625:INFO:Initializing load_model()
2025-10-22 22:56:10,625:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:56:10,662:INFO:Initializing get_config()
2025-10-22 22:56:10,662:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:56:10,662:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:56:10,662:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:56:10,872:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:56:10,874:INFO:get_config() successfully completed......................................
2025-10-22 22:56:10,967:INFO:Initializing load_model()
2025-10-22 22:56:10,967:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 22:56:11,225:INFO:Initializing get_config()
2025-10-22 22:56:11,226:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 22:56:11,226:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 22:56:11,226:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 22:56:11,416:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 22:56:11,416:INFO:get_config() successfully completed......................................
2025-10-22 23:00:31,636:INFO:Initializing load_model()
2025-10-22 23:00:31,637:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 23:00:31,677:INFO:Initializing get_config()
2025-10-22 23:00:31,677:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 23:00:31,677:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 23:00:31,677:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 23:00:31,904:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 23:00:31,905:INFO:get_config() successfully completed......................................
2025-10-22 23:00:31,984:INFO:Initializing load_model()
2025-10-22 23:00:31,984:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-22 23:00:32,017:INFO:Initializing get_config()
2025-10-22 23:00:32,017:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002061F6A6450>, variable=X_train)
2025-10-22 23:00:32,017:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-10-22 23:00:32,017:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-10-22 23:00:32,247:INFO:Variable:  returned as       nacionalidad       origen tipo_turista_preferido compania_viaje  \
55839     Colombia       Cúcuta             naturaleza         pareja   
74143     Colombia       Boyacá               cultural           solo   
53722     Colombia  Bucaramanga               cultural        familia   
61548     Colombia       Boyacá               cultural         pareja   
74714     Colombia     Medellín               aventura         pareja   
...            ...          ...                    ...            ...   
28271     Colombia        Pasto             naturaleza        familia   
52847     Colombia  Bucaramanga               cultural         amigos   
33370     Colombia     Medellín               cultural         pareja   
38599     Colombia     Medellín               cultural           solo   
29387     Colombia     Sogamoso               cultural         amigos   

      restricciones_movilidad  \
55839                 ninguna   
74143                 ninguna   
53722                 ninguna   
61548                 ninguna   
74714                 ninguna   
...                       ...   
28271                 ninguna   
52847                 ninguna   
33370                 ninguna   
38599                 ninguna   
29387                 ninguna   

                                          nombre_sitio        tipo_sitio  \
55839                    Plaza Mayor de Villa de Leyva             plaza   
74143                  Parque Principal de Santa Sofía             museo   
53722                  Parque Principal de Santa Sofía             museo   
61548                      Centro Histórico de Sáchica  centro_historico   
74714                                  Museo Digitarte             museo   
...                                                ...               ...   
28271                   Sendero a la Laguna de Iguaque        senderismo   
52847  Parque Arqueológico de Monquirá (El Infiernito)      arqueologico   
33370            Caminos Reales (tramo Villa de Leyva)  centro_historico   
38599                                  Museo Digitarte             museo   
29387                         FIBAS Jardín de Desierto  centro_historico   

      accesibilidad_general idioma_info ubicacion_geografica  ...  \
55839                  alta          es       villa_de_leyva  ...   
74143                  alta          es          santa_sofia  ...   
53722                  alta          es          santa_sofia  ...   
61548                  alta          es              sachica  ...   
74714                  alta          es       villa_de_leyva  ...   
...                     ...         ...                  ...  ...   
28271                  alta          es       villa_de_leyva  ...   
52847                 media          es       villa_de_leyva  ...   
33370                 media       es/en       villa_de_leyva  ...   
38599                  alta          es       villa_de_leyva  ...   
29387                 media       es/en       villa_de_leyva  ...   

      presupuesto_estimado sitios_visitados calificacion_sitios_previos  \
55839             232070.0             14.0                         3.2   
74143             150000.0              8.0                         4.6   
53722             202974.0             13.0                         2.7   
61548             150000.0             13.0                         5.0   
74714             253659.0              3.0                         3.6   
...                    ...              ...                         ...   
28271             150000.0             16.0                         2.5   
52847             186552.0             27.0                         3.7   
33370             150000.0              6.0                         3.9   
38599             203906.0             11.0                         4.6   
29387             327967.0             19.0                         4.0   

      tiempo_estancia_promedio  costo_entrada  afluencia_promedio  \
55839                     35.0            0.0                 4.0   
74143                     76.0        12706.0                 4.0   
53722                     76.0        12706.0                 4.0   
61548                     57.0            0.0                 4.0   
74714                     48.0        11299.0                 4.0   
...                        ...            ...                 ...   
28271                    109.0         3245.0                 2.0   
52847                     42.0         9271.0                 2.0   
33370                     53.0         2433.0                 3.0   
38599                     86.0        11299.0                 4.0   
29387                     29.0         6771.0                 3.0   

       duracion_esperada  admite_mascotas  ratio_costo_presu  afinidad_tipo  
55839               22.0              1.0           0.000000           0.50  
74143              122.0              0.0           0.564711           0.90  
53722              122.0              0.0           0.417328           0.90  
61548               46.0              0.0           0.000000           0.90  
74714               61.0              0.0           0.296960           0.50  
...                  ...              ...                ...            ...  
28271              165.0              0.0           0.144222           0.90  
52847               62.0              0.0           0.331311           0.85  
33370               58.0              1.0           0.108133           0.90  
38599               61.0              0.0           0.369419           0.90  
29387               20.0              1.0           0.137636           0.90  

[56002 rows x 26 columns]
2025-10-22 23:00:32,247:INFO:get_config() successfully completed......................................
2025-10-23 09:00:36,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 09:00:36,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 09:00:36,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 09:00:36,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 09:01:21,696:INFO:Initializing load_model()
2025-10-23 09:01:21,696:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-23 09:03:22,734:INFO:Initializing load_model()
2025-10-23 09:03:22,735:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-23 09:08:47,679:INFO:Initializing load_model()
2025-10-23 09:08:47,679:INFO:load_model(model_name=modelo_cls_like_v3, platform=None, authentication=None, verbose=True)
2025-10-23 10:28:10,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 10:28:10,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 10:28:10,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 10:28:10,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 10:30:26,545:INFO:PyCaret ClassificationExperiment
2025-10-23 10:30:26,545:INFO:Logging name: clf-default-name
2025-10-23 10:30:26,545:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-23 10:30:26,545:INFO:version 3.3.2
2025-10-23 10:30:26,545:INFO:Initializing setup()
2025-10-23 10:30:26,545:INFO:self.USI: 57ce
2025-10-23 10:30:26,545:INFO:self._variable_keys: {'X', 'n_jobs_param', 'gpu_n_jobs_param', 'is_multiclass', 'idx', 'log_plots_param', 'target_param', 'USI', 'data', 'html_param', 'pipeline', 'seed', 'logging_param', 'fold_shuffle_param', 'X_train', 'exp_name_log', 'y_train', 'exp_id', 'memory', '_available_plots', 'fold_groups_param', 'y', 'fix_imbalance', 'X_test', 'fold_generator', '_ml_usecase', 'gpu_param', 'y_test'}
2025-10-23 10:30:26,545:INFO:Checking environment
2025-10-23 10:30:26,545:INFO:python_version: 3.11.13
2025-10-23 10:30:26,545:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-23 10:30:26,545:INFO:machine: AMD64
2025-10-23 10:30:26,545:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-23 10:30:26,549:INFO:Memory: svmem(total=16856211456, available=3663450112, percent=78.3, used=13192761344, free=3663450112)
2025-10-23 10:30:26,550:INFO:Physical Core: 4
2025-10-23 10:30:26,550:INFO:Logical Core: 8
2025-10-23 10:30:26,550:INFO:Checking libraries
2025-10-23 10:30:26,550:INFO:System:
2025-10-23 10:30:26,550:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-23 10:30:26,550:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-23 10:30:26,550:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-23 10:30:26,550:INFO:PyCaret required dependencies:
2025-10-23 10:30:29,344:INFO:                 pip: 25.2
2025-10-23 10:30:29,344:INFO:          setuptools: 80.9.0
2025-10-23 10:30:29,344:INFO:             pycaret: 3.3.2
2025-10-23 10:30:29,344:INFO:             IPython: 9.6.0
2025-10-23 10:30:29,344:INFO:          ipywidgets: 8.1.7
2025-10-23 10:30:29,344:INFO:                tqdm: 4.67.1
2025-10-23 10:30:29,344:INFO:               numpy: 1.26.4
2025-10-23 10:30:29,344:INFO:              pandas: 2.1.4
2025-10-23 10:30:29,344:INFO:              jinja2: 3.1.6
2025-10-23 10:30:29,344:INFO:               scipy: 1.11.4
2025-10-23 10:30:29,345:INFO:              joblib: 1.3.2
2025-10-23 10:30:29,345:INFO:             sklearn: 1.4.2
2025-10-23 10:30:29,345:INFO:                pyod: 2.0.5
2025-10-23 10:30:29,345:INFO:            imblearn: 0.14.0
2025-10-23 10:30:29,345:INFO:   category_encoders: 2.7.0
2025-10-23 10:30:29,345:INFO:            lightgbm: 4.6.0
2025-10-23 10:30:29,345:INFO:               numba: 0.61.0
2025-10-23 10:30:29,345:INFO:            requests: 2.32.5
2025-10-23 10:30:29,345:INFO:          matplotlib: 3.7.5
2025-10-23 10:30:29,345:INFO:          scikitplot: 0.3.7
2025-10-23 10:30:29,345:INFO:         yellowbrick: 1.5
2025-10-23 10:30:29,345:INFO:              plotly: 5.24.1
2025-10-23 10:30:29,345:INFO:    plotly-resampler: Not installed
2025-10-23 10:30:29,345:INFO:             kaleido: 1.1.0
2025-10-23 10:30:29,345:INFO:           schemdraw: 0.15
2025-10-23 10:30:29,345:INFO:         statsmodels: 0.14.5
2025-10-23 10:30:29,345:INFO:              sktime: 0.26.0
2025-10-23 10:30:29,345:INFO:               tbats: 1.1.3
2025-10-23 10:30:29,345:INFO:            pmdarima: 2.0.4
2025-10-23 10:30:29,345:INFO:              psutil: 7.1.1
2025-10-23 10:30:29,345:INFO:          markupsafe: 3.0.3
2025-10-23 10:30:29,345:INFO:             pickle5: Not installed
2025-10-23 10:30:29,345:INFO:         cloudpickle: 3.1.1
2025-10-23 10:30:29,345:INFO:         deprecation: 2.1.0
2025-10-23 10:30:29,345:INFO:              xxhash: 3.6.0
2025-10-23 10:30:29,345:INFO:           wurlitzer: Not installed
2025-10-23 10:30:29,345:INFO:PyCaret optional dependencies:
2025-10-23 10:30:42,427:INFO:                shap: 0.44.1
2025-10-23 10:30:42,427:INFO:           interpret: 0.7.3
2025-10-23 10:30:42,427:INFO:                umap: 0.5.7
2025-10-23 10:30:42,427:INFO:     ydata_profiling: 4.17.0
2025-10-23 10:30:42,427:INFO:  explainerdashboard: 0.5.1
2025-10-23 10:30:42,427:INFO:             autoviz: Not installed
2025-10-23 10:30:42,427:INFO:           fairlearn: 0.7.0
2025-10-23 10:30:42,427:INFO:          deepchecks: Not installed
2025-10-23 10:30:42,427:INFO:             xgboost: 3.1.0
2025-10-23 10:30:42,427:INFO:            catboost: 1.2.8
2025-10-23 10:30:42,427:INFO:              kmodes: 0.12.2
2025-10-23 10:30:42,427:INFO:             mlxtend: 0.23.4
2025-10-23 10:30:42,427:INFO:       statsforecast: 1.5.0
2025-10-23 10:30:42,427:INFO:        tune_sklearn: Not installed
2025-10-23 10:30:42,427:INFO:                 ray: Not installed
2025-10-23 10:30:42,427:INFO:            hyperopt: 0.2.7
2025-10-23 10:30:42,427:INFO:              optuna: 4.5.0
2025-10-23 10:30:42,427:INFO:               skopt: 0.10.2
2025-10-23 10:30:42,427:INFO:              mlflow: 3.5.0
2025-10-23 10:30:42,427:INFO:              gradio: 5.49.1
2025-10-23 10:30:42,427:INFO:             fastapi: 0.119.1
2025-10-23 10:30:42,427:INFO:             uvicorn: 0.38.0
2025-10-23 10:30:42,427:INFO:              m2cgen: 0.10.0
2025-10-23 10:30:42,428:INFO:           evidently: 0.4.40
2025-10-23 10:30:42,428:INFO:               fugue: 0.8.7
2025-10-23 10:30:42,428:INFO:           streamlit: Not installed
2025-10-23 10:30:42,428:INFO:             prophet: Not installed
2025-10-23 10:30:42,428:INFO:None
2025-10-23 10:30:42,428:INFO:Set up data.
2025-10-23 10:30:42,611:INFO:Set up folding strategy.
2025-10-23 10:32:01,052:INFO:PyCaret ClassificationExperiment
2025-10-23 10:32:01,052:INFO:Logging name: clf-default-name
2025-10-23 10:32:01,052:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-23 10:32:01,052:INFO:version 3.3.2
2025-10-23 10:32:01,052:INFO:Initializing setup()
2025-10-23 10:32:01,052:INFO:self.USI: da48
2025-10-23 10:32:01,052:INFO:self._variable_keys: {'X', 'n_jobs_param', 'gpu_n_jobs_param', 'is_multiclass', 'idx', 'log_plots_param', 'target_param', 'USI', 'data', 'html_param', 'pipeline', 'seed', 'logging_param', 'fold_shuffle_param', 'X_train', 'exp_name_log', 'y_train', 'exp_id', 'memory', '_available_plots', 'fold_groups_param', 'y', 'fix_imbalance', 'X_test', 'fold_generator', '_ml_usecase', 'gpu_param', 'y_test'}
2025-10-23 10:32:01,052:INFO:Checking environment
2025-10-23 10:32:01,052:INFO:python_version: 3.11.13
2025-10-23 10:32:01,053:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-23 10:32:01,053:INFO:machine: AMD64
2025-10-23 10:32:01,053:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-23 10:32:01,057:INFO:Memory: svmem(total=16856211456, available=3508146176, percent=79.2, used=13348065280, free=3508146176)
2025-10-23 10:32:01,057:INFO:Physical Core: 4
2025-10-23 10:32:01,057:INFO:Logical Core: 8
2025-10-23 10:32:01,057:INFO:Checking libraries
2025-10-23 10:32:01,057:INFO:System:
2025-10-23 10:32:01,057:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-23 10:32:01,057:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-23 10:32:01,057:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-23 10:32:01,057:INFO:PyCaret required dependencies:
2025-10-23 10:32:01,057:INFO:                 pip: 25.2
2025-10-23 10:32:01,057:INFO:          setuptools: 80.9.0
2025-10-23 10:32:01,058:INFO:             pycaret: 3.3.2
2025-10-23 10:32:01,058:INFO:             IPython: 9.6.0
2025-10-23 10:32:01,058:INFO:          ipywidgets: 8.1.7
2025-10-23 10:32:01,058:INFO:                tqdm: 4.67.1
2025-10-23 10:32:01,058:INFO:               numpy: 1.26.4
2025-10-23 10:32:01,058:INFO:              pandas: 2.1.4
2025-10-23 10:32:01,058:INFO:              jinja2: 3.1.6
2025-10-23 10:32:01,058:INFO:               scipy: 1.11.4
2025-10-23 10:32:01,058:INFO:              joblib: 1.3.2
2025-10-23 10:32:01,058:INFO:             sklearn: 1.4.2
2025-10-23 10:32:01,058:INFO:                pyod: 2.0.5
2025-10-23 10:32:01,058:INFO:            imblearn: 0.14.0
2025-10-23 10:32:01,058:INFO:   category_encoders: 2.7.0
2025-10-23 10:32:01,058:INFO:            lightgbm: 4.6.0
2025-10-23 10:32:01,058:INFO:               numba: 0.61.0
2025-10-23 10:32:01,058:INFO:            requests: 2.32.5
2025-10-23 10:32:01,058:INFO:          matplotlib: 3.7.5
2025-10-23 10:32:01,058:INFO:          scikitplot: 0.3.7
2025-10-23 10:32:01,058:INFO:         yellowbrick: 1.5
2025-10-23 10:32:01,058:INFO:              plotly: 5.24.1
2025-10-23 10:32:01,058:INFO:    plotly-resampler: Not installed
2025-10-23 10:32:01,058:INFO:             kaleido: 1.1.0
2025-10-23 10:32:01,058:INFO:           schemdraw: 0.15
2025-10-23 10:32:01,058:INFO:         statsmodels: 0.14.5
2025-10-23 10:32:01,058:INFO:              sktime: 0.26.0
2025-10-23 10:32:01,058:INFO:               tbats: 1.1.3
2025-10-23 10:32:01,058:INFO:            pmdarima: 2.0.4
2025-10-23 10:32:01,058:INFO:              psutil: 7.1.1
2025-10-23 10:32:01,058:INFO:          markupsafe: 3.0.3
2025-10-23 10:32:01,058:INFO:             pickle5: Not installed
2025-10-23 10:32:01,058:INFO:         cloudpickle: 3.1.1
2025-10-23 10:32:01,058:INFO:         deprecation: 2.1.0
2025-10-23 10:32:01,058:INFO:              xxhash: 3.6.0
2025-10-23 10:32:01,059:INFO:           wurlitzer: Not installed
2025-10-23 10:32:01,059:INFO:PyCaret optional dependencies:
2025-10-23 10:32:01,059:INFO:                shap: 0.44.1
2025-10-23 10:32:01,059:INFO:           interpret: 0.7.3
2025-10-23 10:32:01,059:INFO:                umap: 0.5.7
2025-10-23 10:32:01,059:INFO:     ydata_profiling: 4.17.0
2025-10-23 10:32:01,059:INFO:  explainerdashboard: 0.5.1
2025-10-23 10:32:01,059:INFO:             autoviz: Not installed
2025-10-23 10:32:01,059:INFO:           fairlearn: 0.7.0
2025-10-23 10:32:01,059:INFO:          deepchecks: Not installed
2025-10-23 10:32:01,059:INFO:             xgboost: 3.1.0
2025-10-23 10:32:01,059:INFO:            catboost: 1.2.8
2025-10-23 10:32:01,059:INFO:              kmodes: 0.12.2
2025-10-23 10:32:01,059:INFO:             mlxtend: 0.23.4
2025-10-23 10:32:01,059:INFO:       statsforecast: 1.5.0
2025-10-23 10:32:01,059:INFO:        tune_sklearn: Not installed
2025-10-23 10:32:01,059:INFO:                 ray: Not installed
2025-10-23 10:32:01,059:INFO:            hyperopt: 0.2.7
2025-10-23 10:32:01,059:INFO:              optuna: 4.5.0
2025-10-23 10:32:01,059:INFO:               skopt: 0.10.2
2025-10-23 10:32:01,059:INFO:              mlflow: 3.5.0
2025-10-23 10:32:01,059:INFO:              gradio: 5.49.1
2025-10-23 10:32:01,059:INFO:             fastapi: 0.119.1
2025-10-23 10:32:01,059:INFO:             uvicorn: 0.38.0
2025-10-23 10:32:01,059:INFO:              m2cgen: 0.10.0
2025-10-23 10:32:01,059:INFO:           evidently: 0.4.40
2025-10-23 10:32:01,060:INFO:               fugue: 0.8.7
2025-10-23 10:32:01,060:INFO:           streamlit: Not installed
2025-10-23 10:32:01,060:INFO:             prophet: Not installed
2025-10-23 10:32:01,060:INFO:None
2025-10-23 10:32:01,060:INFO:Set up data.
2025-10-23 10:32:01,251:INFO:Set up folding strategy.
2025-10-23 10:32:01,482:INFO:Set up train/test split.
2025-10-23 10:32:01,791:INFO:Set up index.
2025-10-23 10:32:01,813:INFO:Assigning column types.
2025-10-23 10:32:02,103:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-23 10:32:02,139:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-23 10:32:02,151:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 10:32:02,214:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:32:02,216:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:32:02,929:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-23 10:32:02,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 10:32:02,960:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:32:02,963:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:32:02,964:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-23 10:32:03,002:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 10:32:03,028:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:32:03,031:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:32:03,070:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 10:32:03,095:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:32:03,098:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:32:03,099:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-23 10:32:03,169:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:32:03,172:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:32:03,244:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:32:03,246:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:32:03,250:INFO:Preparing preprocessing pipeline...
2025-10-23 10:32:03,307:INFO:Set up simple imputation.
2025-10-23 10:32:03,555:INFO:Set up encoding of categorical features.
2025-10-23 10:32:03,564:INFO:Set up removing multicollinearity.
2025-10-23 10:32:03,564:INFO:Set up imbalanced handling.
2025-10-23 10:32:07,877:INFO:Finished creating preprocessing pipeline.
2025-10-23 10:32:07,886:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'presupuesto_estimado',
                                             'costo_entrada', 'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              mi...
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-10-23 10:32:07,886:INFO:Creating final display dataframe.
2025-10-23 10:32:13,937:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 19)
4        Transformed data shape       (98746, 83)
5   Transformed train set shape       (74744, 83)
6    Transformed test set shape       (24002, 83)
7               Ignore features                 1
8              Numeric features                 6
9          Categorical features                11
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation     most_frequent
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20               Fold Generator        GroupKFold
21                  Fold Number                 2
22                     CPU Jobs                 1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              da48
2025-10-23 10:32:13,990:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:32:13,992:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:32:14,052:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:32:14,054:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:32:14,056:INFO:setup() successfully completed in 13.2s...............
2025-10-23 10:32:14,056:INFO:gpu_param set to False
2025-10-23 10:32:14,109:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:32:14,111:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:32:14,167:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:32:14,170:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:32:14,171:INFO:Initializing compare_models()
2025-10-23 10:32:14,171:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015735B48E10>, include=['gbc', 'ridge', 'lda', 'lightgbm', 'ada', 'catboost', 'xgboost'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000015735B48E10>, 'include': ['gbc', 'ridge', 'lda', 'lightgbm', 'ada', 'catboost', 'xgboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-23 10:32:14,171:INFO:Checking exceptions
2025-10-23 10:32:14,366:INFO:Preparing display monitor
2025-10-23 10:32:14,390:INFO:Initializing Gradient Boosting Classifier
2025-10-23 10:32:14,390:INFO:Total runtime is 0.0 minutes
2025-10-23 10:32:14,395:INFO:SubProcess create_model() called ==================================
2025-10-23 10:32:14,397:INFO:Initializing create_model()
2025-10-23 10:32:14,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015735B48E10>, estimator=gbc, fold=GroupKFold(n_splits=2), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015738B01550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:32:14,397:INFO:Checking exceptions
2025-10-23 10:32:14,398:INFO:Importing libraries
2025-10-23 10:32:14,398:INFO:Copying training dataset
2025-10-23 10:32:14,721:INFO:Defining folds
2025-10-23 10:32:14,722:INFO:Declaring metric variables
2025-10-23 10:32:14,724:INFO:Importing untrained model
2025-10-23 10:32:14,726:INFO:Gradient Boosting Classifier Imported successfully
2025-10-23 10:32:14,733:INFO:Starting cross validation
2025-10-23 10:32:14,739:INFO:Cross validating with GroupKFold(n_splits=2), n_jobs=1
2025-10-23 10:32:41,340:INFO:Calculating mean and std
2025-10-23 10:32:41,341:INFO:Creating metrics dataframe
2025-10-23 10:32:41,344:INFO:Uploading results into container
2025-10-23 10:32:41,345:INFO:Uploading model into container now
2025-10-23 10:32:41,345:INFO:_master_model_container: 1
2025-10-23 10:32:41,345:INFO:_display_container: 2
2025-10-23 10:32:41,345:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-23 10:32:41,345:INFO:create_model() successfully completed......................................
2025-10-23 10:32:41,521:INFO:SubProcess create_model() end ==================================
2025-10-23 10:32:41,522:INFO:Creating metrics dataframe
2025-10-23 10:32:41,528:INFO:Initializing Ridge Classifier
2025-10-23 10:32:41,528:INFO:Total runtime is 0.4522899270057678 minutes
2025-10-23 10:32:41,530:INFO:SubProcess create_model() called ==================================
2025-10-23 10:32:41,531:INFO:Initializing create_model()
2025-10-23 10:32:41,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015735B48E10>, estimator=ridge, fold=GroupKFold(n_splits=2), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015738B01550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:32:41,532:INFO:Checking exceptions
2025-10-23 10:32:41,532:INFO:Importing libraries
2025-10-23 10:32:41,532:INFO:Copying training dataset
2025-10-23 10:32:41,838:INFO:Defining folds
2025-10-23 10:32:41,839:INFO:Declaring metric variables
2025-10-23 10:32:41,843:INFO:Importing untrained model
2025-10-23 10:32:41,846:INFO:Ridge Classifier Imported successfully
2025-10-23 10:32:41,854:INFO:Starting cross validation
2025-10-23 10:32:41,859:INFO:Cross validating with GroupKFold(n_splits=2), n_jobs=1
2025-10-23 10:32:46,838:INFO:Calculating mean and std
2025-10-23 10:32:46,840:INFO:Creating metrics dataframe
2025-10-23 10:32:46,842:INFO:Uploading results into container
2025-10-23 10:32:46,843:INFO:Uploading model into container now
2025-10-23 10:32:46,844:INFO:_master_model_container: 2
2025-10-23 10:32:46,844:INFO:_display_container: 2
2025-10-23 10:32:46,844:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-23 10:32:46,845:INFO:create_model() successfully completed......................................
2025-10-23 10:32:47,021:INFO:SubProcess create_model() end ==================================
2025-10-23 10:32:47,021:INFO:Creating metrics dataframe
2025-10-23 10:32:47,025:INFO:Initializing Linear Discriminant Analysis
2025-10-23 10:32:47,025:INFO:Total runtime is 0.543911592165629 minutes
2025-10-23 10:32:47,027:INFO:SubProcess create_model() called ==================================
2025-10-23 10:32:47,029:INFO:Initializing create_model()
2025-10-23 10:32:47,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015735B48E10>, estimator=lda, fold=GroupKFold(n_splits=2), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015738B01550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:32:47,029:INFO:Checking exceptions
2025-10-23 10:32:47,029:INFO:Importing libraries
2025-10-23 10:32:47,029:INFO:Copying training dataset
2025-10-23 10:32:47,329:INFO:Defining folds
2025-10-23 10:32:47,330:INFO:Declaring metric variables
2025-10-23 10:32:47,333:INFO:Importing untrained model
2025-10-23 10:32:47,338:INFO:Linear Discriminant Analysis Imported successfully
2025-10-23 10:32:47,344:INFO:Starting cross validation
2025-10-23 10:32:47,350:INFO:Cross validating with GroupKFold(n_splits=2), n_jobs=1
2025-10-23 10:32:52,841:INFO:Calculating mean and std
2025-10-23 10:32:52,842:INFO:Creating metrics dataframe
2025-10-23 10:32:52,844:INFO:Uploading results into container
2025-10-23 10:32:52,845:INFO:Uploading model into container now
2025-10-23 10:32:52,845:INFO:_master_model_container: 3
2025-10-23 10:32:52,845:INFO:_display_container: 2
2025-10-23 10:32:52,846:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-23 10:32:52,846:INFO:create_model() successfully completed......................................
2025-10-23 10:32:53,016:INFO:SubProcess create_model() end ==================================
2025-10-23 10:32:53,016:INFO:Creating metrics dataframe
2025-10-23 10:32:53,022:INFO:Initializing Light Gradient Boosting Machine
2025-10-23 10:32:53,023:INFO:Total runtime is 0.6438751180966694 minutes
2025-10-23 10:32:53,026:INFO:SubProcess create_model() called ==================================
2025-10-23 10:32:53,027:INFO:Initializing create_model()
2025-10-23 10:32:53,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015735B48E10>, estimator=lightgbm, fold=GroupKFold(n_splits=2), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015738B01550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:32:53,027:INFO:Checking exceptions
2025-10-23 10:32:53,027:INFO:Importing libraries
2025-10-23 10:32:53,027:INFO:Copying training dataset
2025-10-23 10:32:53,338:INFO:Defining folds
2025-10-23 10:32:53,339:INFO:Declaring metric variables
2025-10-23 10:32:53,342:INFO:Importing untrained model
2025-10-23 10:32:53,346:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-23 10:32:53,354:INFO:Starting cross validation
2025-10-23 10:32:53,360:INFO:Cross validating with GroupKFold(n_splits=2), n_jobs=1
2025-10-23 10:32:55,340:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-23 10:32:55,362:INFO:[LightGBM] [Info] Number of positive: 18695, number of negative: 18695
2025-10-23 10:32:55,438:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027448 seconds.
2025-10-23 10:32:55,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-23 10:32:55,438:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-23 10:32:55,438:INFO:[LightGBM] [Info] Total Bins 18811
2025-10-23 10:32:55,444:INFO:[LightGBM] [Info] Number of data points in the train set: 37390, number of used features: 82
2025-10-23 10:32:55,460:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-23 10:32:58,867:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-23 10:32:58,870:INFO:[LightGBM] [Info] Number of positive: 18677, number of negative: 18677
2025-10-23 10:32:58,908:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017893 seconds.
2025-10-23 10:32:58,909:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-23 10:32:58,909:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-23 10:32:58,909:INFO:[LightGBM] [Info] Total Bins 18618
2025-10-23 10:32:58,910:INFO:[LightGBM] [Info] Number of data points in the train set: 37354, number of used features: 82
2025-10-23 10:32:58,910:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-23 10:33:00,406:INFO:Calculating mean and std
2025-10-23 10:33:00,407:INFO:Creating metrics dataframe
2025-10-23 10:33:00,409:INFO:Uploading results into container
2025-10-23 10:33:00,410:INFO:Uploading model into container now
2025-10-23 10:33:00,410:INFO:_master_model_container: 4
2025-10-23 10:33:00,410:INFO:_display_container: 2
2025-10-23 10:33:00,411:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-23 10:33:00,411:INFO:create_model() successfully completed......................................
2025-10-23 10:33:00,577:INFO:SubProcess create_model() end ==================================
2025-10-23 10:33:00,578:INFO:Creating metrics dataframe
2025-10-23 10:33:00,587:INFO:Initializing Ada Boost Classifier
2025-10-23 10:33:00,587:INFO:Total runtime is 0.7699390014012654 minutes
2025-10-23 10:33:00,590:INFO:SubProcess create_model() called ==================================
2025-10-23 10:33:00,592:INFO:Initializing create_model()
2025-10-23 10:33:00,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015735B48E10>, estimator=ada, fold=GroupKFold(n_splits=2), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015738B01550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:33:00,592:INFO:Checking exceptions
2025-10-23 10:33:00,593:INFO:Importing libraries
2025-10-23 10:33:00,593:INFO:Copying training dataset
2025-10-23 10:33:00,919:INFO:Defining folds
2025-10-23 10:33:00,919:INFO:Declaring metric variables
2025-10-23 10:33:00,922:INFO:Importing untrained model
2025-10-23 10:33:00,927:INFO:Ada Boost Classifier Imported successfully
2025-10-23 10:33:00,934:INFO:Starting cross validation
2025-10-23 10:33:00,942:INFO:Cross validating with GroupKFold(n_splits=2), n_jobs=1
2025-10-23 10:33:02,598:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 10:33:08,457:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 10:33:12,639:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 10:33:12,662:INFO:Calculating mean and std
2025-10-23 10:33:12,663:INFO:Creating metrics dataframe
2025-10-23 10:33:12,665:INFO:Uploading results into container
2025-10-23 10:33:12,665:INFO:Uploading model into container now
2025-10-23 10:33:12,666:INFO:_master_model_container: 5
2025-10-23 10:33:12,666:INFO:_display_container: 2
2025-10-23 10:33:12,666:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-23 10:33:12,666:INFO:create_model() successfully completed......................................
2025-10-23 10:33:12,829:INFO:SubProcess create_model() end ==================================
2025-10-23 10:33:12,829:INFO:Creating metrics dataframe
2025-10-23 10:33:12,835:INFO:Initializing CatBoost Classifier
2025-10-23 10:33:12,836:INFO:Total runtime is 0.9740907748540242 minutes
2025-10-23 10:33:12,841:INFO:SubProcess create_model() called ==================================
2025-10-23 10:33:12,842:INFO:Initializing create_model()
2025-10-23 10:33:12,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015735B48E10>, estimator=catboost, fold=GroupKFold(n_splits=2), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015738B01550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:33:12,842:INFO:Checking exceptions
2025-10-23 10:33:12,842:INFO:Importing libraries
2025-10-23 10:33:12,842:INFO:Copying training dataset
2025-10-23 10:33:13,139:INFO:Defining folds
2025-10-23 10:33:13,140:INFO:Declaring metric variables
2025-10-23 10:33:13,143:INFO:Importing untrained model
2025-10-23 10:33:13,147:INFO:CatBoost Classifier Imported successfully
2025-10-23 10:33:13,155:INFO:Starting cross validation
2025-10-23 10:33:13,160:INFO:Cross validating with GroupKFold(n_splits=2), n_jobs=1
2025-10-23 10:36:10,354:INFO:Calculating mean and std
2025-10-23 10:36:10,357:INFO:Creating metrics dataframe
2025-10-23 10:36:10,362:INFO:Uploading results into container
2025-10-23 10:36:10,364:INFO:Uploading model into container now
2025-10-23 10:36:10,365:INFO:_master_model_container: 6
2025-10-23 10:36:10,365:INFO:_display_container: 2
2025-10-23 10:36:10,366:INFO:<catboost.core.CatBoostClassifier object at 0x00000157342A4490>
2025-10-23 10:36:10,366:INFO:create_model() successfully completed......................................
2025-10-23 10:36:10,652:INFO:SubProcess create_model() end ==================================
2025-10-23 10:36:10,652:INFO:Creating metrics dataframe
2025-10-23 10:36:10,661:INFO:Initializing Extreme Gradient Boosting
2025-10-23 10:36:10,661:INFO:Total runtime is 3.9378419121106463 minutes
2025-10-23 10:36:10,669:INFO:SubProcess create_model() called ==================================
2025-10-23 10:36:10,671:INFO:Initializing create_model()
2025-10-23 10:36:10,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015735B48E10>, estimator=xgboost, fold=GroupKFold(n_splits=2), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015738B01550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:36:10,672:INFO:Checking exceptions
2025-10-23 10:36:10,672:INFO:Importing libraries
2025-10-23 10:36:10,672:INFO:Copying training dataset
2025-10-23 10:36:11,259:INFO:Defining folds
2025-10-23 10:36:11,259:INFO:Declaring metric variables
2025-10-23 10:36:11,267:INFO:Importing untrained model
2025-10-23 10:36:11,275:INFO:Extreme Gradient Boosting Imported successfully
2025-10-23 10:36:11,285:INFO:Starting cross validation
2025-10-23 10:36:11,293:INFO:Cross validating with GroupKFold(n_splits=2), n_jobs=1
2025-10-23 10:36:23,669:INFO:Calculating mean and std
2025-10-23 10:36:23,672:INFO:Creating metrics dataframe
2025-10-23 10:36:23,677:INFO:Uploading results into container
2025-10-23 10:36:23,679:INFO:Uploading model into container now
2025-10-23 10:36:23,681:INFO:_master_model_container: 7
2025-10-23 10:36:23,682:INFO:_display_container: 2
2025-10-23 10:36:23,683:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-10-23 10:36:23,683:INFO:create_model() successfully completed......................................
2025-10-23 10:36:23,873:INFO:SubProcess create_model() end ==================================
2025-10-23 10:36:23,873:INFO:Creating metrics dataframe
2025-10-23 10:36:23,882:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-10-23 10:36:23,892:INFO:Initializing create_model()
2025-10-23 10:36:23,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015735B48E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=GroupKFold(n_splits=2), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:36:23,893:INFO:Checking exceptions
2025-10-23 10:36:23,895:INFO:Importing libraries
2025-10-23 10:36:23,895:INFO:Copying training dataset
2025-10-23 10:36:24,237:INFO:Defining folds
2025-10-23 10:36:24,237:INFO:Declaring metric variables
2025-10-23 10:36:24,237:INFO:Importing untrained model
2025-10-23 10:36:24,237:INFO:Declaring custom model
2025-10-23 10:36:24,238:INFO:Gradient Boosting Classifier Imported successfully
2025-10-23 10:36:24,242:INFO:Cross validation set to False
2025-10-23 10:36:24,242:INFO:Fitting Model
2025-10-23 10:38:33,262:INFO:PyCaret ClassificationExperiment
2025-10-23 10:38:33,262:INFO:Logging name: clf-default-name
2025-10-23 10:38:33,262:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-23 10:38:33,262:INFO:version 3.3.2
2025-10-23 10:38:33,262:INFO:Initializing setup()
2025-10-23 10:38:33,262:INFO:self.USI: 6f1b
2025-10-23 10:38:33,262:INFO:self._variable_keys: {'X', 'n_jobs_param', 'gpu_n_jobs_param', 'is_multiclass', 'idx', 'log_plots_param', 'target_param', 'USI', 'data', 'html_param', 'pipeline', 'seed', 'logging_param', 'fold_shuffle_param', 'X_train', 'exp_name_log', 'y_train', 'exp_id', 'memory', '_available_plots', 'fold_groups_param', 'y', 'fix_imbalance', 'X_test', 'fold_generator', '_ml_usecase', 'gpu_param', 'y_test'}
2025-10-23 10:38:33,262:INFO:Checking environment
2025-10-23 10:38:33,262:INFO:python_version: 3.11.13
2025-10-23 10:38:33,262:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-23 10:38:33,262:INFO:machine: AMD64
2025-10-23 10:38:33,262:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-23 10:38:33,267:INFO:Memory: svmem(total=16856211456, available=2115395584, percent=87.5, used=14740815872, free=2115395584)
2025-10-23 10:38:33,267:INFO:Physical Core: 4
2025-10-23 10:38:33,267:INFO:Logical Core: 8
2025-10-23 10:38:33,267:INFO:Checking libraries
2025-10-23 10:38:33,267:INFO:System:
2025-10-23 10:38:33,267:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-23 10:38:33,267:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-23 10:38:33,267:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-23 10:38:33,267:INFO:PyCaret required dependencies:
2025-10-23 10:38:33,267:INFO:                 pip: 25.2
2025-10-23 10:38:33,267:INFO:          setuptools: 80.9.0
2025-10-23 10:38:33,267:INFO:             pycaret: 3.3.2
2025-10-23 10:38:33,267:INFO:             IPython: 9.6.0
2025-10-23 10:38:33,267:INFO:          ipywidgets: 8.1.7
2025-10-23 10:38:33,268:INFO:                tqdm: 4.67.1
2025-10-23 10:38:33,268:INFO:               numpy: 1.26.4
2025-10-23 10:38:33,268:INFO:              pandas: 2.1.4
2025-10-23 10:38:33,268:INFO:              jinja2: 3.1.6
2025-10-23 10:38:33,268:INFO:               scipy: 1.11.4
2025-10-23 10:38:33,268:INFO:              joblib: 1.3.2
2025-10-23 10:38:33,268:INFO:             sklearn: 1.4.2
2025-10-23 10:38:33,268:INFO:                pyod: 2.0.5
2025-10-23 10:38:33,268:INFO:            imblearn: 0.14.0
2025-10-23 10:38:33,268:INFO:   category_encoders: 2.7.0
2025-10-23 10:38:33,268:INFO:            lightgbm: 4.6.0
2025-10-23 10:38:33,268:INFO:               numba: 0.61.0
2025-10-23 10:38:33,268:INFO:            requests: 2.32.5
2025-10-23 10:38:33,268:INFO:          matplotlib: 3.7.5
2025-10-23 10:38:33,268:INFO:          scikitplot: 0.3.7
2025-10-23 10:38:33,268:INFO:         yellowbrick: 1.5
2025-10-23 10:38:33,268:INFO:              plotly: 5.24.1
2025-10-23 10:38:33,268:INFO:    plotly-resampler: Not installed
2025-10-23 10:38:33,268:INFO:             kaleido: 1.1.0
2025-10-23 10:38:33,268:INFO:           schemdraw: 0.15
2025-10-23 10:38:33,268:INFO:         statsmodels: 0.14.5
2025-10-23 10:38:33,268:INFO:              sktime: 0.26.0
2025-10-23 10:38:33,268:INFO:               tbats: 1.1.3
2025-10-23 10:38:33,268:INFO:            pmdarima: 2.0.4
2025-10-23 10:38:33,268:INFO:              psutil: 7.1.1
2025-10-23 10:38:33,268:INFO:          markupsafe: 3.0.3
2025-10-23 10:38:33,268:INFO:             pickle5: Not installed
2025-10-23 10:38:33,268:INFO:         cloudpickle: 3.1.1
2025-10-23 10:38:33,268:INFO:         deprecation: 2.1.0
2025-10-23 10:38:33,268:INFO:              xxhash: 3.6.0
2025-10-23 10:38:33,268:INFO:           wurlitzer: Not installed
2025-10-23 10:38:33,269:INFO:PyCaret optional dependencies:
2025-10-23 10:38:33,269:INFO:                shap: 0.44.1
2025-10-23 10:38:33,269:INFO:           interpret: 0.7.3
2025-10-23 10:38:33,269:INFO:                umap: 0.5.7
2025-10-23 10:38:33,269:INFO:     ydata_profiling: 4.17.0
2025-10-23 10:38:33,269:INFO:  explainerdashboard: 0.5.1
2025-10-23 10:38:33,269:INFO:             autoviz: Not installed
2025-10-23 10:38:33,269:INFO:           fairlearn: 0.7.0
2025-10-23 10:38:33,269:INFO:          deepchecks: Not installed
2025-10-23 10:38:33,269:INFO:             xgboost: 3.1.0
2025-10-23 10:38:33,269:INFO:            catboost: 1.2.8
2025-10-23 10:38:33,269:INFO:              kmodes: 0.12.2
2025-10-23 10:38:33,269:INFO:             mlxtend: 0.23.4
2025-10-23 10:38:33,269:INFO:       statsforecast: 1.5.0
2025-10-23 10:38:33,269:INFO:        tune_sklearn: Not installed
2025-10-23 10:38:33,269:INFO:                 ray: Not installed
2025-10-23 10:38:33,269:INFO:            hyperopt: 0.2.7
2025-10-23 10:38:33,269:INFO:              optuna: 4.5.0
2025-10-23 10:38:33,269:INFO:               skopt: 0.10.2
2025-10-23 10:38:33,269:INFO:              mlflow: 3.5.0
2025-10-23 10:38:33,269:INFO:              gradio: 5.49.1
2025-10-23 10:38:33,269:INFO:             fastapi: 0.119.1
2025-10-23 10:38:33,269:INFO:             uvicorn: 0.38.0
2025-10-23 10:38:33,269:INFO:              m2cgen: 0.10.0
2025-10-23 10:38:33,269:INFO:           evidently: 0.4.40
2025-10-23 10:38:33,269:INFO:               fugue: 0.8.7
2025-10-23 10:38:33,269:INFO:           streamlit: Not installed
2025-10-23 10:38:33,269:INFO:             prophet: Not installed
2025-10-23 10:38:33,269:INFO:None
2025-10-23 10:38:33,269:INFO:Set up data.
2025-10-23 10:38:33,466:INFO:Set up folding strategy.
2025-10-23 10:38:33,653:INFO:Set up train/test split.
2025-10-23 10:38:33,869:INFO:Set up index.
2025-10-23 10:38:33,889:INFO:Assigning column types.
2025-10-23 10:38:34,260:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-23 10:38:34,299:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-23 10:38:34,300:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 10:38:34,322:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:38:34,325:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:38:34,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-23 10:38:34,360:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 10:38:34,381:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:38:34,383:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:38:34,384:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-23 10:38:34,417:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 10:38:34,438:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:38:34,440:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:38:34,474:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 10:38:34,496:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:38:34,498:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:38:34,499:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-23 10:38:34,551:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:38:34,554:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:38:34,610:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:38:34,612:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:38:34,613:INFO:Preparing preprocessing pipeline...
2025-10-23 10:38:34,657:INFO:Set up simple imputation.
2025-10-23 10:38:34,846:INFO:Set up encoding of categorical features.
2025-10-23 10:38:34,851:INFO:Set up removing multicollinearity.
2025-10-23 10:38:34,851:INFO:Set up imbalanced handling.
2025-10-23 10:38:36,149:INFO:Finished creating preprocessing pipeline.
2025-10-23 10:38:36,159:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'presupuesto_estimado',
                                             'costo_entrada', 'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              mi...
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-10-23 10:38:36,159:INFO:Creating final display dataframe.
2025-10-23 10:38:38,945:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 19)
4        Transformed data shape       (98746, 83)
5   Transformed train set shape       (74744, 83)
6    Transformed test set shape       (24002, 83)
7               Ignore features                 1
8              Numeric features                 6
9          Categorical features                11
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation     most_frequent
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20               Fold Generator        GroupKFold
21                  Fold Number                 5
22                     CPU Jobs                 1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              6f1b
2025-10-23 10:38:39,002:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:38:39,004:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:38:39,061:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 10:38:39,063:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 10:38:39,065:INFO:setup() successfully completed in 6.03s...............
2025-10-23 10:38:39,065:INFO:Initializing compare_models()
2025-10-23 10:38:39,065:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-23 10:38:39,065:INFO:Checking exceptions
2025-10-23 10:38:39,281:INFO:Preparing display monitor
2025-10-23 10:38:39,306:INFO:Initializing Logistic Regression
2025-10-23 10:38:39,307:INFO:Total runtime is 1.6689300537109375e-05 minutes
2025-10-23 10:38:39,311:INFO:SubProcess create_model() called ==================================
2025-10-23 10:38:39,313:INFO:Initializing create_model()
2025-10-23 10:38:39,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:38:39,313:INFO:Checking exceptions
2025-10-23 10:38:39,313:INFO:Importing libraries
2025-10-23 10:38:39,313:INFO:Copying training dataset
2025-10-23 10:38:39,736:INFO:Defining folds
2025-10-23 10:38:39,736:INFO:Declaring metric variables
2025-10-23 10:38:39,741:INFO:Importing untrained model
2025-10-23 10:38:39,744:INFO:Logistic Regression Imported successfully
2025-10-23 10:38:39,750:INFO:Starting cross validation
2025-10-23 10:38:39,753:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:39:07,791:INFO:Calculating mean and std
2025-10-23 10:39:07,792:INFO:Creating metrics dataframe
2025-10-23 10:39:07,794:INFO:Uploading results into container
2025-10-23 10:39:07,795:INFO:Uploading model into container now
2025-10-23 10:39:07,795:INFO:_master_model_container: 1
2025-10-23 10:39:07,795:INFO:_display_container: 2
2025-10-23 10:39:07,795:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-23 10:39:07,795:INFO:create_model() successfully completed......................................
2025-10-23 10:39:08,003:INFO:SubProcess create_model() end ==================================
2025-10-23 10:39:08,003:INFO:Creating metrics dataframe
2025-10-23 10:39:08,008:INFO:Initializing K Neighbors Classifier
2025-10-23 10:39:08,009:INFO:Total runtime is 0.4783904751141866 minutes
2025-10-23 10:39:08,014:INFO:SubProcess create_model() called ==================================
2025-10-23 10:39:08,015:INFO:Initializing create_model()
2025-10-23 10:39:08,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:39:08,015:INFO:Checking exceptions
2025-10-23 10:39:08,016:INFO:Importing libraries
2025-10-23 10:39:08,016:INFO:Copying training dataset
2025-10-23 10:39:08,296:INFO:Defining folds
2025-10-23 10:39:08,297:INFO:Declaring metric variables
2025-10-23 10:39:08,300:INFO:Importing untrained model
2025-10-23 10:39:08,303:INFO:K Neighbors Classifier Imported successfully
2025-10-23 10:39:08,311:INFO:Starting cross validation
2025-10-23 10:39:08,314:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:39:37,871:INFO:Calculating mean and std
2025-10-23 10:39:37,872:INFO:Creating metrics dataframe
2025-10-23 10:39:37,875:INFO:Uploading results into container
2025-10-23 10:39:37,875:INFO:Uploading model into container now
2025-10-23 10:39:37,876:INFO:_master_model_container: 2
2025-10-23 10:39:37,876:INFO:_display_container: 2
2025-10-23 10:39:37,876:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-23 10:39:37,877:INFO:create_model() successfully completed......................................
2025-10-23 10:39:38,074:INFO:SubProcess create_model() end ==================================
2025-10-23 10:39:38,074:INFO:Creating metrics dataframe
2025-10-23 10:39:38,081:INFO:Initializing Naive Bayes
2025-10-23 10:39:38,081:INFO:Total runtime is 0.9795898000399272 minutes
2025-10-23 10:39:38,084:INFO:SubProcess create_model() called ==================================
2025-10-23 10:39:38,085:INFO:Initializing create_model()
2025-10-23 10:39:38,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:39:38,085:INFO:Checking exceptions
2025-10-23 10:39:38,085:INFO:Importing libraries
2025-10-23 10:39:38,085:INFO:Copying training dataset
2025-10-23 10:39:38,370:INFO:Defining folds
2025-10-23 10:39:38,370:INFO:Declaring metric variables
2025-10-23 10:39:38,375:INFO:Importing untrained model
2025-10-23 10:39:38,379:INFO:Naive Bayes Imported successfully
2025-10-23 10:39:38,386:INFO:Starting cross validation
2025-10-23 10:39:38,390:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:39:54,749:INFO:Calculating mean and std
2025-10-23 10:39:54,750:INFO:Creating metrics dataframe
2025-10-23 10:39:54,752:INFO:Uploading results into container
2025-10-23 10:39:54,753:INFO:Uploading model into container now
2025-10-23 10:39:54,753:INFO:_master_model_container: 3
2025-10-23 10:39:54,753:INFO:_display_container: 2
2025-10-23 10:39:54,753:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-23 10:39:54,753:INFO:create_model() successfully completed......................................
2025-10-23 10:39:54,984:INFO:SubProcess create_model() end ==================================
2025-10-23 10:39:54,985:INFO:Creating metrics dataframe
2025-10-23 10:39:54,990:INFO:Initializing Decision Tree Classifier
2025-10-23 10:39:54,990:INFO:Total runtime is 1.2614052057266236 minutes
2025-10-23 10:39:54,995:INFO:SubProcess create_model() called ==================================
2025-10-23 10:39:54,997:INFO:Initializing create_model()
2025-10-23 10:39:54,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:39:54,999:INFO:Checking exceptions
2025-10-23 10:39:54,999:INFO:Importing libraries
2025-10-23 10:39:54,999:INFO:Copying training dataset
2025-10-23 10:39:55,344:INFO:Defining folds
2025-10-23 10:39:55,344:INFO:Declaring metric variables
2025-10-23 10:39:55,348:INFO:Importing untrained model
2025-10-23 10:39:55,357:INFO:Decision Tree Classifier Imported successfully
2025-10-23 10:39:55,366:INFO:Starting cross validation
2025-10-23 10:39:55,371:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:40:26,499:INFO:Calculating mean and std
2025-10-23 10:40:26,500:INFO:Creating metrics dataframe
2025-10-23 10:40:26,503:INFO:Uploading results into container
2025-10-23 10:40:26,504:INFO:Uploading model into container now
2025-10-23 10:40:26,505:INFO:_master_model_container: 4
2025-10-23 10:40:26,505:INFO:_display_container: 2
2025-10-23 10:40:26,506:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-23 10:40:26,506:INFO:create_model() successfully completed......................................
2025-10-23 10:40:26,834:INFO:SubProcess create_model() end ==================================
2025-10-23 10:40:26,835:INFO:Creating metrics dataframe
2025-10-23 10:40:26,841:INFO:Initializing SVM - Linear Kernel
2025-10-23 10:40:26,842:INFO:Total runtime is 1.7922767559687296 minutes
2025-10-23 10:40:26,847:INFO:SubProcess create_model() called ==================================
2025-10-23 10:40:26,848:INFO:Initializing create_model()
2025-10-23 10:40:26,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:40:26,849:INFO:Checking exceptions
2025-10-23 10:40:26,849:INFO:Importing libraries
2025-10-23 10:40:26,850:INFO:Copying training dataset
2025-10-23 10:40:27,439:INFO:Defining folds
2025-10-23 10:40:27,440:INFO:Declaring metric variables
2025-10-23 10:40:27,453:INFO:Importing untrained model
2025-10-23 10:40:27,465:INFO:SVM - Linear Kernel Imported successfully
2025-10-23 10:40:27,484:INFO:Starting cross validation
2025-10-23 10:40:27,496:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:40:54,606:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 10:41:22,990:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 10:41:23,007:INFO:Calculating mean and std
2025-10-23 10:41:23,008:INFO:Creating metrics dataframe
2025-10-23 10:41:23,010:INFO:Uploading results into container
2025-10-23 10:41:23,010:INFO:Uploading model into container now
2025-10-23 10:41:23,010:INFO:_master_model_container: 5
2025-10-23 10:41:23,011:INFO:_display_container: 2
2025-10-23 10:41:23,011:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-23 10:41:23,011:INFO:create_model() successfully completed......................................
2025-10-23 10:41:23,204:INFO:SubProcess create_model() end ==================================
2025-10-23 10:41:23,204:INFO:Creating metrics dataframe
2025-10-23 10:41:23,210:INFO:Initializing Ridge Classifier
2025-10-23 10:41:23,210:INFO:Total runtime is 2.7317363460858664 minutes
2025-10-23 10:41:23,212:INFO:SubProcess create_model() called ==================================
2025-10-23 10:41:23,215:INFO:Initializing create_model()
2025-10-23 10:41:23,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:41:23,215:INFO:Checking exceptions
2025-10-23 10:41:23,216:INFO:Importing libraries
2025-10-23 10:41:23,216:INFO:Copying training dataset
2025-10-23 10:41:23,503:INFO:Defining folds
2025-10-23 10:41:23,504:INFO:Declaring metric variables
2025-10-23 10:41:23,508:INFO:Importing untrained model
2025-10-23 10:41:23,511:INFO:Ridge Classifier Imported successfully
2025-10-23 10:41:23,519:INFO:Starting cross validation
2025-10-23 10:41:23,523:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:41:39,036:INFO:Calculating mean and std
2025-10-23 10:41:39,036:INFO:Creating metrics dataframe
2025-10-23 10:41:39,038:INFO:Uploading results into container
2025-10-23 10:41:39,038:INFO:Uploading model into container now
2025-10-23 10:41:39,039:INFO:_master_model_container: 6
2025-10-23 10:41:39,039:INFO:_display_container: 2
2025-10-23 10:41:39,039:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-23 10:41:39,039:INFO:create_model() successfully completed......................................
2025-10-23 10:41:39,227:INFO:SubProcess create_model() end ==================================
2025-10-23 10:41:39,227:INFO:Creating metrics dataframe
2025-10-23 10:41:39,234:INFO:Initializing Random Forest Classifier
2025-10-23 10:41:39,235:INFO:Total runtime is 2.9988202969233195 minutes
2025-10-23 10:41:39,238:INFO:SubProcess create_model() called ==================================
2025-10-23 10:41:39,239:INFO:Initializing create_model()
2025-10-23 10:41:39,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:41:39,239:INFO:Checking exceptions
2025-10-23 10:41:39,239:INFO:Importing libraries
2025-10-23 10:41:39,239:INFO:Copying training dataset
2025-10-23 10:41:39,559:INFO:Defining folds
2025-10-23 10:41:39,560:INFO:Declaring metric variables
2025-10-23 10:41:39,563:INFO:Importing untrained model
2025-10-23 10:41:39,570:INFO:Random Forest Classifier Imported successfully
2025-10-23 10:41:39,576:INFO:Starting cross validation
2025-10-23 10:41:39,580:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:42:59,074:INFO:Calculating mean and std
2025-10-23 10:42:59,076:INFO:Creating metrics dataframe
2025-10-23 10:42:59,079:INFO:Uploading results into container
2025-10-23 10:42:59,080:INFO:Uploading model into container now
2025-10-23 10:42:59,081:INFO:_master_model_container: 7
2025-10-23 10:42:59,081:INFO:_display_container: 2
2025-10-23 10:42:59,081:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-23 10:42:59,081:INFO:create_model() successfully completed......................................
2025-10-23 10:42:59,287:INFO:SubProcess create_model() end ==================================
2025-10-23 10:42:59,288:INFO:Creating metrics dataframe
2025-10-23 10:42:59,299:INFO:Initializing Quadratic Discriminant Analysis
2025-10-23 10:42:59,299:INFO:Total runtime is 4.333225794633229 minutes
2025-10-23 10:42:59,305:INFO:SubProcess create_model() called ==================================
2025-10-23 10:42:59,307:INFO:Initializing create_model()
2025-10-23 10:42:59,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:42:59,307:INFO:Checking exceptions
2025-10-23 10:42:59,307:INFO:Importing libraries
2025-10-23 10:42:59,307:INFO:Copying training dataset
2025-10-23 10:42:59,613:INFO:Defining folds
2025-10-23 10:42:59,613:INFO:Declaring metric variables
2025-10-23 10:42:59,616:INFO:Importing untrained model
2025-10-23 10:42:59,621:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-23 10:42:59,631:INFO:Starting cross validation
2025-10-23 10:42:59,636:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:43:02,944:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-23 10:43:06,556:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-23 10:43:09,861:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-23 10:43:13,371:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-23 10:43:16,742:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-23 10:43:17,264:INFO:Calculating mean and std
2025-10-23 10:43:17,265:INFO:Creating metrics dataframe
2025-10-23 10:43:17,267:INFO:Uploading results into container
2025-10-23 10:43:17,267:INFO:Uploading model into container now
2025-10-23 10:43:17,267:INFO:_master_model_container: 8
2025-10-23 10:43:17,267:INFO:_display_container: 2
2025-10-23 10:43:17,268:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-23 10:43:17,268:INFO:create_model() successfully completed......................................
2025-10-23 10:43:17,451:INFO:SubProcess create_model() end ==================================
2025-10-23 10:43:17,451:INFO:Creating metrics dataframe
2025-10-23 10:43:17,459:INFO:Initializing Ada Boost Classifier
2025-10-23 10:43:17,459:INFO:Total runtime is 4.635887265205382 minutes
2025-10-23 10:43:17,461:INFO:SubProcess create_model() called ==================================
2025-10-23 10:43:17,462:INFO:Initializing create_model()
2025-10-23 10:43:17,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:43:17,462:INFO:Checking exceptions
2025-10-23 10:43:17,462:INFO:Importing libraries
2025-10-23 10:43:17,462:INFO:Copying training dataset
2025-10-23 10:43:17,757:INFO:Defining folds
2025-10-23 10:43:17,757:INFO:Declaring metric variables
2025-10-23 10:43:17,761:INFO:Importing untrained model
2025-10-23 10:43:17,765:INFO:Ada Boost Classifier Imported successfully
2025-10-23 10:43:17,772:INFO:Starting cross validation
2025-10-23 10:43:17,777:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:43:20,664:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 10:43:26,064:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 10:43:28,715:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 10:43:34,433:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 10:43:37,132:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 10:43:45,251:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 10:43:53,351:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 10:43:58,758:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 10:43:58,775:INFO:Calculating mean and std
2025-10-23 10:43:58,777:INFO:Creating metrics dataframe
2025-10-23 10:43:58,778:INFO:Uploading results into container
2025-10-23 10:43:58,778:INFO:Uploading model into container now
2025-10-23 10:43:58,779:INFO:_master_model_container: 9
2025-10-23 10:43:58,779:INFO:_display_container: 2
2025-10-23 10:43:58,779:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-23 10:43:58,779:INFO:create_model() successfully completed......................................
2025-10-23 10:43:58,987:INFO:SubProcess create_model() end ==================================
2025-10-23 10:43:58,988:INFO:Creating metrics dataframe
2025-10-23 10:43:58,997:INFO:Initializing Gradient Boosting Classifier
2025-10-23 10:43:58,997:INFO:Total runtime is 5.328185109297434 minutes
2025-10-23 10:43:59,000:INFO:SubProcess create_model() called ==================================
2025-10-23 10:43:59,001:INFO:Initializing create_model()
2025-10-23 10:43:59,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:43:59,001:INFO:Checking exceptions
2025-10-23 10:43:59,001:INFO:Importing libraries
2025-10-23 10:43:59,001:INFO:Copying training dataset
2025-10-23 10:43:59,315:INFO:Defining folds
2025-10-23 10:43:59,315:INFO:Declaring metric variables
2025-10-23 10:43:59,319:INFO:Importing untrained model
2025-10-23 10:43:59,324:INFO:Gradient Boosting Classifier Imported successfully
2025-10-23 10:43:59,333:INFO:Starting cross validation
2025-10-23 10:43:59,338:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:45:46,296:INFO:Calculating mean and std
2025-10-23 10:45:46,297:INFO:Creating metrics dataframe
2025-10-23 10:45:46,299:INFO:Uploading results into container
2025-10-23 10:45:46,299:INFO:Uploading model into container now
2025-10-23 10:45:46,300:INFO:_master_model_container: 10
2025-10-23 10:45:46,300:INFO:_display_container: 2
2025-10-23 10:45:46,300:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-23 10:45:46,300:INFO:create_model() successfully completed......................................
2025-10-23 10:45:46,495:INFO:SubProcess create_model() end ==================================
2025-10-23 10:45:46,495:INFO:Creating metrics dataframe
2025-10-23 10:45:46,503:INFO:Initializing Linear Discriminant Analysis
2025-10-23 10:45:46,503:INFO:Total runtime is 7.119959203402201 minutes
2025-10-23 10:45:46,508:INFO:SubProcess create_model() called ==================================
2025-10-23 10:45:46,509:INFO:Initializing create_model()
2025-10-23 10:45:46,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:45:46,510:INFO:Checking exceptions
2025-10-23 10:45:46,510:INFO:Importing libraries
2025-10-23 10:45:46,510:INFO:Copying training dataset
2025-10-23 10:45:46,814:INFO:Defining folds
2025-10-23 10:45:46,814:INFO:Declaring metric variables
2025-10-23 10:45:46,818:INFO:Importing untrained model
2025-10-23 10:45:46,823:INFO:Linear Discriminant Analysis Imported successfully
2025-10-23 10:45:46,829:INFO:Starting cross validation
2025-10-23 10:45:46,834:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:46:04,875:INFO:Calculating mean and std
2025-10-23 10:46:04,877:INFO:Creating metrics dataframe
2025-10-23 10:46:04,879:INFO:Uploading results into container
2025-10-23 10:46:04,879:INFO:Uploading model into container now
2025-10-23 10:46:04,879:INFO:_master_model_container: 11
2025-10-23 10:46:04,880:INFO:_display_container: 2
2025-10-23 10:46:04,880:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-23 10:46:04,880:INFO:create_model() successfully completed......................................
2025-10-23 10:46:05,102:INFO:SubProcess create_model() end ==================================
2025-10-23 10:46:05,102:INFO:Creating metrics dataframe
2025-10-23 10:46:05,109:INFO:Initializing Extra Trees Classifier
2025-10-23 10:46:05,109:INFO:Total runtime is 7.430059460798899 minutes
2025-10-23 10:46:05,112:INFO:SubProcess create_model() called ==================================
2025-10-23 10:46:05,113:INFO:Initializing create_model()
2025-10-23 10:46:05,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:46:05,113:INFO:Checking exceptions
2025-10-23 10:46:05,113:INFO:Importing libraries
2025-10-23 10:46:05,114:INFO:Copying training dataset
2025-10-23 10:46:05,405:INFO:Defining folds
2025-10-23 10:46:05,405:INFO:Declaring metric variables
2025-10-23 10:46:05,409:INFO:Importing untrained model
2025-10-23 10:46:05,413:INFO:Extra Trees Classifier Imported successfully
2025-10-23 10:46:05,419:INFO:Starting cross validation
2025-10-23 10:46:05,423:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:47:55,568:INFO:Calculating mean and std
2025-10-23 10:47:55,570:INFO:Creating metrics dataframe
2025-10-23 10:47:55,571:INFO:Uploading results into container
2025-10-23 10:47:55,572:INFO:Uploading model into container now
2025-10-23 10:47:55,572:INFO:_master_model_container: 12
2025-10-23 10:47:55,572:INFO:_display_container: 2
2025-10-23 10:47:55,573:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-10-23 10:47:55,573:INFO:create_model() successfully completed......................................
2025-10-23 10:47:55,781:INFO:SubProcess create_model() end ==================================
2025-10-23 10:47:55,782:INFO:Creating metrics dataframe
2025-10-23 10:47:55,793:INFO:Initializing Extreme Gradient Boosting
2025-10-23 10:47:55,793:INFO:Total runtime is 9.274785002072651 minutes
2025-10-23 10:47:55,796:INFO:SubProcess create_model() called ==================================
2025-10-23 10:47:55,797:INFO:Initializing create_model()
2025-10-23 10:47:55,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=xgboost, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:47:55,797:INFO:Checking exceptions
2025-10-23 10:47:55,797:INFO:Importing libraries
2025-10-23 10:47:55,798:INFO:Copying training dataset
2025-10-23 10:47:56,112:INFO:Defining folds
2025-10-23 10:47:56,113:INFO:Declaring metric variables
2025-10-23 10:47:56,116:INFO:Importing untrained model
2025-10-23 10:47:56,120:INFO:Extreme Gradient Boosting Imported successfully
2025-10-23 10:47:56,128:INFO:Starting cross validation
2025-10-23 10:47:56,131:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:48:30,331:INFO:Calculating mean and std
2025-10-23 10:48:30,332:INFO:Creating metrics dataframe
2025-10-23 10:48:30,333:INFO:Uploading results into container
2025-10-23 10:48:30,334:INFO:Uploading model into container now
2025-10-23 10:48:30,334:INFO:_master_model_container: 13
2025-10-23 10:48:30,334:INFO:_display_container: 2
2025-10-23 10:48:30,335:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-10-23 10:48:30,335:INFO:create_model() successfully completed......................................
2025-10-23 10:48:30,530:INFO:SubProcess create_model() end ==================================
2025-10-23 10:48:30,530:INFO:Creating metrics dataframe
2025-10-23 10:48:30,538:INFO:Initializing Light Gradient Boosting Machine
2025-10-23 10:48:30,538:INFO:Total runtime is 9.85386847257614 minutes
2025-10-23 10:48:30,541:INFO:SubProcess create_model() called ==================================
2025-10-23 10:48:30,543:INFO:Initializing create_model()
2025-10-23 10:48:30,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015732FBF490>, estimator=lightgbm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=5290     U11254
74143    U09160
45753    U05763
66092    U03672
53555    U00066
          ...  
8610     U11740
48829    U03572
627      U11519
16727    U07514
53994    U10817
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000157600BDB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 10:48:30,543:INFO:Checking exceptions
2025-10-23 10:48:30,543:INFO:Importing libraries
2025-10-23 10:48:30,543:INFO:Copying training dataset
2025-10-23 10:48:30,844:INFO:Defining folds
2025-10-23 10:48:30,844:INFO:Declaring metric variables
2025-10-23 10:48:30,849:INFO:Importing untrained model
2025-10-23 10:48:30,853:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-23 10:48:30,860:INFO:Starting cross validation
2025-10-23 10:48:30,865:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 10:48:34,073:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-23 10:48:34,076:INFO:[LightGBM] [Info] Number of positive: 29935, number of negative: 29935
2025-10-23 10:48:34,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034025 seconds.
2025-10-23 10:48:34,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-23 10:48:34,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-23 10:48:34,148:INFO:[LightGBM] [Info] Total Bins 20502
2025-10-23 10:48:34,150:INFO:[LightGBM] [Info] Number of data points in the train set: 59870, number of used features: 82
2025-10-23 10:48:34,151:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-23 10:48:38,592:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-23 10:48:38,596:INFO:[LightGBM] [Info] Number of positive: 29833, number of negative: 29833
2025-10-23 10:48:38,681:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050356 seconds.
2025-10-23 10:48:38,681:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-23 10:48:38,681:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-23 10:48:38,681:INFO:[LightGBM] [Info] Total Bins 20498
2025-10-23 10:48:38,682:INFO:[LightGBM] [Info] Number of data points in the train set: 59666, number of used features: 82
2025-10-23 10:48:38,683:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-23 10:48:42,862:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-23 10:48:42,865:INFO:[LightGBM] [Info] Number of positive: 29894, number of negative: 29894
2025-10-23 10:48:42,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028923 seconds.
2025-10-23 10:48:42,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-23 10:48:42,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-23 10:48:42,928:INFO:[LightGBM] [Info] Total Bins 20327
2025-10-23 10:48:42,929:INFO:[LightGBM] [Info] Number of data points in the train set: 59788, number of used features: 82
2025-10-23 10:48:42,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-23 10:48:47,185:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-23 10:48:47,188:INFO:[LightGBM] [Info] Number of positive: 29827, number of negative: 29827
2025-10-23 10:48:47,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029744 seconds.
2025-10-23 10:48:47,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-23 10:48:47,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-23 10:48:47,251:INFO:[LightGBM] [Info] Total Bins 20513
2025-10-23 10:48:47,252:INFO:[LightGBM] [Info] Number of data points in the train set: 59654, number of used features: 82
2025-10-23 10:48:47,253:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-23 10:48:51,471:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-23 10:48:51,475:INFO:[LightGBM] [Info] Number of positive: 29999, number of negative: 29999
2025-10-23 10:48:51,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040338 seconds.
2025-10-23 10:48:51,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-23 10:48:51,545:INFO:[LightGBM] [Info] Total Bins 20485
2025-10-23 10:48:51,546:INFO:[LightGBM] [Info] Number of data points in the train set: 59998, number of used features: 82
2025-10-23 10:48:51,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-10-23 10:49:54,748:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 10:49:54,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 10:49:54,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 10:49:54,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 11:02:11,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 11:02:11,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 11:02:11,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 11:02:11,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 11:02:14,230:INFO:PyCaret ClassificationExperiment
2025-10-23 11:02:14,230:INFO:Logging name: clf-default-name
2025-10-23 11:02:14,230:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-23 11:02:14,231:INFO:version 3.3.2
2025-10-23 11:02:14,231:INFO:Initializing setup()
2025-10-23 11:02:14,231:INFO:self.USI: 8fa2
2025-10-23 11:02:14,231:INFO:self._variable_keys: {'exp_id', 'log_plots_param', 'target_param', 'fold_generator', 'is_multiclass', 'memory', 'gpu_param', 'y_test', 'y_train', 'data', 'logging_param', 'pipeline', 'seed', '_ml_usecase', 'idx', 'y', 'fold_shuffle_param', '_available_plots', 'exp_name_log', 'fold_groups_param', 'fix_imbalance', 'X', 'USI', 'html_param', 'X_train', 'gpu_n_jobs_param', 'n_jobs_param', 'X_test'}
2025-10-23 11:02:14,231:INFO:Checking environment
2025-10-23 11:02:14,231:INFO:python_version: 3.11.13
2025-10-23 11:02:14,231:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-23 11:02:14,231:INFO:machine: AMD64
2025-10-23 11:02:14,231:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-23 11:02:14,238:INFO:Memory: svmem(total=16856211456, available=1715875840, percent=89.8, used=15140335616, free=1715875840)
2025-10-23 11:02:14,238:INFO:Physical Core: 4
2025-10-23 11:02:14,239:INFO:Logical Core: 8
2025-10-23 11:02:14,239:INFO:Checking libraries
2025-10-23 11:02:14,239:INFO:System:
2025-10-23 11:02:14,239:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-23 11:02:14,239:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-23 11:02:14,239:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-23 11:02:14,239:INFO:PyCaret required dependencies:
2025-10-23 11:02:15,845:INFO:                 pip: 25.2
2025-10-23 11:02:15,845:INFO:          setuptools: 80.9.0
2025-10-23 11:02:15,846:INFO:             pycaret: 3.3.2
2025-10-23 11:02:15,846:INFO:             IPython: 9.6.0
2025-10-23 11:02:15,846:INFO:          ipywidgets: 8.1.7
2025-10-23 11:02:15,846:INFO:                tqdm: 4.67.1
2025-10-23 11:02:15,846:INFO:               numpy: 1.26.4
2025-10-23 11:02:15,846:INFO:              pandas: 2.1.4
2025-10-23 11:02:15,846:INFO:              jinja2: 3.1.6
2025-10-23 11:02:15,846:INFO:               scipy: 1.11.4
2025-10-23 11:02:15,846:INFO:              joblib: 1.3.2
2025-10-23 11:02:15,846:INFO:             sklearn: 1.4.2
2025-10-23 11:02:15,846:INFO:                pyod: 2.0.5
2025-10-23 11:02:15,846:INFO:            imblearn: 0.14.0
2025-10-23 11:02:15,847:INFO:   category_encoders: 2.7.0
2025-10-23 11:02:15,847:INFO:            lightgbm: 4.6.0
2025-10-23 11:02:15,847:INFO:               numba: 0.61.0
2025-10-23 11:02:15,847:INFO:            requests: 2.32.5
2025-10-23 11:02:15,847:INFO:          matplotlib: 3.7.5
2025-10-23 11:02:15,847:INFO:          scikitplot: 0.3.7
2025-10-23 11:02:15,847:INFO:         yellowbrick: 1.5
2025-10-23 11:02:15,847:INFO:              plotly: 5.24.1
2025-10-23 11:02:15,847:INFO:    plotly-resampler: Not installed
2025-10-23 11:02:15,847:INFO:             kaleido: 1.1.0
2025-10-23 11:02:15,847:INFO:           schemdraw: 0.15
2025-10-23 11:02:15,847:INFO:         statsmodels: 0.14.5
2025-10-23 11:02:15,847:INFO:              sktime: 0.26.0
2025-10-23 11:02:15,847:INFO:               tbats: 1.1.3
2025-10-23 11:02:15,847:INFO:            pmdarima: 2.0.4
2025-10-23 11:02:15,847:INFO:              psutil: 7.1.1
2025-10-23 11:02:15,847:INFO:          markupsafe: 3.0.3
2025-10-23 11:02:15,847:INFO:             pickle5: Not installed
2025-10-23 11:02:15,847:INFO:         cloudpickle: 3.1.1
2025-10-23 11:02:15,847:INFO:         deprecation: 2.1.0
2025-10-23 11:02:15,848:INFO:              xxhash: 3.6.0
2025-10-23 11:02:15,848:INFO:           wurlitzer: Not installed
2025-10-23 11:02:15,848:INFO:PyCaret optional dependencies:
2025-10-23 11:02:21,463:INFO:                shap: 0.44.1
2025-10-23 11:02:21,464:INFO:           interpret: 0.7.3
2025-10-23 11:02:21,464:INFO:                umap: 0.5.7
2025-10-23 11:02:21,464:INFO:     ydata_profiling: 4.17.0
2025-10-23 11:02:21,464:INFO:  explainerdashboard: 0.5.1
2025-10-23 11:02:21,464:INFO:             autoviz: Not installed
2025-10-23 11:02:21,464:INFO:           fairlearn: 0.7.0
2025-10-23 11:02:21,464:INFO:          deepchecks: Not installed
2025-10-23 11:02:21,464:INFO:             xgboost: 3.1.0
2025-10-23 11:02:21,464:INFO:            catboost: 1.2.8
2025-10-23 11:02:21,464:INFO:              kmodes: 0.12.2
2025-10-23 11:02:21,464:INFO:             mlxtend: 0.23.4
2025-10-23 11:02:21,464:INFO:       statsforecast: 1.5.0
2025-10-23 11:02:21,464:INFO:        tune_sklearn: Not installed
2025-10-23 11:02:21,464:INFO:                 ray: Not installed
2025-10-23 11:02:21,464:INFO:            hyperopt: 0.2.7
2025-10-23 11:02:21,464:INFO:              optuna: 4.5.0
2025-10-23 11:02:21,464:INFO:               skopt: 0.10.2
2025-10-23 11:02:21,464:INFO:              mlflow: 3.5.0
2025-10-23 11:02:21,464:INFO:              gradio: 5.49.1
2025-10-23 11:02:21,464:INFO:             fastapi: 0.119.1
2025-10-23 11:02:21,464:INFO:             uvicorn: 0.38.0
2025-10-23 11:02:21,464:INFO:              m2cgen: 0.10.0
2025-10-23 11:02:21,464:INFO:           evidently: 0.4.40
2025-10-23 11:02:21,464:INFO:               fugue: 0.8.7
2025-10-23 11:02:21,464:INFO:           streamlit: Not installed
2025-10-23 11:02:21,464:INFO:             prophet: Not installed
2025-10-23 11:02:21,464:INFO:None
2025-10-23 11:02:21,464:INFO:Set up data.
2025-10-23 11:02:21,663:INFO:Set up folding strategy.
2025-10-23 11:02:21,891:INFO:Set up train/test split.
2025-10-23 11:02:22,106:INFO:Set up index.
2025-10-23 11:02:22,128:INFO:Assigning column types.
2025-10-23 11:02:22,402:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-23 11:02:22,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-23 11:02:22,440:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 11:02:22,470:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:02:22,472:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:02:22,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-23 11:02:22,826:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 11:02:22,847:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:02:22,849:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:02:22,850:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-23 11:02:22,884:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 11:02:22,905:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:02:22,907:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:02:22,943:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 11:02:22,964:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:02:22,966:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:02:22,966:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-23 11:02:23,022:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:02:23,024:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:02:23,080:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:02:23,082:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:02:23,088:INFO:Preparing preprocessing pipeline...
2025-10-23 11:02:23,141:INFO:Set up simple imputation.
2025-10-23 11:02:23,330:INFO:Set up encoding of categorical features.
2025-10-23 11:02:23,338:INFO:Set up removing multicollinearity.
2025-10-23 11:02:23,338:INFO:Set up imbalanced handling.
2025-10-23 11:02:27,918:INFO:Finished creating preprocessing pipeline.
2025-10-23 11:02:27,927:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'presupuesto_estimado',
                                             'costo_entrada', 'admite_mascotas',
                                             'ratio_costo_presu',
                                             'afinidad_tipo'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              mi...
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-10-23 11:02:27,927:INFO:Creating final display dataframe.
2025-10-23 11:02:34,146:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            y_like
2                   Target type            Binary
3           Original data shape       (80004, 19)
4        Transformed data shape       (98748, 83)
5   Transformed train set shape       (74746, 83)
6    Transformed test set shape       (24002, 83)
7               Ignore features                 1
8              Numeric features                 6
9          Categorical features                11
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation     most_frequent
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20               Fold Generator        GroupKFold
21                  Fold Number                 5
22                     CPU Jobs                 1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              8fa2
2025-10-23 11:02:34,200:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:02:34,202:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:02:34,259:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:02:34,261:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:02:34,263:INFO:setup() successfully completed in 20.42s...............
2025-10-23 11:02:34,263:INFO:Initializing compare_models()
2025-10-23 11:02:34,263:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-23 11:02:34,263:INFO:Checking exceptions
2025-10-23 11:02:34,486:INFO:Preparing display monitor
2025-10-23 11:02:34,530:INFO:Initializing Logistic Regression
2025-10-23 11:02:34,531:INFO:Total runtime is 1.6705195109049478e-05 minutes
2025-10-23 11:02:34,548:INFO:SubProcess create_model() called ==================================
2025-10-23 11:02:34,552:INFO:Initializing create_model()
2025-10-23 11:02:34,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=lr, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:02:34,552:INFO:Checking exceptions
2025-10-23 11:02:34,552:INFO:Importing libraries
2025-10-23 11:02:34,552:INFO:Copying training dataset
2025-10-23 11:02:34,961:INFO:Defining folds
2025-10-23 11:02:34,961:INFO:Declaring metric variables
2025-10-23 11:02:34,965:INFO:Importing untrained model
2025-10-23 11:02:34,968:INFO:Logistic Regression Imported successfully
2025-10-23 11:02:34,975:INFO:Starting cross validation
2025-10-23 11:02:34,982:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:02:58,090:INFO:Calculating mean and std
2025-10-23 11:02:58,091:INFO:Creating metrics dataframe
2025-10-23 11:02:58,096:INFO:Uploading results into container
2025-10-23 11:02:58,097:INFO:Uploading model into container now
2025-10-23 11:02:58,098:INFO:_master_model_container: 1
2025-10-23 11:02:58,098:INFO:_display_container: 2
2025-10-23 11:02:58,098:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-23 11:02:58,098:INFO:create_model() successfully completed......................................
2025-10-23 11:02:58,266:INFO:SubProcess create_model() end ==================================
2025-10-23 11:02:58,266:INFO:Creating metrics dataframe
2025-10-23 11:02:58,271:INFO:Initializing K Neighbors Classifier
2025-10-23 11:02:58,271:INFO:Total runtime is 0.39568537871042886 minutes
2025-10-23 11:02:58,276:INFO:SubProcess create_model() called ==================================
2025-10-23 11:02:58,279:INFO:Initializing create_model()
2025-10-23 11:02:58,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=knn, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:02:58,279:INFO:Checking exceptions
2025-10-23 11:02:58,279:INFO:Importing libraries
2025-10-23 11:02:58,279:INFO:Copying training dataset
2025-10-23 11:02:58,613:INFO:Defining folds
2025-10-23 11:02:58,613:INFO:Declaring metric variables
2025-10-23 11:02:58,616:INFO:Importing untrained model
2025-10-23 11:02:58,620:INFO:K Neighbors Classifier Imported successfully
2025-10-23 11:02:58,628:INFO:Starting cross validation
2025-10-23 11:02:58,635:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:03:29,110:INFO:Calculating mean and std
2025-10-23 11:03:29,112:INFO:Creating metrics dataframe
2025-10-23 11:03:29,114:INFO:Uploading results into container
2025-10-23 11:03:29,116:INFO:Uploading model into container now
2025-10-23 11:03:29,116:INFO:_master_model_container: 2
2025-10-23 11:03:29,116:INFO:_display_container: 2
2025-10-23 11:03:29,116:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-23 11:03:29,117:INFO:create_model() successfully completed......................................
2025-10-23 11:03:29,284:INFO:SubProcess create_model() end ==================================
2025-10-23 11:03:29,284:INFO:Creating metrics dataframe
2025-10-23 11:03:29,291:INFO:Initializing Naive Bayes
2025-10-23 11:03:29,292:INFO:Total runtime is 0.9127055406570435 minutes
2025-10-23 11:03:29,295:INFO:SubProcess create_model() called ==================================
2025-10-23 11:03:29,297:INFO:Initializing create_model()
2025-10-23 11:03:29,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=nb, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:03:29,298:INFO:Checking exceptions
2025-10-23 11:03:29,298:INFO:Importing libraries
2025-10-23 11:03:29,298:INFO:Copying training dataset
2025-10-23 11:03:29,646:INFO:Defining folds
2025-10-23 11:03:29,646:INFO:Declaring metric variables
2025-10-23 11:03:29,649:INFO:Importing untrained model
2025-10-23 11:03:29,654:INFO:Naive Bayes Imported successfully
2025-10-23 11:03:29,660:INFO:Starting cross validation
2025-10-23 11:03:29,667:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:03:45,673:INFO:Calculating mean and std
2025-10-23 11:03:45,674:INFO:Creating metrics dataframe
2025-10-23 11:03:45,676:INFO:Uploading results into container
2025-10-23 11:03:45,676:INFO:Uploading model into container now
2025-10-23 11:03:45,677:INFO:_master_model_container: 3
2025-10-23 11:03:45,677:INFO:_display_container: 2
2025-10-23 11:03:45,677:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-23 11:03:45,677:INFO:create_model() successfully completed......................................
2025-10-23 11:03:45,832:INFO:SubProcess create_model() end ==================================
2025-10-23 11:03:45,832:INFO:Creating metrics dataframe
2025-10-23 11:03:45,839:INFO:Initializing Decision Tree Classifier
2025-10-23 11:03:45,839:INFO:Total runtime is 1.1884823719660442 minutes
2025-10-23 11:03:45,841:INFO:SubProcess create_model() called ==================================
2025-10-23 11:03:45,843:INFO:Initializing create_model()
2025-10-23 11:03:45,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=dt, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:03:45,843:INFO:Checking exceptions
2025-10-23 11:03:45,843:INFO:Importing libraries
2025-10-23 11:03:45,843:INFO:Copying training dataset
2025-10-23 11:03:46,187:INFO:Defining folds
2025-10-23 11:03:46,187:INFO:Declaring metric variables
2025-10-23 11:03:46,191:INFO:Importing untrained model
2025-10-23 11:03:46,193:INFO:Decision Tree Classifier Imported successfully
2025-10-23 11:03:46,202:INFO:Starting cross validation
2025-10-23 11:03:46,207:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:04:07,841:INFO:Calculating mean and std
2025-10-23 11:04:07,841:INFO:Creating metrics dataframe
2025-10-23 11:04:07,843:INFO:Uploading results into container
2025-10-23 11:04:07,844:INFO:Uploading model into container now
2025-10-23 11:04:07,844:INFO:_master_model_container: 4
2025-10-23 11:04:07,844:INFO:_display_container: 2
2025-10-23 11:04:07,845:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-10-23 11:04:07,845:INFO:create_model() successfully completed......................................
2025-10-23 11:04:08,007:INFO:SubProcess create_model() end ==================================
2025-10-23 11:04:08,007:INFO:Creating metrics dataframe
2025-10-23 11:04:08,013:INFO:Initializing SVM - Linear Kernel
2025-10-23 11:04:08,013:INFO:Total runtime is 1.5580449064572655 minutes
2025-10-23 11:04:08,016:INFO:SubProcess create_model() called ==================================
2025-10-23 11:04:08,018:INFO:Initializing create_model()
2025-10-23 11:04:08,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=svm, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:04:08,019:INFO:Checking exceptions
2025-10-23 11:04:08,019:INFO:Importing libraries
2025-10-23 11:04:08,019:INFO:Copying training dataset
2025-10-23 11:04:08,340:INFO:Defining folds
2025-10-23 11:04:08,340:INFO:Declaring metric variables
2025-10-23 11:04:08,343:INFO:Importing untrained model
2025-10-23 11:04:08,349:INFO:SVM - Linear Kernel Imported successfully
2025-10-23 11:04:08,356:INFO:Starting cross validation
2025-10-23 11:04:08,365:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:04:18,207:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 11:04:28,121:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 11:04:38,807:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 11:04:56,592:INFO:Calculating mean and std
2025-10-23 11:04:56,593:INFO:Creating metrics dataframe
2025-10-23 11:04:56,596:INFO:Uploading results into container
2025-10-23 11:04:56,597:INFO:Uploading model into container now
2025-10-23 11:04:56,598:INFO:_master_model_container: 5
2025-10-23 11:04:56,598:INFO:_display_container: 2
2025-10-23 11:04:56,598:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-23 11:04:56,598:INFO:create_model() successfully completed......................................
2025-10-23 11:04:56,762:INFO:SubProcess create_model() end ==================================
2025-10-23 11:04:56,763:INFO:Creating metrics dataframe
2025-10-23 11:04:56,770:INFO:Initializing Ridge Classifier
2025-10-23 11:04:56,770:INFO:Total runtime is 2.3706743915875754 minutes
2025-10-23 11:04:56,773:INFO:SubProcess create_model() called ==================================
2025-10-23 11:04:56,774:INFO:Initializing create_model()
2025-10-23 11:04:56,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=ridge, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:04:56,774:INFO:Checking exceptions
2025-10-23 11:04:56,774:INFO:Importing libraries
2025-10-23 11:04:56,775:INFO:Copying training dataset
2025-10-23 11:04:57,132:INFO:Defining folds
2025-10-23 11:04:57,132:INFO:Declaring metric variables
2025-10-23 11:04:57,138:INFO:Importing untrained model
2025-10-23 11:04:57,143:INFO:Ridge Classifier Imported successfully
2025-10-23 11:04:57,149:INFO:Starting cross validation
2025-10-23 11:04:57,157:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:05:12,907:INFO:Calculating mean and std
2025-10-23 11:05:12,908:INFO:Creating metrics dataframe
2025-10-23 11:05:12,910:INFO:Uploading results into container
2025-10-23 11:05:12,910:INFO:Uploading model into container now
2025-10-23 11:05:12,911:INFO:_master_model_container: 6
2025-10-23 11:05:12,911:INFO:_display_container: 2
2025-10-23 11:05:12,911:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-10-23 11:05:12,911:INFO:create_model() successfully completed......................................
2025-10-23 11:05:13,074:INFO:SubProcess create_model() end ==================================
2025-10-23 11:05:13,074:INFO:Creating metrics dataframe
2025-10-23 11:05:13,081:INFO:Initializing Random Forest Classifier
2025-10-23 11:05:13,081:INFO:Total runtime is 2.6425103108088175 minutes
2025-10-23 11:05:13,086:INFO:SubProcess create_model() called ==================================
2025-10-23 11:05:13,087:INFO:Initializing create_model()
2025-10-23 11:05:13,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=rf, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:05:13,088:INFO:Checking exceptions
2025-10-23 11:05:13,088:INFO:Importing libraries
2025-10-23 11:05:13,088:INFO:Copying training dataset
2025-10-23 11:05:13,388:INFO:Defining folds
2025-10-23 11:05:13,388:INFO:Declaring metric variables
2025-10-23 11:05:13,392:INFO:Importing untrained model
2025-10-23 11:05:13,396:INFO:Random Forest Classifier Imported successfully
2025-10-23 11:05:13,403:INFO:Starting cross validation
2025-10-23 11:05:13,410:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:06:37,100:INFO:Calculating mean and std
2025-10-23 11:06:37,102:INFO:Creating metrics dataframe
2025-10-23 11:06:37,106:INFO:Uploading results into container
2025-10-23 11:06:37,107:INFO:Uploading model into container now
2025-10-23 11:06:37,107:INFO:_master_model_container: 7
2025-10-23 11:06:37,108:INFO:_display_container: 2
2025-10-23 11:06:37,109:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-10-23 11:06:37,109:INFO:create_model() successfully completed......................................
2025-10-23 11:06:37,342:INFO:SubProcess create_model() end ==================================
2025-10-23 11:06:37,342:INFO:Creating metrics dataframe
2025-10-23 11:06:37,351:INFO:Initializing Quadratic Discriminant Analysis
2025-10-23 11:06:37,351:INFO:Total runtime is 4.04701824982961 minutes
2025-10-23 11:06:37,358:INFO:SubProcess create_model() called ==================================
2025-10-23 11:06:37,359:INFO:Initializing create_model()
2025-10-23 11:06:37,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=qda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:06:37,360:INFO:Checking exceptions
2025-10-23 11:06:37,360:INFO:Importing libraries
2025-10-23 11:06:37,361:INFO:Copying training dataset
2025-10-23 11:06:37,939:INFO:Defining folds
2025-10-23 11:06:37,940:INFO:Declaring metric variables
2025-10-23 11:06:37,949:INFO:Importing untrained model
2025-10-23 11:06:37,953:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-23 11:06:37,967:INFO:Starting cross validation
2025-10-23 11:06:37,975:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:06:43,379:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-23 11:06:47,335:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-23 11:06:51,071:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-23 11:06:54,682:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-23 11:06:58,479:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear

2025-10-23 11:06:59,016:INFO:Calculating mean and std
2025-10-23 11:06:59,017:INFO:Creating metrics dataframe
2025-10-23 11:06:59,019:INFO:Uploading results into container
2025-10-23 11:06:59,020:INFO:Uploading model into container now
2025-10-23 11:06:59,021:INFO:_master_model_container: 8
2025-10-23 11:06:59,021:INFO:_display_container: 2
2025-10-23 11:06:59,021:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-23 11:06:59,021:INFO:create_model() successfully completed......................................
2025-10-23 11:06:59,180:INFO:SubProcess create_model() end ==================================
2025-10-23 11:06:59,180:INFO:Creating metrics dataframe
2025-10-23 11:06:59,187:INFO:Initializing Ada Boost Classifier
2025-10-23 11:06:59,187:INFO:Total runtime is 4.410956251621246 minutes
2025-10-23 11:06:59,190:INFO:SubProcess create_model() called ==================================
2025-10-23 11:06:59,192:INFO:Initializing create_model()
2025-10-23 11:06:59,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=ada, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:06:59,194:INFO:Checking exceptions
2025-10-23 11:06:59,194:INFO:Importing libraries
2025-10-23 11:06:59,194:INFO:Copying training dataset
2025-10-23 11:06:59,485:INFO:Defining folds
2025-10-23 11:06:59,485:INFO:Declaring metric variables
2025-10-23 11:06:59,488:INFO:Importing untrained model
2025-10-23 11:06:59,493:INFO:Ada Boost Classifier Imported successfully
2025-10-23 11:06:59,499:INFO:Starting cross validation
2025-10-23 11:06:59,504:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:07:02,602:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 11:07:08,577:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 11:07:11,648:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 11:07:20,314:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 11:07:28,968:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 11:07:37,467:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

2025-10-23 11:07:43,016:WARNING:c:\Users\Usuario\anaconda3\envs\villaIA_leyva\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-10-23 11:07:43,032:INFO:Calculating mean and std
2025-10-23 11:07:43,034:INFO:Creating metrics dataframe
2025-10-23 11:07:43,036:INFO:Uploading results into container
2025-10-23 11:07:43,037:INFO:Uploading model into container now
2025-10-23 11:07:43,038:INFO:_master_model_container: 9
2025-10-23 11:07:43,038:INFO:_display_container: 2
2025-10-23 11:07:43,038:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-10-23 11:07:43,038:INFO:create_model() successfully completed......................................
2025-10-23 11:07:43,215:INFO:SubProcess create_model() end ==================================
2025-10-23 11:07:43,215:INFO:Creating metrics dataframe
2025-10-23 11:07:43,224:INFO:Initializing Gradient Boosting Classifier
2025-10-23 11:07:43,224:INFO:Total runtime is 5.144894929726918 minutes
2025-10-23 11:07:43,230:INFO:SubProcess create_model() called ==================================
2025-10-23 11:07:43,231:INFO:Initializing create_model()
2025-10-23 11:07:43,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=gbc, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:07:43,231:INFO:Checking exceptions
2025-10-23 11:07:43,231:INFO:Importing libraries
2025-10-23 11:07:43,231:INFO:Copying training dataset
2025-10-23 11:07:43,553:INFO:Defining folds
2025-10-23 11:07:43,553:INFO:Declaring metric variables
2025-10-23 11:07:43,557:INFO:Importing untrained model
2025-10-23 11:07:43,562:INFO:Gradient Boosting Classifier Imported successfully
2025-10-23 11:07:43,570:INFO:Starting cross validation
2025-10-23 11:07:43,577:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:09:42,694:INFO:Calculating mean and std
2025-10-23 11:09:42,695:INFO:Creating metrics dataframe
2025-10-23 11:09:42,698:INFO:Uploading results into container
2025-10-23 11:09:42,698:INFO:Uploading model into container now
2025-10-23 11:09:42,699:INFO:_master_model_container: 10
2025-10-23 11:09:42,699:INFO:_display_container: 2
2025-10-23 11:09:42,699:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-23 11:09:42,700:INFO:create_model() successfully completed......................................
2025-10-23 11:09:42,885:INFO:SubProcess create_model() end ==================================
2025-10-23 11:09:42,886:INFO:Creating metrics dataframe
2025-10-23 11:09:42,894:INFO:Initializing Linear Discriminant Analysis
2025-10-23 11:09:42,895:INFO:Total runtime is 7.139411207040151 minutes
2025-10-23 11:09:42,899:INFO:SubProcess create_model() called ==================================
2025-10-23 11:09:42,901:INFO:Initializing create_model()
2025-10-23 11:09:42,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=lda, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:09:42,902:INFO:Checking exceptions
2025-10-23 11:09:42,902:INFO:Importing libraries
2025-10-23 11:09:42,902:INFO:Copying training dataset
2025-10-23 11:09:43,283:INFO:Defining folds
2025-10-23 11:09:43,284:INFO:Declaring metric variables
2025-10-23 11:09:43,290:INFO:Importing untrained model
2025-10-23 11:09:43,293:INFO:Linear Discriminant Analysis Imported successfully
2025-10-23 11:09:43,299:INFO:Starting cross validation
2025-10-23 11:09:43,306:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:10:03,626:INFO:Calculating mean and std
2025-10-23 11:10:03,627:INFO:Creating metrics dataframe
2025-10-23 11:10:03,630:INFO:Uploading results into container
2025-10-23 11:10:03,631:INFO:Uploading model into container now
2025-10-23 11:10:03,631:INFO:_master_model_container: 11
2025-10-23 11:10:03,631:INFO:_display_container: 2
2025-10-23 11:10:03,632:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-23 11:10:03,632:INFO:create_model() successfully completed......................................
2025-10-23 11:10:03,815:INFO:SubProcess create_model() end ==================================
2025-10-23 11:10:03,815:INFO:Creating metrics dataframe
2025-10-23 11:10:03,828:INFO:Initializing Extra Trees Classifier
2025-10-23 11:10:03,828:INFO:Total runtime is 7.488306697209676 minutes
2025-10-23 11:10:03,832:INFO:SubProcess create_model() called ==================================
2025-10-23 11:10:03,833:INFO:Initializing create_model()
2025-10-23 11:10:03,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233282B6850>, estimator=et, fold=GroupKFold(n_splits=5), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=55839    U04622
74143    U09160
53722    U10858
61548    U09535
74714    U02827
          ...  
28271    U08865
52847    U02871
33370    U17436
38599    U00373
29387    U03046
Name: id_usuario, Length: 56002, dtype: string, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002334CBE1C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-23 11:10:03,833:INFO:Checking exceptions
2025-10-23 11:10:03,833:INFO:Importing libraries
2025-10-23 11:10:03,833:INFO:Copying training dataset
2025-10-23 11:10:04,147:INFO:Defining folds
2025-10-23 11:10:04,147:INFO:Declaring metric variables
2025-10-23 11:10:04,150:INFO:Importing untrained model
2025-10-23 11:10:04,156:INFO:Extra Trees Classifier Imported successfully
2025-10-23 11:10:04,161:INFO:Starting cross validation
2025-10-23 11:10:04,166:INFO:Cross validating with GroupKFold(n_splits=5), n_jobs=1
2025-10-23 11:13:08,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 11:13:08,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 11:13:08,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 11:13:08,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-23 11:13:10,863:INFO:PyCaret ClassificationExperiment
2025-10-23 11:13:10,863:INFO:Logging name: clf-default-name
2025-10-23 11:13:10,863:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-23 11:13:10,863:INFO:version 3.3.2
2025-10-23 11:13:10,863:INFO:Initializing setup()
2025-10-23 11:13:10,863:INFO:self.USI: bf11
2025-10-23 11:13:10,863:INFO:self._variable_keys: {'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'memory', 'X_test', 'idx', 'y_test', 'X_train', 'exp_name_log', 'target_param', 'logging_param', 'data', 'exp_id', 'fold_shuffle_param', '_available_plots', 'html_param', 'y', 'pipeline', 'USI', 'log_plots_param', 'X', 'fold_generator', 'gpu_param', 'seed', '_ml_usecase'}
2025-10-23 11:13:10,863:INFO:Checking environment
2025-10-23 11:13:10,864:INFO:python_version: 3.11.13
2025-10-23 11:13:10,864:INFO:python_build: ('main', 'Jun  5 2025 13:03:15')
2025-10-23 11:13:10,864:INFO:machine: AMD64
2025-10-23 11:13:10,864:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-23 11:13:10,869:INFO:Memory: svmem(total=16856211456, available=1926397952, percent=88.6, used=14929813504, free=1926397952)
2025-10-23 11:13:10,869:INFO:Physical Core: 4
2025-10-23 11:13:10,869:INFO:Logical Core: 8
2025-10-23 11:13:10,869:INFO:Checking libraries
2025-10-23 11:13:10,869:INFO:System:
2025-10-23 11:13:10,869:INFO:    python: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]
2025-10-23 11:13:10,869:INFO:executable: c:\Users\Usuario\anaconda3\envs\villaIA_leyva\python.exe
2025-10-23 11:13:10,869:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-23 11:13:10,869:INFO:PyCaret required dependencies:
2025-10-23 11:13:11,587:INFO:                 pip: 25.2
2025-10-23 11:13:11,587:INFO:          setuptools: 80.9.0
2025-10-23 11:13:11,587:INFO:             pycaret: 3.3.2
2025-10-23 11:13:11,587:INFO:             IPython: 9.6.0
2025-10-23 11:13:11,587:INFO:          ipywidgets: 8.1.7
2025-10-23 11:13:11,587:INFO:                tqdm: 4.67.1
2025-10-23 11:13:11,587:INFO:               numpy: 1.26.4
2025-10-23 11:13:11,587:INFO:              pandas: 2.1.4
2025-10-23 11:13:11,587:INFO:              jinja2: 3.1.6
2025-10-23 11:13:11,587:INFO:               scipy: 1.11.4
2025-10-23 11:13:11,587:INFO:              joblib: 1.3.2
2025-10-23 11:13:11,587:INFO:             sklearn: 1.4.2
2025-10-23 11:13:11,587:INFO:                pyod: 2.0.5
2025-10-23 11:13:11,587:INFO:            imblearn: 0.14.0
2025-10-23 11:13:11,587:INFO:   category_encoders: 2.7.0
2025-10-23 11:13:11,587:INFO:            lightgbm: 4.6.0
2025-10-23 11:13:11,587:INFO:               numba: 0.61.0
2025-10-23 11:13:11,587:INFO:            requests: 2.32.5
2025-10-23 11:13:11,587:INFO:          matplotlib: 3.7.5
2025-10-23 11:13:11,587:INFO:          scikitplot: 0.3.7
2025-10-23 11:13:11,587:INFO:         yellowbrick: 1.5
2025-10-23 11:13:11,587:INFO:              plotly: 5.24.1
2025-10-23 11:13:11,587:INFO:    plotly-resampler: Not installed
2025-10-23 11:13:11,587:INFO:             kaleido: 1.1.0
2025-10-23 11:13:11,587:INFO:           schemdraw: 0.15
2025-10-23 11:13:11,587:INFO:         statsmodels: 0.14.5
2025-10-23 11:13:11,587:INFO:              sktime: 0.26.0
2025-10-23 11:13:11,587:INFO:               tbats: 1.1.3
2025-10-23 11:13:11,587:INFO:            pmdarima: 2.0.4
2025-10-23 11:13:11,587:INFO:              psutil: 7.1.1
2025-10-23 11:13:11,587:INFO:          markupsafe: 3.0.3
2025-10-23 11:13:11,587:INFO:             pickle5: Not installed
2025-10-23 11:13:11,588:INFO:         cloudpickle: 3.1.1
2025-10-23 11:13:11,588:INFO:         deprecation: 2.1.0
2025-10-23 11:13:11,588:INFO:              xxhash: 3.6.0
2025-10-23 11:13:11,588:INFO:           wurlitzer: Not installed
2025-10-23 11:13:11,588:INFO:PyCaret optional dependencies:
2025-10-23 11:13:15,152:INFO:                shap: 0.44.1
2025-10-23 11:13:15,152:INFO:           interpret: 0.7.3
2025-10-23 11:13:15,152:INFO:                umap: 0.5.7
2025-10-23 11:13:15,152:INFO:     ydata_profiling: 4.17.0
2025-10-23 11:13:15,152:INFO:  explainerdashboard: 0.5.1
2025-10-23 11:13:15,152:INFO:             autoviz: Not installed
2025-10-23 11:13:15,153:INFO:           fairlearn: 0.7.0
2025-10-23 11:13:15,153:INFO:          deepchecks: Not installed
2025-10-23 11:13:15,153:INFO:             xgboost: 3.1.0
2025-10-23 11:13:15,153:INFO:            catboost: 1.2.8
2025-10-23 11:13:15,153:INFO:              kmodes: 0.12.2
2025-10-23 11:13:15,153:INFO:             mlxtend: 0.23.4
2025-10-23 11:13:15,153:INFO:       statsforecast: 1.5.0
2025-10-23 11:13:15,153:INFO:        tune_sklearn: Not installed
2025-10-23 11:13:15,153:INFO:                 ray: Not installed
2025-10-23 11:13:15,153:INFO:            hyperopt: 0.2.7
2025-10-23 11:13:15,153:INFO:              optuna: 4.5.0
2025-10-23 11:13:15,153:INFO:               skopt: 0.10.2
2025-10-23 11:13:15,153:INFO:              mlflow: 3.5.0
2025-10-23 11:13:15,153:INFO:              gradio: 5.49.1
2025-10-23 11:13:15,153:INFO:             fastapi: 0.119.1
2025-10-23 11:13:15,153:INFO:             uvicorn: 0.38.0
2025-10-23 11:13:15,153:INFO:              m2cgen: 0.10.0
2025-10-23 11:13:15,153:INFO:           evidently: 0.4.40
2025-10-23 11:13:15,153:INFO:               fugue: 0.8.7
2025-10-23 11:13:15,153:INFO:           streamlit: Not installed
2025-10-23 11:13:15,153:INFO:             prophet: Not installed
2025-10-23 11:13:15,153:INFO:None
2025-10-23 11:13:15,154:INFO:Set up data.
2025-10-23 11:13:15,368:INFO:Set up folding strategy.
2025-10-23 11:13:15,603:INFO:Set up train/test split.
2025-10-23 11:13:15,839:INFO:Set up index.
2025-10-23 11:13:15,859:INFO:Assigning column types.
2025-10-23 11:13:16,150:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-23 11:13:16,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-23 11:13:16,193:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 11:13:16,226:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:13:16,229:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:13:16,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-23 11:13:16,294:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 11:13:16,314:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:13:16,317:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:13:16,317:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-23 11:13:16,354:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 11:13:16,375:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:13:16,377:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:13:16,411:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-23 11:13:16,432:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:13:16,434:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:13:16,435:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-23 11:13:16,491:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:13:16,493:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:13:16,548:INFO:Soft dependency imported: xgboost: 3.1.0
2025-10-23 11:13:16,550:INFO:Soft dependency imported: catboost: 1.2.8
2025-10-23 11:13:16,552:INFO:Preparing preprocessing pipeline...
2025-10-23 11:13:16,599:INFO:Set up simple imputation.
2025-10-23 11:13:16,810:INFO:Set up encoding of ordinal features.
2025-10-23 11:13:16,908:INFO:Set up encoding of categorical features.
2025-10-23 11:13:16,915:INFO:Set up removing multicollinearity.
2025-10-23 11:13:16,915:INFO:Set up imbalanced handling.
2025-10-23 11:13:22,449:INFO:Finished creating preprocessing pipeline.
2025-10-23 11:13:22,466:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Usuario\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'presupuesto_estimado',
                                             'costo_entrada', 'admite_mascotas',
                                             'frecuencia_viaje',
                                             'sitios_visitados',
                                             'calificacion_sitios_previos',
                                             'tiempo_estancia_promedio',
                                             'afluencia_promedio',
                                             'duracion_esperada',
                                             '...
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-10-23 11:13:22,466:INFO:Creating final display dataframe.
