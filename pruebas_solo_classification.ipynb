{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a24d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- imports & config ---\n",
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "DATA_PATH = \"dataset_Recomendacion_villa_de_leyva_eleccion (2).csv\"   # ajústalo\n",
    "CAT_PATH  = \"catalogo_vdl_lugares_unico.csv\"               # ajústalo\n",
    "SEP, ENC  = \";\", \"utf-8-sig\"\n",
    "RANDOM_SEED = 42\n",
    "K_LIST = [3, 5, 10]\n",
    "TEST_USER_FRAC = 0.20     # % de usuarios para hold-out honesto\n",
    "\n",
    "# --- normalizador de encabezados con caracteres raros ---\n",
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ren = {\n",
    "        \"compa¤¡a_viaje\": \"compania_viaje\",\n",
    "        \"‚poca_visita\": \"epoca_visita\",\n",
    "    }\n",
    "    ren = {k:v for k,v in ren.items() if k in df.columns}\n",
    "    return df.rename(columns=ren)\n",
    "\n",
    "# --- métricas Top-K ---\n",
    "def _dcg_at_k(rels): return float(np.sum([r/np.log2(i+2) for i,r in enumerate(rels)]))\n",
    "\n",
    "def recall_at_k(g, k, score_col, rel_col):\n",
    "    g = g.sort_values(score_col, ascending=False)\n",
    "    topk = g.head(k)\n",
    "    tot = g[rel_col].sum()\n",
    "    return float(\"nan\") if tot==0 else float(topk[rel_col].sum()/tot)\n",
    "\n",
    "def ndcg_at_k(g, k, score_col, rel_col):\n",
    "    g = g.sort_values(score_col, ascending=False)\n",
    "    dcg  = _dcg_at_k(g.head(k)[rel_col].tolist())\n",
    "    idcg = _dcg_at_k(sorted(g[rel_col].tolist(), reverse=True)[:k])\n",
    "    return float(\"nan\") if idcg==0 else float(dcg/idcg)\n",
    "\n",
    "def coverage_at_k(df, k, score_col, item_col=\"nombre_sitio\"):\n",
    "    topk = (df.sort_values([\"id_usuario\", score_col], ascending=[True, False])\n",
    "              .groupby(\"id_usuario\").head(k))\n",
    "    return float(topk[item_col].nunique() / df[item_col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc8d6d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Esquema OK. Ejemplo columnas: ['id_usuario', 'edad', 'nacionalidad', 'origen', 'tipo_turista_preferido', 'compania_viaje', 'frecuencia_viaje', 'restricciones_movilidad', 'presupuesto_estimado', 'sitios_visitados', 'calificacion_sitios_previos', 'tiempo_estancia_promedio', 'nombre_sitio', 'tipo_sitio', 'costo_entrada']\n",
      "Shape: (100000, 30)\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# Config y carga inicial\n",
    "# =======================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "\n",
    "ENC = \"utf-8-sig\"\n",
    "SEP = \";\"\n",
    "DATA_PATH = \"dataset_Recomendacion_villa_de_leyva_eleccion (2).csv\"  # <-- ajusta si aplica\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=SEP, encoding=ENC)\n",
    "\n",
    "# 1) Normaliza encabezados y espacios\n",
    "# (Se asume que ya tienes normalize_columns; si no, te la paso)\n",
    "df = normalize_columns(df)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# ================================\n",
    "# 2) Parche de esquema (sinónimos)\n",
    "# ================================\n",
    "CANDIDATES = {\n",
    "    \"compania_viaje\":        [\"compania_viaje\",\"compañia_viaje\",\"compan_a_viaje\",\"companaviaje\"],\n",
    "    \"costo_entrada\":         [\"costo_entrada\",\"costoentrada\",\"precio_entrada\",\"costo\"],\n",
    "    \"afluencia_promedio\":    [\"afluencia_promedio\",\"afluencia\",\"afluencia_prom\"],\n",
    "    \"duracion_esperada\":     [\"duracion_esperada\",\"duracion_estimada\",\"duracion\",\"tiempo_esperado\"],\n",
    "    \"presupuesto_estimado\":  [\"presupuesto_estimado\",\"presupuesto\",\"budget\"],\n",
    "    \"tipo_turista_preferido\":[\"tipo_turista_preferido\",\"preferencia\",\"perfil_preferido\"],\n",
    "}\n",
    "for tgt, opts in CANDIDATES.items():\n",
    "    if tgt not in df.columns:\n",
    "        for c in opts:\n",
    "            if c in df.columns:\n",
    "                df = df.rename(columns={c: tgt})\n",
    "                break\n",
    "\n",
    "# ==============================================================\n",
    "# 3) Canonicalización de valores categóricos (acentos, espacios)\n",
    "# ==============================================================\n",
    "CANON_MAP = {\n",
    "    \"gastronomia\": \"gastronomico\",\n",
    "    \"gastronomía\": \"gastronomico\",\n",
    "    \"relax_fotografia\": \"relax_fotografia\",\n",
    "    \"relax_fotografía\": \"relax_fotografia\",\n",
    "    \"parque tematico\": \"parque_tematico\",\n",
    "    \"enoturismo\": \"gastronomico\",\n",
    "}\n",
    "def canon(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    s = s.strip().lower().replace(\" \", \"_\")\n",
    "    return CANON_MAP.get(s, s)\n",
    "\n",
    "def normalize_values(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    df2 = df_in.copy()\n",
    "    cols = [\"tipo_turista_preferido\",\"tipo_sitio\",\"epoca_visita\",\n",
    "            \"accesibilidad_general\",\"ubicacion_geografica\",\"idioma_info\"]\n",
    "    for c in cols:\n",
    "        if c in df2.columns:\n",
    "            df2[c] = df2[c].astype(str).map(canon)\n",
    "    return df2\n",
    "\n",
    "df = normalize_values(df)\n",
    "\n",
    "# ====================================\n",
    "# 4) Validación mínima de requeridos\n",
    "# ====================================\n",
    "REQ = [\"costo_entrada\",\"presupuesto_estimado\",\"tipo_sitio\",\n",
    "       \"tipo_turista_preferido\",\"epoca_visita\",\"rating_usuario\"]  # <-- añade rating_usuario\n",
    "missing = [c for c in REQ if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Faltan columnas obligatorias: {missing}\\nDisponibles: {list(df.columns)}\")\n",
    "\n",
    "# ==========================================================\n",
    "# 5) Limpieza específica (admite_mascotas texto -> numérico)\n",
    "# ==========================================================\n",
    "if \"admite_mascotas\" in df.columns:\n",
    "    # Mapea variantes comunes a 0/1, preserva si ya es numérica\n",
    "    _map = {\"si\":1,\"sí\":1,\"SI\":1,\"Sí\":1,\"Si\":1,\"no\":0,\"NO\":0,\"No\":0,1:1,0:0,\"1\":1,\"0\":0,True:1,False:0}\n",
    "    try:\n",
    "        df[\"admite_mascotas\"] = df[\"admite_mascotas\"].map(_map).astype(\"float\")\n",
    "    except Exception:\n",
    "        pass  # si ya es numérica, sigue\n",
    "\n",
    "# ============================================\n",
    "# 6) Coerción numérica segura (si existen)\n",
    "# ============================================\n",
    "for c in [\"costo_entrada\",\"presupuesto_estimado\",\"edad\",\"frecuencia_viaje\",\n",
    "          \"sitios_visitados\",\"calificacion_sitios_previos\",\"tiempo_estancia_promedio\",\n",
    "          \"afluencia_promedio\",\"duracion_esperada\",\"admite_mascotas\",\"rating_usuario\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# ============================================\n",
    "# 7) Anti-leakage (si llega objetivo filtrado)\n",
    "# ============================================\n",
    "if \"sitio_recomendado\" in df.columns and df[\"sitio_recomendado\"].dtype == object:\n",
    "    # Si por error incluye nombres de sitios como \"objetivo\", rehace como binario\n",
    "    df[\"sitio_recomendado\"] = (df[\"rating_usuario\"] >= 4.0).astype(int)\n",
    "\n",
    "# ===================================================\n",
    "# 8) Definición de columnas por tipo (para modelado)\n",
    "# ===================================================\n",
    "CAT_COLS = [\n",
    "    \"nacionalidad\",\"origen\",\"tipo_turista_preferido\",\"compania_viaje\",\n",
    "    \"restricciones_movilidad\",\"nombre_sitio\",\"tipo_sitio\",\"accesibilidad_general\",\n",
    "    \"idioma_info\",\"ubicacion_geografica\",\"clima_predominante\",\"epoca_visita\"\n",
    "]\n",
    "NUM_COLS = [\n",
    "    \"edad\",\"frecuencia_viaje\",\"presupuesto_estimado\",\"sitios_visitados\",\n",
    "    \"calificacion_sitios_previos\",\"tiempo_estancia_promedio\",\"costo_entrada\",\n",
    "    \"afluencia_promedio\",\"duracion_esperada\",\"admite_mascotas\"\n",
    "]\n",
    "\n",
    "# ================================================\n",
    "# 9) Afinidad (perfil × tipo de sitio) canónica\n",
    "# ================================================\n",
    "AFINIDAD = {\n",
    "    \"cultural\":   {\"museo\":0.9,\"centro_historico\":0.9,\"arquitectura\":0.85,\"arqueologico\":0.85,\"plaza\":0.7,\"religioso\":0.7},\n",
    "    \"naturaleza\": {\"naturaleza\":0.95,\"senderismo\":0.9,\"mirador\":0.8},\n",
    "    \"aventura\":   {\"senderismo\":0.9,\"parque_tematico\":0.75,\"mirador\":0.75,\"naturaleza\":0.7},\n",
    "    \"gastronomico\":{\"gastronomico\":0.95},\n",
    "    \"relax\":      {\"mirador\":0.9,\"plaza\":0.8,\"naturaleza\":0.75,\"arquitectura\":0.8},\n",
    "}\n",
    "\n",
    "# =======================================\n",
    "# 10) Feature engineering determinístico\n",
    "# =======================================\n",
    "def make_features(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "    # a) Ratio costo / (15% del presupuesto) con protecciones\n",
    "    denom = (X[\"presupuesto_estimado\"] * 0.15).replace(0, np.nan)\n",
    "    X[\"ratio_costo_presu\"] = (X[\"costo_entrada\"] / denom).clip(0, 3).fillna(0)\n",
    "    # b) Afinidad (fallback=0.5 si no hay match)\n",
    "    X[\"afinidad_tipo\"] = X.apply(\n",
    "        lambda r: AFINIDAD.get(str(r[\"tipo_turista_preferido\"]), {}).get(str(r[\"tipo_sitio\"]), 0.5), axis=1\n",
    "    )\n",
    "    # c) Interacciones categóricas\n",
    "    X[\"x_tipoTur__tipoSit\"] = X[\"tipo_turista_preferido\"].astype(str) + \"×\" + X[\"tipo_sitio\"].astype(str)\n",
    "    X[\"x_epoca__tipoSit\"]   = X[\"epoca_visita\"].astype(str) + \"×\" + X[\"tipo_sitio\"].astype(str)\n",
    "    return X\n",
    "\n",
    "df = make_features(df)\n",
    "\n",
    "# =======================================\n",
    "# 11) Etiqueta binaria para clasificación\n",
    "# =======================================\n",
    "df[\"y_like\"] = (df[\"rating_usuario\"] >= 4.0).astype(int)\n",
    "\n",
    "# ==========================================================\n",
    "# 12) Conjunto final de columnas de entrada (X) extendidas\n",
    "# ==========================================================\n",
    "CAT_COLS_X = CAT_COLS + [\"x_tipoTur__tipoSit\",\"x_epoca__tipoSit\"]\n",
    "NUM_COLS_X = NUM_COLS + [\"ratio_costo_presu\",\"afinidad_tipo\"]\n",
    "\n",
    "print(\"✅ Esquema OK. Ejemplo columnas:\", df.columns[:15].tolist())\n",
    "print(\"Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4bfa86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios train/test: 16000 4000\n",
      "Filas train/test: (80004, 30) (19996, 30)\n",
      "Frac usuarios test real: 0.2\n",
      "Interacciones por usuario (train): {'min': 1, 'p25': 3, 'median': 5, 'p75': 6, 'max': 16}\n",
      "Interacciones por usuario (test):  {'min': 1, 'p25': 3, 'median': 5, 'p75': 6, 'max': 14}\n",
      "Tasa y_like train/test: 0.3326 / 0.3234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# --- Versión con tus líneas + checks ---\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "users = df[\"id_usuario\"].drop_duplicates().to_numpy()\n",
    "n_test = max(1, int(round(len(users) * TEST_USER_FRAC)))  # evita 0\n",
    "test_users = set(rng.choice(users, size=n_test, replace=False))\n",
    "\n",
    "train_df = df[~df[\"id_usuario\"].isin(test_users)].reset_index(drop=True)\n",
    "test_df  = df[ df[\"id_usuario\"].isin(test_users)].reset_index(drop=True)\n",
    "\n",
    "print(\"Usuarios train/test:\", train_df[\"id_usuario\"].nunique(), test_df[\"id_usuario\"].nunique())\n",
    "print(\"Filas train/test:\", train_df.shape, test_df.shape)\n",
    "\n",
    "# --- Sanity checks útiles ---\n",
    "# 1) No hay usuarios compartidos\n",
    "overlap = set(train_df[\"id_usuario\"]).intersection(set(test_df[\"id_usuario\"]))\n",
    "assert len(overlap) == 0, f\"Fuga de usuarios entre splits: {len(overlap)}\"\n",
    "\n",
    "# 2) Proporción de usuarios en test (aprox TEST_USER_FRAC)\n",
    "print(\"Frac usuarios test real:\", round(test_df[\"id_usuario\"].nunique() / len(users), 4))\n",
    "\n",
    "# 3) Distribución de interacciones por usuario en cada split\n",
    "def _stats_per_user(df_):\n",
    "    g = df_.groupby(\"id_usuario\").size()\n",
    "    return {\"min\": int(g.min()), \"p25\": int(g.quantile(0.25)), \"median\": int(g.median()),\n",
    "            \"p75\": int(g.quantile(0.75)), \"max\": int(g.max())}\n",
    "\n",
    "print(\"Interacciones por usuario (train):\", _stats_per_user(train_df))\n",
    "print(\"Interacciones por usuario (test): \", _stats_per_user(test_df))\n",
    "\n",
    "# 4) (Opcional) Balance de la etiqueta en cada split si existe y_like\n",
    "if \"y_like\" in df.columns:\n",
    "    def _label_rate(d):\n",
    "        return float(d[\"y_like\"].mean()) if \"y_like\" in d.columns else float(\"nan\")\n",
    "    print(\"Tasa y_like train/test:\", round(_label_rate(train_df),4), \"/\", round(_label_rate(test_df),4))\n",
    "\n",
    "# --- Alternativa con GroupShuffleSplit (recomendable y equivalente) ---\n",
    "# gss = GroupShuffleSplit(n_splits=1, test_size=TEST_USER_FRAC, random_state=RANDOM_SEED)\n",
    "# idx_train, idx_test = next(gss.split(df, groups=df[\"id_usuario\"]))\n",
    "# train_df = df.iloc[idx_train].reset_index(drop=True)\n",
    "# test_df  = df.iloc[idx_test].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33c92cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios train/test: 16000 4000\n",
      "Filas train/test: (80004, 29) (19996, 29)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "users = df[\"id_usuario\"].drop_duplicates().to_numpy()\n",
    "test_users = set(rng.choice(users, size=int(len(users)*TEST_USER_FRAC), replace=False))\n",
    "\n",
    "train_df = df[~df[\"id_usuario\"].isin(test_users)].reset_index(drop=True)\n",
    "test_df  = df[ df[\"id_usuario\"].isin(test_users)].reset_index(drop=True)\n",
    "\n",
    "print(\"Usuarios train/test:\", train_df[\"id_usuario\"].nunique(), test_df[\"id_usuario\"].nunique())\n",
    "print(\"Filas train/test:\", train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfd809b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "gbc          Gradient Boosting Classifier    0.8484  0.9215  0.7377  0.7923   \n",
      "ridge                    Ridge Classifier    0.8493  0.9213  0.7304  0.7995   \n",
      "lda          Linear Discriminant Analysis    0.8489  0.9212  0.7404  0.7919   \n",
      "ada                  Ada Boost Classifier    0.8485  0.9208  0.7541  0.7827   \n",
      "lightgbm  Light Gradient Boosting Machine    0.8483  0.9203  0.7382  0.7917   \n",
      "catboost              CatBoost Classifier    0.8465  0.9191  0.7358  0.7887   \n",
      "xgboost         Extreme Gradient Boosting    0.8418  0.9140  0.7308  0.7798   \n",
      "rf               Random Forest Classifier    0.8464  0.9067  0.7338  0.7898   \n",
      "et                 Extra Trees Classifier    0.8194  0.8887  0.5882  0.8178   \n",
      "lr                    Logistic Regression    0.7586  0.8129  0.5739  0.6573   \n",
      "dt               Decision Tree Classifier    0.7818  0.7551  0.6753  0.6710   \n",
      "nb                            Naive Bayes    0.6674  0.7046  0.0000  0.0000   \n",
      "knn                K Neighbors Classifier    0.5985  0.5077  0.2348  0.3471   \n",
      "dummy                    Dummy Classifier    0.6674  0.5000  0.0000  0.0000   \n",
      "svm                   SVM - Linear Kernel    0.5367  0.4978  0.4000  0.1347   \n",
      "qda       Quadratic Discriminant Analysis    0.5115  0.4958  0.4727  0.3321   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "gbc       0.7639  0.6525  0.6534    13.652  \n",
      "ridge     0.7633  0.6531  0.6546     3.414  \n",
      "lda       0.7652  0.6540  0.6549     3.720  \n",
      "ada       0.7680  0.6556  0.6559     6.688  \n",
      "lightgbm  0.7640  0.6524  0.6533     3.976  \n",
      "catboost  0.7613  0.6483  0.6492    25.912  \n",
      "xgboost   0.7545  0.6379  0.6387     5.620  \n",
      "rf        0.7607  0.6479  0.6489    12.166  \n",
      "et        0.6841  0.5624  0.5774    13.632  \n",
      "lr        0.6124  0.4384  0.4408     8.620  \n",
      "dt        0.6731  0.5093  0.5094     4.374  \n",
      "nb        0.0000  0.0000  0.0000     3.540  \n",
      "knn       0.2800  0.0160  0.0166     5.788  \n",
      "dummy     0.0000  0.0000  0.0000     3.224  \n",
      "svm       0.2015  0.0000  0.0000     8.008  \n",
      "qda       0.3439 -0.0001 -0.0013     3.610  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  14%|█▍        | 1/7 [00:00<00:01,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n",
      "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
      "Fold                                                          \n",
      "0       0.8463  0.9190  0.7499  0.7816  0.7654  0.6511  0.6514\n",
      "1       0.8506  0.9232  0.7521  0.7777  0.7647  0.6553  0.6555\n",
      "2       0.8466  0.9186  0.7399  0.7864  0.7624  0.6493  0.6500\n",
      "3       0.8453  0.9182  0.7255  0.8010  0.7614  0.6473  0.6491\n",
      "4       0.8522  0.9246  0.7492  0.7954  0.7716  0.6626  0.6632\n",
      "Mean    0.8482  0.9207  0.7433  0.7884  0.7651  0.6531  0.6538\n",
      "Std     0.0027  0.0027  0.0098  0.0086  0.0036  0.0054  0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  14%|█▍        | 1/7 [00:00<00:01,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
      "Fold                                                          \n",
      "0       0.8481  0.9205  0.7338  0.7961  0.7637  0.6521  0.6533\n",
      "1       0.8518  0.9242  0.7410  0.7872  0.7634  0.6557  0.6563\n",
      "2       0.8484  0.9196  0.7228  0.8020  0.7603  0.6499  0.6518\n",
      "3       0.8454  0.9190  0.7145  0.8090  0.7588  0.6457  0.6484\n",
      "4       0.8520  0.9253  0.7355  0.8036  0.7680  0.6597  0.6610\n",
      "Mean    0.8491  0.9217  0.7295  0.7996  0.7629  0.6526  0.6542\n",
      "Std     0.0025  0.0025  0.0096  0.0074  0.0032  0.0048  0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  14%|█▍        | 1/7 [00:00<00:01,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
      "Fold                                                          \n",
      "0       0.8469  0.9199  0.7413  0.7882  0.7641  0.6509  0.6516\n",
      "1       0.8522  0.9237  0.7526  0.7814  0.7667  0.6587  0.6589\n",
      "2       0.8482  0.9193  0.7335  0.7945  0.7628  0.6514  0.6526\n",
      "3       0.8451  0.9186  0.7261  0.8002  0.7613  0.6470  0.6487\n",
      "4       0.8523  0.9248  0.7487  0.7960  0.7716  0.6626  0.6633\n",
      "Mean    0.8490  0.9213  0.7404  0.7921  0.7653  0.6541  0.6550\n",
      "Std     0.0029  0.0025  0.0097  0.0066  0.0036  0.0057  0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
      "Fold                                                       \n",
      "0       0.8473  0.0  0.7387  0.7910  0.7639  0.6513  0.6522\n",
      "1       0.8523  0.0  0.7493  0.7836  0.7661  0.6583  0.6586\n",
      "2       0.8489  0.0  0.7300  0.7986  0.7628  0.6523  0.6537\n",
      "3       0.8451  0.0  0.7221  0.8028  0.7603  0.6464  0.6483\n",
      "4       0.8525  0.0  0.7428  0.8002  0.7704  0.6620  0.6630\n",
      "Mean    0.8492  0.0  0.7366  0.7952  0.7647  0.6540  0.6552\n",
      "Std     0.0029  0.0  0.0096  0.0070  0.0034  0.0055  0.0051\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "✅ Modelo guardado: modelo_cls_like_v2\n"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import (\n",
    "    setup, compare_models, tune_model, blend_models,\n",
    "    finalize_model, save_model\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inspect\n",
    "\n",
    "# --------- Tipos explícitos (tu parte) ----------\n",
    "train_df = train_df.copy(deep=True)\n",
    "train_df[\"id_usuario\"] = train_df[\"id_usuario\"].astype(\"string\")\n",
    "\n",
    "for c in CAT_COLS_X:\n",
    "    if c in train_df.columns:\n",
    "        train_df[c] = train_df[c].astype(\"string\").copy()\n",
    "\n",
    "for c in NUM_COLS_X:\n",
    "    if c in train_df.columns:\n",
    "        train_df[c] = pd.to_numeric(train_df[c], errors=\"coerce\").astype(\"float64\").copy()\n",
    "\n",
    "data_in = train_df[[\"id_usuario\"] + CAT_COLS_X + NUM_COLS_X + [\"y_like\"]].copy()\n",
    "\n",
    "# --------- Kwargs “deseables” (algunos pueden no existir en tu versión) ----------\n",
    "desired_kwargs = dict(\n",
    "    data = data_in,\n",
    "    target = \"y_like\",\n",
    "    session_id = RANDOM_SEED,\n",
    "    fold = 5,\n",
    "    fold_strategy = \"groupkfold\",\n",
    "    fold_groups = \"id_usuario\",\n",
    "    categorical_features = CAT_COLS_X,\n",
    "    ignore_features = [\"id_usuario\"],\n",
    "    remove_multicollinearity = True,\n",
    "    multicollinearity_threshold = 0.95,\n",
    "\n",
    "    # Imputación explícita (version-friendly)\n",
    "    numeric_imputation = \"mean\",\n",
    "    categorical_imputation = \"most_frequent\",\n",
    "\n",
    "    # Alta cardinalidad\n",
    "    high_cardinality_features = [\"nombre_sitio\",\"x_tipoTur__tipoSit\",\"x_epoca__tipoSit\"],\n",
    "    high_cardinality_method = \"frequency\",\n",
    "\n",
    "    # Otros\n",
    "    fix_imbalance = False,\n",
    "    n_jobs = 1,\n",
    "    verbose = False,\n",
    "    use_gpu = False,\n",
    ")\n",
    "\n",
    "# --------- Filtra kwargs según la firma real de setup ----------\n",
    "sig = inspect.signature(setup)\n",
    "allowed = set(sig.parameters.keys())\n",
    "safe_kwargs = {k: v for k, v in desired_kwargs.items() if k in allowed}\n",
    "\n",
    "# (Por si tu versión tiene “html” o “imputation_type” válidos, puedes añadirlos a mano:)\n",
    "extra_maybe = {}\n",
    "for k, v in [(\"html\", False), (\"imputation_type\", \"simple\")]:\n",
    "    if k in allowed:\n",
    "        extra_maybe[k] = v\n",
    "safe_kwargs.update(extra_maybe)\n",
    "\n",
    "# --------- Llamada segura a setup ----------\n",
    "setup_cls = setup(**safe_kwargs)\n",
    "\n",
    "# --------- Selección, tuning, blending, final ----------\n",
    "best3 = compare_models(n_select=3, sort=\"AUC\")\n",
    "tuned = [tune_model(m, optimize=\"AUC\") for m in best3]\n",
    "blend = blend_models(tuned)\n",
    "final_cls = finalize_model(blend)\n",
    "save_model(final_cls, \"modelo_cls_like_v2\")\n",
    "print(\"✅ Modelo guardado: modelo_cls_like_v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42e64b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n",
      "\n",
      "=== Métricas Top-K en TEST ===\n",
      "    Recall@K  NDCG@K  Coverage@K\n",
      "3     0.6430  0.6875         1.0\n",
      "5     0.8791  0.7640         1.0\n",
      "10    0.9980  0.8055         1.0\n",
      "\n",
      "AUC global (binario): 0.8095\n",
      "\n",
      "Usuarios test eval: 4000\n",
      "Items únicos en test: 87\n",
      "Tasa de positivos (y_like=1): 0.3234\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Evaluación del modelo guardado en test_df\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import load_model, predict_model\n",
    "\n",
    "# --- 0) Asegúrate de tener en memoria (o vuelve a definir) ---\n",
    "#     normalize_columns, canon, normalize_values, make_features,\n",
    "#     CAT_COLS_X, NUM_COLS_X, K_LIST, SEP/ENC si las usas, etc.\n",
    "#     (Si vienes del mismo notebook ya están).\n",
    "\n",
    "# --- 1) Copia y preprocesa test_df igual que train ---\n",
    "test_proc = test_df.copy(deep=True)\n",
    "\n",
    "# Normaliza encabezados y espacios (si aplican en tu flujo)\n",
    "test_proc = normalize_columns(test_proc)\n",
    "test_proc.columns = test_proc.columns.str.strip()\n",
    "\n",
    "# Canonicaliza valores categóricos (acentos/espacios a forma canónica)\n",
    "test_proc = normalize_values(test_proc)\n",
    "\n",
    "# Feature engineering (mismas transformaciones que en train)\n",
    "test_proc = make_features(test_proc)\n",
    "\n",
    "# Tipos: categóricas → string; numéricas → float\n",
    "test_proc[\"id_usuario\"] = test_proc[\"id_usuario\"].astype(\"string\")\n",
    "for c in CAT_COLS_X:\n",
    "    if c in test_proc.columns:\n",
    "        test_proc[c] = test_proc[c].astype(\"string\")\n",
    "for c in NUM_COLS_X:\n",
    "    if c in test_proc.columns:\n",
    "        test_proc[c] = pd.to_numeric(test_proc[c], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "# Objetivo binario (por si aún no existe en test)\n",
    "if \"y_like\" not in test_proc.columns and \"rating_usuario\" in test_proc.columns:\n",
    "    test_proc[\"rating_usuario\"] = pd.to_numeric(test_proc[\"rating_usuario\"], errors=\"coerce\")\n",
    "    test_proc[\"y_like\"] = (test_proc[\"rating_usuario\"] >= 4.0).astype(int)\n",
    "\n",
    "# --- 2) Carga el modelo PyCaret guardado ---\n",
    "model = load_model(\"modelo_cls_like_v2\")\n",
    "\n",
    "# --- 3) Obtener scores SIN pasar id_usuario como feature ---\n",
    "\n",
    "# 3.0) Guarda el id para reconstruir df_scores luego\n",
    "user_ids = test_proc[\"id_usuario\"].astype(\"string\").values\n",
    "\n",
    "# IMPORTANTE: el modelo se entrenó SIN 'id_usuario'\n",
    "cols_infer = CAT_COLS_X + NUM_COLS_X\n",
    "data_infer = test_proc[cols_infer].copy()\n",
    "\n",
    "score_vec = None\n",
    "\n",
    "# Intento 1: probabilidades directamente del pipeline completo\n",
    "try:\n",
    "    proba = model.predict_proba(data_infer)\n",
    "    # localizar índice de la clase positiva (1); si no existe, usa la última columna\n",
    "    pos_idx = None\n",
    "    if hasattr(model, \"classes_\"):\n",
    "        import numpy as np\n",
    "        classes = np.array(model.classes_)\n",
    "        where_1 = np.where(classes == 1)[0]\n",
    "        if len(where_1) > 0:\n",
    "            pos_idx = int(where_1[0])\n",
    "    if pos_idx is None:\n",
    "        pos_idx = -1\n",
    "    score_vec = proba[:, pos_idx].astype(float)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Intento 2: decision_function → sigmoide\n",
    "if score_vec is None:\n",
    "    try:\n",
    "        import numpy as np\n",
    "        dfun = model.decision_function(data_infer)\n",
    "        dfun = np.asarray(dfun, dtype=float)\n",
    "        if dfun.ndim == 2 and dfun.shape[1] > 1:\n",
    "            pos_idx = -1\n",
    "            if hasattr(model, \"classes_\"):\n",
    "                classes = np.array(model.classes_)\n",
    "                where_1 = np.where(classes == 1)[0]\n",
    "                if len(where_1) > 0:\n",
    "                    pos_idx = int(where_1[0])\n",
    "            dfun = dfun[:, pos_idx]\n",
    "        score_vec = 1.0 / (1.0 + np.exp(-dfun))  # sigmoide para ranking\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Intento 3: etiquetas (fallback; menos ideal para ranking)\n",
    "if score_vec is None:\n",
    "    labels = model.predict(data_infer)\n",
    "    score_vec = (pd.Series(labels).astype(str).isin([\"1\",\"True\",\"true\"])).astype(float).values\n",
    "\n",
    "# Construye df_scores (recuerda volver a poner el id guardado)\n",
    "df_scores = pd.DataFrame({\n",
    "    \"id_usuario\": user_ids,\n",
    "    \"nombre_sitio\": test_proc[\"nombre_sitio\"].values,\n",
    "    \"score\": score_vec,\n",
    "    \"relevancia\": test_proc[\"y_like\"].astype(float).values\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 4) Métricas Top-K ---\n",
    "def _dcg_at_k(rels):\n",
    "    return float(np.sum([r/np.log2(i+2) for i, r in enumerate(rels)]))\n",
    "\n",
    "def recall_at_k(g, k, score_col, rel_col):\n",
    "    g = g.sort_values(score_col, ascending=False)\n",
    "    topk = g.head(k)\n",
    "    tot = g[rel_col].sum()\n",
    "    return float(\"nan\") if tot==0 else float(topk[rel_col].sum()/tot)\n",
    "\n",
    "def ndcg_at_k(g, k, score_col, rel_col):\n",
    "    g = g.sort_values(score_col, ascending=False)\n",
    "    dcg  = _dcg_at_k(g.head(k)[rel_col].tolist())\n",
    "    idcg = _dcg_at_k(sorted(g[rel_col].tolist(), reverse=True)[:k])\n",
    "    return float(\"nan\") if idcg==0 else float(dcg/idcg)\n",
    "\n",
    "def coverage_at_k(df, k, score_col, item_col=\"nombre_sitio\"):\n",
    "    topk = (df.sort_values([\"id_usuario\", score_col], ascending=[True, False])\n",
    "              .groupby(\"id_usuario\").head(k))\n",
    "    return float(topk[item_col].nunique() / df[item_col].nunique())\n",
    "\n",
    "# Calcula Recall@K, NDCG@K por usuario y cobertura global\n",
    "results = {}\n",
    "for k in K_LIST:\n",
    "    rec_k = (df_scores.groupby(\"id_usuario\")\n",
    "                     .apply(lambda g: recall_at_k(g, k, \"score\", \"relevancia\"))\n",
    "                     .mean(skipna=True))\n",
    "    ndcg_k = (df_scores.groupby(\"id_usuario\")\n",
    "                      .apply(lambda g: ndcg_at_k(g, k, \"score\", \"relevancia\"))\n",
    "                      .mean(skipna=True))\n",
    "    cov_k = coverage_at_k(df_scores, k, \"score\", item_col=\"nombre_sitio\")\n",
    "    results[k] = {\"Recall@K\": rec_k, \"NDCG@K\": ndcg_k, \"Coverage@K\": cov_k}\n",
    "\n",
    "eval_df = pd.DataFrame(results).T\n",
    "print(\"\\n=== Métricas Top-K en TEST ===\")\n",
    "print(eval_df.round(4))\n",
    "\n",
    "# --- 5) (Opcional) AUC global para referencia de clasificación ---\n",
    "try:\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    auc_global = roc_auc_score(df_scores[\"relevancia\"], df_scores[\"score\"])\n",
    "    print(\"\\nAUC global (binario):\", round(float(auc_global), 4))\n",
    "except Exception as e:\n",
    "    print(\"\\nAUC no disponible:\", e)\n",
    "\n",
    "# --- 6) (Opcional) Quick sanity checks ---\n",
    "print(\"\\nUsuarios test eval:\", df_scores[\"id_usuario\"].nunique())\n",
    "print(\"Items únicos en test:\", df_scores[\"nombre_sitio\"].nunique())\n",
    "print(\"Tasa de positivos (y_like=1):\", round(float(df_scores[\"relevancia\"].mean()), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbd52636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Recomendaciones para PERFIL 1 (cultural, pareja) ===\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "arg must be a list, tuple, 1-d array, or Series",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 197\u001b[39m\n\u001b[32m    179\u001b[39m usuario_naturaleza = {\n\u001b[32m    180\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mid_usuario\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSIMU-002\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    181\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnacionalidad\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mColombia\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33madmite_mascotas\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m\n\u001b[32m    194\u001b[39m }\n\u001b[32m    196\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Recomendaciones para PERFIL 1 (cultural, pareja) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrecommend_for_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43musuario_cultural\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTOP_N\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiversity_lambda\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDIVERSITY_LAMBDA\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    199\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Recomendaciones para PERFIL 2 (naturaleza, familia) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28mprint\u001b[39m(recommend_for_user(usuario_naturaleza, top_n=TOP_N, diversity_lambda=DIVERSITY_LAMBDA))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 119\u001b[39m, in \u001b[36mrecommend_for_user\u001b[39m\u001b[34m(user_profile, model_name, catalog_path, top_n, diversity_lambda)\u001b[39m\n\u001b[32m    116\u001b[39m X = make_features(X)\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# 4) Dtypes como en train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m X = \u001b[43m_ensure_model_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# 5) Carga modelo y predice score de clase positiva\u001b[39;00m\n\u001b[32m    122\u001b[39m model = load_model(model_name)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36m_ensure_model_dtypes\u001b[39m\u001b[34m(X)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m NUM_COLS_X:\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m X.columns:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         X[c] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoerce\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat64\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\anaconda3\\envs\\villaIA_leyva\\Lib\\site-packages\\pandas\\core\\tools\\numeric.py:196\u001b[39m, in \u001b[36mto_numeric\u001b[39m\u001b[34m(arg, errors, downcast, dtype_backend)\u001b[39m\n\u001b[32m    194\u001b[39m     values = np.array([arg], dtype=\u001b[33m\"\u001b[39m\u001b[33mO\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33marg must be a list, tuple, 1-d array, or Series\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    198\u001b[39m     values = arg\n",
      "\u001b[31mTypeError\u001b[39m: arg must be a list, tuple, 1-d array, or Series"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Simulación: recomendar Top-N a un usuario nuevo\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import load_model, predict_model\n",
    "\n",
    "# --- Config comunes (ajusta si aplica) ---\n",
    "ENC, SEP = \"utf-8-sig\", \";\"\n",
    "CAT_PATH = \"catalogo_vdl_lugares_unico.csv\"   # <-- ruta a tu catálogo\n",
    "MODEL_NAME = \"modelo_cls_like_v2\"             # <-- nombre del modelo guardado\n",
    "TOP_N = 5                                     # cuántas recomendaciones\n",
    "DIVERSITY_LAMBDA = 0.25                       # penalización por repetir tipo_sitio (0 = nada, 0.2-0.4 razonable)\n",
    "\n",
    "# --- Reutiliza tus utilidades (asegúrate de tenerlas definidas antes en el notebook) ---\n",
    "#   - normalize_columns(df)\n",
    "#   - canon(s)\n",
    "#   - normalize_values(df)  -> aplica canon a columnas categóricas clave\n",
    "#   - make_features(df)     -> crea ratio_costo_presu, afinidad_tipo, cruces\n",
    "#   - CAT_COLS_X, NUM_COLS_X\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helpers\n",
    "# ------------------------------------------------------------\n",
    "def _ensure_catalog_schema(cat: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Garantiza columnas mínimas del catálogo y tipos numéricos.\n",
    "    Completa faltantes con defaults razonables.\n",
    "    \"\"\"\n",
    "    cat = cat.copy()\n",
    "    needed = [\n",
    "        \"nombre_sitio\",\"tipo_sitio\",\"ubicacion_geografica\",\"clima_predominante\",\n",
    "        \"costo_entrada\",\"afluencia_promedio\",\"accesibilidad_general\",\n",
    "        \"duracion_esperada\",\"admite_mascotas\",\"idioma_info\"\n",
    "    ]\n",
    "    for col in needed:\n",
    "        if col not in cat.columns:\n",
    "            # Defaults mínimos\n",
    "            if col in [\"costo_entrada\",\"afluencia_promedio\",\"duracion_esperada\",\"admite_mascotas\"]:\n",
    "                cat[col] = 0\n",
    "            else:\n",
    "                cat[col] = \"\"\n",
    "    # tipos numéricos\n",
    "    for c in [\"costo_entrada\",\"afluencia_promedio\",\"duracion_esperada\",\"admite_mascotas\"]:\n",
    "        cat[c] = pd.to_numeric(cat[c], errors=\"coerce\")\n",
    "    # valores categóricos a forma canónica\n",
    "    cat = normalize_values(cat)\n",
    "    return cat\n",
    "\n",
    "def _broadcast_user_over_catalog(user_profile: dict, catalog: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Crea el producto cartesiano: duplica el perfil del usuario sobre todos los sitios del catálogo.\n",
    "    \"\"\"\n",
    "    user_df = pd.DataFrame([user_profile])\n",
    "    # canoniza valores de usuario\n",
    "    user_df = normalize_values(user_df)\n",
    "    # repetimos el usuario tantas filas como sitios\n",
    "    user_expanded = pd.concat([user_df]*len(catalog), ignore_index=True)\n",
    "    # combinamos columnas de usuario + columnas del catálogo\n",
    "    X = pd.concat([user_expanded.reset_index(drop=True), catalog.reset_index(drop=True)], axis=1)\n",
    "    return X\n",
    "\n",
    "def _ensure_model_dtypes(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Asegura dtypes compatibles con el pipeline de entrenamiento.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    # categóricas a string\n",
    "    for c in CAT_COLS_X:\n",
    "        if c in X.columns:\n",
    "            X[c] = X[c].astype(\"string\")\n",
    "    # numéricas a float\n",
    "    for c in NUM_COLS_X:\n",
    "        if c in X.columns:\n",
    "            X[c] = pd.to_numeric(X[c], errors=\"coerce\").astype(\"float64\")\n",
    "    return X\n",
    "\n",
    "def _mmr_diversify(df_scored: pd.DataFrame, score_col: str, tipo_col: str = \"tipo_sitio\",\n",
    "                   top_n: int = 5, lam: float = 0.25) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reranking muy simple estilo MMR por 'tipo_sitio':\n",
    "    - Escoge greedy el mayor score\n",
    "    - Penaliza candidatos del mismo tipo: score' = score - lam * (#seleccionados de ese tipo)\n",
    "    \"\"\"\n",
    "    work = df_scored.copy()\n",
    "    work[\"_sel\"] = 0\n",
    "    chosen_idx = []\n",
    "    type_counts = {}\n",
    "    for _ in range(min(top_n, len(work))):\n",
    "        # penalización dinámica\n",
    "        penal = work[tipo_col].map(lambda t: lam * type_counts.get(t, 0))\n",
    "        work[\"_adj\"] = work[score_col] - penal\n",
    "        pick = work[\"_adj\"].idxmax()\n",
    "        chosen_idx.append(pick)\n",
    "        t = work.at[pick, tipo_col]\n",
    "        type_counts[t] = type_counts.get(t, 0) + 1\n",
    "        work = work.drop(index=pick)\n",
    "    return df_scored.loc[chosen_idx]\n",
    "\n",
    "def recommend_for_user(user_profile: dict, model_name: str = MODEL_NAME,\n",
    "                       catalog_path: str = CAT_PATH, top_n: int = TOP_N,\n",
    "                       diversity_lambda: float = DIVERSITY_LAMBDA) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga catálogo + modelo, arma el set usuario×sitio, predice y devuelve Top-N (diversificado).\n",
    "    \"\"\"\n",
    "    # 1) Lee y normaliza catálogo\n",
    "    cat = pd.read_csv(catalog_path, sep=SEP, encoding=ENC)\n",
    "    cat = normalize_columns(cat)\n",
    "    cat.columns = cat.columns.str.strip()\n",
    "    cat = _ensure_catalog_schema(cat)\n",
    "\n",
    "    # 2) Ensambla matriz usuario×sitio\n",
    "    X = _broadcast_user_over_catalog(user_profile, cat)\n",
    "\n",
    "    # 3) Feature engineering igual que en train\n",
    "    X = make_features(X)\n",
    "\n",
    "    # 4) Dtypes como en train\n",
    "    X = _ensure_model_dtypes(X)\n",
    "\n",
    "    # 5) Carga modelo y predice score de clase positiva\n",
    "    model = load_model(model_name)\n",
    "    preds = predict_model(model, data=X[CAT_COLS_X + NUM_COLS_X])\n",
    "\n",
    "    # buscar columna de probabilidad\n",
    "    candidates = [\"prediction_score\",\"Score\",\"score\",\"prediction_score_1\",\"Score_1\"]\n",
    "    score_col = next((c for c in candidates if c in preds.columns), None)\n",
    "    if score_col is None:\n",
    "        # fallback genérico\n",
    "        proba_1 = [c for c in preds.columns if str(c).lower().endswith((\"_1\",\"class_1\",\"score_1\"))]\n",
    "        score_col = proba_1[0] if proba_1 else None\n",
    "    if score_col is None:\n",
    "        raise RuntimeError(f\"No se encontró columna de score/probabilidad en {list(preds.columns)}\")\n",
    "\n",
    "    # 6) Arma dataframe de salida con metadatos del catálogo + score\n",
    "    out = pd.DataFrame({\n",
    "        \"nombre_sitio\": X[\"nombre_sitio\"].values,\n",
    "        \"tipo_sitio\":   X[\"tipo_sitio\"].values,\n",
    "        \"ubicacion_geografica\": X.get(\"ubicacion_geografica\", pd.Series([\"\"]*len(X))).values,\n",
    "        \"costo_entrada\": pd.to_numeric(X.get(\"costo_entrada\", pd.Series([0]*len(X))), errors=\"coerce\"),\n",
    "        \"admite_mascotas\": pd.to_numeric(X.get(\"admite_mascotas\", pd.Series([0]*len(X))), errors=\"coerce\"),\n",
    "        \"idioma_info\": X.get(\"idioma_info\", pd.Series([\"\"]*len(X))).values,\n",
    "        \"score_like\": preds[score_col].astype(float).values\n",
    "    })\n",
    "\n",
    "    # 7) Orden inicial por score y re-ranking diversificado\n",
    "    out = out.sort_values(\"score_like\", ascending=False).reset_index(drop=True)\n",
    "    out_div = _mmr_diversify(out, score_col=\"score_like\", tipo_col=\"tipo_sitio\",\n",
    "                             top_n=top_n, lam=diversity_lambda)\n",
    "\n",
    "    # 8) Formatea\n",
    "    out_div = out_div.copy()\n",
    "    out_div[\"score_like\"] = out_div[\"score_like\"].round(4)\n",
    "    return out_div.reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Ejemplo de simulación con 2 perfiles\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Perfil 1: turista cultural en pareja, presupuesto medio, visita en temporada seca\n",
    "usuario_cultural = {\n",
    "    \"id_usuario\": \"SIMU-001\",\n",
    "    \"nacionalidad\": \"Colombia\",\n",
    "    \"origen\": \"Bogota\",\n",
    "    \"tipo_turista_preferido\": \"cultural\",\n",
    "    \"compania_viaje\": \"pareja\",\n",
    "    \"restricciones_movilidad\": \"ninguna\",\n",
    "    \"epoca_visita\": \"temporada_seca\",\n",
    "    \"presupuesto_estimado\": 250000,     # COP totales del viaje (ajusta a tu definición)\n",
    "    \"frecuencia_viaje\": 3,\n",
    "    \"sitios_visitados\": 5,\n",
    "    \"calificacion_sitios_previos\": 4.2,\n",
    "    \"tiempo_estancia_promedio\": 2,      # días\n",
    "    \"edad\": 28,\n",
    "    \"admite_mascotas\": 0\n",
    "}\n",
    "\n",
    "# Perfil 2: naturaleza/aventura en familia, bajo costo, visita en festivos\n",
    "usuario_naturaleza = {\n",
    "    \"id_usuario\": \"SIMU-002\",\n",
    "    \"nacionalidad\": \"Colombia\",\n",
    "    \"origen\": \"Tunja\",\n",
    "    \"tipo_turista_preferido\": \"naturaleza\",\n",
    "    \"compania_viaje\": \"familia\",\n",
    "    \"restricciones_movilidad\": \"ninguna\",\n",
    "    \"epoca_visita\": \"puente_festivo\",\n",
    "    \"presupuesto_estimado\": 120000,\n",
    "    \"frecuencia_viaje\": 1,\n",
    "    \"sitios_visitados\": 2,\n",
    "    \"calificacion_sitios_previos\": 3.8,\n",
    "    \"tiempo_estancia_promedio\": 1,\n",
    "    \"edad\": 36,\n",
    "    \"admite_mascotas\": 1\n",
    "}\n",
    "\n",
    "print(\"\\n=== Recomendaciones para PERFIL 1 (cultural, pareja) ===\")\n",
    "print(recommend_for_user(usuario_cultural, top_n=TOP_N, diversity_lambda=DIVERSITY_LAMBDA))\n",
    "\n",
    "print(\"\\n=== Recomendaciones para PERFIL 2 (naturaleza, familia) ===\")\n",
    "print(recommend_for_user(usuario_naturaleza, top_n=TOP_N, diversity_lambda=DIVERSITY_LAMBDA))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e547f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_74b2c th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_74b2c_row0_col0, #T_74b2c_row0_col3, #T_74b2c_row0_col4, #T_74b2c_row0_col5, #T_74b2c_row1_col0, #T_74b2c_row1_col1, #T_74b2c_row1_col2, #T_74b2c_row1_col4, #T_74b2c_row1_col5, #T_74b2c_row1_col6, #T_74b2c_row1_col7, #T_74b2c_row2_col0, #T_74b2c_row2_col1, #T_74b2c_row2_col2, #T_74b2c_row2_col3, #T_74b2c_row2_col4, #T_74b2c_row2_col5, #T_74b2c_row2_col6, #T_74b2c_row2_col7, #T_74b2c_row3_col0, #T_74b2c_row3_col1, #T_74b2c_row3_col2, #T_74b2c_row3_col3, #T_74b2c_row3_col4, #T_74b2c_row3_col5, #T_74b2c_row3_col6, #T_74b2c_row3_col7, #T_74b2c_row4_col0, #T_74b2c_row4_col1, #T_74b2c_row4_col2, #T_74b2c_row4_col3, #T_74b2c_row4_col4, #T_74b2c_row4_col6, #T_74b2c_row4_col7, #T_74b2c_row5_col0, #T_74b2c_row5_col1, #T_74b2c_row5_col2, #T_74b2c_row5_col3, #T_74b2c_row5_col4, #T_74b2c_row5_col5, #T_74b2c_row5_col6, #T_74b2c_row5_col7, #T_74b2c_row6_col0, #T_74b2c_row6_col1, #T_74b2c_row6_col2, #T_74b2c_row6_col3, #T_74b2c_row6_col4, #T_74b2c_row6_col5, #T_74b2c_row6_col6, #T_74b2c_row6_col7, #T_74b2c_row7_col0, #T_74b2c_row7_col1, #T_74b2c_row7_col2, #T_74b2c_row7_col3, #T_74b2c_row7_col4, #T_74b2c_row7_col5, #T_74b2c_row7_col6, #T_74b2c_row7_col7, #T_74b2c_row8_col0, #T_74b2c_row8_col1, #T_74b2c_row8_col2, #T_74b2c_row8_col3, #T_74b2c_row8_col5, #T_74b2c_row8_col6, #T_74b2c_row8_col7, #T_74b2c_row9_col0, #T_74b2c_row9_col1, #T_74b2c_row9_col2, #T_74b2c_row9_col3, #T_74b2c_row9_col4, #T_74b2c_row9_col5, #T_74b2c_row9_col6, #T_74b2c_row9_col7, #T_74b2c_row10_col0, #T_74b2c_row10_col1, #T_74b2c_row10_col2, #T_74b2c_row10_col3, #T_74b2c_row10_col4, #T_74b2c_row10_col5, #T_74b2c_row10_col6, #T_74b2c_row10_col7, #T_74b2c_row11_col0, #T_74b2c_row11_col1, #T_74b2c_row11_col2, #T_74b2c_row11_col3, #T_74b2c_row11_col4, #T_74b2c_row11_col5, #T_74b2c_row11_col6, #T_74b2c_row11_col7, #T_74b2c_row12_col0, #T_74b2c_row12_col1, #T_74b2c_row12_col2, #T_74b2c_row12_col3, #T_74b2c_row12_col4, #T_74b2c_row12_col5, #T_74b2c_row12_col6, #T_74b2c_row12_col7, #T_74b2c_row13_col0, #T_74b2c_row13_col1, #T_74b2c_row13_col2, #T_74b2c_row13_col3, #T_74b2c_row13_col4, #T_74b2c_row13_col5, #T_74b2c_row13_col6, #T_74b2c_row13_col7, #T_74b2c_row14_col0, #T_74b2c_row14_col1, #T_74b2c_row14_col2, #T_74b2c_row14_col3, #T_74b2c_row14_col4, #T_74b2c_row14_col5, #T_74b2c_row14_col6, #T_74b2c_row14_col7, #T_74b2c_row15_col0, #T_74b2c_row15_col1, #T_74b2c_row15_col2, #T_74b2c_row15_col3, #T_74b2c_row15_col4, #T_74b2c_row15_col5, #T_74b2c_row15_col6, #T_74b2c_row15_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_74b2c_row0_col1, #T_74b2c_row0_col2, #T_74b2c_row0_col6, #T_74b2c_row0_col7, #T_74b2c_row1_col3, #T_74b2c_row4_col5, #T_74b2c_row8_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_74b2c_row0_col8, #T_74b2c_row1_col8, #T_74b2c_row2_col8, #T_74b2c_row3_col8, #T_74b2c_row4_col8, #T_74b2c_row5_col8, #T_74b2c_row6_col8, #T_74b2c_row7_col8, #T_74b2c_row8_col8, #T_74b2c_row9_col8, #T_74b2c_row10_col8, #T_74b2c_row11_col8, #T_74b2c_row12_col8, #T_74b2c_row13_col8, #T_74b2c_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_74b2c_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_74b2c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_74b2c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_74b2c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_74b2c_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_74b2c_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_74b2c_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_74b2c_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_74b2c_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_74b2c_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_74b2c_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row0\" class=\"row_heading level0 row0\" >gbc</th>\n",
       "      <td id=\"T_74b2c_row0_col0\" class=\"data row0 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_74b2c_row0_col1\" class=\"data row0 col1\" >0.8495</td>\n",
       "      <td id=\"T_74b2c_row0_col2\" class=\"data row0 col2\" >0.9223</td>\n",
       "      <td id=\"T_74b2c_row0_col3\" class=\"data row0 col3\" >0.7571</td>\n",
       "      <td id=\"T_74b2c_row0_col4\" class=\"data row0 col4\" >0.7831</td>\n",
       "      <td id=\"T_74b2c_row0_col5\" class=\"data row0 col5\" >0.7699</td>\n",
       "      <td id=\"T_74b2c_row0_col6\" class=\"data row0 col6\" >0.6581</td>\n",
       "      <td id=\"T_74b2c_row0_col7\" class=\"data row0 col7\" >0.6583</td>\n",
       "      <td id=\"T_74b2c_row0_col8\" class=\"data row0 col8\" >29.2380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row1\" class=\"row_heading level0 row1\" >ridge</th>\n",
       "      <td id=\"T_74b2c_row1_col0\" class=\"data row1 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_74b2c_row1_col1\" class=\"data row1 col1\" >0.8309</td>\n",
       "      <td id=\"T_74b2c_row1_col2\" class=\"data row1 col2\" >0.9217</td>\n",
       "      <td id=\"T_74b2c_row1_col3\" class=\"data row1 col3\" >0.8554</td>\n",
       "      <td id=\"T_74b2c_row1_col4\" class=\"data row1 col4\" >0.7016</td>\n",
       "      <td id=\"T_74b2c_row1_col5\" class=\"data row1 col5\" >0.7709</td>\n",
       "      <td id=\"T_74b2c_row1_col6\" class=\"data row1 col6\" >0.6389</td>\n",
       "      <td id=\"T_74b2c_row1_col7\" class=\"data row1 col7\" >0.6468</td>\n",
       "      <td id=\"T_74b2c_row1_col8\" class=\"data row1 col8\" >3.9680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row2\" class=\"row_heading level0 row2\" >lda</th>\n",
       "      <td id=\"T_74b2c_row2_col0\" class=\"data row2 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_74b2c_row2_col1\" class=\"data row2 col1\" >0.8307</td>\n",
       "      <td id=\"T_74b2c_row2_col2\" class=\"data row2 col2\" >0.9216</td>\n",
       "      <td id=\"T_74b2c_row2_col3\" class=\"data row2 col3\" >0.8552</td>\n",
       "      <td id=\"T_74b2c_row2_col4\" class=\"data row2 col4\" >0.7014</td>\n",
       "      <td id=\"T_74b2c_row2_col5\" class=\"data row2 col5\" >0.7707</td>\n",
       "      <td id=\"T_74b2c_row2_col6\" class=\"data row2 col6\" >0.6386</td>\n",
       "      <td id=\"T_74b2c_row2_col7\" class=\"data row2 col7\" >0.6465</td>\n",
       "      <td id=\"T_74b2c_row2_col8\" class=\"data row2 col8\" >4.7040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row3\" class=\"row_heading level0 row3\" >lightgbm</th>\n",
       "      <td id=\"T_74b2c_row3_col0\" class=\"data row3 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_74b2c_row3_col1\" class=\"data row3 col1\" >0.8481</td>\n",
       "      <td id=\"T_74b2c_row3_col2\" class=\"data row3 col2\" >0.9215</td>\n",
       "      <td id=\"T_74b2c_row3_col3\" class=\"data row3 col3\" >0.7458</td>\n",
       "      <td id=\"T_74b2c_row3_col4\" class=\"data row3 col4\" >0.7866</td>\n",
       "      <td id=\"T_74b2c_row3_col5\" class=\"data row3 col5\" >0.7656</td>\n",
       "      <td id=\"T_74b2c_row3_col6\" class=\"data row3 col6\" >0.6534</td>\n",
       "      <td id=\"T_74b2c_row3_col7\" class=\"data row3 col7\" >0.6539</td>\n",
       "      <td id=\"T_74b2c_row3_col8\" class=\"data row3 col8\" >5.2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "      <td id=\"T_74b2c_row4_col0\" class=\"data row4 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_74b2c_row4_col1\" class=\"data row4 col1\" >0.8394</td>\n",
       "      <td id=\"T_74b2c_row4_col2\" class=\"data row4 col2\" >0.9193</td>\n",
       "      <td id=\"T_74b2c_row4_col3\" class=\"data row4 col3\" >0.8177</td>\n",
       "      <td id=\"T_74b2c_row4_col4\" class=\"data row4 col4\" >0.7313</td>\n",
       "      <td id=\"T_74b2c_row4_col5\" class=\"data row4 col5\" >0.7721</td>\n",
       "      <td id=\"T_74b2c_row4_col6\" class=\"data row4 col6\" >0.6487</td>\n",
       "      <td id=\"T_74b2c_row4_col7\" class=\"data row4 col7\" >0.6511</td>\n",
       "      <td id=\"T_74b2c_row4_col8\" class=\"data row4 col8\" >10.9320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row5\" class=\"row_heading level0 row5\" >catboost</th>\n",
       "      <td id=\"T_74b2c_row5_col0\" class=\"data row5 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_74b2c_row5_col1\" class=\"data row5 col1\" >0.8463</td>\n",
       "      <td id=\"T_74b2c_row5_col2\" class=\"data row5 col2\" >0.9192</td>\n",
       "      <td id=\"T_74b2c_row5_col3\" class=\"data row5 col3\" >0.7430</td>\n",
       "      <td id=\"T_74b2c_row5_col4\" class=\"data row5 col4\" >0.7838</td>\n",
       "      <td id=\"T_74b2c_row5_col5\" class=\"data row5 col5\" >0.7628</td>\n",
       "      <td id=\"T_74b2c_row5_col6\" class=\"data row5 col6\" >0.6493</td>\n",
       "      <td id=\"T_74b2c_row5_col7\" class=\"data row5 col7\" >0.6498</td>\n",
       "      <td id=\"T_74b2c_row5_col8\" class=\"data row5 col8\" >101.5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row6\" class=\"row_heading level0 row6\" >xgboost</th>\n",
       "      <td id=\"T_74b2c_row6_col0\" class=\"data row6 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_74b2c_row6_col1\" class=\"data row6 col1\" >0.8425</td>\n",
       "      <td id=\"T_74b2c_row6_col2\" class=\"data row6 col2\" >0.9158</td>\n",
       "      <td id=\"T_74b2c_row6_col3\" class=\"data row6 col3\" >0.7358</td>\n",
       "      <td id=\"T_74b2c_row6_col4\" class=\"data row6 col4\" >0.7786</td>\n",
       "      <td id=\"T_74b2c_row6_col5\" class=\"data row6 col5\" >0.7565</td>\n",
       "      <td id=\"T_74b2c_row6_col6\" class=\"data row6 col6\" >0.6403</td>\n",
       "      <td id=\"T_74b2c_row6_col7\" class=\"data row6 col7\" >0.6409</td>\n",
       "      <td id=\"T_74b2c_row6_col8\" class=\"data row6 col8\" >7.9940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row7\" class=\"row_heading level0 row7\" >rf</th>\n",
       "      <td id=\"T_74b2c_row7_col0\" class=\"data row7 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_74b2c_row7_col1\" class=\"data row7 col1\" >0.8447</td>\n",
       "      <td id=\"T_74b2c_row7_col2\" class=\"data row7 col2\" >0.9082</td>\n",
       "      <td id=\"T_74b2c_row7_col3\" class=\"data row7 col3\" >0.7506</td>\n",
       "      <td id=\"T_74b2c_row7_col4\" class=\"data row7 col4\" >0.7753</td>\n",
       "      <td id=\"T_74b2c_row7_col5\" class=\"data row7 col5\" >0.7627</td>\n",
       "      <td id=\"T_74b2c_row7_col6\" class=\"data row7 col6\" >0.6473</td>\n",
       "      <td id=\"T_74b2c_row7_col7\" class=\"data row7 col7\" >0.6475</td>\n",
       "      <td id=\"T_74b2c_row7_col8\" class=\"data row7 col8\" >17.3760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row8\" class=\"row_heading level0 row8\" >et</th>\n",
       "      <td id=\"T_74b2c_row8_col0\" class=\"data row8 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_74b2c_row8_col1\" class=\"data row8 col1\" >0.8318</td>\n",
       "      <td id=\"T_74b2c_row8_col2\" class=\"data row8 col2\" >0.9010</td>\n",
       "      <td id=\"T_74b2c_row8_col3\" class=\"data row8 col3\" >0.6568</td>\n",
       "      <td id=\"T_74b2c_row8_col4\" class=\"data row8 col4\" >0.8018</td>\n",
       "      <td id=\"T_74b2c_row8_col5\" class=\"data row8 col5\" >0.7220</td>\n",
       "      <td id=\"T_74b2c_row8_col6\" class=\"data row8 col6\" >0.6031</td>\n",
       "      <td id=\"T_74b2c_row8_col7\" class=\"data row8 col7\" >0.6094</td>\n",
       "      <td id=\"T_74b2c_row8_col8\" class=\"data row8 col8\" >20.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row9\" class=\"row_heading level0 row9\" >lr</th>\n",
       "      <td id=\"T_74b2c_row9_col0\" class=\"data row9 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_74b2c_row9_col1\" class=\"data row9 col1\" >0.7261</td>\n",
       "      <td id=\"T_74b2c_row9_col2\" class=\"data row9 col2\" >0.8166</td>\n",
       "      <td id=\"T_74b2c_row9_col3\" class=\"data row9 col3\" >0.7688</td>\n",
       "      <td id=\"T_74b2c_row9_col4\" class=\"data row9 col4\" >0.5649</td>\n",
       "      <td id=\"T_74b2c_row9_col5\" class=\"data row9 col5\" >0.6512</td>\n",
       "      <td id=\"T_74b2c_row9_col6\" class=\"data row9 col6\" >0.4343</td>\n",
       "      <td id=\"T_74b2c_row9_col7\" class=\"data row9 col7\" >0.4483</td>\n",
       "      <td id=\"T_74b2c_row9_col8\" class=\"data row9 col8\" >12.4040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_74b2c_row10_col0\" class=\"data row10 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_74b2c_row10_col1\" class=\"data row10 col1\" >0.7815</td>\n",
       "      <td id=\"T_74b2c_row10_col2\" class=\"data row10 col2\" >0.7561</td>\n",
       "      <td id=\"T_74b2c_row10_col3\" class=\"data row10 col3\" >0.6802</td>\n",
       "      <td id=\"T_74b2c_row10_col4\" class=\"data row10 col4\" >0.6688</td>\n",
       "      <td id=\"T_74b2c_row10_col5\" class=\"data row10 col5\" >0.6744</td>\n",
       "      <td id=\"T_74b2c_row10_col6\" class=\"data row10 col6\" >0.5101</td>\n",
       "      <td id=\"T_74b2c_row10_col7\" class=\"data row10 col7\" >0.5101</td>\n",
       "      <td id=\"T_74b2c_row10_col8\" class=\"data row10 col8\" >5.0860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row11\" class=\"row_heading level0 row11\" >nb</th>\n",
       "      <td id=\"T_74b2c_row11_col0\" class=\"data row11 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_74b2c_row11_col1\" class=\"data row11 col1\" >0.4586</td>\n",
       "      <td id=\"T_74b2c_row11_col2\" class=\"data row11 col2\" >0.5784</td>\n",
       "      <td id=\"T_74b2c_row11_col3\" class=\"data row11 col3\" >0.7541</td>\n",
       "      <td id=\"T_74b2c_row11_col4\" class=\"data row11 col4\" >0.3532</td>\n",
       "      <td id=\"T_74b2c_row11_col5\" class=\"data row11 col5\" >0.4810</td>\n",
       "      <td id=\"T_74b2c_row11_col6\" class=\"data row11 col6\" >0.0510</td>\n",
       "      <td id=\"T_74b2c_row11_col7\" class=\"data row11 col7\" >0.0678</td>\n",
       "      <td id=\"T_74b2c_row11_col8\" class=\"data row11 col8\" >3.8480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n",
       "      <td id=\"T_74b2c_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_74b2c_row12_col1\" class=\"data row12 col1\" >0.5236</td>\n",
       "      <td id=\"T_74b2c_row12_col2\" class=\"data row12 col2\" >0.5077</td>\n",
       "      <td id=\"T_74b2c_row12_col3\" class=\"data row12 col3\" >0.4556</td>\n",
       "      <td id=\"T_74b2c_row12_col4\" class=\"data row12 col4\" >0.3392</td>\n",
       "      <td id=\"T_74b2c_row12_col5\" class=\"data row12 col5\" >0.3888</td>\n",
       "      <td id=\"T_74b2c_row12_col6\" class=\"data row12 col6\" >0.0121</td>\n",
       "      <td id=\"T_74b2c_row12_col7\" class=\"data row12 col7\" >0.0125</td>\n",
       "      <td id=\"T_74b2c_row12_col8\" class=\"data row12 col8\" >7.2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row13\" class=\"row_heading level0 row13\" >svm</th>\n",
       "      <td id=\"T_74b2c_row13_col0\" class=\"data row13 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_74b2c_row13_col1\" class=\"data row13 col1\" >0.5952</td>\n",
       "      <td id=\"T_74b2c_row13_col2\" class=\"data row13 col2\" >0.5062</td>\n",
       "      <td id=\"T_74b2c_row13_col3\" class=\"data row13 col3\" >0.2162</td>\n",
       "      <td id=\"T_74b2c_row13_col4\" class=\"data row13 col4\" >0.1359</td>\n",
       "      <td id=\"T_74b2c_row13_col5\" class=\"data row13 col5\" >0.1258</td>\n",
       "      <td id=\"T_74b2c_row13_col6\" class=\"data row13 col6\" >0.0014</td>\n",
       "      <td id=\"T_74b2c_row13_col7\" class=\"data row13 col7\" >0.0021</td>\n",
       "      <td id=\"T_74b2c_row13_col8\" class=\"data row13 col8\" >13.3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n",
       "      <td id=\"T_74b2c_row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_74b2c_row14_col1\" class=\"data row14 col1\" >0.4619</td>\n",
       "      <td id=\"T_74b2c_row14_col2\" class=\"data row14 col2\" >0.5042</td>\n",
       "      <td id=\"T_74b2c_row14_col3\" class=\"data row14 col3\" >0.6288</td>\n",
       "      <td id=\"T_74b2c_row14_col4\" class=\"data row14 col4\" >0.3383</td>\n",
       "      <td id=\"T_74b2c_row14_col5\" class=\"data row14 col5\" >0.3984</td>\n",
       "      <td id=\"T_74b2c_row14_col6\" class=\"data row14 col6\" >0.0074</td>\n",
       "      <td id=\"T_74b2c_row14_col7\" class=\"data row14 col7\" >0.0130</td>\n",
       "      <td id=\"T_74b2c_row14_col8\" class=\"data row14 col8\" >4.6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74b2c_level0_row15\" class=\"row_heading level0 row15\" >dummy</th>\n",
       "      <td id=\"T_74b2c_row15_col0\" class=\"data row15 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_74b2c_row15_col1\" class=\"data row15 col1\" >0.6674</td>\n",
       "      <td id=\"T_74b2c_row15_col2\" class=\"data row15 col2\" >0.5000</td>\n",
       "      <td id=\"T_74b2c_row15_col3\" class=\"data row15 col3\" >0.0000</td>\n",
       "      <td id=\"T_74b2c_row15_col4\" class=\"data row15 col4\" >0.0000</td>\n",
       "      <td id=\"T_74b2c_row15_col5\" class=\"data row15 col5\" >0.0000</td>\n",
       "      <td id=\"T_74b2c_row15_col6\" class=\"data row15 col6\" >0.0000</td>\n",
       "      <td id=\"T_74b2c_row15_col7\" class=\"data row15 col7\" >0.0000</td>\n",
       "      <td id=\"T_74b2c_row15_col8\" class=\"data row15 col8\" >3.6320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2047335a910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_15f81_row5_col0, #T_15f81_row5_col1, #T_15f81_row5_col2, #T_15f81_row5_col3, #T_15f81_row5_col4, #T_15f81_row5_col5, #T_15f81_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_15f81\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_15f81_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_15f81_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_15f81_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_15f81_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_15f81_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_15f81_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_15f81_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_15f81_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_15f81_row0_col0\" class=\"data row0 col0\" >0.8498</td>\n",
       "      <td id=\"T_15f81_row0_col1\" class=\"data row0 col1\" >0.9239</td>\n",
       "      <td id=\"T_15f81_row0_col2\" class=\"data row0 col2\" >0.7765</td>\n",
       "      <td id=\"T_15f81_row0_col3\" class=\"data row0 col3\" >0.7744</td>\n",
       "      <td id=\"T_15f81_row0_col4\" class=\"data row0 col4\" >0.7754</td>\n",
       "      <td id=\"T_15f81_row0_col5\" class=\"data row0 col5\" >0.6626</td>\n",
       "      <td id=\"T_15f81_row0_col6\" class=\"data row0 col6\" >0.6626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15f81_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_15f81_row1_col0\" class=\"data row1 col0\" >0.8435</td>\n",
       "      <td id=\"T_15f81_row1_col1\" class=\"data row1 col1\" >0.9156</td>\n",
       "      <td id=\"T_15f81_row1_col2\" class=\"data row1 col2\" >0.7563</td>\n",
       "      <td id=\"T_15f81_row1_col3\" class=\"data row1 col3\" >0.7677</td>\n",
       "      <td id=\"T_15f81_row1_col4\" class=\"data row1 col4\" >0.7620</td>\n",
       "      <td id=\"T_15f81_row1_col5\" class=\"data row1 col5\" >0.6454</td>\n",
       "      <td id=\"T_15f81_row1_col6\" class=\"data row1 col6\" >0.6455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15f81_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_15f81_row2_col0\" class=\"data row2 col0\" >0.8498</td>\n",
       "      <td id=\"T_15f81_row2_col1\" class=\"data row2 col1\" >0.9244</td>\n",
       "      <td id=\"T_15f81_row2_col2\" class=\"data row2 col2\" >0.7478</td>\n",
       "      <td id=\"T_15f81_row2_col3\" class=\"data row2 col3\" >0.7873</td>\n",
       "      <td id=\"T_15f81_row2_col4\" class=\"data row2 col4\" >0.7670</td>\n",
       "      <td id=\"T_15f81_row2_col5\" class=\"data row2 col5\" >0.6563</td>\n",
       "      <td id=\"T_15f81_row2_col6\" class=\"data row2 col6\" >0.6568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15f81_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_15f81_row3_col0\" class=\"data row3 col0\" >0.8494</td>\n",
       "      <td id=\"T_15f81_row3_col1\" class=\"data row3 col1\" >0.9241</td>\n",
       "      <td id=\"T_15f81_row3_col2\" class=\"data row3 col2\" >0.7755</td>\n",
       "      <td id=\"T_15f81_row3_col3\" class=\"data row3 col3\" >0.7761</td>\n",
       "      <td id=\"T_15f81_row3_col4\" class=\"data row3 col4\" >0.7758</td>\n",
       "      <td id=\"T_15f81_row3_col5\" class=\"data row3 col5\" >0.6624</td>\n",
       "      <td id=\"T_15f81_row3_col6\" class=\"data row3 col6\" >0.6624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15f81_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_15f81_row4_col0\" class=\"data row4 col0\" >0.8497</td>\n",
       "      <td id=\"T_15f81_row4_col1\" class=\"data row4 col1\" >0.9191</td>\n",
       "      <td id=\"T_15f81_row4_col2\" class=\"data row4 col2\" >0.7565</td>\n",
       "      <td id=\"T_15f81_row4_col3\" class=\"data row4 col3\" >0.7828</td>\n",
       "      <td id=\"T_15f81_row4_col4\" class=\"data row4 col4\" >0.7694</td>\n",
       "      <td id=\"T_15f81_row4_col5\" class=\"data row4 col5\" >0.6580</td>\n",
       "      <td id=\"T_15f81_row4_col6\" class=\"data row4 col6\" >0.6582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15f81_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_15f81_row5_col0\" class=\"data row5 col0\" >0.8485</td>\n",
       "      <td id=\"T_15f81_row5_col1\" class=\"data row5 col1\" >0.9214</td>\n",
       "      <td id=\"T_15f81_row5_col2\" class=\"data row5 col2\" >0.7625</td>\n",
       "      <td id=\"T_15f81_row5_col3\" class=\"data row5 col3\" >0.7777</td>\n",
       "      <td id=\"T_15f81_row5_col4\" class=\"data row5 col4\" >0.7699</td>\n",
       "      <td id=\"T_15f81_row5_col5\" class=\"data row5 col5\" >0.6570</td>\n",
       "      <td id=\"T_15f81_row5_col6\" class=\"data row5 col6\" >0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15f81_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_15f81_row6_col0\" class=\"data row6 col0\" >0.0025</td>\n",
       "      <td id=\"T_15f81_row6_col1\" class=\"data row6 col1\" >0.0035</td>\n",
       "      <td id=\"T_15f81_row6_col2\" class=\"data row6 col2\" >0.0115</td>\n",
       "      <td id=\"T_15f81_row6_col3\" class=\"data row6 col3\" >0.0068</td>\n",
       "      <td id=\"T_15f81_row6_col4\" class=\"data row6 col4\" >0.0052</td>\n",
       "      <td id=\"T_15f81_row6_col5\" class=\"data row6 col5\" >0.0063</td>\n",
       "      <td id=\"T_15f81_row6_col6\" class=\"data row6 col6\" >0.0063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x204733d7d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c42be_row5_col0, #T_c42be_row5_col1, #T_c42be_row5_col2, #T_c42be_row5_col3, #T_c42be_row5_col4, #T_c42be_row5_col5, #T_c42be_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c42be\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c42be_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_c42be_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_c42be_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_c42be_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_c42be_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_c42be_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_c42be_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c42be_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c42be_row0_col0\" class=\"data row0 col0\" >0.8299</td>\n",
       "      <td id=\"T_c42be_row0_col1\" class=\"data row0 col1\" >0.9241</td>\n",
       "      <td id=\"T_c42be_row0_col2\" class=\"data row0 col2\" >0.8676</td>\n",
       "      <td id=\"T_c42be_row0_col3\" class=\"data row0 col3\" >0.6971</td>\n",
       "      <td id=\"T_c42be_row0_col4\" class=\"data row0 col4\" >0.7731</td>\n",
       "      <td id=\"T_c42be_row0_col5\" class=\"data row0 col5\" >0.6396</td>\n",
       "      <td id=\"T_c42be_row0_col6\" class=\"data row0 col6\" >0.6494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c42be_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c42be_row1_col0\" class=\"data row1 col0\" >0.8264</td>\n",
       "      <td id=\"T_c42be_row1_col1\" class=\"data row1 col1\" >0.9168</td>\n",
       "      <td id=\"T_c42be_row1_col2\" class=\"data row1 col2\" >0.8407</td>\n",
       "      <td id=\"T_c42be_row1_col3\" class=\"data row1 col3\" >0.6975</td>\n",
       "      <td id=\"T_c42be_row1_col4\" class=\"data row1 col4\" >0.7624</td>\n",
       "      <td id=\"T_c42be_row1_col5\" class=\"data row1 col5\" >0.6276</td>\n",
       "      <td id=\"T_c42be_row1_col6\" class=\"data row1 col6\" >0.6344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c42be_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c42be_row2_col0\" class=\"data row2 col0\" >0.8348</td>\n",
       "      <td id=\"T_c42be_row2_col1\" class=\"data row2 col1\" >0.9253</td>\n",
       "      <td id=\"T_c42be_row2_col2\" class=\"data row2 col2\" >0.8609</td>\n",
       "      <td id=\"T_c42be_row2_col3\" class=\"data row2 col3\" >0.7048</td>\n",
       "      <td id=\"T_c42be_row2_col4\" class=\"data row2 col4\" >0.7751</td>\n",
       "      <td id=\"T_c42be_row2_col5\" class=\"data row2 col5\" >0.6466</td>\n",
       "      <td id=\"T_c42be_row2_col6\" class=\"data row2 col6\" >0.6547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c42be_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c42be_row3_col0\" class=\"data row3 col0\" >0.8298</td>\n",
       "      <td id=\"T_c42be_row3_col1\" class=\"data row3 col1\" >0.9245</td>\n",
       "      <td id=\"T_c42be_row3_col2\" class=\"data row3 col2\" >0.8621</td>\n",
       "      <td id=\"T_c42be_row3_col3\" class=\"data row3 col3\" >0.7006</td>\n",
       "      <td id=\"T_c42be_row3_col4\" class=\"data row3 col4\" >0.7730</td>\n",
       "      <td id=\"T_c42be_row3_col5\" class=\"data row3 col5\" >0.6392</td>\n",
       "      <td id=\"T_c42be_row3_col6\" class=\"data row3 col6\" >0.6480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c42be_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c42be_row4_col0\" class=\"data row4 col0\" >0.8314</td>\n",
       "      <td id=\"T_c42be_row4_col1\" class=\"data row4 col1\" >0.9195</td>\n",
       "      <td id=\"T_c42be_row4_col2\" class=\"data row4 col2\" >0.8502</td>\n",
       "      <td id=\"T_c42be_row4_col3\" class=\"data row4 col3\" >0.7032</td>\n",
       "      <td id=\"T_c42be_row4_col4\" class=\"data row4 col4\" >0.7698</td>\n",
       "      <td id=\"T_c42be_row4_col5\" class=\"data row4 col5\" >0.6387</td>\n",
       "      <td id=\"T_c42be_row4_col6\" class=\"data row4 col6\" >0.6458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c42be_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_c42be_row5_col0\" class=\"data row5 col0\" >0.8305</td>\n",
       "      <td id=\"T_c42be_row5_col1\" class=\"data row5 col1\" >0.9220</td>\n",
       "      <td id=\"T_c42be_row5_col2\" class=\"data row5 col2\" >0.8563</td>\n",
       "      <td id=\"T_c42be_row5_col3\" class=\"data row5 col3\" >0.7006</td>\n",
       "      <td id=\"T_c42be_row5_col4\" class=\"data row5 col4\" >0.7707</td>\n",
       "      <td id=\"T_c42be_row5_col5\" class=\"data row5 col5\" >0.6383</td>\n",
       "      <td id=\"T_c42be_row5_col6\" class=\"data row5 col6\" >0.6465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c42be_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_c42be_row6_col0\" class=\"data row6 col0\" >0.0027</td>\n",
       "      <td id=\"T_c42be_row6_col1\" class=\"data row6 col1\" >0.0033</td>\n",
       "      <td id=\"T_c42be_row6_col2\" class=\"data row6 col2\" >0.0096</td>\n",
       "      <td id=\"T_c42be_row6_col3\" class=\"data row6 col3\" >0.0031</td>\n",
       "      <td id=\"T_c42be_row6_col4\" class=\"data row6 col4\" >0.0045</td>\n",
       "      <td id=\"T_c42be_row6_col5\" class=\"data row6 col5\" >0.0061</td>\n",
       "      <td id=\"T_c42be_row6_col6\" class=\"data row6 col6\" >0.0067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20472e58850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f7237_row5_col0, #T_f7237_row5_col1, #T_f7237_row5_col2, #T_f7237_row5_col3, #T_f7237_row5_col4, #T_f7237_row5_col5, #T_f7237_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f7237\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f7237_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_f7237_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_f7237_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_f7237_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_f7237_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_f7237_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_f7237_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f7237_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f7237_row0_col0\" class=\"data row0 col0\" >0.8307</td>\n",
       "      <td id=\"T_f7237_row0_col1\" class=\"data row0 col1\" >0.9237</td>\n",
       "      <td id=\"T_f7237_row0_col2\" class=\"data row0 col2\" >0.8668</td>\n",
       "      <td id=\"T_f7237_row0_col3\" class=\"data row0 col3\" >0.6987</td>\n",
       "      <td id=\"T_f7237_row0_col4\" class=\"data row0 col4\" >0.7737</td>\n",
       "      <td id=\"T_f7237_row0_col5\" class=\"data row0 col5\" >0.6410</td>\n",
       "      <td id=\"T_f7237_row0_col6\" class=\"data row0 col6\" >0.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7237_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f7237_row1_col0\" class=\"data row1 col0\" >0.8262</td>\n",
       "      <td id=\"T_f7237_row1_col1\" class=\"data row1 col1\" >0.9166</td>\n",
       "      <td id=\"T_f7237_row1_col2\" class=\"data row1 col2\" >0.8394</td>\n",
       "      <td id=\"T_f7237_row1_col3\" class=\"data row1 col3\" >0.6974</td>\n",
       "      <td id=\"T_f7237_row1_col4\" class=\"data row1 col4\" >0.7618</td>\n",
       "      <td id=\"T_f7237_row1_col5\" class=\"data row1 col5\" >0.6268</td>\n",
       "      <td id=\"T_f7237_row1_col6\" class=\"data row1 col6\" >0.6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7237_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f7237_row2_col0\" class=\"data row2 col0\" >0.8362</td>\n",
       "      <td id=\"T_f7237_row2_col1\" class=\"data row2 col1\" >0.9251</td>\n",
       "      <td id=\"T_f7237_row2_col2\" class=\"data row2 col2\" >0.8609</td>\n",
       "      <td id=\"T_f7237_row2_col3\" class=\"data row2 col3\" >0.7072</td>\n",
       "      <td id=\"T_f7237_row2_col4\" class=\"data row2 col4\" >0.7765</td>\n",
       "      <td id=\"T_f7237_row2_col5\" class=\"data row2 col5\" >0.6491</td>\n",
       "      <td id=\"T_f7237_row2_col6\" class=\"data row2 col6\" >0.6570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7237_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f7237_row3_col0\" class=\"data row3 col0\" >0.8292</td>\n",
       "      <td id=\"T_f7237_row3_col1\" class=\"data row3 col1\" >0.9239</td>\n",
       "      <td id=\"T_f7237_row3_col2\" class=\"data row3 col2\" >0.8589</td>\n",
       "      <td id=\"T_f7237_row3_col3\" class=\"data row3 col3\" >0.7005</td>\n",
       "      <td id=\"T_f7237_row3_col4\" class=\"data row3 col4\" >0.7717</td>\n",
       "      <td id=\"T_f7237_row3_col5\" class=\"data row3 col5\" >0.6375</td>\n",
       "      <td id=\"T_f7237_row3_col6\" class=\"data row3 col6\" >0.6459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7237_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f7237_row4_col0\" class=\"data row4 col0\" >0.8315</td>\n",
       "      <td id=\"T_f7237_row4_col1\" class=\"data row4 col1\" >0.9188</td>\n",
       "      <td id=\"T_f7237_row4_col2\" class=\"data row4 col2\" >0.8513</td>\n",
       "      <td id=\"T_f7237_row4_col3\" class=\"data row4 col3\" >0.7030</td>\n",
       "      <td id=\"T_f7237_row4_col4\" class=\"data row4 col4\" >0.7701</td>\n",
       "      <td id=\"T_f7237_row4_col5\" class=\"data row4 col5\" >0.6390</td>\n",
       "      <td id=\"T_f7237_row4_col6\" class=\"data row4 col6\" >0.6463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7237_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_f7237_row5_col0\" class=\"data row5 col0\" >0.8308</td>\n",
       "      <td id=\"T_f7237_row5_col1\" class=\"data row5 col1\" >0.9216</td>\n",
       "      <td id=\"T_f7237_row5_col2\" class=\"data row5 col2\" >0.8555</td>\n",
       "      <td id=\"T_f7237_row5_col3\" class=\"data row5 col3\" >0.7014</td>\n",
       "      <td id=\"T_f7237_row5_col4\" class=\"data row5 col4\" >0.7708</td>\n",
       "      <td id=\"T_f7237_row5_col5\" class=\"data row5 col5\" >0.6387</td>\n",
       "      <td id=\"T_f7237_row5_col6\" class=\"data row5 col6\" >0.6466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7237_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_f7237_row6_col0\" class=\"data row6 col0\" >0.0033</td>\n",
       "      <td id=\"T_f7237_row6_col1\" class=\"data row6 col1\" >0.0033</td>\n",
       "      <td id=\"T_f7237_row6_col2\" class=\"data row6 col2\" >0.0095</td>\n",
       "      <td id=\"T_f7237_row6_col3\" class=\"data row6 col3\" >0.0035</td>\n",
       "      <td id=\"T_f7237_row6_col4\" class=\"data row6 col4\" >0.0050</td>\n",
       "      <td id=\"T_f7237_row6_col5\" class=\"data row6 col5\" >0.0072</td>\n",
       "      <td id=\"T_f7237_row6_col6\" class=\"data row6 col6\" >0.0077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2047335a910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_801b3_row5_col0, #T_801b3_row5_col1, #T_801b3_row5_col2, #T_801b3_row5_col3, #T_801b3_row5_col4, #T_801b3_row5_col5, #T_801b3_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_801b3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_801b3_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_801b3_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_801b3_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_801b3_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_801b3_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_801b3_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_801b3_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_801b3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_801b3_row0_col0\" class=\"data row0 col0\" >0.8325</td>\n",
       "      <td id=\"T_801b3_row0_col1\" class=\"data row0 col1\" >0.0000</td>\n",
       "      <td id=\"T_801b3_row0_col2\" class=\"data row0 col2\" >0.8620</td>\n",
       "      <td id=\"T_801b3_row0_col3\" class=\"data row0 col3\" >0.7033</td>\n",
       "      <td id=\"T_801b3_row0_col4\" class=\"data row0 col4\" >0.7746</td>\n",
       "      <td id=\"T_801b3_row0_col5\" class=\"data row0 col5\" >0.6435</td>\n",
       "      <td id=\"T_801b3_row0_col6\" class=\"data row0 col6\" >0.6520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_801b3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_801b3_row1_col0\" class=\"data row1 col0\" >0.8279</td>\n",
       "      <td id=\"T_801b3_row1_col1\" class=\"data row1 col1\" >0.0000</td>\n",
       "      <td id=\"T_801b3_row1_col2\" class=\"data row1 col2\" >0.8345</td>\n",
       "      <td id=\"T_801b3_row1_col3\" class=\"data row1 col3\" >0.7020</td>\n",
       "      <td id=\"T_801b3_row1_col4\" class=\"data row1 col4\" >0.7626</td>\n",
       "      <td id=\"T_801b3_row1_col5\" class=\"data row1 col5\" >0.6291</td>\n",
       "      <td id=\"T_801b3_row1_col6\" class=\"data row1 col6\" >0.6349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_801b3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_801b3_row2_col0\" class=\"data row2 col0\" >0.8371</td>\n",
       "      <td id=\"T_801b3_row2_col1\" class=\"data row2 col1\" >0.0000</td>\n",
       "      <td id=\"T_801b3_row2_col2\" class=\"data row2 col2\" >0.8553</td>\n",
       "      <td id=\"T_801b3_row2_col3\" class=\"data row2 col3\" >0.7109</td>\n",
       "      <td id=\"T_801b3_row2_col4\" class=\"data row2 col4\" >0.7764</td>\n",
       "      <td id=\"T_801b3_row2_col5\" class=\"data row2 col5\" >0.6500</td>\n",
       "      <td id=\"T_801b3_row2_col6\" class=\"data row2 col6\" >0.6569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_801b3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_801b3_row3_col0\" class=\"data row3 col0\" >0.8317</td>\n",
       "      <td id=\"T_801b3_row3_col1\" class=\"data row3 col1\" >0.0000</td>\n",
       "      <td id=\"T_801b3_row3_col2\" class=\"data row3 col2\" >0.8560</td>\n",
       "      <td id=\"T_801b3_row3_col3\" class=\"data row3 col3\" >0.7058</td>\n",
       "      <td id=\"T_801b3_row3_col4\" class=\"data row3 col4\" >0.7737</td>\n",
       "      <td id=\"T_801b3_row3_col5\" class=\"data row3 col5\" >0.6417</td>\n",
       "      <td id=\"T_801b3_row3_col6\" class=\"data row3 col6\" >0.6493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_801b3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_801b3_row4_col0\" class=\"data row4 col0\" >0.8329</td>\n",
       "      <td id=\"T_801b3_row4_col1\" class=\"data row4 col1\" >0.0000</td>\n",
       "      <td id=\"T_801b3_row4_col2\" class=\"data row4 col2\" >0.8470</td>\n",
       "      <td id=\"T_801b3_row4_col3\" class=\"data row4 col3\" >0.7070</td>\n",
       "      <td id=\"T_801b3_row4_col4\" class=\"data row4 col4\" >0.7707</td>\n",
       "      <td id=\"T_801b3_row4_col5\" class=\"data row4 col5\" >0.6410</td>\n",
       "      <td id=\"T_801b3_row4_col6\" class=\"data row4 col6\" >0.6474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_801b3_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_801b3_row5_col0\" class=\"data row5 col0\" >0.8324</td>\n",
       "      <td id=\"T_801b3_row5_col1\" class=\"data row5 col1\" >0.0000</td>\n",
       "      <td id=\"T_801b3_row5_col2\" class=\"data row5 col2\" >0.8510</td>\n",
       "      <td id=\"T_801b3_row5_col3\" class=\"data row5 col3\" >0.7058</td>\n",
       "      <td id=\"T_801b3_row5_col4\" class=\"data row5 col4\" >0.7716</td>\n",
       "      <td id=\"T_801b3_row5_col5\" class=\"data row5 col5\" >0.6411</td>\n",
       "      <td id=\"T_801b3_row5_col6\" class=\"data row5 col6\" >0.6481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_801b3_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_801b3_row6_col0\" class=\"data row6 col0\" >0.0030</td>\n",
       "      <td id=\"T_801b3_row6_col1\" class=\"data row6 col1\" >0.0000</td>\n",
       "      <td id=\"T_801b3_row6_col2\" class=\"data row6 col2\" >0.0095</td>\n",
       "      <td id=\"T_801b3_row6_col3\" class=\"data row6 col3\" >0.0031</td>\n",
       "      <td id=\"T_801b3_row6_col4\" class=\"data row6 col4\" >0.0049</td>\n",
       "      <td id=\"T_801b3_row6_col5\" class=\"data row6 col5\" >0.0068</td>\n",
       "      <td id=\"T_801b3_row6_col6\" class=\"data row6 col6\" >0.0073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2044e5934d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['edad', 'frecuencia_viaje',\n",
       "                                              'presupuesto_estimado',\n",
       "                                              'sitios_visitados',\n",
       "                                              'calificacion_sitios_previos',\n",
       "                                              'tiempo_estancia_promedio',\n",
       "                                              'costo_entrada',\n",
       "                                              'afluencia_promedio',\n",
       "                                              'duracion_esperada',\n",
       "                                              'admite_mascotas',\n",
       "                                              'ratio_costo_presu',\n",
       "                                              'afinidad_tipo'],\n",
       "                                     transf...\n",
       "                                                                fit_intercept=False,\n",
       "                                                                max_iter=None,\n",
       "                                                                positive=False,\n",
       "                                                                random_state=1391,\n",
       "                                                                solver='auto',\n",
       "                                                                tol=0.0001)),\n",
       "                                               ('Linear Discriminant Analysis',\n",
       "                                                LinearDiscriminantAnalysis(covariance_estimator=None,\n",
       "                                                                           n_components=None,\n",
       "                                                                           priors=None,\n",
       "                                                                           shrinkage=None,\n",
       "                                                                           solver='svd',\n",
       "                                                                           store_covariance=False,\n",
       "                                                                           tol=0.0001))],\n",
       "                                   flatten_transform=True, n_jobs=1,\n",
       "                                   verbose=False, voting='hard',\n",
       "                                   weights=None))],\n",
       "          verbose=False),\n",
       " 'modelo_cls_like_v2.pkl')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.classification import (\n",
    "    setup, compare_models, tune_model, blend_models,\n",
    "    finalize_model, predict_model, pull, save_model\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Copias profundas y tipos explícitos (evita vistas read-only)\n",
    "train_df = train_df.copy(deep=True)\n",
    "\n",
    "# Asegura que id_usuario esté como string (pero NO como feature)\n",
    "train_df[\"id_usuario\"] = train_df[\"id_usuario\"].astype(\"string\")\n",
    "\n",
    "for c in CAT_COLS_X:\n",
    "    if c in train_df.columns:\n",
    "        train_df[c] = train_df[c].astype(\"string\").copy()\n",
    "\n",
    "for c in NUM_COLS_X:\n",
    "    if c in train_df.columns:\n",
    "        train_df[c] = pd.to_numeric(train_df[c], errors=\"coerce\").astype(\"float64\").copy()\n",
    "\n",
    "# 2) Setup — sin SMOTE y sin paralelismo en la primera corrida\n",
    "setup_cls = setup(\n",
    "    data = train_df[[\"id_usuario\"] + CAT_COLS_X + NUM_COLS_X + [\"y_like\"]].copy(),\n",
    "    target = \"y_like\",\n",
    "    fold = 5,\n",
    "    fold_strategy = \"groupkfold\",\n",
    "    fold_groups = \"id_usuario\",          # usa el id para agrupar\n",
    "    categorical_features = CAT_COLS_X,\n",
    "    ignore_features = [\"id_usuario\"],     # << clave: no lo pases como feature\n",
    "    remove_multicollinearity = True,\n",
    "    multicollinearity_threshold = 0.95,\n",
    "    imputation_type = \"simple\",\n",
    "    fix_imbalance = True,                # << desactivar por ahora\n",
    "    n_jobs = 1,                           # << sin paralelismo (evita bug loky/writeable)\n",
    "    verbose = False\n",
    ")\n",
    "\n",
    "best3 = compare_models(n_select=3, sort=\"AUC\")\n",
    "tuned = [tune_model(m, optimize=\"AUC\") for m in best3]\n",
    "blend = blend_models(tuned)\n",
    "final_cls = finalize_model(blend)\n",
    "save_model(final_cls, \"modelo_cls_like_v2\")\n",
    "\n",
    "# Si esto corre OK, ya puedes volver a activar fix_imbalance=True y/o subir n_jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "villaIA_leyva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
